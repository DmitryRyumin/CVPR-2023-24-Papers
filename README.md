# CVPR-2023-Papers

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Version](https://img.shields.io/badge/version-v0.0.0-rc0)
![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/CVPR-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/README.md)
![GitHub contributors](https://img.shields.io/github/contributors/dmitryryumin/CVPR-2023-Papers)
![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/t/dmitryryumin/CVPR-2023-Papers)
![GitHub closed issues](https://img.shields.io/github/issues-closed/DmitryRyumin/CVPR-2023-Papers)
![GitHub issues](https://img.shields.io/github/issues/DmitryRyumin/CVPR-2023-Papers)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/DmitryRyumin/CVPR-2023-Papers)
![GitHub pull requests](https://img.shields.io/github/issues-pr/dmitryryumin/CVPR-2023-Papers)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/CVPR-2023-Papers)
![GitHub watchers](https://img.shields.io/github/watchers/dmitryryumin/CVPR-2023-Papers)
![GitHub forks](https://img.shields.io/github/forks/dmitryryumin/CVPR-2023-Papers)
![GitHub Repo stars](https://img.shields.io/github/stars/dmitryryumin/CVPR-2023-Papers)
<!-- ![Papers Implemented](https://badgen.net/badge/Papers%20implemented/0) -->

---

CVPR 2023 Papers: Explore a comprehensive collection of cutting-edge research papers presented at [*CVPR 2023*](https://cvpr2023.thecvf.com/), the premier computer vision conference. Keep up to date with the latest advances in computer vision and deep learning. Code implementations included. :star: the repository for the development of visual intelligence!

<p align="center">
    <a href="https://cvpr2023.thecvf.com/" target="_blank">
        <img width="600" src="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/images/CVPR2023-banner.svg" alt="CVPR 2023">
    </a>
<p>

---

Explore the [*CVPR 2023 online conference list*](https://openaccess.thecvf.com/CVPR2023?day=all) with a comprehensive collection of accepted papers. Access additional resources such as PDFs, Supplementary Material, arXiv links and BibTeX citations for in-depth exploration of the research presented.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> ***NOTE*:** Conference table will be up to date all the time.

| **Conference** | Year |
|----------------|:----:|
| ICASSP | [2023](https://github.com/DmitryRyumin/ICASSP-2023-Papers) |
| INTERSPEECH | [2023](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers) |

---

## Contributors

<a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/CVPR-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/CVPR-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/CVPR-2023-Papers/issues) or contact me via [*email*](mailto:ryumin.d@iias.spb.su)**. Your participation is crucial to making this repository even better.

---

## [Papers](https://public.tableau.com/views/CVPR2023SubjectAreasbyTeamSize/Dashboard2a?:showVizHome=no)

### 3D from Multi-View and Sensors

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|----------|:---------:|:---------:|
| NeuMap: Neural Coordinate Mapping by Auto-Transdecoder for Camera Localization | [![GitHub](https://img.shields.io/github/stars/Tangshitao/NeuMap)](https://github.com/Tangshitao/NeuMap) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_NeuMap_Neural_Coordinate_Mapping_by_Auto-Transdecoder_for_Camera_Localization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11177-b31b1b.svg)](https://arxiv.org/abs/2211.11177) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u4DGwkXuJXA) |
| Object Pose Estimation with Statistical Guarantees: Conformal Keypoint Detection and Geometric Uncertainty Propagation | [![GitHub](https://img.shields.io/github/stars/NVlabs/ConformalKeypoint)](https://github.com/NVlabs/ConformalKeypoint) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Object_Pose_Estimation_With_Statistical_Guarantees_Conformal_Keypoint_Detection_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12246-b31b1b.svg)](https://arxiv.org/abs/2303.12246) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NWUf4hd571E) |
| NeuralUDF: Learning Unsigned Distance Fields for Multi-View Reconstruction of Surfaces with Arbitrary Topologies | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.xxlong.site/NeuralUDF/) <br /> [![GitHub](https://img.shields.io/github/stars/xxlong0/NeuralUDF)](https://github.com/xxlong0/NeuralUDF) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Long_NeuralUDF_Learning_Unsigned_Distance_Fields_for_Multi-View_Reconstruction_of_Surfaces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14173-b31b1b.svg)](https://arxiv.org/abs/2211.14173) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JnaXx7qyYQY) |
| NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-View Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yunfan1202.github.io/NEF/) <br /> [![GitHub](https://img.shields.io/github/stars/yunfan1202/NEF_code)](https://github.com/yunfan1202/NEF_code) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_NEF_Neural_Edge_Fields_for_3D_Parametric_Curve_Reconstruction_From_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07653-b31b1b.svg)](https://arxiv.org/abs/2303.07653) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_F4EnZ1I_2g) |
| Looking Through the Glass: Neural Surface Reconstruction Against High Specular Reflections | [![GitHub](https://img.shields.io/github/stars/JiaxiongQ/NeuS-HSR)](https://github.com/JiaxiongQ/NeuS-HSR) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_Looking_Through_the_Glass_Neural_Surface_Reconstruction_Against_High_Specular_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08706-b31b1b.svg)](https://arxiv.org/abs/2304.08706) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lwHd-GJAmMA) |
| Multi-View Azimuth Stereo via Tangent Space Consistency | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xucao-42.github.io/mvas_homepage/) <br /> [![GitHub](https://img.shields.io/github/stars/xucao-42/mvas)](https://github.com/xucao-42/mvas) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Multi-View_Azimuth_Stereo_via_Tangent_Space_Consistency_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16447-b31b1b.svg)](https://arxiv.org/abs/2303.16447) | :heavy_minus_sign: |
| Instant Multi-View Head Capture through Learnable Registration | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://tempeh.is.tue.mpg.de/) <br /> [![GitHub](https://img.shields.io/github/stars/TimoBolkart/TEMPEH)](https://github.com/TimoBolkart/TEMPEH) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bolkart_Instant_Multi-View_Head_Capture_Through_Learnable_Registration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07437-b31b1b.svg)](https://arxiv.org/abs/2306.07437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AolpvKpmjEw) |
| EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chengwei-zheng.github.io/EditableNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/chengwei-zheng/EditableNeRF_cvpr23)](https://github.com/chengwei-zheng/EditableNeRF_cvpr23) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_EditableNeRF_Editing_Topologically_Varying_Neural_Radiance_Fields_by_Key_Points_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04247-b31b1b.svg)](https://arxiv.org/abs/2212.04247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Eu2twgbg4kI) |
| Iterative Geometry Encoding Volume for Stereo Matching | [![GitHub](https://img.shields.io/github/stars/gangweiX/IGEV)](https://github.com/gangweiX/IGEV) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Iterative_Geometry_Encoding_Volume_for_Stereo_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06615-b31b1b.svg)](https://arxiv.org/abs/2303.06615) | :heavy_minus_sign: |
| Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery from Sparse Image Ensemble | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chhankyao.github.io/hi-lassie/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Hi-LASSIE_High-Fidelity_Articulated_Shape_and_Skeleton_Discovery_From_Sparse_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.11042-b31b1b.svg)](https://arxiv.org/abs/2212.11042) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s9FWABEm0WU) |
| VDN-NeRF: Resolving Shape-Radiance Ambiguity via View-Dependence Normalization |  |  |  |
| Neuralangelo: High-Fidelity Neural Surface Reconstruction |  |  |  |
| In-Hand 3D Object Scanning from an RGB Sequence |  |  |  |
| SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation of Point Clouds |  |  |  |
| FAC: 3D Representation Learning via Foreground Aware Feature Contrast |  |  |  |
| Neural Kernel Surface Reconstruction |  |  |  |
| NeRFVS: Neural Radiance Fields for Free View Synthesis via Geometry Scaffolds |  |  |  |
| HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of Indoor Scenes with Iterative Intertwined Regularization |  |  |  |
| Multi-Space Neural Radiance Fields |  |  |  |
| MSF: Motion-guided Sequential Fusion for Efficient 3D Object Detection from Point Cloud Sequences |  |  |  |

### Image and Video Synthesis and Generation

> Will soon be added

### Humans: Face, Body, Pose, Gesture, Movement

> Will soon be added

### Transfer, Meta, Low-Shot, Continual, or Long-Tail Learning

> Will soon be added

### Recognition: Categorization, Detection, Retrieval

> Will soon be added

### Vision, Language, and Reasoning

> Will soon be added

### Low-Level Vision

> Will soon be added

### Segmentation, Grouping and Shape Analysis

> Will soon be added

### Deep Learning Architectures and Techniques

> Will soon be added

### Multi-Modal Learning

> Will soon be added

### 3D from Single Images

> Will soon be added

### Medical and Biological Vision, Cell Microscopy

> Will soon be added

### Video: Action and Event Understanding

> Will soon be added

### Autonomous Driving

> Will soon be added

### Self-Supervised or Unsupervised Representation Learning

> Will soon be added

### Datasets and Evaluation

> Will soon be added

### Scene Analysis and Understanding

> Will soon be added

### Adversarial Attack and Defense

> Will soon be added

### Efficient and Scalable Vision

> Will soon be added

### Computational Imaging

> Will soon be added

### Video: Low-Level Analysis, Motion, and Tracking

> Will soon be added

### Vision Applications and Systems

> Will soon be added

### Vision + Graphics

> Will soon be added

### Robotics

> Will soon be added

### Transparency, Fairness, Accountability, Privacy, Ethics in Vision

> Will soon be added

### Explainable Computer Vision

> Will soon be added

### Embodied Vision: Active Agents, Simulation

> Will soon be added

### Document Analysis and Understanding

> Will soon be added

### Machine Learning (other than Deep Learning)

> Will soon be added

### Physics-based Vision and Shape-from-X

> Will soon be added

### Biometrics

> Will soon be added

### Others

> Will soon be added

### Optimization Methods (other than Deep Learning)

> Will soon be added

### Photogrammetry and Remote Sensing

> Will soon be added

### Computer Vision Theory

> Will soon be added

### Computer Vision for Social Good

> Will soon be added
