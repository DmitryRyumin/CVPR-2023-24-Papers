# CVPR-2023-Papers

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
![Version](https://img.shields.io/badge/version-v0.0.0-rc0)
![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/CVPR-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/README.md)
![GitHub contributors](https://img.shields.io/github/contributors/dmitryryumin/CVPR-2023-Papers)
![GitHub commit activity (branch)](https://img.shields.io/github/commit-activity/t/dmitryryumin/CVPR-2023-Papers)
![GitHub closed issues](https://img.shields.io/github/issues-closed/DmitryRyumin/CVPR-2023-Papers)
![GitHub issues](https://img.shields.io/github/issues/DmitryRyumin/CVPR-2023-Papers)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/DmitryRyumin/CVPR-2023-Papers)
![GitHub pull requests](https://img.shields.io/github/issues-pr/dmitryryumin/CVPR-2023-Papers)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/CVPR-2023-Papers)
![GitHub watchers](https://img.shields.io/github/watchers/dmitryryumin/CVPR-2023-Papers)
![GitHub forks](https://img.shields.io/github/forks/dmitryryumin/CVPR-2023-Papers)
![GitHub Repo stars](https://img.shields.io/github/stars/dmitryryumin/CVPR-2023-Papers)
<!-- ![Papers Implemented](https://badgen.net/badge/Papers%20implemented/0) -->

---

CVPR 2023 Papers: Explore a comprehensive collection of cutting-edge research papers presented at [*CVPR 2023*](https://cvpr2023.thecvf.com/), the premier computer vision conference. Keep up to date with the latest advances in computer vision and deep learning. Code implementations included. :star: the repository for the development of visual intelligence!

<p align="center">
    <a href="https://cvpr2023.thecvf.com/" target="_blank">
        <img width="600" src="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/images/CVPR2023-banner.svg" alt="CVPR 2023">
    </a>
<p>

---

Explore the [*CVPR 2023 online conference list*](https://openaccess.thecvf.com/CVPR2023?day=all) with a comprehensive collection of accepted papers. Access additional resources such as PDFs, Supplementary Material, arXiv links and BibTeX citations for in-depth exploration of the research presented.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> ***NOTE*:** Conference table will be up to date all the time.

<table>
    <tr>
        <td><strong>Conference</strong></td>
        <td colspan="1" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
      <td colspan="2" align="center"><i>Speech (SP)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td><a href="https://github.com/DmitryRyumin/ICASSP-2023-Papers" target="_blank">2023</a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank">2023</a></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/CVPR-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/CVPR-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/CVPR-2023-Papers/issues) or contact me via [*email*](mailto:ryumin.d@iias.spb.su)**. Your participation is crucial to making this repository even better.

---

## [Papers](https://public.tableau.com/views/CVPR2023SubjectAreasbyTeamSize/Dashboard2a?:showVizHome=no)

<details open>
<summary>List of sections<a id="sections"></a></summary>

- [3D from Multi-View and Sensors](#3d-from-multi-view-and-sensors)
- [Image and Video Synthesis and Generation](#image-and-video-synthesis-and-generation)
- [Humans: Face, Body, Pose, Gesture, Movement](#humans-face-body-pose-gesture-movement)
- [Transfer, Meta, Low-Shot, Continual, or Long-Tail Learning](#transfer-meta-low-shot-continual-or-long-tail-learning)
- [Recognition: Categorization, Detection, Retrieval](#recognition-categorization-detection-retrieval)
- [Vision, Language, and Reasoning](#vision-language-and-reasoning)
- [Low-Level Vision](#low-level-vision)
- [Segmentation, Grouping and Shape Analysis](#segmentation-grouping-and-shape-analysis)
- [Deep Learning Architectures and Techniques](#deep-learning-architectures-and-techniques)
- [Multi-Modal Learning](#multi-modal-learning)
- [3D from Single Images](#3d-from-single-images)
- [Medical and Biological Vision, Cell Microscopy](#medical-and-biological-vision-cell-microscopy)
- [Video: Action and Event Understanding](#video-action-and-event-understanding)
- [Autonomous Driving](#autonomous-driving)
- [Self-Supervised or Unsupervised Representation Learning](#self-supervised-or-unsupervised-representation-learning)
- [Datasets and Evaluation](#datasets-and-evaluation)
- [Scene Analysis and Understanding](#scene-analysis-and-understanding)
- [Adversarial Attack and Defense](#adversarial-attack-and-defense)
- [Efficient and Scalable Vision](#efficient-and-scalable-vision)
- [Computational Imaging](#computational-imaging)
- [Video: Low-Level Analysis, Motion, and Tracking](#video-low-level-analysis-motion-and-tracking)
- [Vision Applications and Systems](#vision-applications-and-systems)
- [Vision and Graphics](#vision-and-graphics)
- [Robotics](#robotics)
- [Transparency, Fairness, Accountability, Privacy, Ethics in Vision](#transparency-fairness-accountability-privacy-ethics-in-vision)
- [Explainable Computer Vision](#explainable-computer-vision)
- [Embodied Vision: Active Agents, Simulation](#embodied-vision-active-agents-simulation)
- [Document Analysis and Understanding](#document-analysis-and-understanding)
- [Machine Learning (other than Deep Learning)](#machine-learning-other-than-deep-learning)
- [Physics-based Vision and Shape-from-X](#physics-based-vision-and-shape-from-x)
- [Biometrics](#biometrics)
- [Optimization Methods (other than Deep Learning)](#optimization-methods-other-than-deep-learning)
- [Photogrammetry and Remote Sensing](#photogrammetry-and-remote-sensing)
- [Computer Vision Theory](#computer-vision-theory)
- [Computer Vision for Social Good](#computer-vision-for-social-good)
- [Others](#others)

</details>

### 3D from Multi-View and Sensors

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| NeuMap: Neural Coordinate Mapping by Auto-Transdecoder for Camera Localization | [![GitHub](https://img.shields.io/github/stars/Tangshitao/NeuMap)](https://github.com/Tangshitao/NeuMap) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_NeuMap_Neural_Coordinate_Mapping_by_Auto-Transdecoder_for_Camera_Localization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11177-b31b1b.svg)](https://arxiv.org/abs/2211.11177) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u4DGwkXuJXA) |
| Object Pose Estimation with Statistical Guarantees: Conformal Keypoint Detection and Geometric Uncertainty Propagation | [![GitHub](https://img.shields.io/github/stars/NVlabs/ConformalKeypoint)](https://github.com/NVlabs/ConformalKeypoint) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Object_Pose_Estimation_With_Statistical_Guarantees_Conformal_Keypoint_Detection_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12246-b31b1b.svg)](https://arxiv.org/abs/2303.12246) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NWUf4hd571E) |
| NeuralUDF: Learning Unsigned Distance Fields for Multi-View Reconstruction of Surfaces with Arbitrary Topologies | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.xxlong.site/NeuralUDF/) <br /> [![GitHub](https://img.shields.io/github/stars/xxlong0/NeuralUDF)](https://github.com/xxlong0/NeuralUDF) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Long_NeuralUDF_Learning_Unsigned_Distance_Fields_for_Multi-View_Reconstruction_of_Surfaces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14173-b31b1b.svg)](https://arxiv.org/abs/2211.14173) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JnaXx7qyYQY) |
| NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-View Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yunfan1202.github.io/NEF/) <br /> [![GitHub](https://img.shields.io/github/stars/yunfan1202/NEF_code)](https://github.com/yunfan1202/NEF_code) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_NEF_Neural_Edge_Fields_for_3D_Parametric_Curve_Reconstruction_From_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07653-b31b1b.svg)](https://arxiv.org/abs/2303.07653) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_F4EnZ1I_2g) |
| Looking Through the Glass: Neural Surface Reconstruction Against High Specular Reflections | [![GitHub](https://img.shields.io/github/stars/JiaxiongQ/NeuS-HSR)](https://github.com/JiaxiongQ/NeuS-HSR) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_Looking_Through_the_Glass_Neural_Surface_Reconstruction_Against_High_Specular_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08706-b31b1b.svg)](https://arxiv.org/abs/2304.08706) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lwHd-GJAmMA) |
| Multi-View Azimuth Stereo via Tangent Space Consistency | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xucao-42.github.io/mvas_homepage/) <br /> [![GitHub](https://img.shields.io/github/stars/xucao-42/mvas)](https://github.com/xucao-42/mvas) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Multi-View_Azimuth_Stereo_via_Tangent_Space_Consistency_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16447-b31b1b.svg)](https://arxiv.org/abs/2303.16447) | :heavy_minus_sign: |
| Instant Multi-View Head Capture through Learnable Registration | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://tempeh.is.tue.mpg.de/) <br /> [![GitHub](https://img.shields.io/github/stars/TimoBolkart/TEMPEH)](https://github.com/TimoBolkart/TEMPEH) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bolkart_Instant_Multi-View_Head_Capture_Through_Learnable_Registration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07437-b31b1b.svg)](https://arxiv.org/abs/2306.07437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AolpvKpmjEw) |
| EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chengwei-zheng.github.io/EditableNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/chengwei-zheng/EditableNeRF_cvpr23)](https://github.com/chengwei-zheng/EditableNeRF_cvpr23) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_EditableNeRF_Editing_Topologically_Varying_Neural_Radiance_Fields_by_Key_Points_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04247-b31b1b.svg)](https://arxiv.org/abs/2212.04247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Eu2twgbg4kI) |
| Iterative Geometry Encoding Volume for Stereo Matching | [![GitHub](https://img.shields.io/github/stars/gangweiX/IGEV)](https://github.com/gangweiX/IGEV) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Iterative_Geometry_Encoding_Volume_for_Stereo_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06615-b31b1b.svg)](https://arxiv.org/abs/2303.06615) | :heavy_minus_sign: |
| Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery from Sparse Image Ensemble | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chhankyao.github.io/hi-lassie/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Hi-LASSIE_High-Fidelity_Articulated_Shape_and_Skeleton_Discovery_From_Sparse_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.11042-b31b1b.svg)](https://arxiv.org/abs/2212.11042) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s9FWABEm0WU) |
| VDN-NeRF: Resolving Shape-Radiance Ambiguity via View-Dependence Normalization |  |  |  |
| Neuralangelo: High-Fidelity Neural Surface Reconstruction |  |  |  |
| In-Hand 3D Object Scanning from an RGB Sequence |  |  |  |
| SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation of Point Clouds |  |  |  |
| FAC: 3D Representation Learning via Foreground Aware Feature Contrast |  |  |  |
| Neural Kernel Surface Reconstruction |  |  |  |
| NeRFVS: Neural Radiance Fields for Free View Synthesis via Geometry Scaffolds |  |  |  |
| HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of Indoor Scenes with Iterative Intertwined Regularization |  |  |  |
| Multi-Space Neural Radiance Fields |  |  |  |
| MSF: Motion-guided Sequential Fusion for Efficient 3D Object Detection from Point Cloud Sequences |  |  |  |
| PVO: Panoptic Visual Odometry |  |  |  |
| Diffusion-SDF: Text-to-Shape via Voxelized Diffusion |  |  |  |
| Rotation-Invariant Transformer for Point Cloud Matching |  |  |  |
| HexPlane: A Fast Representation for Dynamic Scenes |  |  |  |
| Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders |  |  |  |
| Progressive Neighbor Consistency Mining for Correspondence Pruning |  |  |  |
| SCoDA: Domain Adaptive Shape Completion for Real Scans |  |  |  |
| Adaptive Patch Deformation for Textureless-Resilient Multi-View Stereo |  |  |  |
| Level-S<sup>2</sup>fM: Structure from Motion on Neural Level Set of Implicit Surfaces |  |  |  |
| PLA: Language-Driven Open-Vocabulary 3D Scene Understanding |  |  |  |
| SUDS: Scalable Urban Dynamic Scenes |  |  |  |
| 3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds |  |  |  |
| BAEFormer: Bi-Directional and Early Interaction Transformers for Bird's Eye View Semantic Segmentation |  |  |  |
| Dionysus: Recovering Scene Structures by Dividing into Semantic Pieces |  |  |  |
| LP-DIF: Learning Local Pattern-Specific Deep Implicit Function for 3D Objects and Scenes |  |  |  |
| Neural Kaleidoscopic Space Sculpting |  |  |  |
| Starting from Non-Parametric Networks for 3D Point Cloud Analysis |  |  |  |
| Panoptic Compositional Feature Field for Editable Scene Rendering with Network-Inferred Labels via Metric Learning |  |  |  |
| Robust Dynamic Radiance Fields |  |  |  |
| BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields |  |  |  |
| Consistent Direct Time-of-Flight Video Depth Super-Resolution |  |  |  |
| Patch-based 3D Natural Scene Generation from a Single Example |  |  |  |
| 3D Video Loops from Asynchronous Input |  |  |  |
| UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View |  |  |  |
| Neural Scene Chronology |  |  |  |
| RUST: Latent Neural Scene Representations from Unposed Imagery |  |  |  |
| Painting 3D Nature in 2D: View Synthesis of Natural Scenes from a Single Semantic Mask |  |  |  |
| F<sup>2</sup>-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories |  |  |  |
| VL-SAT: Visual-Linguistic Semantics Assisted Training for 3D Semantic Scene Graph Prediction in Point Cloud |  |  |  |
| REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos |  |  |  |
| MVImgNet: A Large-Scale Dataset of Multi-View Images |  |  |  |
| Shakes on a Plane: Unsupervised Depth Estimation from Unstabilized Photography |  |  |  |
| GINA-3D: Learning to Generate Implicit Neural Assets in the Wild |  |  |  |
| MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures |  |  |  |
| DynIBaR: Neural Dynamic Image-based Rendering |  |  |  |
| IMP: Iterative Matching and Pose Estimation with Adaptive Pooling |  |  |  |
| Learning the Distribution of Errors in Stereo Matching for Joint Disparity and Uncertainty Estimation |  |  |  |
| NeAT: Learning Neural Implicit Surfaces with Arbitrary Topologies from Multi-View Images |  |  |  |
| ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision |  |  |  |
| Bi-LRFusion: Bi-Directional LiDAR-Radar Fusion for 3D Dynamic Object Detection |  |  |  |
| NeRF-DS: Neural Radiance Fields for Dynamic Specular Objects |  |  |  |
| LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion |  |  |  |
| 3D Registration with Maximal Cliques |  |  |  |
| OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation |  |  |  |
| Progressive Spatio-Temporal Alignment for Efficient Event-based Motion Estimation |  |  |  |
| RefSR-NeRF: Towards High Fidelity and Super Resolution View Synthesis |  |  |  |
| NoPe-NeRF: Optimising Neural Radiance Field with No Pose Prior |  |  |  |
| Spherical Transformer for LiDAR-based 3D Recognition |  |  |  |
| Progressively Optimized Local Radiance Fields for Robust View Synthesis |  |  |  |
| PersonNeRF: Personalized Reconstruction from Photo Collections |  |  |  |
| NeuWigs: A Neural Dynamic Model for Volumetric Hair Capture and Animation |  |  |  |
| Representing Volumetric Videos as Dynamic MLP Maps |  |  |  |
| Rethinking the Approximation Error in 3D Surface Fitting for Point Cloud Normal Estimation |  |  |  |
| A Practical Stereo Depth System for Smart Glasses |  |  |  |
| Compressing Volumetric Radiance Fields to 1 MB |  |  |  |
| HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling |  |  |  |
| Point2Pix: Photo-Realistic Point Cloud Rendering via Neural Radiance Fields |  |  |  |
| Command-Driven Articulated Object Understanding and Manipulation |  |  |  |
| SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates |  |  |  |
| PaletteNeRF: Palette-based Appearance Editing of Neural Radiance Fields |  |  |  |
| NeRFLiX: High-Quality Neural View Synthesis by Learning a Degradation-Driven Inter-Viewpoint MiXer |  |  |  |
| SegLoc: Learning Segmentation-based Representations for Privacy-Preserving Visual Localization |  |  |  |
| expOSE: Accurate Initialization-Free Projective Factorization using Exponential Regularization |  |  |  |
| Neural Vector Fields: Implicit Representation by Explicit Learning |  |  |  |
| Unsupervised Inference of Signed Distance Functions from Single Sparse Point Clouds without Learning Priors |  |  |  |
| Learning to Measure the Point Cloud Reconstruction Loss in a Representation Space |  |  |  |
| Grad-PU: Arbitrary-Scale Point Cloud Upsampling via Gradient Descent with Learned Distance Functions |  |  |  |
| TensoIR: Tensorial Inverse Rendering |  |  |  |
| Multi-View Inverse Rendering for Large-Scale Real-World Indoor Scenes |  |  |  |
| Frequency-Modulated Point Cloud Rendering with Easy Editing |  |  |  |
| VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking |  |  |  |
| RGBD2: Generative Scene Synthesis via Incremental View Inpainting using RGBD Diffusion Models |  |  |  |
| Multi-View Stereo Representation Revist: Region-Aware MVSNet |  |  |  |
| AutoRecon: Automated 3D Object Discovery and Reconstruction |  |  |  |
| Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories |  |  |  |
| Binarizing Sparse Convolutional Networks for Efficient Point Cloud Analysis |  |  |  |
| LargeKernel3D: Scaling up Kernels in 3D Sparse CNNs |  |  |  |
| Learning 3D Scene Priors with 2D Supervision |  |  |  |
| NeuralEditor: Editing Neural Radiance Fields via Manipulating Point Clouds |  |  |  |
| NeuralPCI: Spatio-Temporal Neural Field for 3D Point Cloud Multi-Frame Non-Linear Interpolation |  |  |  |
| Two-View Geometry Scoring without Correspondences |  |  |  |
| Deep Graph-based Spatial Consistency for Robust Non-rigid Point Cloud Registration |  |  |  |
| RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo |  |  |  |
| Depth Estimation from Camera Image and mmWave Radar Point Cloud |  |  |  |
| Hierarchical Supervision and Shuffle Data Augmentation for 3D Semi-Supervised Object Detection |  |  |  |
| Multiscale Tensor Decomposition and Rendering Equation Encoding for View Synthesis |  |  |  |
| PATS: Patch Area Transportation with Subdivision for Local Feature Matching |  |  |  |
| Depth Estimation from Indoor Panoramas with Neural Scene Representation |  |  |  |
| Masked Representation Learning for Domain Generalized Stereo Matching |  |  |  |
| GANHead: Towards Generative Animatable Neural Head Avatars |  |  |  |
| Panoptic Lifting for 3D Scene Understanding with Neural Fields |  |  |  |
| Visual-Tactile Sensing for In-Hand Object Reconstruction |  |  |  |
| IterativePFN: True Iterative Point Cloud Filtering |  |  |  |
| Towards Better Gradient Consistency for Neural Signed Distance Functions via Level Set Alignment |  |  |  |
| GarmentTracking: Category-Level Garment Pose Tracking |  |  |  |
| Learning Transformation-Predictive Representations for Detection and Description of Local Features |  |  |  |
| Local Implicit Ray Function for Generalizable Radiance Field Representation |  |  |  |
| Grid-guided Neural Radiance Fields for Large Urban Scenes |  |  |  |
| EventNeRF: Neural Radiance Fields from a Single Colour Event Camera |  |  |  |
| Learning Optical Expansion from Scale Matching |  |  |  |
| Self-Supervised 3D Scene Flow Estimation Guided by Superpoints |  |  |  |
| Adaptive Annealing for Robust Geometric Estimation |  |  |  |
| SurfelNeRF: Neural Surfel Radiance Fields for Online Photorealistic Reconstruction of Indoor Scenes |  |  |  |
| PlaneDepth: Self-Supervised Depth Estimation via Orthogonal Planes |  |  |  |
| High-Res Facial Appearance Capture from Polarized Smartphone Images |  |  |  |
| Tensor4D: Efficient Neural 4D Decomposition for High-Fidelity Dynamic Reconstruction and Rendering |  |  |  |
| Fully Self-Supervised Depth Estimation from Defocus Clue |  |  |  |
| Adaptive Assignment for Geometry Aware Local Feature Matching |  |  |  |
| Efficient Second-Order Plane Adjustment |  |  |  |
| Learning Adaptive Dense Event Stereo from the Image Domain |  |  |  |
| FreeNeRF: Improving Few-Shot Neural Rendering with Free Frequency Regularization |  |  |  |
| SteerNeRF: Accelerating NeRF Rendering via Smooth Viewpoint Trajectory |  |  |  |
| Cross-guided Optimization of Radiance Fields with Multi-View Image Super-Resolution for High-Resolution Novel View Synthesis |  |  |  |
| AeDet: Azimuth-Invariant Multi-View 3D Object Detection |  |  |  |
| Local-to-Global Registration for Bundle-Adjusting Neural Radiance Fields |  |  |  |
| DKM: Dense Kernelized Feature Matching for Geometry Estimation |  |  |  |
| DINER: Depth-Aware Image-based NEural Radiance fields |  |  |  |
| HGNet: Learning Hierarchical Geometry from Points, Edges, and Surfaces |  |  |  |
| Instant Volumetric Head Avatars |  |  |  |
| 3D Line Mapping Revisited |  |  |  |
| Learning to Fuse Monocular and Multi-View Cues for Multi-Frame Depth Estimation in Dynamic Scenes |  |  |  |
| ESLAM: Efficient Dense SLAM System based on Hybrid Representation of Signed Distance Fields |  |  |  |
| Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting |  |  |  |
| SparsePose: Sparse-View Camera Pose Regression and Refinement |  |  |  |
| Controllable Mesh Generation through Sparse Latent Point Diffusion Models |  |  |  |
| ARO-Net: Learning Implicit Fields from Anchored Radial Observations |  |  |  |
| Semantic Ray: Learning a Generalizable Semantic Field with Cross-Reprojection Attention |  |  |  |
| Sphere-guided Training of Neural Implicit Surfaces |  |  |  |
| Finding Geometric Models by Clustering in the Consensus Space |  |  |  |
| NeuralDome: A Neural Modeling Pipeline on Multi-View Human-Object Interactions |  |  |  |
| Privacy-Preserving Representations are not Enough: Recovering Scene Content from Camera Poses |  |  |  |
| Robust Multiview Point Cloud Registration with Reliable Pose Graph Initialization and History Reweighting |  |  |  |
| Neural Part Priors: Learning to Optimize Part-based Object Completion in RGB-D Scans |  |  |  |
| Accelerated Coordinate Encoding: Learning to Relocalize in Minutes using RGB and Poses |  |  |  |
| Gated Stereo: Joint Depth Estimation from Gated and Wide-Baseline Active Stereo Cues |  |  |  |
| Revisiting Rotation Averaging: Uncertainties and Robust Losses |  |  |  |
| NeRF-Supervised Deep Stereo |  |  |  |
| POEM: Reconstructing Hand in a Point Embedded Multi-View Stereo |  |  |  |
| vMAP: Vectorised Object Mapping for Neural Field SLAM |  |  |  |
| PET-NeuS: Positional Encoding Tri-Planes for Neural Surfaces |  |  |  |
| Learnable Skeleton-Aware 3D Point Cloud Sampling |  |  |  |
| ObjectMatch: Robust Registration using Canonical Object Correspondences |  |  |  |
| DiffRF: Rendering-guided 3D Radiance Field Diffusion |  |  |  |
| Learning a Depth Covariance Function |  |  |  |
| Viewpoint Equivariance for Multi-View 3D Object Detection |  |  |  |
| BlendFields: Few-Shot Example-Driven Facial Modeling |  |  |  |
| Implicit Surface Contrastive Clustering for LiDAR Point Clouds |  |  |  |
| Self-Supervised Super-Plane for Neural 3D Reconstruction |  |  |  |
| DiffusioNeRF: Regularizing Neural Radiance Fields with Denoising Diffusion Models |  |  |  |
| AligNeRF: High-Fidelity Neural Radiance Fields via Alignment-Aware Training |  |  |  |
| VisFusion: Visibility-Aware Online 3D Scene Reconstruction from Videos |  |  |  |
| Fast Monocular Scene Reconstruction with Global-Sparse Local-Dense Grids |  |  |  |
| Semi-Weakly Supervised Object Kinematic Motion Prediction |  |  |  |
| OmniVidar: Omnidirectional Depth Estimation from Multi-Fisheye Images |  |  |  |
| ContraNeRF: Generalizable Neural Radiance Fields for Synthetic-to-Real Novel View Synthesis via Contrastive Learning |  |  |  |
| PointVector: A Vector Representation In Point Cloud Analysis |  |  |  |
| Poly-PC: A Polyhedral Network for Multiple Point Cloud Tasks at Once |  |  |  |
| Learning Neural Duplex Radiance Fields for Real-Time View Synthesis |  |  |  |
| VolRecon: Volume Rendering of Signed Ray Distance Functions for Generalizable Multi-View Reconstruction |  |  |  |
| CompletionFormer: Depth Completion with Convolutions and Vision Transformers |  |  |  |
| Exact-NeRF: An Exploration of a Precise Volumetric Parameterization for Neural Radiance Fields |  |  |  |
| Collaboration Helps Camera Overtake LiDAR in 3D Detection |  |  |  |
| SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural Radiance Fields |  |  |  |
| GeoMVSNet: Learning Multi-View Stereo with Geometry Perception |  |  |  |
| 3D Shape Reconstruction of Semi-Transparent Worms |  |  |  |
| Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast Solution |  |  |  |
| Virtual Occlusions through Implicit Depth |  |  |  |
| Neural Fields meet Explicit Geometric Representations for Inverse Rendering of Urban Scenes |  |  |  |
| Building Rearticulable Models for Arbitrary 3D Objects from 4D Point Clouds |  |  |  |
| DynamicStereo: Consistent Dynamic Depth from Stereo Videos |  |  |  |
| Robust Outlier Rejection for 3D Registration with Variational Bayes |  |  |  |
| Meta Architecture for Point Cloud Analysis |  |  |  |
| DyLiN: Making Light Field Networks Dynamic |  |  |  |
| Domain Generalized Stereo Matching via Hierarchical Visual Transformation |  |  |  |
| Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting |  |  |  |
| LightedDepth: Video Depth Estimation in Light of Limited Inference View Angles |  |  |  |
| Long-Term Visual Localization with Mobile Sensors |  |  |  |
| Revisiting the P3P Problem |  |  |  |
| I<sup>2</sup>-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs |  |  |  |
| WildLight: In-the-Wild Inverse Rendering with a Flashlight |  |  |  |
| SE-ORNet: Self-Ensembling Orientation-Aware Network for Unsupervised Point Cloud Shape Correspondence |  |  |  |
| Teleidoscopic Imaging System for Microscale 3D Shape Reconstruction |  |  |  |
| NeuDA: Neural Deformable Anchor for High-Fidelity Implicit Surface Reconstruction |  |  |  |
| PointClustering: Unsupervised Point Cloud Pre-Training using Transformation Invariance in Clustering |  |  |  |
| PermutoSDF: Fast Multi-View Reconstruction with Implicit Surfaces using Permutohedral Lattices |  |  |  |
| TriVol: Point Cloud Rendering via Triple Volumes |  |  |  |
| Towards Unbiased Volume Rendering of Neural Implicit Surfaces with Geometry Priors |  |  |  |
| Semi-Supervised Stereo-based 3D Object Detection via Cross-View Consensus |  |  |  |
| Self-Supervised Pre-Training with Masked Shape Prediction for 3D Scene Understanding |  |  |  |
| Octree Guided Unoriented Surface Reconstruction |  |  |  |
| Towards Domain Generalization for Multi-View 3D Object Detection in Bird-Eye-View |  |  |  |
| Learning Neural Volumetric Representations of Dynamic Humans in Minutes |  |  |  |
| AnchorFormer: Point Cloud Completion from Discriminative Nodes |  |  |  |
| Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization |  |  |  |
| GANmouflage: 3D Object Nondetection with Texture Fields |  |  |  |
| PEAL: Prior-embedded Explicit Attention Learning for Low-Overlap Point Cloud Registration |  |  |  |
| NeRFLight: Fast and Light Neural Radiance Fields using a Shared Feature Grid |  |  |  |
| TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable Rendering |  |  |  |
| Generating Part-Aware Editable 3D Shapes without 3D Supervision |  |  |  |
| ALTO: Alternating Latent Topologies for Implicit 3D Reconstruction |  |  |  |
| ORCa: Glossy Objects as Radiance-Field Cameras |  |  |  |
| NeFII: Inverse Rendering for Reflectance Decomposition with Near-Field Indirect Illumination |  |  |  |
| BEV-guided Multi-Modality Fusion for Driving Perception |  |  |  |
| <i>K</i>-Planes: Explicit Radiance Fields in Space, Time, and Appearance |  |  |  |
| RobustNeRF: Ignoring Distractors with Robust Losses |  |  |  |
| Unsupervised Deep Asymmetric Stereo Matching with Spatially-Adaptive Self-Similarity |  |  |  |
| ProxyFormer: Proxy Alignment Assisted Point Cloud Completion with Missing Part Sensitive Transformer |  |  |  |
| Diffusion-based Signed Distance Fields for 3D Shape Generation |  |  |  |
| FeatureBooster: Boosting Feature Descriptors with a Lightweight Neural Network |  |  |  |
| Temporal Interpolation is All You Need for Dynamic Neural Radiance Fields |  |  |  |
| Neural Lens Modeling |  |  |  |
| Multi-View Reconstruction using Signed Ray Distance Functions (SRDF) |  |  |  |
| Masked Wavelet Representation for Compact Neural Radiance Fields |  |  |  |
| A Rotation-Translation-Decoupled Solution for Robust and Efficient Visual-Inertial Initialization |  |  |  |
| MACARONS: Mapping and Coverage Anticipation with RGB Online Self-Supervision |  |  |  |
| DualRefine: Self-Supervised Depth and Pose Estimation through Iterative Epipolar Sampling and Refinement Toward Equilibrium |  |  |  |
| CLIP<sup>2</sup>: Contrastive Language-Image-Point Pretraining from Real-World Point Cloud Data |  |  |  |
| Semidefinite Relaxations for Robust Multiview Triangulation |  |  |  |
| High-Frequency Stereo Matching Network |  |  |  |
| CAP: Robust Point Cloud Classification via Semantic and Structural Modeling |  |  |  |
| Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM |  |  |  |
| Temporally Consistent Online Depth Estimation using Point-based Fusion |  |  |  |
| Learning Neural Parametric Head Models |  |  |  |
| PointConvFormer: Revenge of the Point-based Convolution |  |  |  |
| Four-View Geometry with Unknown Radial Distortion |  |  |  |
| Seeing through the Glass: Neural 3D Reconstruction of Object Inside a Transparent Container |  |  |  |

### Image and Video Synthesis and Generation

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Towards Universal Fake Image Detectors that Generalize Across Generative Models |  |  |  |
| Implicit Diffusion Models for Continuous Super-Resolution |  |  |  |
| High-Fidelity Guided Image Synthesis with Latent Diffusion Models |  |  |  |
| DBARF: Deep Bundle-Adjusting Generalizable Neural Radiance Fields |  |  |  |
| Deep Arbitrary-Scale Image Super-Resolution via Scale-Equivariance Pursuit |  |  |  |
| Balanced Spherical Grid for Egocentric View Synthesis |  |  |  |
| SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation |  |  |  |
| DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation |  |  |  |
| Self-guided Diffusion Models |  |  |  |
| Multi-Concept Customization of Text-to-Image Diffusion |  |  |  |
| 3D-Aware Conditional Image Synthesis |  |  |  |
| QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity |  |  |  |
| SceneComposer: Any-Level Semantic Image Synthesis |  |  |  |
| DiffCollage: Parallel Generation of Large Content with Diffusion Models |  |  |  |
| Putting People in Their Place: Affordance-Aware Human Insertion into Scenes |  |  |  |
| Hybrid Neural Rendering for Large-Scale Scenes with Motion Blur |  |  |  |
| Binary Latent Diffusion |  |  |  |
| StyleRes: Transforming the Residuals for Real Image Editing with StyleGAN |  |  |  |
| KD-DLGAN: Data Limited Image Generation via Knowledge Distillation |  |  |  |
| <i>SeaThru</i>-NeRF: Neural Radiance Fields in Scattering Media |  |  |  |
| PointAvatar: Deformable Point-based Head Avatars from Videos |  |  |  |
| 3DAvatarGAN: Bridging Domains for Personalized Editable Avatars |  |  |  |
| Neural Preset for Color Style Transfer |  |  |  |
| Zero-Shot Generative Model Adaptation via Image-Specific Prompt Learning |  |  |  |
| DyNCA: Real-Time Dynamic Texture Synthesis using Neural Cellular Automata |  |  |  |
| Exploring Incompatible Knowledge Transfer in Few-Shot Image Generation |  |  |  |
| HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with Discrete and Continuous Denoising |  |  |  |
| Towards Accurate Image Coding: Improved Autoregressive Image Generation with Dynamic Vector Quantization |  |  |  |
| RiDDLE: Reversible and Diversified De-Identification with Latent Encryptor |  |  |  |
| LayoutDiffusion: Controllable Diffusion Model for Layout-to-Image Generation |  |  |  |
| LipFormer: High-Fidelity and Generalizable Talking Face Generation with A Pre-learned Facial Codebook |  |  |  |
| Not All Image Regions Matter: Masked Vector Quantization for Autoregressive Image Generation |  |  |  |
| GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis |  |  |  |
| High-Fidelity Generalized Emotional Talking Face Generation with Multi-Modal Emotion Space Learning |  |  |  |
| Consistent View Synthesis with Pose-guided Diffusion Models |  |  |  |
| StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-based Generator |  |  |  |
| Imagic: Text-based Real Image Editing with Diffusion Models |  |  |  |
| Large-Capacity and Flexible Video Steganography via Invertible Neural Network |  |  |  |
| Quantitative Manipulation of Custom Attributes on 3D-Aware Image Synthesis |  |  |  |
| Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent Portrait Synthesis from Monocular Image |  |  |  |
| CF-Font: Content Fusion for Few-Shot Font Generation |  |  |  |
| One-Shot High-Fidelity Talking-Head Synthesis with Deformable Neural Radiance Field |  |  |  |
| Unsupervised Domain Adaption with Pixel-Level Discriminator for Image-Aware Layout Generation |  |  |  |
| Diffusion Probabilistic Model Made Slim |  |  |  |
| Collaborative Diffusion for Multi-Modal Face Generation and Editing |  |  |  |
| High-Fidelity Facial Avatar Reconstruction from Monocular Video with Generative Priors |  |  |  |
| Network-Free, Unsupervised Semantic Segmentation with Synthetic Images |  |  |  |
| Visual Prompt Tuning for Generative Transfer Learning |  |  |  |
| Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models to Learn Any Unseen Style |  |  |  |
| Catch Missing Details: Image Reconstruction with Frequency Augmented Variational Autoencoder |  |  |  |
| Towards Bridging the Performance Gaps of Joint Energy-based Models |  |  |  |
| GLeaD: Improving GANs with a Generator-Leading Task |  |  |  |
| Structural Multiplane Image: Bridging Neural View Synthesis and 3D Reconstruction |  |  |  |
| SPARF: Neural Radiance Fields from Sparse and Noisy Poses |  |  |  |
| DeltaEdit: Exploring Text-Free Training for Text-Driven Image Manipulation |  |  |  |
| Inferring and Leveraging Parts from Object Shape for Improving Semantic Image Synthesis |  |  |  |
| VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation |  |  |  |
| MaskSketch: Unpaired Structure-guided Masked Image Generation |  |  |  |
| Affordance Diffusion: Synthesizing Hand-Object Interactions |  |  |  |
| Interactive Cartoonization with Controllable Perceptual Factors |  |  |  |
| MetaPortrait: Identity-Preserving Talking Head Generation with Fast Personalized Adaptation |  |  |  |
| Paint by Example: Exemplar-based Image Editing with Diffusion Models |  |  |  |
| GLIGEN: Open-Set Grounded Text-to-Image Generation |  |  |  |
| L-CoIns: Language-based Colorization with Instance Awareness |  |  |  |
| DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation |  |  |  |
| Evading DeepFake Detectors via Adversarial Statistical Consistency |  |  |  |
| GlassesGAN: Eyewear Personalization using Synthetic Appearance Discovery and Targeted Subspace Modeling |  |  |  |
| GP-VTON: Towards General Purpose Virtual Try-on via Collaborative Local-Flow Global-Parsing Learning |  |  |  |
| Where is My Spot? Few-Shot Image Generation via Latent Subspace Optimization |  |  |  |
| Regularized Vector Quantization for Tokenized Image Synthesis |  |  |  |
| EDICT: Exact Diffusion Inversion via Coupled Transformations |  |  |  |
| Scaling up GANs for Text-to-Image Synthesis |  |  |  |
| Shape-Aware Text-Driven Layered Video Editing |  |  |  |
| A Unified Pyramid Recurrent Network for Video Frame Interpolation |  |  |  |
| TAPS3D: Text-guided 3D Textured Shape Generation from Pseudo Supervision |  |  |  |
| Fine-Grained Face Swapping via Regional GAN Inversion |  |  |  |
| OTAvatar: One-Shot Talking Face Avatar with Controllable Tri-Plane Rendering |  |  |  |
| Deep Stereo Video Inpainting |  |  |  |
| StyleGAN Salon: Multi-View Latent Optimization for Pose-Invariant Hairstyle Transfer |  |  |  |
| Cross-GAN Auditing: Unsupervised Identification of Attribute Level Similarities and Differences between Pretrained Generative Models |  |  |  |
| Unsupervised Volumetric Animation |  |  |  |
| SINE: SINgle Image Editing with Text-to-Image Diffusion Models |  |  |  |
| Progressive Disentangled Representation Learning for Fine-Grained Controllable Talking Head Synthesis |  |  |  |
| CAP-VSTNet: Content Affinity Preserved Versatile Style Transfer |  |  |  |
| DeepVecFont-v2: Exploiting Transformers to Synthesize Vector Fonts with Higher Quality |  |  |  |
| LEMaRT: Label-Efficient Masked Region Transform for Image Harmonization |  |  |  |
| SINE: Semantic-Driven Image-based NeRF Editing with Prior-guided Editing Field |  |  |  |
| Exploring Intra-Class Variation Factors with Learnable Cluster Prompts for Semi-Supervised Image Synthesis |  |  |  |
| Image Cropping with Spatial-Aware Feature and Rank Consistency |  |  |  |
| <i>Picture that Sketch</i>: Photorealistic Image Generation from Abstract Sketches |  |  |  |
| MonoHuman: Animatable Human Neural Field from Monocular Video |  |  |  |
| PixHt-Lab: Pixel Height based Light Effect Generation for Image Compositing |  |  |  |
| Neural Pixel Composition for 3D-4D View Synthesis from Multi-Views |  |  |  |
| SpaText: Spatio-Textual Representation for Controllable Image Generation |  |  |  |
| Exploring Motion Ambiguity and Alignment for High-Quality Video Frame Interpolation |  |  |  |
| MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation |  |  |  |
| Synthesizing Photorealistic Virtual Humans Through Cross-Modal Disentanglement |  |  |  |
| Video Probabilistic Diffusion Models in Projected Latent Space |  |  |  |
| Variational Distribution Learning for Unsupervised Text-to-Image Generation |  |  |  |
| Linking Garment with Person via Semantically Associated Landmarks for Virtual Try-On |  |  |  |
| UV Volumes for Real-Time Rendering of Editable Free-View Human Performance |  |  |  |
| Null-Text Inversion for Editing Real Images using Guided Diffusion Models |  |  |  |
| Polynomial Implicit Neural Representations for Large Diverse Datasets |  |  |  |
| Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation |  |  |  |
| Conditional Image-to-Video Generation with Latent Flow Diffusion Models |  |  |  |
| Local 3D Editing via 3D Distillation of CLIP Knowledge |  |  |  |
| Private Image Generation with Dual-Purpose Auxiliary Classifier |  |  |  |
| MAGVIT: Masked Generative Video Transformer |  |  |  |
| Dimensionality-Varying Diffusion Process |  |  |  |
| VIVE3D: Viewpoint-Independent Video Editing using 3D-Aware GANs |  |  |  |
| LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data |  |  |  |
| DATID-3D: Diversity-Preserved Domain Adaptation using Text-to-Image Diffusion for 3D Generative Model |  |  |  |
| Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint |  |  |  |
| High-Fidelity and Freely Controllable Talking Head Video Generation |  |  |  |
| SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation |  |  |  |
| StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields |  |  |  |
| MOSO: Decomposing MOtion, Scene and Object for Video Prediction |  |  |  |
| Multi Domain Learning for Motion Magnification |  |  |  |
| GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields |  |  |  |
| Hierarchical B-frame Video Coding using Two-Layer CANF without Motion Coding |  |  |  |
| Blemish-Aware and Progressive Face Retouching with Limited Paired Data |  |  |  |
| Text-guided Unsupervised Latent Transformation for Multi-attribute Image Manipulation |  |  |  |
| NeuralField-LDM: Scene Generation with Hierarchical Latent Diffusion Models |  |  |  |
| Fix the Noise: Disentangling Source Feature for Controllable Domain Translation |  |  |  |
| Class-Balancing Diffusion Models |  |  |  |
| DPE: Disentanglement of Pose and Expression for General Video Portrait Editing |  |  |  |
| Inversion-based Style Transfer with Diffusion Models |  |  |  |
| Deep Curvilinear Editing: Commutative and Nonlinear Image Manipulation for Pretrained Deep Generative Model |  |  |  |
| FlowGrad: Controlling the Output of Generative ODEs with Gradients |  |  |  |
| Graph Transformer GANs for Graph-Constrained House Generation |  |  |  |
| Master: Meta Style Transformer for Controllable Zero-Shot and Few-Shot Artistic Style Transfer |  |  |  |
| Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars |  |  |  |
| Ham2Pose: Animating Sign Language Notation into Pose Sequences |  |  |  |
| Neural Transformation Fields for Arbitrary-Styled Font Generation |  |  |  |
| LayoutDM: Transformer-based Diffusion Model for Layout Generation |  |  |  |
| Removing Objects from Neural Radiance Fields |  |  |  |
| Person Image Synthesis via Denoising Diffusion Model |  |  |  |
| AdaptiveMix: Improving GAN Training via Feature Space Shrinkage |  |  |  |
| Learning Joint Latent Space EBM Prior Model for Multi-Layer Generator |  |  |  |
| 3D Neural Field Generation using Triplane Diffusion|  |  |  |
| OmniAvatar: Geometry-guided Controllable 3D Head Synthesis |  |  |  |
| RWSC-Fusion: Region-Wise Style-Controlled Fusion Network for the Prohibited X-ray Security Image Synthesis |  |  |  |
| ObjectStitch: Object Compositing with Diffusion Model |  |  |  |
| Persistent Nature: A Generative Model of Unbounded 3D Worlds |  |  |  |
| Masked and Adaptive Transformer for Exemplar based Image Translation |  |  |  |
| Spider GAN: Leveraging Friendly Neighbors to Accelerate GAN Training |  |  |  |
| Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild |  |  |  |
| Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models |  |  |  |
| All are Worth Words: A ViT Backbone for Diffusion Models |  |  |  |
| Few-Shot Semantic Image Synthesis with Class Affinity Transfer |  |  |  |
| Blowing in the Wind: CycleNet for Human Cinemagraphs from Still Images |  |  |  |
| StyleGene: Crossover and Mutation of Region-Level Facial Genes for Kinship Face Synthesis |  |  |  |
| MixNeRF: Modeling a Ray with Mixture Density for Novel View Synthesis from Sparse Inputs |  |  |  |
| MoStGAN-V: Video Generation with Temporal Motion Styles |  |  |  |
| Frame Interpolation Transformer and Uncertainty Guidance |  |  |  |
| Towards End-to-End Generative Modeling of Long Videos with Memory-Efficient Bidirectional Transformers |  |  |  |
| HOLODIFFUSION: Training a 3D Diffusion Model using 2D Images |  |  |  |
| Neural Texture Synthesis with Guided Correspondence |  |  |  |
| PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360&deg; |  |  |  |
| InstructPix2Pix: Learning to Follow Image Editing Instructions |  |  |  |
| Unpaired Image-to-Image Translation with Shortest Path Regularization |  |  |  |
| Freestyle Layout-to-Image Synthesis |  |  |  |
| On Distillation of Guided Diffusion Models |  |  |  |
| Single Image Backdoor Inversion via Robust Smoothed Classifiers |  |  |  |
| Make-a-Story: Visual Memory Conditioned Consistent Story Generation |  |  |  |
| Towards Practical Plug-and-Play Diffusion Models |  |  |  |
| Efficient Scale-Invariant Generator with Column-Row Entangled Pixel Synthesis |  |  |  |
| Wavelet Diffusion Models are Fast and Scalable Image Generators |  |  |  |
| 3D GAN Inversion with Facial Symmetry Prior |  |  |  |
| Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert |  |  |  |
| PCT-Net: Full Resolution Image Harmonization Using Pixel-Wise Color Transformations |  |  |  |
| ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts |  |  |  |
| Video Compression with Entropy-Constrained Neural Representations |  |  |  |
| Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models |  |  |  |
| CoralStyleCLIP: Co-optimized Region and Layer Selection for Image Editing |  |  |  |
| Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding |  |  |  |
| Sequential Training of GANs Against GAN-classifiers Reveals Correlated ``Knowledge Gaps`` Present among Independently Trained GAN Instances |  |  |  |
| Attribute-Preserving Face Dataset Anonymization via Latent Code Optimization |  |  |  |
| Shifted Diffusion for Text-to-Image Generation |  |  |  |
| HandsOff: Labeled Dataset Generation with no Additional Human Annotations |  |  |  |
| Lookahead Diffusion Probabilistic Models for Refining Mean Estimation |  |  |  |
| Imagen Editor and EditBench: Advancing and Evaluating Text-guided Image Inpainting |  |  |  |
| Re-GAN: Data-Efficient GANs Training via Architectural Reconfiguration |  |  |  |
| BBDM: Image-to-Image Translation with Brownian Bridge Diffusion Models |  |  |  |
| VectorFusion: Text-to-SVG by Abstracting Pixel-based Diffusion Models |  |  |  |

### Humans: Face, Body, Pose, Gesture, Movement

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Micron-BERT: BERT-based Facial Micro-Expression Recognition |  |  |  |
| NIKI: Neural Inverse Kinematics with Invertible Neural Networks for 3D Human Pose and Shape Estimation |  |  |  |
| A Characteristic Function-based Method for Bottom-Up Human Pose Estimation |  |  |  |
| Executing your Commands via Motion Diffusion in Latent Space |  |  |  |
| MSINet: Twins Contrastive Search of Multi-Scale Interaction for Object ReID |  |  |  |
| Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation |  |  |  |
| Global-to-Local Modeling for Video-based 3D Human Pose and Shape Estimation |  |  |  |
| Dynamic Aggregated Network for Gait Recognition |  |  |  |
| Object Pop-Up: Can We Infer 3D Objects and Their Poses from Human Interactions Alone? |  |  |  |
| Unsupervised Sampling Promoting for Stochastic Human Trajectory Prediction |  |  |  |
| ECON: Explicit Clothed humans Optimized via Normal integration |  |  |  |
| Neuron Structure Modeling for Generalizable Remote Physiological Measurement |  |  |  |
| Continuous Sign Language Recognition with Correlation Network |  |  |  |
| Parametric Implicit Face Representation for Audio-Driven Facial Reenactment |  |  |  |
| CrowdCLIP: Unsupervised Crowd Counting via Vision-Language Model |  |  |  |
| PoseExaminer: Automated Testing of Out-of-Distribution Robustness in Human Pose and Shape Estimation |  |  |  |
| 3D Human Mesh Estimation from Virtual Markers |  |  |  |
| 3D Human Pose Estimation via Intuitive Physics |  |  |  |
| ARCTIC: A Dataset for Dexterous Bimanual Hand-Object Manipulation |  |  |  |
| Generating Holistic 3D Human Motion from Speech |  |  |  |
| HARP: Personalized Hand Reconstruction from a Monocular RGB Video |  |  |  |
| Learning Locally Editable Virtual Humans |  |  |  |
| Reconstructing Signing Avatars from Video using Linguistic Priors |  |  |  |
| DrapeNet: Garment Generation and Self-Supervised Draping |  |  |  |
| X-Avatar: Expressive Human Avatars |  |  |  |
| Hi4D: 4D Instance Segmentation of Close Human Interaction |  |  |  |
| Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-Supervised Scene Decomposition |  |  |  |
| CloSET: Modeling Clothed Humans on Continuous Surface with Explicit Template Decomposition |  |  |  |
| Graphics Capsule: Learning Hierarchical 3D Face Representations from 2D Images |  |  |  |
| Rethinking the Learning Paradigm for Dynamic Facial Expression Recognition |  |  |  |
| HandNeRF: Neural Radiance Fields for Animatable Interacting Hands |  |  |  |
| Relightable Neural Human Assets from Multi-View Gradient Illuminations |  |  |  |
| Being Comes from Not-being: Open-Vocabulary Text-to-Motion Generation with Wordless Training |  |  |  |
| DeFeeNet: Consecutive 3D Human Motion Prediction with Deviation Feedback |  |  |  |
| BioNet: A Biologically-Inspired Network for Face Recognition |  |  |  |
| Boosting Detection in Crowd Analysis via Underutilized Output Features |  |  |  |
| Learning Analytical Posterior Probability for Human Mesh Recovery |  |  |  |
| Listening Human Behavior: 3D Human Pose Estimation with Acoustic Signals |  |  |  |
| Detecting and Grounding Multi-Modal Media Manipulation |  |  |  |
| RelightableHands: Efficient Neural Relighting of Articulated Hand Models |  |  |  |
| MEGANE: Morphable Eyeglass and Avatar Network |  |  |  |
| SunStage: Portrait Reconstruction and Relighting using the Sun as a Light Stage |  |  |  |
| TryOnDiffusion: A Tale of Two UNets |  |  |  |
| Semi-Supervised Hand Appearance Recovery via Structure Disentanglement and Dual Adversarial Discrimination |  |  |  |
| POTTER: Pooling Attention Transformer for Efficient Human Mesh Recovery |  |  |  |
| Scene-Aware Egocentric 3D Human Pose Estimation |  |  |  |
| PSVT: End-to-End Multi-Person 3D Pose and Shape Estimation with Progressive Video Transformers |  |  |  |
| Trajectory-Aware Body Interaction Transformer for Multi-Person Pose Forecasting |  |  |  |
| A2J-Transformer: Anchor-to-Joint Transformer Network for 3D Interacting Hand Pose Estimation from a Single RGB Image |  |  |  |
| TRACE: 5D Temporal Regression of Avatars with Dynamic Cameras in 3D Environments |  |  |  |
| Skinned Motion Retargeting with Residual Perception of Motion Semantics & Geometry |  |  |  |
| Generating Human Motion from Textual Descriptions with Discrete Representations |  |  |  |
| Learning Human Mesh Recovery in 3D Scenes |  |  |  |
| AVFace: Towards Detailed Audio-Visual 4D Face Reconstruction |  |  |  |
| 3D-Aware Face Swapping |  |  |  |
| Neural Residual Radiance Fields for Streamably Free-Viewpoint Videos |  |  |  |
| GFPose: Learning 3D Human Pose Prior with Gradient Fields |  |  |  |
| Rethinking Feature-based Knowledge Distillation for Face Recognition |  |  |  |
| One-Stage 3D Whole-Body Mesh Recovery with Component Aware Transformer |  |  |  |
| Towards Stable Human Pose Estimation via Cross-View Fusion and Foot Stabilization |  |  |  |
| Ego-Body Pose Estimation via Ego-Head Pose Estimation |  |  |  |
| TOPLight: Lightweight Neural Networks with Task-Oriented Pretraining for Visible-Infrared Recognition |  |  |  |
| StyleIPSB: Identity-Preserving Semantic Basis of StyleGAN for High Fidelity Face Swapping |  |  |  |
| Improving Fairness in Facial Albedo Estimation via Visual-Textual Cues |  |  |  |
| FLEX: Full-Body Grasping without Full-Body Grasps |  |  |  |
| EDGE: Editable Dance Generation From Music |  |  |  |
|Complete 3D Human Reconstruction from a Single Incomplete Image |  |  |  |
| Zero-Shot Pose Transfer for Unrigged Stylized 3D Characters |  |  |  |
| Hand Avatar: Free-Pose Hand Animation and Rendering from Monocular Video |  |  |  |
| Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes |  |  |  |
| Learning Neural Proto-Face Field for Disentangled 3D Face Modeling in the Wild |  |  |  |
| CLAMP: Prompt-based Contrastive Learning for Connecting Language and Animal Pose |  |  |  |
| Invertible Neural Skinning |  |  |  |
| DiffusionRig: Learning Personalized Priors for Facial Appearance Editing |  |  |  |
| Harmonious Feature Learning for Interactive Hand-Object Pose Estimation |  |  |  |
| Leapfrog Diffusion Model for Stochastic Trajectory Prediction |  |  |  |
| NeuFace: Realistic 3D Neural Face Rendering from Multi-View Images |  |  |  |
| DiffSwap: High-Fidelity and Controllable Face Swapping via 3D-Aware Masked Diffusion |  |  |  |
| GFIE: A Dataset and Baseline for Gaze-Following from 2D to 3D in Indoor Environments |  |  |  |
| Hierarchical Temporal Transformer for 3D Hand Pose Estimation and Action Recognition from Egocentric RGB Videos |  |  |  |
| Decompose more and Aggregate Better: Two Closer Looks at Frequency Representation Learning for Human Motion Prediction |  |  |  |
| Human Pose as Compositional Tokens |  |  |  |
| Normal-guided Garment UV Prediction for Human Re-Texturing |  |  |  |
| Dynamic Graph Learning with Content-guided Spatial-Frequency Relation Reasoning for Deepfake Detection |  |  |  |
| VGFlow: Visibility Guided Flow Network for Human Reposing |  |  |  |
| Mutual Information-based Temporal Difference Learning for Human Pose Estimation in Video |  |  |  |
| PREIM3D: 3D Consistent Precise Image Attribute Editing from a Single Image |  |  |  |
| HuManiFlow: Ancestor-Conditioned Normalising Flows on SO(3) Manifolds for Human Pose and Shape Distribution Estimation |  |  |  |
| Implicit Identity Driven Deepfake Face Swapping Detection |  |  |  |
| Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion |  |  |  |
| 3D-Aware Facial Landmark Detection via Multi-View Consistent Training on Synthetic Data |  |  |  |
| SLOPER4D: A Scene-Aware Dataset for Global 4D Human Pose Estimation in Urban Environments |  |  |  |
| Zero-Shot Text-to-Parameter Translation for Game Character Auto-Creation |  |  |  |
| AssemblyHands: Towards Egocentric Activity Understanding via 3D Hand Pose Estimation |  |  |  |
| UDE: A Unified Driving Engine for Human Motion Generation |  |  |  |
| CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior |  |  |  |
| Semi-Supervised 2D Human Pose Estimation Driven by Position Inconsistency Pseudo Label Correction Module |  |  |  |
| Learning Personalized High Quality Volumetric Head Avatars from Monocular RGB Videos |  |  |  |
| HOOD: Hierarchical Graphs for Generalized Modelling of Clothing Dynamics |  |  |  |
| ACR: Attention Collaboration-based Regressor for Arbitrary Two-Hand Reconstruction |  |  |  |
| HumanBench: Towards General Human-Centric Perception with Projector Assisted Pretraining |  |  |  |
| CIMI4D: A Large Multimodal Climbing Motion Dataset under Human-Scene Interactions |  |  |  |
| Human Pose Estimation in Extremely Low-Light Conditions |  |  |  |
| DistilPose: Tokenized Pose Regression with Heatmap Distillation |  |  |  |
| Human Body Shape Completion with Implicit Shape and Flow Learning |  |  |  |
| Source-Free Adaptive Gaze Estimation by Uncertainty Reduction |  |  |  |
| Music-Driven Group Choreography |  |  |  |
| Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation |  |  |  |
| MARLIN: Masked Autoencoder for Facial Video Representation LearnINg |  |  |  |
| Transformer-based Unified Recognition of Two Hands Manipulating Objects |  |  |  |
| Implicit Identity Leakage: The Stumbling Block to Improving Deepfake Detection Generalization |  |  |  |
| ScarceNet: Animal Pose Estimation with Scarce Annotations |  |  |  |
| FFHQ-UV: Normalized Facial UV-Texture Dataset for 3D Face Reconstruction |  |  |  |
| MoDi: Unconditional Motion Synthesis from Diverse Data |  |  |  |
| Feature Representation Learning with Adaptive Displacement Generation and Transformer Fusion for Micro-Expression Recognition |  |  |  |
| MeMaHand: Exploiting Mesh-Mano Interaction for Single Image Two-Hand Reconstruction |  |  |  |
| Stimulus Verification is a Universal and Effective Sampler in Multi-Modal Human Trajectory Prediction |  |  |  |
| TokenHPE: Learning Orientation Tokens for Efficient Head Pose Estimation via Transformers |  |  |  |
| Handy: Towards a High Fidelity 3D Hand Shape and Appearance Model |  |  |  |
| CIRCLE: Capture in Rich Contextual Environments |  |  |  |
| Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention |  |  |  |
| Implicit Neural Head Synthesis via Controllable Local Deformation Fields |  |  |  |
| Continuous Intermediate Token Learning with Implicit Motion Manifold for Keyframe based Motion Interpolation |  |  |  |
| JRDB-Pose: A Large-Scale Dataset for Multi-Person Pose Estimation and Tracking |  |  |  |
| STAR Loss: Reducing Semantic Ambiguity in Facial Landmark Detection |  |  |  |
| GM-NeRF: Learning Generalizable Model-based Neural Radiance Fields from Multi-View Images |  |  |  |
| Decoupled Multimodal Distilling for Emotion Recognition |  |  |  |
| HaLP: Hallucinating Latent Positives for Skeleton-based Self-Supervised Learning of Actions |  |  |  |
| ReDirTrans: Latent-to-Latent Translation for Gaze and Head Redirection |  |  |  |
| QPGesture: Quantization-based and Phase-guided Motion Matching for Natural Speech-Driven Gesture Generation |  |  |  |
| Multi-Modal Gait Recognition via Effective Spatial-Temporal Feature Fusion |  |  |  |
| Probabilistic Knowledge Distillation of Face Ensembles |  |  |  |
| Learning Semantic-Aware Disentangled Representation for Flexible 3D Human Body Editing |  |  |  |
| Parameter Efficient Local Implicit Image Function Network for Face Segmentation |  |  |  |
| HumanGen: Generating Human Radiance Fields with Explicit Priors |  |  |  |
| Biomechanics-guided Facial Action Unit Detection through Force Modeling |  |  |  |
| Decoupling Human and Camera Motion from Videos in the Wild |  |  |  |
| Overcoming the Trade-Off Between Accuracy and Plausibility in 3D Hand Shape Reconstruction |  |  |  |
| Instant-NVR: Instant Neural Volumetric Rendering for Human-Object Interactions from Monocular RGBD Stream |  |  |  |
| PoseFormerV2: Exploring Frequency Domain for Efficient and Robust 3D Human Pose Estimation |  |  |  |
| Analyzing and Diagnosing Pose Estimation with Attributions |  |  |  |
| Unsupervised Visible-Infrared Person Re-Identification via Progressive Graph Matching and Alternate Learning |  |  |  |
| Shape-Erased Feature Learning for Visible-Infrared Person Re-Identification |  |  |  |
| Distilling Cross-Temporal Contexts for Continuous Sign Language Recognition |  |  |  |
| Avatars Grow Legs: Generating Smooth Human Motion from Sparse Tracking Inputs with Diffusion Model |  |  |  |
| Local Connectivity-based Density Estimation for Face Clustering |  |  |  |
| SelfME: Self-Supervised Motion Learning for Micro-Expression Recognition |  |  |  |
| Detecting Human-Object Contact in Images |  |  |  |
| Controllable Light Diffusion for Portraits |  |  |  |
| InstantAvatar: Learning Avatars from Monocular Video in 60 Seconds |  |  |  |
| <i>NeMo</i>: 3D <i>Ne</i>ural <i>Mo</i>tion Fields from Multiple Video Instances of the Same Action |  |  |  |
| Privacy-Preserving Adversarial Facial Features |  |  |  |
| Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation |  |  |  |
| DSFNet: Dual Space Fusion Network for Occlusion-Robust 3D Dense Face Alignment |  |  |  |
| Clothed Human Performance Capture with a Double-Layer Neural Radiance Fields |  |  |  |
| Continuous Landmark Detection with 3D Queries |  |  |  |
| Learning a 3D Morphable Face Reflectance Model from Low-Cost Data |  |  |  |
| AUNet: Learning Relations between Action Units for Face Forgery Detection |  |  |  |
| 3D Human Pose Estimation with Spatio-Temporal Criss-Cross Attention |  |  |  |
| Implicit 3D Human Mesh Recovery using Consistency with Pose and Shape from Unseen-View |  |  |  |
| 3D Human Keypoints Estimation from Point Clouds in the Wild without Human Labels |  |  |  |
| Multi-Label Compound Expression Recognition: C-EXPR Database & Network |  |  |  |
| FlexNeRF: Photorealistic Free-Viewpoint Rendering of Moving Humans from Sparse Views |  |  |  |
| Two-Stage Co-Segmentation Network based on Discriminative Representation for Recovering Human Mesh from Videos |  |  |  |
| Co-Speech Gesture Synthesis by Reinforcement Learning with Contrastive Pre-trained Rewards |  |  |  |
| FeatER: An Efficient Network for Human Reconstruction via <u>Feat</u>ure Map-based Transform<u>ER</u> |  |  |  |

### Transfer, Meta, Low-Shot, Continual, or Long-Tail Learning

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Recognition: Categorization, Detection, Retrieval

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Vision, Language, and Reasoning

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Low-Level Vision

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Segmentation, Grouping and Shape Analysis

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Deep Learning Architectures and Techniques

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Multi-Modal Learning

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### 3D from Single Images

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Medical and Biological Vision, Cell Microscopy

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Video: Action and Event Understanding

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Autonomous Driving

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Self-Supervised or Unsupervised Representation Learning

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Datasets and Evaluation

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Scene Analysis and Understanding

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Adversarial Attack and Defense

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Efficient and Scalable Vision

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Computational Imaging

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

> Will soon be added

### Video: Low-Level Analysis, Motion, and Tracking

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Uncovering the Missing Pattern: Unified Framework Towards Trajectory Imputation and Prediction |  |  |  |
| Tracking Multiple Deformable Objects in Egocentric Videos |  |  |  |
| Tracking through Containers and Occluders in the Wild |  |  |  |
| TarViS: A Unified Approach for Target-based Video Segmentation |  |  |  |
| VideoTrack: Learning to Track Objects via Video Transformer |  |  |  |
| ARKitTrack: A New Diverse Dataset for Tracking using Mobile RGB-D Data |  |  |  |
| A Dynamic Multi-Scale Voxel Flow Network for Video Prediction |  |  |  |
| Representation Learning for Visual Object Tracking by Masked Appearance Transfer |  |  |  |
| EqMotion: Equivariant Multi-Agent Motion Prediction with Invariant Interaction Reasoning |  |  |  |
| Semi-Supervised Video Inpainting with Cycle Consistency Constraints |  |  |  |
| Generalized Relation Modeling for Transformer Tracking |  |  |  |
| Breaking the ``Object`` in Video Object Segmentation |  |  |  |
| Unifying Short and Long-Term Tracking with Graph Hierarchies |  |  |  |
| Simple Cues Lead to a Strong Multi-Object Tracker |  |  |  |
| Unified Mask Embedding and Correspondence Learning for Self-Supervised Video Segmentation |  |  |  |
| MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors |  |  |  |
| SeqTrack: Sequence to Sequence Learning for Visual Object Tracking |  |  |  |
| Joint Visual Grounding and Tracking with Natural Language Specification |  |  |  |
| Boosting Video Object Segmentation via Space-Time Correspondence Learning |  |  |  |
| Visual Prompt Multi-Modal Tracking |  |  |  |
| OVTrack: Open-Vocabulary Multiple Object Tracking |  |  |  |
| TransFlow: Transformer as Flow Learner |  |  |  |
| Focus on Details: Online Multi-Object Tracking with Diverse Fine-grained Representation |  |  |  |
| Autoregressive Visual Tracking |  |  |  |
| Bootstrapping Objectness from Videos by Relaxed Common Fate and Visual Grouping |  |  |  |
| Tangentially Elongated Gaussian Belief Propagation for Event-based Incremental Optical Flow Estimation |  |  |  |
| Bridging Search Region Interaction with Template for RGB-T Tracking |  |  |  |
| Efficient RGB-T Tracking via Cross-Modality Distillation |  |  |  |
| MotionTrack: Learning Robust Short-Term and Long-Term Motions for Multi-Object Tracking |  |  |  |
| Self-Supervised AutoFlow |  |  |  |
| UTM: A Unified Multiple Object Tracking Model with Identity-Aware Feature Enhancement |  |  |  |
| BiFormer: Learning Bilateral Motion Estimation via Bilateral Transformer for 4K Video Frame Interpolation |  |  |  |
| Spatial-then-Temporal Self-Supervised Learning for Video Correspondence |  |  |  |
| BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects |  |  |  |
| MED-VT: Multiscale Encoder-Decoder Video Transformer with Application to Object Segmentation |  |  |  |
| Context-Aware Relative Object Queries to Unify Video Instance and Panoptic Segmentation |  |  |  |
| Unsupervised Space-Time Network for Temporally-Consistent Segmentation of Multiple Motions |  |  |  |
| Resource-Efficient RGBD Aerial Tracking |  |  |  |
| MMVC: Learned Multi-Mode Video Compression with Block-based Prediction Mode Selection and Density-Adaptive Entropy Coding |  |  |  |
| Streaming Video Model |  |  |  |
| Weakly Supervised Class-Agnostic Motion Prediction for Autonomous Driving |  |  |  |
| LSTFE-Net: Long Short-Term Feature Enhancement Network for Video Small Object Detection |  |  |  |
| DistractFlow: Improving Optical Flow Estimation via Realistic Distractions and Pseudo-Labeling |  |  |  |
| SCOTCH and SODA: A Transformer Video Shadow Detection Framework |  |  |  |
| ZBS: Zero-Shot Background Subtraction via Instance-Level Background Modeling and Foreground Selection |  |  |  |
| Frame-Event Alignment and Fusion Network for High Frame Rate Tracking |  |  |  |

### Vision Applications and Systems

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Context De-confounded Emotion Recognition |  |  |  |
| Intrinsic Physical Concepts Discovery with Object-Centric Predictive Models |  |  |  |
| Automatic High Resolution Wire Segmentation and Removal |  |  |  |
| Class Balanced Adaptive Pseudo Labeling for Federated Semi-Supervised Learning |  |  |  |
| Weakly Supervised Video Emotion Detection and Prediction via Cross-Modal Temporal Erasing Network |  |  |  |
| Probing Sentiment-Oriented Pre-Training Inspired by Human Sentiment Perception Mechanism |  |  |  |
| DIP: Dual Incongruity Perceiving Network for Sarcasm Detection |  |  |  |
| Adaptive Human Matting for Dynamic Videos |  |  |  |
| LayoutFormer++: Conditional Graphic Layout Generation via Constraint Serialization and Decoding Space Restriction |  |  |  |
| Prototypical Residual Networks for Anomaly Detection and Localization |  |  |  |
| Are Binary Annotations Sufficient? Video Moment Retrieval via Hierarchical Uncertainty-based Active Learning |  |  |  |
| Affordance Grounding from Demonstration Video to Target Image |  |  |  |
| Natural Language-Assisted Sign Language Recognition |  |  |  |
| CiCo: Domain-Aware Sign Language Retrieval via Cross-Lingual Contrastive Learning |  |  |  |
| Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation |  |  |  |
| Collaborative Noisy Label Cleaner: Learning Scene-Aware Trailers for Multi-Modal Highlight Detection in Movies |  |  |  |
| Open-Set Fine-Grained Retrieval via Prompting Vision-Language Evaluator |  |  |  |
| Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking |  |  |  |
| Visual Exemplar Driven Task-Prompting for Unified Perception in Autonomous Driving |  |  |  |
| Exploiting Unlabelled Photos for Stronger Fine-Grained SBIR |  |  |  |
| What Can Human Sketches Do for Object Detection? |  |  |  |
| Dynamic Conceptional Contrastive Learning for Generalized Category Discovery |  |  |  |
| Balanced Energy Regularization Loss for Out-of-Distribution Detection |  |  |  |
| Lite DETR : An Interleaved Multi-Scale Encoder for Efficient DETR |  |  |  |
| CLIP for All Things Zero-Shot Sketch-based Image Retrieval, Fine-Grained or Not |  |  |  |
| PosterLayout: A New Benchmark and Approach for Content-Aware Visual-Textual Presentation Layout |  |  |  |
| Re-Thinking Federated Active Learning based on Inter-Class Diversity |  |  |  |
| Consistent-Teacher: Towards Reducing Inconsistent Pseudo-Targets in Semi-Supervised Object Detection |  |  |  |
| Cloud-Device Collaborative Adaptation to Continual Changing Environments in the Real-World |  |  |  |
| Bridging Precision and Confidence: A Train-Time Loss for Calibrating Object Detection |  |  |  |
| AccelIR: Task-Aware Image Compression for Accelerating Neural Restoration |  |  |  |
| Multiclass Confidence and Localization Calibration for Object Detection |  |  |  |
| Auto-CARD: Efficient and Robust Codec Avatar Driving for Real-Time Mobile Telepresence |  |  |  |
| Deep Random Projector: Accelerated Deep Image Prior |  |  |  |
| SIEDOB: Semantic Image Editing by Disentangling Object and Background |  |  |  |

### Vision and Graphics

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| NeUDF: Leaning Neural Unsigned Distance Fields with Volume Rendering |  |  |  |
| <i>RaBit</i>: Pa<i>ra</i>metric Modeling of 3D <i>Bi</i>ped Car<i>t</i>oon Characters with a Topological-Consistent Dataset |  |  |  |
| DualVector: Unsupervised Vector Font Synthesis with Dual-Part Representation |  |  |  |
| Magic3D: High-Resolution Text-to-3D Content Creation |  |  |  |
| Pointersect: Neural Rendering with Cloud-Ray Intersection |  |  |  |
| Humans as Light Bulbs: 3D Human Reconstruction from Thermal Reflection |  |  |  |
| ABLE-NeRF: Attention-based Rendering with Learnable Embeddings for Neural Radiance Field |  |  |  |
| JAWS: Just A Wild Shot for Cinematic Transfer in Neural Radiance Fields |  |  |  |
| LayoutDM: Discrete Diffusion Model for Controllable Layout Generation |  |  |  |
| LightPainter: Interactive Portrait Relighting with Freehand Scribble |  |  |  |
| RODIN: A Generative Model for Sculpting 3D Digital Avatars using Diffusion |  |  |  |
| NerVE: Neural Volumetric Edges for Parametric Curve Extraction from Point Cloud |  |  |  |
| CAMS: CAnonicalized Manipulation Spaces for Category-Level Functional Hand-Object Manipulation Synthesis |  |  |  |
| VecFontSDF: Learning to Reconstruct and Synthesize High-Quality Vector Fonts via Signed Distance Functions |  |  |  |
| Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process |  |  |  |
| Latent-NeRF for Shape-guided Generation of 3D Shapes and Textures |  |  |  |
| Parts2Words: Learning Joint Embedding of Point Clouds and Texts by Bidirectional Matching between Parts and Words |  |  |  |
| Multiplicative Fourier Level of Detail |  |  |  |
| SECAD-Net: Self-Supervised CAD Reconstruction by Learning Sketch-Extrude Operations |  |  |  |
| Transfer4D: A Framework for Frugal Motion Capture and Deformation Transfer |  |  |  |
| Plateau-reduced Differentiable Path Tracing |  |  |  |
| 3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions |  |  |  |
| Differentiable Shadow Mapping for Efficient Inverse Graphics |  |  |  |
| Inverse Rendering of Translucent Objects using Physical and Neural Renderers |  |  |  |
| MAIR: Multi-View Attention Inverse Rendering with 3D Spatially-Varying Lighting Estimation |  |  |  |
| Neural Fourier Filter Bank |  |  |  |
| UMat: Uncertainty-Aware Single Image High Resolution Material Capture |  |  |  |
| Neural Congealing: Aligning Images to a Joint Semantic Atlas |  |  |  |
| PlenVDB: Memory Efficient VDB-based Radiance Fields for Fast Training and Rendering |  |  |  |
| VectorFloorSeg: Two-Stream Graph Attention Network for Vectorized Roughcast Floorplan Segmentation |  |  |  |
| Learning to Render Novel Views from Wide-Baseline Stereo Pairs |  |  |  |
| CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language |  |  |  |

### Robotics

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Object-Goal Visual Navigation via Effective Exploration of Relations among Historical Navigation States |  |  |  |
| TTA-COPE: Test-Time Adaptation for Category-Level Object Pose Estimation |  |  |  |
| Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation using Scene Object Spectrum Grounding |  |  |  |
| Learning Human-to-Robot Handovers from Point Clouds |  |  |  |
| Robot Structure Prior Guided Temporal Attention for Camera-to-Robot Pose Estimation from Image Sequence |  |  |  |
| PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations |  |  |  |
| DexArt: Benchmarking Generalizable Dexterous Manipulation with Articulated Objects |  |  |  |
| PyPose: A Library for Robot Learning with Physics-based Optimization |  |  |  |
| Target-Referenced Reactive Grasping for Dynamic Objects |  |  |  |
| Autonomous Manipulation Learning for Similar Deformable Objects via only One Demonstration |  |  |  |
| Renderable Neural Radiance Map for Visual Navigation |  |  |  |
| Efficient Map Sparsification based on 2D and 3D Discretized Grids |  |  |  |
| Policy Adaptation from Foundation Model Feedback |  |  |  |
| NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis |  |  |  |
| Markerless Camera-to-Robot Pose Estimation via Self-Supervised Sim-to-Real Transfer |  |  |  |
| Affordances from Human Videos as a Versatile Representation for Robotics |  |  |  |
| DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization |  |  |  |
| GrowSP: Unsupervised Semantic Segmentation of 3D Point Clouds |  |  |  |
| Neural Volumetric Memory for Visual Locomotion Control |  |  |  |
| Multi-Object Manipulation via Object-Centric Neural Scattering Functions |  |  |  |
| Local-guided Global: Paired Similarity Representation for Visual Reinforcement Learning |  |  |  |
| HypLiLoc: Towards Effective LiDAR Pose Regression with Hyperbolic Fusion |  |  |  |
| Imitation Learning as State Matching via Differentiable Physics |  |  |  |

### Transparency, Fairness, Accountability, Privacy, Ethics in Vision

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Effective Ambiguity Attack Against Passport-based DNN Intellectual Property Protection Schemes through Fully Connected Layer Substitution |  |  |  |
| Progressive Open Space Expansion for Open-Set Model Attribution |  |  |  |
| Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack |  |  |  |
| DartBlur: Privacy Preservation with Detection Artifact Suppression |  |  |  |
| Reinforcement Learning-based Black-Box Model Inversion Attacks |  |  |  |
| Model-Agnostic Gender Debiased Image Captioning |  |  |  |
| Uncurated Image-Text Datasets: Shedding Light on Demographic Bias |  |  |  |
| AltFreezing for more General Video Face Forgery Detection |  |  |  |
| Make Landscape Flatter in Differentially Private Federated Learning |  |  |  |
| DynaFed: Tackling Client Data Heterogeneity with Global Dynamics |  |  |  |
| Re-Thinking Model Inversion Attacks Against Deep Neural Networks |  |  |  |
| Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models |  |  |  |
| TrojViT: Trojan Insertion in Vision Transformers |  |  |  |
| Difficulty-based Sampling for Debiased Contrastive Representation Learning |  |  |  |
| Model Barrier: A Compact Un-Transferable Isolation Domain for Model Intellectual Property Protection |  |  |  |
| Fair Scratch Tickets: Finding Fair Sparse Networks without Weight Training |  |  |  |
| CLIP2Protect: Protecting Facial Privacy using Text-guided Makeup via Adversarial Latent Search |  |  |  |
| Bias in Pruned Vision Models: In-Depth Analysis and Countermeasures |  |  |  |
| Learning to Generate Image Embeddings with User-Level Differential Privacy |  |  |  |
| Bias Mimicking: A Simple Sampling Approach for Bias Mitigation |  |  |  |
| CaPriDe Learning: Confidential and Private Decentralized Learning based on Encryption-Friendly Distillation Loss |  |  |  |
| DeAR: Debiasing Vision-Language Models with Additive Residuals |  |  |  |
| Deep Deterministic Uncertainty: A New Simple Baseline |  |  |  |
| Manipulating Transfer Learning for Property Inference |  |  |  |
| Training Debiased Subnetworks with Contrastive Weight Pruning |  |  |  |
| Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models |  |  |  |
| STDLens: Model Hijacking-Resilient Federated Learning for Object Detection |  |  |  |
| Architectural Backdoors in Neural Networks |  |  |  |
| MEDIC: Remove Model Backdoors via Importance Driven Cloning |  |  |  |
| Learning Debiased Representations via Conditional Attribute Interpolation |  |  |  |

### Explainable Computer Vision

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Are Data-Driven Explanations Robust Against Out-of-Distribution Data? | [![GitHub](https://img.shields.io/github/stars/tangli-udel/DRE)](https://github.com/tangli-udel/DRE) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Are_Data-Driven_Explanations_Robust_Against_Out-of-Distribution_Data_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16390-b31b1b.svg)](http://arxiv.org/abs/2303.16390) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=logVgiC4x54) |
| Uncertainty-Aware Unsupervised Image Deblurring with Deep Residual Prior | [![GitHub](https://img.shields.io/github/stars/xl-tang3/UAUDeblur)](https://github.com/xl-tang3/UAUDeblur)|[![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Uncertainty-Aware_Unsupervised_Image_Deblurring_With_Deep_Residual_Prior_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.05361-b31b1b.svg)](http://arxiv.org/abs/2210.05361) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9ZfN5Jt7vVA) |
| Teaching Matters: Investigating the Role of Supervision in Vision Transformers | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://www.cs.umd.edu/~sakshams/vit_analysis/) <br /> [![GitHub](https://img.shields.io/github/stars/mwalmer-umd/vit_analysis)](https://github.com/mwalmer-umd/vit_analysis) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Walmer_Teaching_Matters_Investigating_the_Role_of_Supervision_in_Vision_Transformers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03862-b31b1b.svg)](http://arxiv.org/abs/2212.03862) | :heavy_minus_sign: |
| Adversarial Counterfactual Visual Explanations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://guillaumejs2403.github.io/projects/ace.html) <br /> [![GitHub](https://img.shields.io/github/stars/guillaumejs2403/ACE)](https://github.com/guillaumejs2403/ACE) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jeanneret_Adversarial_Counterfactual_Visual_Explanations_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09962-b31b1b.svg)](http://arxiv.org/abs/2303.09962) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ykTUSSTZOME) |
| SketchXAI: A First Look at Explainability for Human Sketches | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sketchxai.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/WinKawaks/SketchXAI)](https://github.com/WinKawaks/SketchXAI) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qu_SketchXAI_A_First_Look_at_Explainability_for_Human_Sketches_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11744-b31b1b.svg)](http://arxiv.org/abs/2304.11744) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RcY3NJlTGyE) |
| Doubly Right Object Recognition: A why Prompt for Visual Rationales |  |  |  |
| Overlooked Factors in Concept-based Explanations: Dataset Choice, Concept Learnability, and Human Capability |  |  |  |
| Initialization Noise in Image Gradients and Saliency Maps |  |  |  |
| Learning Bottleneck Concepts in Image Classification |  |  |  |
| Zero-Shot Model Diagnosis |  |  |  |
| OCTET: Object-Aware Counterfactual Explanations |  |  |  |
| X-Pruner: eXplainable Pruning for Vision Transformers |  |  |  |
| Don't Lie to Me! Robust and Efficient Explainability with Verified Perturbation Analysis |  |  |  |
| CRAFT: Concept Recursive Activation FacTorization for Explainability |  |  |  |
| Grounding Counterfactual Explanation of Image Classifiers to Textual Concept Space |  |  |  |
| Explaining Image Classifiers with Multiscale Directional Image Representation |  |  |  |
| IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients |  |  |  |
| Language in a Bottle: Language Model Guided Concept Bottlenecks for Interpretable Image Classification |  |  |  |
| Gradient-based Uncertainty Attribution for Explainable Bayesian Deep Learning |  |  |  |
| PIP-Net: Patch-based Intuitive Prototypes for Interpretable Image Classification |  |  |  |
| Shortcomings of Top-Down Randomization-based Sanity Checks for Evaluations of Deep Neural Network Explanations |  |  |  |
| Spatial-Temporal Concept based Explanation of 3D ConvNets |  |  |  |
| A Practical Upper Bound for the Worst-Case Attribution Deviations |  |  |  |
| Adversarial Normalization: I can Visualize Everything (ICE) |  |  |  |

### Embodied Vision: Active Agents, Simulation

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Open-World Multi-Task Control through Goal-Aware Representation Learning and Adaptive Horizon Prediction |  |  |  |
| Layout-based Causal Inference for Object Navigation |  |  |  |
| EC<sup>2</sup>: Emergent Communication for Embodied Control |  |  |  |
| GAPartNet: Cross-Category Domain-Generalizable Object Perception and Manipulation via Generalizable and Actionable Parts |  |  |  |
| Phone2Proc: Bringing Robust Robots into Our Chaotic World |  |  |  |
| PIRLNav: Pretraining with Imitation and RL Finetuning for ObjectNav |  |  |  |
| CoWs on PASTURE: Baselines and Benchmarks for Language-Driven Zero-Shot Object Navigation |  |  |  |
| 3D-Aware Object Goal Navigation via Simultaneous Exploration and Identification |  |  |  |
| Modality-Invariant Visual Odometry for Embodied Vision |  |  |  |
| UniDexGrasp: Universal Robotic Dexterous Grasping via Learning Diverse Proposal Generation and Goal-Conditioned Policy |  |  |  |
| EXCALIBUR: Encouraging and Evaluating Embodied Exploration |  |  |  |
| Leverage Interactive Affinity for Affordance Learning |  |  |  |
| LANA: A Language-Capable Navigator for Instruction Following and Generation |  |  |  |
| Galactic: Scaling End-to-End Reinforcement Learning for Rearrangement at 100k Steps-Per-Second |  |  |  |

### Document Analysis and Understanding

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Towards Flexible Multi-Modal Document Models |  |  |  |
| Improving Table Structure Recognition with Visual-Alignment Sequential Coordinate Modeling |  |  |  |
| Unifying Layout Generation with a Decoupled Diffusion Model |  |  |  |
| Conditional Text Image Generation with Diffusion Models |  |  |  |
| Turning a CLIP Model into a Scene Text Detector |  |  |  |
| Unifying Vision, Text, and Layout for Universal Document Processing |  |  |  |
| Modeling Entities as Semantic Points for Visual Information Extraction in the Wild |  |  |  |
| GeoLayoutLM: Geometric Pre-Training for Visual Information Extraction |  |  |  |
| Handwritten Text Generation from Visual Archetypes |  |  |  |
| Towards Robust Tampered Text Detection in Document Image: New dataset and New Solution |  |  |  |
| M<sup>6<sup>Doc: A Large-Scale Multi-Format, Multi-Type, Multi-Layout, Multi-Language, Multi-Annotation Category Dataset for Modern Document Layout Analysis |  |  |  |
| Disentangling Writer and Character Styles for Handwriting Generation |  |  |  |

### Machine Learning (other than Deep Learning)

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Deep Incomplete Multi-View Clustering with Cross-View Partial Sample and Prototype Alignment |  |  |  |
| Towards Better Decision Forests: Forest Alternating Optimization |  |  |  |
| Class Adaptive Network Calibration |  |  |  |
| Defining and Quantifying the Emergence of Sparse Concepts in DNNs |  |  |  |
| MOT Masked Optimal Transport for Partial Domain Adaptation |  |  |  |
| Adaptive Graph Convolutional Subspace Clustering |  |  |  |
| Reliable and Interpretable Personalized Federated Learning |  |  |  |
| Confidence-Aware Personalized Federated Learning via Variational Expectation Maximization |  |  |  |
| Efficient Verification of Neural Networks against LVM-based Specifications |  |  |  |
| You Are Catching My Attention: Are Vision Transformers Bad Learners under Backdoor Attacks? |  |  |  |
| Leveraging Inter-Rater Agreement for Classification in the Presence of Noisy Labels |  |  |  |
| Sliced Optimal Partial Transport |  |  |  |
| A Meta-Learning Approach to Predicting Performance and Data Requirements |  |  |  |
| Towards Effective Visual Representations for Partial-Label Learning |  |  |  |

### Physics-based Vision and Shape-from-X

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Learning Anchor Transformations for 3D Garment Animation |  |  |  |
| High-Fidelity Event-Radiance Recovery via Transient Event Frequency |  |  |  |
| Complementary Intrinsics from Neural Radiance Fields and CNNs for Outdoor Scene Relighting |  |  |  |
| Fresnel Microfacet BRDF: Unification of Polari-Radiometric Surface-Body Reflection |  |  |  |
| Event-based Shape from Polarization |  |  |  |
| Weakly-Supervised Single-View Image Relighting |  |  |  |
| DANI-Net: Uncalibrated Photometric Stereo by Differentiable Shadow Handling, Anisotropic Reflectance Modeling, and Neural Inverse Rendering |  |  |  |
| Learning Accurate 3D Shape based on Stereo Polarimetric Imaging |  |  |  |
| Visibility Constrained Wide-Band Illumination Spectrum Design for Seeing-in-the-Dark |  |  |  |
| Light Source Separation and Intrinsic Image Decomposition under AC Illumination |  |  |  |
| OReX: Object Reconstruction from Planar Cross-Sections using Neural Fields |  |  |  |
| Unsupervised Intrinsic Image Decomposition with LiDAR Intensity |  |  |  |

### Biometrics

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Instance-Aware Domain Generalization for Face Anti-Spoofing |  [![GitHub](https://img.shields.io/github/stars/qianyuzqy/IADG)](https://github.com/qianyuzqy/IADG) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Instance-Aware_Domain_Generalization_for_Face_Anti-Spoofing_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05640-b31b1b.svg)](https://arxiv.org/abs/2304.05640) | ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=p8IrAiEgfiE) |
| OpenGait: Revisiting Gait Recognition Toward Better Practicality | [![GitHub](https://img.shields.io/github/stars/qianyuzqy/IADG)](https://github.com/ShiqiYu/OpenGait) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_OpenGait_Revisiting_Gait_Recognition_Towards_Better_Practicality_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06597-b31b1b.svg)](https://arxiv.org/abs/2211.06597) | :heavy_minus_sign: |
| Recognizability Embedding Enhancement for Very Low-Resolution Face Recognition and Quality Estimation | :heavy_minus_sign: |  [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chai_Recognizability_Embedding_Enhancement_for_Very_Low-Resolution_Face_Recognition_and_Quality_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10066-b31b1b.svg)](https://arxiv.org/abs/2304.10066) | ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=e8MtMhkxE7M) |
| GaitGCI: Generative Counterfactual Intervention for Gait Recognition | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dou_GaitGCI_Generative_Counterfactual_Intervention_for_Gait_Recognition_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.03428-b31b1b.svg)](https://arxiv.org/abs/2306.03428) | ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=95QcfX0Pbi0) |
| Rethinking Domain Generalization for Face Anti-Spoofing: Separability and Alignment | [![GitHub](https://img.shields.io/github/stars/sunyiyou/SAFAS)](https://github.com/sunyiyou/SAFAS) |[![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Rethinking_Domain_Generalization_for_Face_Anti-Spoofing_Separability_and_Alignment_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13662-b31b1b.svg)](https://arxiv.org/abs/2303.13662) | ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u9APqG02AeQ) |
| AstroNet: When Astrocyte Meets Artificial Neural Network | :heavy_minus_sign: |  [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Han_AstroNet_When_Astrocyte_Meets_Artificial_Neural_Network_CVPR_2023_paper.pdf)| :heavy_minus_sign: |
| DCFace: Synthetic Face Generation with Dual Condition Diffusion Model | [![GitHub](https://img.shields.io/github/stars/mk-minchul/dcface)](https://github.com/mk-minchul/dcface) | |[![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_DCFace_Synthetic_Face_Generation_With_Dual_Condition_Diffusion_Model_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.07060-b31b1b.svg)](https://arxiv.org/abs/2304.07060)| ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jm1bDutCM80) |
| LidarGait: Benchmarking 3D Gait Recognition with Point Clouds | ![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lidargait.github.io/) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_LidarGait_Benchmarking_3D_Gait_Recognition_With_Point_Clouds_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10598-b31b1b.svg)](https://arxiv.org/abs/2211.10598) | :heavy_minus_sign: |
| CR-FIQA: Face Image Quality Assessment by Learning Sample Relative Classifiability | [![GitHub](https://img.shields.io/github/stars/fdbtrs/CR-FIQA)](https://github.com/fdbtrs/CR-FIQA) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Boutros_CR-FIQA_Face_Image_Quality_Assessment_by_Learning_Sample_Relative_Classifiability_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2112.06592-b31b1b.svg)](https://arxiv.org/abs/2112.06592)| ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Qf_F1YLql6I) |
| Dual-Bridging with Adversarial Noise Generation for Domain Adaptive rPPG Estimation | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Dual-Bridging_With_Adversarial_Noise_Generation_for_Domain_Adaptive_rPPG_Estimation_CVPR_2023_paper.pdf) | ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=n6jns55AyGw) |
| Evading Forensic Classifiers with Attribute-Conditioned Adversarial Faces | [![GitHub](https://img.shields.io/github/stars/koushiksrivats/face_attribute_attack)](https://github.com/koushiksrivats/face_attribute_attack) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shamshad_Evading_Forensic_Classifiers_With_Attribute-Conditioned_Adversarial_Faces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.13091-b31b1b.svg)](https://arxiv.org/abs/2306.13091)| ![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZkPuU3lIK9U) |

### Optimization Methods (other than Deep Learning)

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Pose Synchronization under Multiple Pair-Wise Relative Poses |  |  |  |
| Adaptive Global Decay Process for Event Cameras |  |  |  |
| Wide-Angle Rectification via Content-Aware Conformal Mapping |  |  |  |
| On the Convergence of IRLS and its Variants in Outlier-Robust Estimation |  |  |  |
| A General Regret Bound of Preconditioned Gradient Method for DNN Training |  |  |  |
| Robust and Scalable Gaussian Process Regression and its Applications |  |  |  |
| EMT-NAS: Transferring Architectural Knowledge between Tasks from Different Datasets |  |  |  |
| Transformer-based Learned Optimization |  |  |  |
| Efficient Robust Principal Component Analysis via Block Krylov Iteration and CUR Decomposition |  |  |  |
| Solving Relaxations of MAP-MRF Problems: Combinatorial In-Face Frank-Wolfe Directions |  |  |  |
| Robust Generalization against Photon-Limited Corruptions via Worst-Case Sharpness Minimization |  |  |  |
| Elastic Aggregation for Federated Optimization |  |  |  |

### Photogrammetry and Remote Sensing

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| MethaneMapper: Spectral Absorption Aware Hyperspectral Transformer for Methane Detection |  |  |  |
| Probability-based Global Cross-Modal Upsampling for Pansharpening |  |  |  |
| Learning Correspondence Uncertainty via Differentiable Nonlinear Least Squares |  |  |  |
| Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection |  |  |  |
| ViTs for SITS: Vision Transformers for Satellite Image Time Series |  |  |  |
| Quantum-Inspired Spectral-Spatial Pyramid Network for Hyperspectral Image Classification |  |  |  |
| TopDiG: Class-Agnostic Topological Directional Graph Extraction from Remote Sensing Images |  |  |  |
| OmniCity: Omnipotent City Understanding with Multi-Level and Multi-View Images |  |  |  |

### Computer Vision Theory

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Neural Dependencies Emerging from Learning Massive Categories |  |  |  |
| Gaussian Label Distribution Learning for Spherical Image Object Detection |  |  |  |
| Unbalanced Optimal Transport: A Unified Framework for Object Detection |  |  |  |
| DropKey for Vision Transformer |  |  |  |
| SplineCam: Exact Visualization and Characterization of Deep Network Geometry and Decision Boundaries |  |  |  |

### Computer Vision for Social Good

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Unlearnable Clusters: Towards Label-Agnostic Unlearnable Examples | [![GitHub](https://img.shields.io/github/stars/jiamingzhang94/Unlearnable-Clusters)](https://github.com/jiamingzhang94/Unlearnable-Clusters) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Unlearnable_Clusters_Towards_Label-Agnostic_Unlearnable_Examples_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01217-b31b1b.svg)](http://arxiv.org/abs/2301.01217) | :heavy_minus_sign: |
| On the Difficulty of Unpaired Infrared-to-Visible Video Translation: Fine-Grained Content-Rich Patches Transfer | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_On_the_Difficulty_of_Unpaired_Infrared-to-Visible_Video_Translation_Fine-Grained_Content-Rich_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ENiyidPXqb8) |
| SCConv: Spatial and Channel Reconstruction Convolution for Feature Redundancy | :heavy_minus_sign: | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_SCConv_Spatial_and_Channel_Reconstruction_Convolution_for_Feature_Redundancy_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YDV_qAw9c1k) |
| TruFor: Leveraging All-Round Clues for Trustworthy Image Forgery Detection and Localization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://grip-unina.github.io/TruFor/) <br /> [![GitHub](https://img.shields.io/github/stars/grip-unina/TruFor)](https://github.com/grip-unina/TruFor) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Guillaro_TruFor_Leveraging_All-Round_Clues_for_Trustworthy_Image_Forgery_Detection_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10957-b31b1b.svg)](http://arxiv.org/abs/2212.10957) | :heavy_minus_sign: |
| Angelic Patches for Improving Third-Party Object Detector Performance | [![GitHub](https://img.shields.io/github/stars/averysi224/angelic_patches)](https://github.com/averysi224/angelic_patches) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Si_Angelic_Patches_for_Improving_Third-Party_Object_Detector_Performance_CVPR_2023_paper.pdf) | :heavy_minus_sign: |

### Others

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" />
</a>

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| A Bag-of-Prototypes Representation for Dataset-Level Applications |  |  |  |
| Learning to Retain while Acquiring: Combating Distribution-Shift in Adversarial Data-Free Knowledge Distillation |  |  |  |
| Label Information Bottleneck for Label Enhancement |  |  |  |
| DISC: Learning from Noisy Labels via Dynamic Instance-Specific Selection and Correction |  |  |  |
| Restoration of Hand-Drawn Architectural Drawings using Latent Space Mapping with Degradation Generator |  |  |  |
| DaFKD: Domain-Aware Federated Knowledge Distillation |  |  |  |
| Enhanced Stable View Synthesis |  |  |  |
| ScaleFL: Resource-Adaptive Federated Learning with Heterogeneous Clients |  |  |  |
| GradMA: A Gradient-Memory-based Accelerated Federated Learning with Alleviated Catastrophic Forgetting |  |  |  |
| High-Resolution Image Reconstruction with Latent Diffusion Models from Human Brain Activity |  |  |  |
| A Unified Knowledge Distillation Framework for Deep Directed Graphical Models |  |  |  |
| How to Prevent the Poor Performance Clients for Personalized Federated Learning? |  |  |  |
