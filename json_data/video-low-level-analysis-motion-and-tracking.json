[
  {
    "title": "Uncovering the Missing Pattern: Unified Framework Towards Trajectory Imputation and Prediction",
    "base_url": null,
    "title_page": null,
    "repo": "colorfulfuture/GC-VRNN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Uncovering_the_Missing_Pattern_Unified_Framework_Towards_Trajectory_Imputation_and_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16005",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "fneLvMJIALo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Tracking Multiple Deformable Objects in Egocentric Videos",
    "base_url": null,
    "title_page": null,
    "repo": "Mingzhen-Huang/DETracker",
    "web_page": null,
    "github_page": "https://mingzhenhuang.com/projects/detracker.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Tracking_Multiple_Deformable_Objects_in_Egocentric_Videos_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Tracking through Containers and Occluders in the Wild",
    "base_url": null,
    "title_page": null,
    "repo": "basilevh/tcow",
    "web_page": "https://tcow.cs.columbia.edu/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Van_Hoorick_Tracking_Through_Containers_and_Occluders_in_the_Wild_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.03052",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "WODiwfq9d2g",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "TarViS: A Unified Approach for Target-based Video Segmentation <br/> <img alt=\"CVPR - Highlight\" src=\"https://img.shields.io/badge/CVPR-Highlight-FFFF00\"/>",
    "base_url": null,
    "title_page": null,
    "repo": "Ali2500/TarViS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Athar_TarViS_A_Unified_Approach_for_Target-Based_Video_Segmentation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.02657",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qecFRmSYq40",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "VideoTrack: Learning to Track Objects via Video Transformer",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_VideoTrack_Learning_To_Track_Objects_via_Video_Transformer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "v-SvFZ0FrF8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "ARKitTrack: A New Diverse Dataset for Tracking using Mobile RGB-D Data",
    "base_url": null,
    "title_page": null,
    "repo": "lawrence-cj/ARKitTrack",
    "web_page": null,
    "github_page": "https://arkittrack.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_ARKitTrack_A_New_Diverse_Dataset_for_Tracking_Using_Mobile_RGB-D_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13885",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "r02f6egcpdw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "A Dynamic Multi-Scale Voxel Flow Network for Video Prediction <br/> <img alt=\"CVPR - Highlight\" src=\"https://img.shields.io/badge/CVPR-Highlight-FFFF00\"/>",
    "base_url": null,
    "title_page": null,
    "repo": "megvii-research/CVPR2023-DMVFN",
    "web_page": null,
    "github_page": "https://huxiaotaostasy.github.io/DMVFN/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_A_Dynamic_Multi-Scale_Voxel_Flow_Network_for_Video_Prediction_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.09875",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "rlghCGbAqUo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Representation Learning for Visual Object Tracking by Masked Appearance Transfer",
    "base_url": null,
    "title_page": null,
    "repo": "difhnp/MAT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Representation_Learning_for_Visual_Object_Tracking_by_Masked_Appearance_Transfer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "EqMotion: Equivariant Multi-Agent Motion Prediction with Invariant Interaction Reasoning",
    "base_url": null,
    "title_page": null,
    "repo": "MediaBrain-SJTU/EqMotion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_EqMotion_Equivariant_Multi-Agent_Motion_Prediction_With_Invariant_Interaction_Reasoning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10876",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ROactuGU1YA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Semi-Supervised Video Inpainting with Cycle Consistency Constraints",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Semi-Supervised_Video_Inpainting_With_Cycle_Consistency_Constraints_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2208.06807",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Generalized Relation Modeling for Transformer Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "Little-Podi/GRM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Generalized_Relation_Modeling_for_Transformer_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16580",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "bQKN3HV-8XI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Breaking the <code>Object</code> in Video Object Segmentation",
    "base_url": null,
    "title_page": null,
    "repo": "TRI-ML/VOST",
    "web_page": "https://www.vostdataset.org/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tokmakov_Breaking_the_Object_in_Video_Object_Segmentation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.06200",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "SBdA6HCXf_M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Unifying Short and Long-Term Tracking with Graph Hierarchies",
    "base_url": null,
    "title_page": null,
    "repo": "dvl-tum/SUSHI",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cetintas_Unifying_Short_and_Long-Term_Tracking_With_Graph_Hierarchies_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.03038",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Q1TiZukGQYQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Simple Cues Lead to a Strong Multi-Object Tracker",
    "base_url": null,
    "title_page": null,
    "repo": "dvl-tum/GHOST",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Seidenschwarz_Simple_Cues_Lead_to_a_Strong_Multi-Object_Tracker_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2206.04656",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "3gozhzOHwE0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Unified Mask Embedding and Correspondence Learning for Self-Supervised Video Segmentation",
    "base_url": null,
    "title_page": null,
    "repo": "0liliulei/Mask-VOS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Unified_Mask_Embedding_and_Correspondence_Learning_for_Self-Supervised_Video_Segmentation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10100",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "LJj4frqBgqY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained Object Detectors",
    "base_url": null,
    "title_page": null,
    "repo": "megvii-research/MOTRv2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_MOTRv2_Bootstrapping_End-to-End_Multi-Object_Tracking_by_Pretrained_Object_Detectors_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.09791",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "7WnQgQLQLE4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "SeqTrack: Sequence to Sequence Learning for Visual Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "microsoft/VideoX",
    "web_page": null,
    "github_page": "https://github.com/microsoft/VideoX/tree/master/SeqTrack",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_SeqTrack_Sequence_to_Sequence_Learning_for_Visual_Object_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.14394",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jb_zZqrEcJA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Joint Visual Grounding and Tracking with Natural Language Specification",
    "base_url": null,
    "title_page": null,
    "repo": "lizhou-cs/JointNLT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Joint_Visual_Grounding_and_Tracking_With_Natural_Language_Specification_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12027",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "kUN7tchiG2Q",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Boosting Video Object Segmentation via Space-Time Correspondence Learning",
    "base_url": null,
    "title_page": null,
    "repo": "wenguanwang/VOS_Correspondence",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Boosting_Video_Object_Segmentation_via_Space-Time_Correspondence_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.06211",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Visual Prompt Multi-Modal Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "jiawen-zhu/ViPT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Visual_Prompt_Multi-Modal_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10826",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "OVTrack: Open-Vocabulary Multiple Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "SysCV/ovtrack",
    "web_page": "https://www.vis.xyz/pub/ovtrack/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_OVTrack_Open-Vocabulary_Multiple_Object_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.08408",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "tMQ_sh0JbpY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "TransFlow: Transformer as Flow Learner <br/> <img alt=\"CVPR - Highlight\" src=\"https://img.shields.io/badge/CVPR-Highlight-FFFF00\"/>",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_TransFlow_Transformer_As_Flow_Learner_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.11523",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "xbnyj9wspqA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Focus on Details: Online Multi-Object Tracking with Diverse Fine-grained Representation",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_Focus_on_Details_Online_Multi-Object_Tracking_With_Diverse_Fine-Grained_Representation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.14589",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "j4TJJEsqllM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Autoregressive Visual Tracking <br/> <img alt=\"CVPR - Highlight\" src=\"https://img.shields.io/badge/CVPR-Highlight-FFFF00\"/>",
    "base_url": null,
    "title_page": null,
    "repo": "MIV-XJTU/ARTrack",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "fOkpG5SNaX0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Bootstrapping Objectness from Videos by Relaxed Common Fate and Visual Grouping",
    "base_url": null,
    "title_page": null,
    "repo": "TonyLianLong/RCF-UnsupVideoSeg",
    "web_page": null,
    "github_page": "https://rcf-video.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lian_Bootstrapping_Objectness_From_Videos_by_Relaxed_Common_Fate_and_Visual_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.08025",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "dyaDEvT4YkY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Tangentially Elongated Gaussian Belief Propagation for Event-based Incremental Optical Flow Estimation",
    "base_url": null,
    "title_page": null,
    "repo": "DensoITLab/tegbp",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Nagata_Tangentially_Elongated_Gaussian_Belief_Propagation_for_Event-Based_Incremental_Optical_Flow_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "rClkk5MY33A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Bridging Search Region Interaction with Template for RGB-T Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "RyanHTR/TBSI",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hui_Bridging_Search_Region_Interaction_With_Template_for_RGB-T_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Efficient RGB-T Tracking via Cross-Modality Distillation <br/> <img alt=\"CVPR - Highlight\" src=\"https://img.shields.io/badge/CVPR-Highlight-FFFF00\"/>",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Efficient_RGB-T_Tracking_via_Cross-Modality_Distillation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "isTrxcb1dVs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "MotionTrack: Learning Robust Short-Term and Long-Term Motions for Multi-Object Tracking",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_MotionTrack_Learning_Robust_Short-Term_and_Long-Term_Motions_for_Multi-Object_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10404",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "HaS9cM75J7Y",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Self-Supervised AutoFlow",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Self-Supervised_AutoFlow_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.01762",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "e8EuIgzJeYc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "UTM: A Unified Multiple Object Tracking Model with Identity-Aware Feature Enhancement",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/You_UTM_A_Unified_Multiple_Object_Tracking_Model_With_Identity-Aware_Feature_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qLR4WJVi5O4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "BiFormer: Learning Bilateral Motion Estimation via Bilateral Transformer for 4K Video Frame Interpolation",
    "base_url": null,
    "title_page": null,
    "repo": "JunHeum/BiFormer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Park_BiFormer_Learning_Bilateral_Motion_Estimation_via_Bilateral_Transformer_for_4K_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.02225",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Spatial-then-Temporal Self-Supervised Learning for Video Correspondence",
    "base_url": null,
    "title_page": null,
    "repo": "qianduoduolr/Spa-then-Temp",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Spatial-Then-Temporal_Self-Supervised_Learning_for_Video_Correspondence_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2209.07778",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "tN-PRaLS_pw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects",
    "base_url": null,
    "title_page": null,
    "repo": "NVlabs/BundleSDF",
    "web_page": null,
    "github_page": "https://bundlesdf.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_BundleSDF_Neural_6-DoF_Tracking_and_3D_Reconstruction_of_Unknown_Objects_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14158",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "XH5t0wEH3d0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "MED-VT: Multiscale Encoder-Decoder Video Transformer with Application to Object Segmentation",
    "base_url": null,
    "title_page": null,
    "repo": "rkyuca/medvt",
    "web_page": null,
    "github_page": "https://rkyuca.github.io/medvt/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Karim_MED-VT_Multiscale_Encoder-Decoder_Video_Transformer_With_Application_To_Object_Segmentation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.05930",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "nVb9aVPyr4I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Context-Aware Relative Object Queries to Unify Video Instance and Panoptic Segmentation",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Choudhuri_Context-Aware_Relative_Object_Queries_To_Unify_Video_Instance_and_Panoptic_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "N6A9Q8Nji7M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Unsupervised Space-Time Network for Temporally-Consistent Segmentation of Multiple Motions <br/> <img alt=\"CVPR - Highlight\" src=\"https://img.shields.io/badge/CVPR-Highlight-FFFF00\"/>",
    "base_url": null,
    "title_page": null,
    "repo": "Etienne-Meunier-Inria/ST-Space-Time-Flow-Segmentation",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Meunier_Unsupervised_Space-Time_Network_for_Temporally-Consistent_Segmentation_of_Multiple_Motions_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "fZHEOJeDQoc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Resource-Efficient RGBD Aerial Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "yjybuaa/RGBDAerialTracking",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Resource-Efficient_RGBD_Aerial_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "yJ4Hsh8S2iA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "MMVC: Learned Multi-Mode Video Compression with Block-based Prediction Mode Selection and Density-Adaptive Entropy Coding",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_MMVC_Learned_Multi-Mode_Video_Compression_With_Block-Based_Prediction_Mode_Selection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.02273",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "mt7smZiL4CA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Streaming Video Model",
    "base_url": null,
    "title_page": null,
    "repo": "yuzhms/Streaming-Video-Model",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Streaming_Video_Model_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17228",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Weakly Supervised Class-Agnostic Motion Prediction for Autonomous Driving",
    "base_url": null,
    "title_page": null,
    "repo": "L1bra1/WeakMotion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Weakly_Supervised_Class-Agnostic_Motion_Prediction_for_Autonomous_Driving_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Q6CcZ6uPqhI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "LSTFE-Net: Long Short-Term Feature Enhancement Network for Video Small Object Detection",
    "base_url": null,
    "title_page": null,
    "repo": "xiaojs18/LSTFE-Net",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_LSTFE-NetLong_Short-Term_Feature_Enhancement_Network_for_Video_Small_Object_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "f3vX21qP_hA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "DistractFlow: Improving Optical Flow Estimation via Realistic Distractions and Pseudo-Labeling",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Jeong_DistractFlow_Improving_Optical_Flow_Estimation_via_Realistic_Distractions_and_Pseudo-Labeling_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14078",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "SCOTCH and SODA: A Transformer Video Shadow Detection Framework",
    "base_url": null,
    "title_page": null,
    "repo": "lihaoliu-cambridge/scotch-and-soda",
    "web_page": null,
    "github_page": "https://lihaoliu-cambridge.github.io/scotch_and_soda/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_SCOTCH_and_SODA_A_Transformer_Video_Shadow_Detection_Framework_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.06885",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "ZBS: Zero-Shot Background Subtraction via Instance-Level Background Modeling and Foreground Selection",
    "base_url": null,
    "title_page": null,
    "repo": "CASIA-IVA-Lab/ZBS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/An_ZBS_Zero-Shot_Background_Subtraction_via_Instance-Level_Background_Modeling_and_Foreground_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14679",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-WuowqTbFIw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  },
  {
    "title": "Frame-Event Alignment and Fusion Network for High Frame Rate Tracking",
    "base_url": null,
    "title_page": null,
    "repo": "Jee-King/AFNet",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Frame-Event_Alignment_and_Fusion_Network_for_High_Frame_Rate_Tracking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.15688",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "W7EjOiGMiAQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Low-Level Analysis, Motion, and Tracking"
  }
]