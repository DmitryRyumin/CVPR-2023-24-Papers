[
  {
    "title": "Open Set Action Recognition via Multi-Label Evidential Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "charliezhaoyinpeng/mule",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Open_Set_Action_Recognition_via_Multi-Label_Evidential_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12698",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "S185R1vT2Qk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "FLAG3D: A 3D Fitness Activity Dataset with Language Instruction",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://andytang15.github.io/FLAG3D/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_FLAG3D_A_3D_Fitness_Activity_Dataset_With_Language_Instruction_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04638",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "CgdRmk0BVvM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "MoLo: Motion-Augmented Long-Short Contrastive Learning for Few-Shot Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "alibaba-mmai-research/MoLo",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_MoLo_Motion-Augmented_Long-Short_Contrastive_Learning_for_Few-Shot_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.00946",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Ig1HGTrrA54",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "The Wisdom of Crowds: Temporal Progressive Attention for Early Action Prediction",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "alexandrosstergiou/progressive-action-prediction",
    "web_page": null,
    "github_page": "https://alexandrosstergiou.github.io/project_pages/TemPr/index.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Stergiou_The_Wisdom_of_Crowds_Temporal_Progressive_Attention_for_Early_Action_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2204.13340",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "dcmd8U47BT8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Use Your Head: Improving Long-Tail Video Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "tobyperrett/lmr",
    "web_page": null,
    "github_page": "https://tobyperrett.github.io/lmr/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Perrett_Use_Your_Head_Improving_Long-Tail_Video_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.01143",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "TXEMh99Ukmg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Decomposed Cross-Modal Distillation for RGB-based Temporal Action Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Decomposed_Cross-Modal_Distillation_for_RGB-Based_Temporal_Action_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17285",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2upFWX7NVqc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Video Test-Time Adaptation for Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "wlin-at/ViTTA",
    "web_page": null,
    "github_page": "https://wlin-at.github.io/vitta",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Video_Test-Time_Adaptation_for_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.15393",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "RzdYgE1hN2o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "How Can Objects Help Action Recognition?",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "google-research/scenic",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_How_Can_Objects_Help_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2306.11726",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4E_X1hCj4yU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Text-Visual Prompting for Efficient 2D Temporal Video Grounding",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "intel/TVP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Text-Visual_Prompting_for_Efficient_2D_Temporal_Video_Grounding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.04995",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "zj2s_G3066s",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Enlarging Instance-Specific and Class-Specific Information for Open-Set Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Jun-CEN/PSL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cen_Enlarging_Instance-Specific_and_Class-Specific_Information_for_Open-Set_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15467",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "SofkzNeymP4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "TimeBalance: Temporally-Invariant and Temporally-Distinctive Video Representations for Semi-Supervised Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "DAVEISHAN/TimeBalance",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dave_TimeBalance_Temporally-Invariant_and_Temporally-Distinctive_Video_Representations_for_Semi-Supervised_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16268",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2c5LM6YqPKQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Video Representations from Large Language Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "facebookresearch/LaViLa",
    "web_page": null,
    "github_page": "https://facebookresearch.github.io/LaViLa/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Learning_Video_Representations_From_Large_Language_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04501",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "tbQaP07xQ4c",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Fine-tuned CLIP Models are Efficient Video Learners",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "muzairkhattak/ViFi-CLIP",
    "web_page": null,
    "github_page": "https://muzairkhattak.github.io/ViFi-CLIP/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Rasheed_Fine-Tuned_CLIP_Models_Are_Efficient_Video_Learners_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.03640",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "uqPLPIyWBb0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Efficient Movie Scene Detection Using State-Space Transformers",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "md-mohaiminul/TranS4mer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Islam_Efficient_Movie_Scene_Detection_Using_State-Space_Transformers_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.14427",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "EOmVAByPQbE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "AdamsFormer for Spatial Action Localization in the Future",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chi_AdamsFormer_for_Spatial_Action_Localization_in_the_Future_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PK0O-ynPgr0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "A Light Weight Model for Active Speaker Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Junhua-Liao/Light-ASD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liao_A_Light_Weight_Model_for_Active_Speaker_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.04439",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "spGacmYdvYs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "System-Status-Aware Adaptive Network for Online Streaming Video Understanding",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Foo_System-Status-Aware_Adaptive_Network_for_Online_Streaming_Video_Understanding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15742",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8DrTkS247xs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "STMixer: A One-Stage Sparse Action Detector",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MCG-NJU/STMixer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_STMixer_A_One-Stage_Sparse_Action_Detector_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15879",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Sy4jozsQLM0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Revisiting Temporal Modeling for CLIP-Based Image-to-Video Knowledge Transferring",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "farewellthree/STAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Revisiting_Temporal_Modeling_for_CLIP-Based_Image-to-Video_Knowledge_Transferring_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.11116",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "kaDItcB1iFw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Distilling Vision-Language Pre-Training To Collaborate With Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ju-chen/Efficient-Prompt",
    "web_page": null,
    "github_page": "https://voide1220.github.io/distillation_collaboration/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ju_Distilling_Vision-Language_Pre-Training_To_Collaborate_With_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.09335",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Real-Time Multi-Person Eyeblink Detection in the Wild for Untrimmed Video",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "wenzhengzeng/MPEblink",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_Real-Time_Multi-Person_Eyeblink_Detection_in_the_Wild_for_Untrimmed_Video_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16053",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ngME7dym0Uk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Modeling Video As Stochastic Processes for Fine-Grained Video Representation Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "hengRUC/VSP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Modeling_Video_As_Stochastic_Processes_for_Fine-Grained_Video_Representation_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ANfWcISTPK8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Re<sup>2</sup>TAL: <u>Re</u>wiring Pretrained Video Backbones for <u>Re</u>versible <u>T</u>emporal <u>A</u>ction <u>L</u>ocalization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "coolbay/Re2TAL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Re2TAL_Rewiring_Pretrained_Video_Backbones_for_Reversible_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.14053",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Oa29cFo_nMY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Discriminative Representations for Skeleton based Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zhysora/FR-Head",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Learning_Discriminative_Representations_for_Skeleton_Based_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.03729",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ix6rADaCjNs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Procedure-Aware Video Representation from Instructional Videos and their Narrations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "facebookresearch/ProcedureVRL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Learning_Procedure-Aware_Video_Representation_From_Instructional_Videos_and_Their_Narrations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17839",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "YPq-rziL8Jo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Collecting Cross-Modal Presence-Absence Evidence for Weakly-Supervised Audio-Visual Event Perception",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MengyuanChen21/CVPR2023-CMPAE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Collecting_Cross-Modal_Presence-Absence_Evidence_for_Weakly-Supervised_Audio-Visual_Event_Perception_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "PivoTAL: Prior-Driven Supervision for Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Rizve_PivoTAL_Prior-Driven_Supervision_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6kAoQjXfzio",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Cascade Evidential Learning for Open-World Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Cascade_Evidential_Learning_for_Open-World_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Soft-Landing Strategy for Alleviating the Task Discrepancy Problem in Temporal Action Localization Tasks",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Soft-Landing_Strategy_for_Alleviating_the_Task_Discrepancy_Problem_in_Temporal_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.06023",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "SVFormer: Semi-Supervised Video Transformer for Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ChenHsing/SVFormer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xing_SVFormer_Semi-Supervised_Video_Transformer_for_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13222",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "t5NjEvWRLVk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "AutoAD: Movie Description in Context",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://www.robots.ox.ac.uk/~vgg/research/autoad/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Han_AutoAD_Movie_Description_in_Context_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16899",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "gMQSoib6lSI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "STMT: A Spatial-Temporal Mesh Transformer for MoCap-based Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zgzxy001/STMT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_STMT_A_Spatial-Temporal_Mesh_Transformer_for_MoCap-Based_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.18177",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Jo5soeHw0RQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Boosting Weakly-Supervised Temporal Action Localization with Text Information",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "lgzlIlIlI/Boosting-WTAL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Boosting_Weakly-Supervised_Temporal_Action_Localization_With_Text_Information_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.00607",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "n8p4ZU85LXM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Aligning Step-by-Step Instructional Diagrams to Video Demonstrations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "DavidZhang73/AssemblyVideoManualAlignment",
    "web_page": "https://academic.davidz.cn/en/publication/zhang-cvpr-2023/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Aligning_Step-by-Step_Instructional_Diagrams_to_Video_Demonstrations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13800",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8iC5QyP8U6o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Improving Weakly Supervised Temporal Action Localization by Bridging Train-Test Gap in Pseudo Labels",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zhou745/GauFuse_WSTAL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Improving_Weakly_Supervised_Temporal_Action_Localization_by_Bridging_Train-Test_Gap_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.07978",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Weakly Supervised Video Representation Learning with Unaligned Text for Sequential Videos",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "svip-lab/WeakSVR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_Weakly_Supervised_Video_Representation_Learning_With_Unaligned_Text_for_Sequential_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12370",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "AqozSRYP7Pc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Dense-Localizing Audio-Visual Events in Untrimmed Videos: A Large-Scale Benchmark and Baseline",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ttgeng233/UnAV",
    "web_page": null,
    "github_page": "https://unav100.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Geng_Dense-Localizing_Audio-Visual_Events_in_Untrimmed_Videos_A_Large-Scale_Benchmark_and_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12930",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PPDywLMn1Js",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "LOGO: A Long-Form Video Dataset for Group Action Quality Assessment",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "shiyi-zh0408/LOGO",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_LOGO_A_Long-Form_Video_Dataset_for_Group_Action_Quality_Assessment_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Search-Map-Search: A Frame Selection Paradigm for Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Search-Map-Search_A_Frame_Selection_Paradigm_for_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.10316",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Ywdf6di2QWo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "3Mformer: Multi-Order Multi-Mode Transformer for Skeletal Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_3Mformer_Multi-Order_Multi-Mode_Transformer_for_Skeletal_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14474",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_LzrzFIuaNU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "ProTeGe: Untrimmed Pretraining for Video Temporal Grounding by Video Temporal Grounding",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_ProTeGe_Untrimmed_Pretraining_for_Video_Temporal_Grounding_by_Video_Temporal_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Egocentric Video Task Translation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "facebookresearch/EgoT2",
    "web_page": "https://vision.cs.utexas.edu/projects/egot2/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_Egocentric_Video_Task_Translation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.06301",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "HHWLMFIZ5ow",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Look Around for Anomalies: Weakly-Supervised Anomaly Detection via Context-Motion Relational Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cho_Look_Around_for_Anomalies_Weakly-Supervised_Anomaly_Detection_via_Context-Motion_Relational_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "31ccYdwGDG8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Proposal-based Multiple Instance Learning for Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "RenHuan1999/CVPR2023_P-MIL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_Proposal-Based_Multiple_Instance_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.17861",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hfHGlKyOQ68",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "TriDet: Temporal Action Detection with Relative Boundary Modeling",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "dingfengshi/TriDet",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Shi_TriDet_Temporal_Action_Detection_With_Relative_Boundary_Modeling_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.07347",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "f1gJkUI6rA4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Actionlet-Dependent Contrastive Learning for Unsupervised Skeleton-based Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "LanglandsLin/ActCLR",
    "web_page": null,
    "github_page": "https://langlandslin.github.io/projects/ActCLR/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Actionlet-Dependent_Contrastive_Learning_for_Unsupervised_Skeleton-Based_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10904",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jwX0Zc8s10w",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "EVAL: Explainable Video Anomaly Localization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_EVAL_Explainable_Video_Anomaly_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.07900",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6x8GUDWkN68",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "daniel-code/TubeViT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Piergiovanni_Rethinking_Video_ViTs_Sparse_Video_Tubes_for_Joint_Image_and_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.03229",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Weakly Supervised Temporal Sentence Grounding with Uncertainty-guided Self-Training",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Weakly_Supervised_Temporal_Sentence_Grounding_With_Uncertainty-Guided_Self-Training_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "KyXVUlBjiZ4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Leveraging Temporal Context in Low Representational Power Regimes",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://camilofosco.com/etm_website/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Fosco_Leveraging_Temporal_Context_in_Low_Representational_Power_Regimes_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "a5-gWsUMVXw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "PIVOT: Prompting for Video Continual Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Villa_PIVOT_Prompting_for_Video_Continual_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04842",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "On the Benefits of 3D Pose and Tracking for Human Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "brjathu/LART",
    "web_page": "https://people.eecs.berkeley.edu/~jathushan/LART/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Rajasegaran_On_the_Benefits_of_3D_Pose_and_Tracking_for_Human_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.01199",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "NaQ: Leveraging Narrations as Queries to Supervise Episodic Memory",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "srama2512/NaQ",
    "web_page": "https://vision.cs.utexas.edu/projects/naq/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ramakrishnan_NaQ_Leveraging_Narrations_As_Queries_To_Supervise_Episodic_Memory_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.00746",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Selective Structured State-Spaces for Long-Form Video Understanding",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Selective_Structured_State-Spaces_for_Long-Form_Video_Understanding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14526",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "CcQHyaZLIpQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Frame Flexible Network",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "BeSpontaneous/FFN-pytorch",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Frame_Flexible_Network_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14817",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "JFHqyw20T8M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "ASPnet: Action Segmentation with Shared-Private Representation of Multiple Data Sources",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/van_Amsterdam_ASPnet_Action_Segmentation_With_Shared-Private_Representation_of_Multiple_Data_Sources_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Unified Keypoint-based Action Recognition Framework via Structured Keypoint Pooling",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hachiuma_Unified_Keypoint-Based_Action_Recognition_Framework_via_Structured_Keypoint_Pooling_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15270",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Transferable Spatiotemporal Representations from Natural Script Knowledge",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "TencentARC/TVTS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_Learning_Transferable_Spatiotemporal_Representations_From_Natural_Script_Knowledge_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2209.15280",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Jlpe75bsYUg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Masked Video Distillation: Rethinking Masked Feature Modeling for Self-Supervised Video Representation Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ruiwang2021/mvd",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Masked_Video_Distillation_Rethinking_Masked_Feature_Modeling_for_Self-Supervised_Video_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04500",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "btxcb-5NfWo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Bidirectional Cross-Modal Knowledge Exploration for Video Recognition with Pre-trained Vision-Language Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "whwu95/BIKE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Bidirectional_Cross-Modal_Knowledge_Exploration_for_Video_Recognition_With_Pre-Trained_Vision-Language_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.00182",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "cjEvOcN-bmI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Procedure-Aware Pretraining for Instructional Video Understanding",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "salesforce/paprika",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Procedure-Aware_Pretraining_for_Instructional_Video_Understanding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.18230",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "NvuPQbhC3Qo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Latency Matters: Real-Time Action Forecasting Transformer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://karttikeya.github.io/publication/RAFTformer/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "0tbK36hzSM0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Generating Anomalies for Video Anomaly Detection with Prompt-based Feature Mapping",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Generating_Anomalies_for_Video_Anomaly_Detection_With_Prompt-Based_Feature_Mapping_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "iYGfdd3t4ZE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "HierVL: Learning Hierarchical Video-Language Embeddings",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "facebookresearch/HierVL",
    "web_page": "https://vision.cs.utexas.edu/projects/hiervl/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ashutosh_HierVL_Learning_Hierarchical_Video-Language_Embeddings_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.02311",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "I5FIGHc_H5I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Two-Stream Networks for Weakly-Supervised Temporal Action Localization with Semantic-Aware Mechanisms",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Two-Stream_Networks_for_Weakly-Supervised_Temporal_Action_Localization_With_Semantic-Aware_Mechanisms_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "emPtOrt3v2Q",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Hybrid Active Learning via Deep Clustering for Video Action Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "aayushjr/HybridCLAUS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Rana_Hybrid_Active_Learning_via_Deep_Clustering_for_Video_Action_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "nPNAUdLbmCQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Prompt-guided Zero-Shot Anomaly Action Recognition using Pretrained Deep Skeleton Features",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sato_Prompt-Guided_Zero-Shot_Anomaly_Action_Recognition_Using_Pretrained_Deep_Skeleton_Features_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15167",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Unbiased Multiple Instance Learning for Weakly Supervised Video Anomaly Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ktr-hubrt/UMIL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lv_Unbiased_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12369",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "GVSzmgpxDHc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "OpenGVLab/VideoMAEv2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_VideoMAE_V2_Scaling_Video_Masked_Autoencoders_With_Dual_Masking_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16727",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "PDPP: Projected Diffusion for Procedure Planning in Instructional Videos",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MCG-NJU/PDPP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_PDPPProjected_Diffusion_for_Procedure_Planning_in_Instructional_Videos_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14676",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_8IvuN9rjxo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Action Changes by Measuring Verb-Adverb Textual Relationships",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "dmoltisanti/air-cvpr23",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Moltisanti_Learning_Action_Changes_by_Measuring_Verb-Adverb_Textual_Relationships_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15086",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "orQ3YgVMXYk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Reducing the Label Bias for Timestamp Supervised Temporal Action Segmentation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Reducing_the_Label_Bias_for_Timestamp_Supervised_Temporal_Action_Segmentation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "KH7lZiQgqBU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Video Event Restoration based on Keyframes for Video Anomaly Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Video_Event_Restoration_Based_on_Keyframes_for_Video_Anomaly_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.05112",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "IXf1ERTkAH0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Active Exploration of Multimodal Complementarity for Few-Shot Action Recognition",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wanyan_Active_Exploration_of_Multimodal_Complementarity_for_Few-Shot_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Skd4p5G0wgM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Vita-CLIP: Video and Text Adaptive CLIP via Multimodal Prompting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "TalalWasim/Vita-CLIP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wasim_Vita-CLIP_Video_and_Text_Adaptive_CLIP_via_Multimodal_Prompting_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.03307",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Post-Processing Temporal Action Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sauradip/GAP",
    "web_page": null,
    "github_page": "https://sauradip.github.io/project_pages/GAP/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Nag_Post-Processing_Temporal_Action_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.14924",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "sV4Hg46Qa-A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Relational Space-Time Query in Long-Form Videos",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Relational_Space-Time_Query_in_Long-Form_Videos_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "7qtu6-u3Ggo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Therbligs in Action: Video Understanding through Motion Primitives",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dessalene_Therbligs_in_Action_Video_Understanding_Through_Motion_Primitives_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.03631",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Dual-Path Adaptation from Image to Video Transformers",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "park-jungin/DualPath",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Dual-Path_Adaptation_From_Image_to_Video_Transformers_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.09857",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Hierarchical Semantic Contrast for Scene-Aware Video Anomaly Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "shengyangsun/HSC_VAD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Hierarchical_Semantic_Contrast_for_Scene-Aware_Video_Anomaly_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13051",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Exploiting Completeness and Uncertainty of Pseudo Labels for Weakly Supervised Video Anomaly Detection",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ArielZc/CU-Net",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Exploiting_Completeness_and_Uncertainty_of_Pseudo_Labels_for_Weakly_Supervised_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04090",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "TpRkCnDyFNY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Unbiased Scene Graph Generation in Videos",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sayaknag/unbiasedSGG",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Nag_Unbiased_Scene_Graph_Generation_in_Videos_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.00733",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "JkpfcZ6dXEA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  }
]