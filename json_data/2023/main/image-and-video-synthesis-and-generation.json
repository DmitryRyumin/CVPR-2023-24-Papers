[
  {
    "title": "Towards Universal Fake Image Detectors That Generalize Across Generative Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Yuheng-Li/UniversalFakeDetect",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ojha_Towards_Universal_Fake_Image_Detectors_That_Generalize_Across_Generative_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.10174",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Implicit Diffusion Models for Continuous Super-Resolution",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Ree1s/IDM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Implicit_Diffusion_Models_for_Continuous_Super-Resolution_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16491",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "High-Fidelity Guided Image Synthesis With Latent Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "1jsingh/GradOP-Guided-Image-Synthesis",
    "web_page": null,
    "github_page": "https://1jsingh.github.io/gradop",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_High-Fidelity_Guided_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.17084",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Yk83RPCOa2o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DBARF: Deep Bundle-Adjusting Generalizable Neural Radiance Fields",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "AIBluefisher/dbarf",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_DBARF_Deep_Bundle-Adjusting_Generalizable_Neural_Radiance_Fields_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14478",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "wFPO403wtAg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Deep Arbitrary-Scale Image Super-Resolution via Scale-Equivariance Pursuit",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "neuralchen/EQSR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Deep_Arbitrary-Scale_Image_Super-Resolution_via_Scale-Equivariance_Pursuit_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Pq9eI5kxqUE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Balanced Spherical Grid for Egocentric View Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "changwoonchoi/EgoNeRF",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_Balanced_Spherical_Grid_for_Egocentric_View_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12408",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "D-lsBhVP8zw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SDFusion: Multimodal 3D Shape Completion, Reconstruction, and Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "yccyenchicheng/SDFusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cheng_SDFusion_Multimodal_3D_Shape_Completion_Reconstruction_and_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04493",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6EvHJRlUMFQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://dreambooth.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ruiz_DreamBooth_Fine_Tuning_Text-to-Image_Diffusion_Models_for_Subject-Driven_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2208.12242",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "82x4XTSFwBQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Self-Guided Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "dongzhuoyao/self-guided-diffusion-models",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Self-Guided_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2210.06462",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "zwkn640t-u8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Multi-Concept Customization of Text-to-Image Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "adobe-research/custom-diffusion",
    "web_page": null,
    "github_page": "https://www.cs.cmu.edu/~custom-diffusion/dataset.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kumari_Multi-Concept_Customization_of_Text-to-Image_Diffusion_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04488",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "WWNA_IPLO84",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3D-Aware Conditional Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "dunbar12138/pix2pix3D",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_3D-Aware_Conditional_Image_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.08509",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "dDRoI1gjbzk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "siyuhuang/QuantArt",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_QuantArt_Quantizing_Image_Style_Transfer_Towards_High_Visual_Fidelity_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.10431",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "WWNA_IPLO84",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SceneComposer: Any-Level Semantic Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zengxianyu/scenec",
    "web_page": null,
    "github_page": "https://zengyu.me/scenec/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_SceneComposer_Any-Level_Semantic_Image_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.11742",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ky0LWZ_USRA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DiffCollage: Parallel Generation of Large Content With Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://research.nvidia.com/labs/dir/diffcollage/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_DiffCollage_Parallel_Generation_of_Large_Content_With_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17076",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Putting People in Their Place: Affordance-Aware Human Insertion Into Scenes",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "adobe-research/affordance-insertion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kulal_Putting_People_in_Their_Place_Affordance-Aware_Human_Insertion_Into_Scenes_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.14406",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Hybrid Neural Rendering for Large-Scale Scenes With Motion Blur",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "CVMI-Lab/HybridNeuralRendering",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dai_Hybrid_Neural_Rendering_for_Large-Scale_Scenes_With_Motion_Blur_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.12652",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hAhFfKRqDgE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Binary Latent Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ZeWang95/BinaryLatentDiffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Binary_Latent_Diffusion_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.04820",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "channel/UCzkUNNsV1TYuf6U_wGnMlnw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "StyleRes: Transforming the Residuals for Real Image Editing With StyleGAN",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "hamzapehlivan/StyleRes",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Pehlivan_StyleRes_Transforming_the_Residuals_for_Real_Image_Editing_With_StyleGAN_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.14359",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "S9ZswKv8enw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "KD-DLGAN: Data Limited Image Generation via Knowledge Distillation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "cuikaiwen18/KD_DLGAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cui_KD-DLGAN_Data_Limited_Image_Generation_via_Knowledge_Distillation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17158",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SeaThru-NeRF: Neural Radiance Fields in Scattering Media",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "deborahLevy130/seathru_NeRF",
    "web_page": null,
    "github_page": "https://sea-thru-nerf.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Levy_SeaThru-NeRF_Neural_Radiance_Fields_in_Scattering_Media_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.07743",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "dXKCJS4cscg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "PointAvatar: Deformable Point-Based Head Avatars From Videos",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zhengyuf/PointAvatar",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_PointAvatar_Deformable_Point-Based_Head_Avatars_From_Videos_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.08377",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "wll_XtgpU7U",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3DAvatarGAN: Bridging Domains for Personalized Editable Avatars",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://rameenabdal.github.io/3DAvatarGAN/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Abdal_3DAvatarGAN_Bridging_Domains_for_Personalized_Editable_Avatars_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.02700",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Neural Preset for Color Style Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ZHKKKe/NeuralPreset",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ke_Neural_Preset_for_Color_Style_Transfer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13511",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "x6fLAvTPesk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Zero-Shot Generative Model Adaptation via Image-Specific Prompt Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Zero-Shot_Generative_Model_Adaptation_via_Image-Specific_Prompt_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.03119",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "vw9-C3Sz5nM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DyNCA: Real-Time Dynamic Texture Synthesis Using Neural Cellular Automata",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "IVRL/DyNCA",
    "web_page": null,
    "github_page": "https://dynca.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Pajouheshgar_DyNCA_Real-Time_Dynamic_Texture_Synthesis_Using_Neural_Cellular_Automata_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.11417",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ELZC2mX5Z9U",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Exploring Incompatible Knowledge Transfer in Few-Shot Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "yunqing-me/RICK",
    "web_page": null,
    "github_page": "https://yunqing-me.github.io/RICK/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Exploring_Incompatible_Knowledge_Transfer_in_Few-Shot_Image_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.07574",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "s14bA8filtw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "HouseDiffusion: Vector Floorplan Generation via a Diffusion Model With Discrete and Continuous Denoising",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "aminshabani/house_diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Shabani_HouseDiffusion_Vector_Floorplan_Generation_via_a_Diffusion_Model_With_Discrete_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13287",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ku6_gr94n5Q",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Towards Accurate Image Coding: Improved Autoregressive Image Generation With Dynamic Vector Quantization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "CrossmodalGroup/DynamicVectorQuantization",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Towards_Accurate_Image_Coding_Improved_Autoregressive_Image_Generation_With_Dynamic_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.11718",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ir60YW9JCjU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "RiDDLE: Reversible and Diversified De-Identification With Latent Encryptor",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ldz666666/RiDDLE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_RiDDLE_Reversible_and_Diversified_De-Identification_With_Latent_Encryptor_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.05171",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "gqs9Q6ReEn0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "LayoutDiffusion: Controllable Diffusion Model for Layout-to-Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ZGCTroy/LayoutDiffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_LayoutDiffusion_Controllable_Diffusion_Model_for_Layout-to-Image_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17189",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "bJOpJnvhw3s",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "LipFormer: High-Fidelity and Generalizable Talking Face Generation With a Pre-Learned Facial Codebook",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "DaddyJin/awesome-faceReenactment",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_LipFormer_High-Fidelity_and_Generalizable_Talking_Face_Generation_With_a_Pre-Learned_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Not All Image Regions Matter: Masked Vector Quantization for Autoregressive Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "CrossmodalGroup/MaskedVectorQuantization",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Not_All_Image_Regions_Matter_Masked_Vector_Quantization_for_Autoregressive_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.13607",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "o2eyRscEejw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "tobran/GALIP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tao_GALIP_Generative_Adversarial_CLIPs_for_Text-to-Image_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.12959",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "lwhTDY4du_g",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "High-Fidelity Generalized Emotional Talking Face Generation With Multi-Modal Emotion Space Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_High-Fidelity_Generalized_Emotional_Talking_Face_Generation_With_Multi-Modal_Emotion_Space_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.02572",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "eQG6ql83T0w",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Consistent View Synthesis With Pose-Guided Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://poseguided-diffusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tseng_Consistent_View_Synthesis_With_Pose-Guided_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17598",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "eV1jwq14lE0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-Based Generator",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "guanjz20/StyleSync",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Guan_StyleSync_High-Fidelity_Generalized_and_Personalized_Lip_Sync_in_Style-Based_Generator_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.05445",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "yAPDl2dVonY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Imagic: Text-Based Real Image Editing With Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://poseguided-diffusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2210.09276",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "lOZvBGz47wQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Large-Capacity and Flexible Video Steganography via Invertible Neural Network",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MC-E/LF-VSN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Mou_Large-Capacity_and_Flexible_Video_Steganography_via_Invertible_Neural_Network_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.12300",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Quantitative Manipulation of Custom Attributes on 3D-Aware Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Do_Quantitative_Manipulation_of_Custom_Attributes_on_3D-Aware_Image_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent Portrait Synthesis From Monocular Image",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "YuDeng/GRAMInverter",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_Learning_Detailed_Radiance_Manifolds_for_High-Fidelity_and_3D-Consistent_Portrait_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13901",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "nclBOg_CiJo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CF-Font: Content Fusion for Few-Shot Font Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "wangchi95/CF-Font",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_CF-Font_Content_Fusion_for_Few-Shot_Font_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14017",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "biwFd0K3X9o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "One-Shot High-Fidelity Talking-Head Synthesis With Deformable Neural Radiance Field",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://www.waytron.net/hidenerf/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_One-Shot_High-Fidelity_Talking-Head_Synthesis_With_Deformable_Neural_Radiance_Field_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.05097",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "opLdLY8_VYQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Unsupervised Domain Adaption With Pixel-Level Discriminator for Image-Aware Layout Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Unsupervised_Domain_Adaption_With_Pixel-Level_Discriminator_for_Image-Aware_Layout_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14377",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "DBHFzw02T1I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diffusion Probabilistic Model Made Slim",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Diffusion_Probabilistic_Model_Made_Slim_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.17106",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "82N6FsRUfr4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Collaborative Diffusion for Multi-Modal Face Generation and Editing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ziqihuangg/Collaborative-Diffusion",
    "web_page": null,
    "github_page": "https://ziqihuangg.github.io/projects/collaborative-diffusion.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Collaborative_Diffusion_for_Multi-Modal_Face_Generation_and_Editing_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.10530",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "inLK4c8sNhc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "High-Fidelity Facial Avatar Reconstruction From Monocular Video With Generative Priors",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "bbaaii/HFA-GP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bai_High-Fidelity_Facial_Avatar_Reconstruction_From_Monocular_Video_With_Generative_Priors_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.15064",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZWdF8ASl0BQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Network-Free, Unsupervised Semantic Segmentation With Synthetic Images",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Network-Free_Unsupervised_Semantic_Segmentation_With_Synthetic_Images_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": "https://www.amazon.science/publications/network-free-unsupervised-semantic-segmentation-with-synthetic-images",
    "youtube_id": "mfFZdvaF1Tw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Visual Prompt Tuning for Generative Transfer Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "google-research/generative_transfer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sohn_Visual_Prompt_Tuning_for_Generative_Transfer_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2210.00990",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "kOza8-xop_g",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models To Learn Any Unseen Style",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Picsart-AI-Research/Specialist-Diffusion",
    "web_page": null,
    "github_page": "https://specialist-diffusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Specialist_Diffusion_Plug-and-Play_Sample-Efficient_Fine-Tuning_of_Text-to-Image_Diffusion_Models_To_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "5-hkImpVsNI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Catch Missing Details: Image Reconstruction With Frequency Augmented Variational Autoencoder",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "JiauZhang/FA-VAE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Catch_Missing_Details_Image_Reconstruction_With_Frequency_Augmented_Variational_Autoencoder_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.02541",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "wJ9U7tAnQEo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Towards Bridging the Performance Gaps of Joint Energy-Based Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sndnyang/sadajem",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Towards_Bridging_the_Performance_Gaps_of_Joint_Energy-Based_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2209.07959",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GLeaD: Improving GANs With a Generator-Leading Task",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "EzioBy/glead",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bai_GLeaD_Improving_GANs_With_a_Generator-Leading_Task_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.03752",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "bP8Iq_qLuU0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Structural Multiplane Image: Bridging Neural View Synthesis and 3D Reconstruction",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "mf-zhang/Structural-MPI",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Structural_Multiplane_Image_Bridging_Neural_View_Synthesis_and_3D_Reconstruction_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.05937",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8Bbl8oZKAOs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SPARF: Neural Radiance Fields From Sparse and Noisy Poses",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "google-research/sparf",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Truong_SPARF_Neural_Radiance_Fields_From_Sparse_and_Noisy_Poses_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.11738",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_s3_p2Brd_8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DeltaEdit: Exploring Text-Free Training for Text-Driven Image Manipulation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Yueming6568/DeltaEdit",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lyu_DeltaEdit_Exploring_Text-Free_Training_for_Text-Driven_Image_Manipulation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.06285",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8cdZSbhDMIA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Inferring and Leveraging Parts From Object Shape for Improving Semantic Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "csyxwei/iPOSE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Inferring_and_Leveraging_Parts_From_Object_Shape_for_Improving_Semantic_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.19547",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "yVUmjQU9-v4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_VideoFusion_Decomposed_Diffusion_Models_for_High-Quality_Video_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.08320",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hxA0DTZScg0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MaskSketch: Unpaired Structure-Guided Masked Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bashkirova_MaskSketch_Unpaired_Structure-Guided_Masked_Image_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.05496",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2tBzEGASeo0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Affordance Diffusion: Synthesizing Hand-Object Interactions",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "NVlabs/affordance_diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Affordance_Diffusion_Synthesizing_Hand-Object_Interactions_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12538",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "omhEoLzsopo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Interactive Cartoonization With Controllable Perceptual Factors",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ahn_Interactive_Cartoonization_With_Controllable_Perceptual_Factors_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.09555",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "z8B2RiB4DyM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MetaPortrait: Identity-Preserving Talking Head Generation With Fast Personalized Adaptation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Meta-Portrait/MetaPortrait",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_MetaPortrait_Identity-Preserving_Talking_Head_Generation_With_Fast_Personalized_Adaptation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.08062",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "DDEnjbCNNY4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Paint by Example: Exemplar-Based Image Editing With Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Fantasy-Studio/Paint-by-Example",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Paint_by_Example_Exemplar-Based_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13227",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GLIGEN: Open-Set Grounded Text-to-Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "gligen/GLIGEN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_GLIGEN_Open-Set_Grounded_Text-to-Image_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.07093",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-MCkU7IAGKs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "L-CoIns: Language-Based Colorization With Instance Awareness",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "changzheng123/L-CoIns",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chang_L-CoIns_Language-Based_Colorization_With_Instance_Awareness_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sstzal/DiffTalk",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_DiffTalk_Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.03786",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "tup5kbsOJXc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Evading DeepFake Detectors via Adversarial Statistical Consistency",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hou_Evading_DeepFake_Detectors_via_Adversarial_Statistical_Consistency_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.11670",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GlassesGAN: Eyewear Personalization Using Synthetic Appearance Discovery and Targeted Subspace Modeling",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Plesh_GlassesGAN_Eyewear_Personalization_Using_Synthetic_Appearance_Discovery_and_Targeted_Subspace_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2210.14145",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "oMiV__LWV4A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GP-VTON: Towards General Purpose Virtual Try-On via Collaborative Local-Flow Global-Parsing Learning",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "xiezhy6/GP-VTON",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_GP-VTON_Towards_General_Purpose_Virtual_Try-On_via_Collaborative_Local-Flow_Global-Parsing_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13756",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "b-FDMJ0jrw0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Where Is My Spot? Few-Shot Image Generation via Latent Subspace Optimization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "chansey0529/LSO",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Where_Is_My_Spot_Few-Shot_Image_Generation_via_Latent_Subspace_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Regularized Vector Quantization for Tokenized Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Regularized_Vector_Quantization_for_Tokenized_Image_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.06424",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "EDICT: Exact Diffusion Inversion via Coupled Transformations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "salesforce/EDICT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wallace_EDICT_Exact_Diffusion_Inversion_via_Coupled_Transformations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.12446",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2k6DiE_h1eY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Scaling Up GANs for Text-to-Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://mingukkang.github.io/GigaGAN/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Scaling_Up_GANs_for_Text-to-Image_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.05511",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZjxtuDQkOPY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Shape-Aware Text-Driven Layered Video Editing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://text-video-edit.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Shape-Aware_Text-Driven_Layered_Video_Editing_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.13173",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "A Unified Pyramid Recurrent Network for Video Frame Interpolation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "srcn-ivl/UPR-Net",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_A_Unified_Pyramid_Recurrent_Network_for_Video_Frame_Interpolation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.03456",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "clvrjUKgfhI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "TAPS3D: Text-Guided 3D Textured Shape Generation From Pseudo Supervision",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "plusmultiply/TAPS3D",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_TAPS3D_Text-Guided_3D_Textured_Shape_Generation_From_Pseudo_Supervision_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13273",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-eWBEwAkThA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Fine-Grained Face Swapping via Regional GAN Inversion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "e4s2022/e4s",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Fine-Grained_Face_Swapping_via_Regional_GAN_Inversion_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.14068",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Z-cmKVeXHvY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "OTAvatar: One-Shot Talking Face Avatar With Controllable Tri-Plane Rendering",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "theEricMa/OTAvatar",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_OTAvatar_One-Shot_Talking_Face_Avatar_With_Controllable_Tri-Plane_Rendering_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14662",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qpIoMYFr7Aw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Deep Stereo Video Inpainting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Deep_Stereo_Video_Inpainting_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "StyleGAN Salon: Multi-View Latent Optimization for Pose-Invariant Hairstyle Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://stylegan-salon.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Khwanmuang_StyleGAN_Salon_Multi-View_Latent_Optimization_for_Pose-Invariant_Hairstyle_Transfer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.02744",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Cross-GAN Auditing: Unsupervised Identification of Attribute Level Similarities and Differences Between Pretrained Generative Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "mattolson93/cross_gan_auditing",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Olson_Cross-GAN_Auditing_Unsupervised_Identification_of_Attribute_Level_Similarities_and_Differences_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10774",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Unsupervised Volumetric Animation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "snap-research/unsupervised-volumetric-animation",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Siarohin_Unsupervised_Volumetric_Animation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.11326",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SINE: SINgle Image Editing With Text-to-Image Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zhang-zx/SINE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_SINE_SINgle_Image_Editing_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04489",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Progressive Disentangled Representation Learning for Fine-Grained Controllable Talking Head Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Dorniwang/PD-FGC-inference",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Progressive_Disentangled_Representation_Learning_for_Fine-Grained_Controllable_Talking_Head_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.14506",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PdSQt_zNbC4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CAP-VSTNet: Content Affinity Preserved Versatile Style Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "linfengWen98/CAP-VSTNet",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_CAP-VSTNet_Content_Affinity_Preserved_Versatile_Style_Transfer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17867",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "OTJ1wEe29Hc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DeepVecFont-v2: Exploiting Transformers To Synthesize Vector Fonts With Higher Quality",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "yizhiwang96/deepvecfont-v2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_DeepVecFont-v2_Exploiting_Transformers_To_Synthesize_Vector_Fonts_With_Higher_Quality_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14585",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "LEMaRT: Label-Efficient Masked Region Transform for Image Harmonization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "yizhiwang96/deepvecfont-v2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_LEMaRT_Label-Efficient_Masked_Region_Transform_for_Image_Harmonization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.13166",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "xSS4RChu7zk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SINE: Semantic-Driven Image-Based NeRF Editing With Prior-Guided Editing Field",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zju3dv/SINE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_SINE_Semantic-Driven_Image-Based_NeRF_Editing_With_Prior-Guided_Editing_Field_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13277",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "AfAR-PoZ8SM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Exploring Intra-Class Variation Factors With Learnable Cluster Prompts for Semi-Supervised Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Exploring_Intra-Class_Variation_Factors_With_Learnable_Cluster_Prompts_for_Semi-Supervised_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Image Cropping With Spatial-Aware Feature and Rank Consistency",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Image_Cropping_With_CVPR_2023_supplemental.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "J8ImNnEWwGQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Picture That Sketch: Photorealistic Image Generation From Abstract Sketches",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "subhadeepkoley/PictureThatSketch",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Koley_Picture_That_Sketch_Photorealistic_Image_Generation_From_Abstract_Sketches_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.11162",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "k7xFbELpnv4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MonoHuman: Animatable Human Neural Field From Monocular Video",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Yzmblog/MonoHuman",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_MonoHuman_Animatable_Human_Neural_Field_From_Monocular_Video_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.02001",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "T91fXw9dOmM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "PixHt-Lab: Pixel Height Based Light Effect Generation for Image Compositing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sheng_PixHt-Lab_Pixel_Height_Based_Light_Effect_Generation_for_Image_Compositing_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.00137",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "H2B0yrEf86I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Neural Pixel Composition for 3D-4D View Synthesis From Multi-Views",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://www.aayushbansal.xyz/npc/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bansal_Neural_Pixel_Composition_for_3D-4D_View_Synthesis_From_Multi-Views_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2207.10663",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "oTJyUUH2uCk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SpaText: Spatio-Textual Representation for Controllable Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://omriavrahami.com/spatext/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Avrahami_SpaText_Spatio-Textual_Representation_for_Controllable_Image_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.14305",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "VlieNoCwHO4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Exploring Motion Ambiguity and Alignment for High-Quality Video Frame Interpolation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Exploring_Motion_Ambiguity_and_Alignment_for_High-Quality_Video_Frame_Interpolation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2203.10291",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "WoAyz1S_nTI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "researchmm/MM-Diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ruan_MM-Diffusion_Learning_Multi-Modal_Diffusion_Models_for_Joint_Audio_and_Video_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.09478",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "DthMxv2VogU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Synthesizing Photorealistic Virtual Humans Through Cross-Modal Disentanglement",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://ondrejtexler.github.io/synthesizing_humans/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ravichandran_Synthesizing_Photorealistic_Virtual_Humans_Through_Cross-Modal_Disentanglement_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2209.01320",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "oNYy2-_xuhM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Video Probabilistic Diffusion Models in Projected Latent Space",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "sihyun-yu/PVDM",
    "web_page": "https://sihyun.me/PVDM/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Video_Probabilistic_Diffusion_Models_in_Projected_Latent_Space_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.07685",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Variational Distribution Learning for Unsupervised Text-to-Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Variational_Distribution_Learning_for_Unsupervised_Text-to-Image_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16105",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Linking Garment With Person via Semantically Associated Landmarks for Virtual Try-On",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://modelscope.cn/datasets/damo/SAL-HG/summary",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_Linking_Garment_With_Person_via_Semantically_Associated_Landmarks_for_Virtual_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "UV Volumes for Real-Time Rendering of Editable Free-View Human Performance",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "fanegg/UV-Volumes",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_UV_Volumes_for_Real-Time_Rendering_of_Editable_Free-View_Human_Performance_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2203.14402",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "v3PsN-rMAUw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "NULL-Text Inversion for Editing Real Images Using Guided Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "google/prompt-to-prompt",
    "web_page": null,
    "github_page": "https://null-text-inversion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.09794",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qzTlzrMWU2M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Polynomial Implicit Neural Representations for Large Diverse Datasets",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Rajhans0/Poly_INR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_Polynomial_Implicit_Neural_Representations_for_Large_Diverse_Datasets_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.11424",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "YdFpzITgV8M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MichalGeyer/plug-and-play",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tumanyan_Plug-and-Play_Diffusion_Features_for_Text-Driven_Image-to-Image_Translation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.12572",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "eemzbXXU59E",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Conditional Image-to-Video Generation With Latent Flow Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "nihaomiao/CVPR23_LFDM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ni_Conditional_Image-to-Video_Generation_With_Latent_Flow_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13744",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "dgawtQGmMbA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Local 3D Editing via 3D Distillation of CLIP Knowledge",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hyung_Local_3D_Editing_via_3D_Distillation_of_CLIP_Knowledge_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2306.12570",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Private Image Generation With Dual-Purpose Auxiliary Classifier",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Private_Image_Generation_With_Dual-Purpose_Auxiliary_Classifier_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZsjYIZ2s0fw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MAGVIT: Masked Generative Video Transformer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "google-research/magvit",
    "web_page": "https://magvit.cs.cmu.edu/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_MAGVIT_Masked_Generative_Video_Transformer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.05199",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Dimensionality-Varying Diffusion Process",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Dimensionality-Varying_Diffusion_Process_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.16032",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "zpNhHo3s4Eo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "VIVE3D: Viewpoint-Independent Video Editing Using 3D-Aware GANs",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "afruehstueck/VIVE3D",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Fruhstuck_VIVE3D_Viewpoint-Independent_Video_Editing_Using_3D-Aware_GANs_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15893",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qfYGQwOw8pg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "KU-CVLAB/LANIT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Park_LANIT_Language-Driven_Image-to-Image_Translation_for_Unlabeled_Data_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2208.14889",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "gwang-kim/DATID-3D",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_DATID-3D_Diversity-Preserved_Domain_Adaptation_Using_Text-to-Image_Diffusion_for_3D_Generative_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.16374",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "bjXQ4LTVE3E",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "KumapowerLIU/CLCAE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Delving_StyleGAN_Inversion_for_Image_Editing_A_Foundation_Latent_Space_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.11448",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hsB9Wv50dm0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "High-Fidelity and Freely Controllable Talking Head Video Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_High-Fidelity_and_Freely_Controllable_Talking_Head_Video_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.10168",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_syQLfiQ0_c",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "OpenTalker/SadTalker",
    "web_page": null,
    "github_page": "https://sadtalker.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_SadTalker_Learning_Realistic_3D_Motion_Coefficients_for_Stylized_Audio-Driven_Single_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.12194",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "TjUOalcGDtE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Kunhao-Liu/StyleRF",
    "web_page": null,
    "github_page": "https://kunhao-liu.github.io/StyleRF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_StyleRF_Zero-Shot_3D_Style_Transfer_of_Neural_Radiance_Fields_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10598",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "DkbRmmzTU40",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MOSO: Decomposing MOtion, Scene and Object for Video Prediction",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "iva-mzsun/MOSO",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_MOSO_Decomposing_MOtion_Scene_and_Object_for_Video_Prediction_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.03684",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "5kLsKpfJFrQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Multi Domain Learning for Motion Magnification",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "jasdeep-singh-007/Multi-Domain-Learning-for-Motion-Magnification",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_Multi_Domain_Learning_for_Motion_Magnification_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Sg7_sXMnRLo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GazeNeRF: 3D-Aware Gaze Redirection With Neural Radiance Fields",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "AlessandroRuzzi/GazeNeRF",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ruzzi_GazeNeRF_3D-Aware_Gaze_Redirection_With_Neural_Radiance_Fields_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04823",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "JwqKbmUR3DE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Hierarchical B-Frame Video Coding Using Two-Layer CANF Without Motion Coding",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "nycu-clab/tlzmc-cvpr",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Alexandre_Hierarchical_B-Frame_Video_Coding_Using_Two-Layer_CANF_Without_Motion_Coding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.02690",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Blemish-Aware and Progressive Face Retouching With Limited Paired Data",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Blemish-Aware_and_Progressive_Face_Retouching_With_Limited_Paired_Data_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qKy6t8JbUOs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Text-Guided Unsupervised Latent Transformation for Multi-Attribute Image Manipulation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Text-Guided_Unsupervised_Latent_Transformation_for_Multi-Attribute_Image_Manipulation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "NeuralField-LDM: Scene Generation With Hierarchical Latent Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://research.nvidia.com/labs/toronto-ai/NFLDM/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_NeuralField-LDM_Scene_Generation_With_Hierarchical_Latent_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Fix the Noise: Disentangling Source Feature for Controllable Domain Translation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "LeeDongYeun/FixNoise",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Fix_the_Noise_Disentangling_Source_Feature_for_Controllable_Domain_Translation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.11545",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "VqN-rACydQw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Class-Balancing Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "qym7/CBDM-pytorch",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_Class-Balancing_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.00562",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "OWY_2OZ4e_4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DPE: Disentanglement of Pose and Expression for General Video Portrait Editing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "OpenTalker/DPE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Pang_DPE_Disentanglement_of_Pose_and_Expression_for_General_Video_Portrait_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.06281",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "vj9LELgXVJ0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Inversion-Based Style Transfer With Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zyxElsa/InST",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Inversion-Based_Style_Transfer_With_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13203",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "W3urLYx9JZY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Deep Curvilinear Editing: Commutative and Nonlinear Image Manipulation for Pretrained Deep Generative Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Aoshima_Deep_Curvilinear_Editing_Commutative_and_Nonlinear_Image_Manipulation_for_Pretrained_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.14573",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "iVyvQOAhLqI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FlowGrad: Controlling the Output of Generative ODEs With Gradients",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "gnobitab/FlowGrad",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_FlowGrad_Controlling_the_Output_of_Generative_ODEs_With_Gradients_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Graph Transformer GANs for Graph-Constrained House Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Graph_Transformer_GANs_for_Graph-Constrained_House_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.08225",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "rwx9OPkRc4M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Master: Meta Style Transformer for Controllable Zero-Shot and Few-Shot Artistic Style Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Master_Meta_Style_Transformer_for_Controllable_Zero-Shot_and_Few-Shot_Artistic_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.11818",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PJaTztiUsTQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "MrTornado24/Next3D",
    "web_page": null,
    "github_page": "https://mrtornado24.github.io/Next3D/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Next3D_Generative_Neural_Texture_Rasterization_for_3D-Aware_Head_Avatars_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.11208",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "0F6Pmj-1sfI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Ham2Pose: Animating Sign Language Notation Into Pose Sequences",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "rotem-shalev/Ham2Pose",
    "web_page": null,
    "github_page": "https://rotem-shalev.github.io/ham-to-pose/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Arkushin_Ham2Pose_Animating_Sign_Language_Notation_Into_Pose_Sequences_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13613",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_XOsxnwjo7s",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Neural Transformation Fields for Arbitrary-Styled Font Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "fubinfb/NTF",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_Neural_Transformation_Fields_for_Arbitrary-Styled_Font_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Fxp8N7TDVkQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "LayoutDM: Transformer-Based Diffusion Model for Layout Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "CyberAgentAILab/layout-dm",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chai_LayoutDM_Transformer-Based_Diffusion_Model_for_Layout_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.02567",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "n3akFx3mtYU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Removing Objects From Neural Radiance Fields",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "nianticlabs/nerf-object-removal",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Weder_Removing_Objects_From_Neural_Radiance_Fields_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.11966",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "J8r1jgELmsM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Person Image Synthesis via Denoising Diffusion Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ankanbhunia/PIDM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bhunia_Person_Image_Synthesis_via_Denoising_Diffusion_Model_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.12500",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "NsUb2uxj820",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "AdaptiveMix: Improving GAN Training via Feature Space Shrinkage",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "WentianZhang-ML/AdaptiveMix",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_AdaptiveMix_Improving_GAN_Training_via_Feature_Space_Shrinkage_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.01559",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "BFKfw9rfYYU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Learning Joint Latent Space EBM Prior Model for Multi-Layer Generator",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "jcui1224/hierarchical-joint-ebm",
    "web_page": null,
    "github_page": "https://jcui1224.github.io/hierarchical-joint-ebm-proj/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cui_Learning_Joint_Latent_Space_EBM_Prior_Model_for_Multi-Layer_Generator_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2306.06323",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "VGit3sZWNGM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3D Neural Field Generation Using Triplane Diffusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "JRyanShue/NFD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Shue_3D_Neural_Field_Generation_Using_Triplane_Diffusion_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.16677",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "nxAiyoYkTJA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_OmniAvatar_Geometry-Guided_Controllable_3D_Head_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15539",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Z1aXE9q9eUI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "RWSC-Fusion: Region-Wise Style-Controlled Fusion Network for the Prohibited X-Ray Security Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Duan_RWSC-Fusion_Region-Wise_Style-Controlled_Fusion_Network_for_the_Prohibited_X-Ray_Security_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "OuOfUqWo2aQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ObjectStitch: Object Compositing With Diffusion Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Song_ObjectStitch_Object_Compositing_With_Diffusion_Model_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.00932",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "tmHJVatfpn8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Persistent Nature: A Generative Model of Unbounded 3D Worlds",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://chail.github.io/persistent-nature/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chai_Persistent_Nature_A_Generative_Model_of_Unbounded_3D_Worlds_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13515",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "5s1WnwRHmIs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Masked and Adaptive Transformer for Exemplar Based Image Translation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "AiArt-HDU/MATEBIT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Masked_and_Adaptive_Transformer_for_Exemplar_Based_Image_Translation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17123",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qCypRw-FcTM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Spider GAN: Leveraging Friendly Neighbors To Accelerate GAN Training",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "DarthSid95/SpiderStyleGAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Asokan_Spider_GAN_Leveraging_Friendly_Neighbors_To_Accelerate_GAN_Training_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.07613",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "EDrGSguQMBU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "avinabsaha/ReIQA",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Saha_Re-IQA_Unsupervised_Learning_for_Image_Quality_Assessment_in_the_Wild_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.00451",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "gHIAC-L3eFg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Align Your Latents: High-Resolution Video Synthesis With Latent Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "srpkdyy/VideoLDM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Blattmann_Align_Your_Latents_High-Resolution_Video_Synthesis_With_Latent_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.08818",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "All Are Worth Words: A ViT Backbone for Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "baofff/U-ViT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_All_Are_Worth_Words_A_ViT_Backbone_for_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2209.12152",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Y2EbGfUi2SY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Few-Shot Semantic Image Synthesis With Class Affinity Transfer",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "endo-yuki-t/Fewshot-SMIS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Careil_Few-Shot_Semantic_Image_Synthesis_With_Class_Affinity_Transfer_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.02321",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Blowing in the Wind: CycleNet for Human Cinemagraphs From Still Images",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://hbertiche.github.io/CycleNet/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bertiche_Blowing_in_the_Wind_CycleNet_for_Human_Cinemagraphs_From_Still_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.08639",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "KUTJkPVwcO8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "StyleGene: Crossover and Mutation of Region-Level Facial Genes for Kinship Face Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "CVI-SZU/StyleGene",
    "web_page": null,
    "github_page": "https://wmpscc.github.io/stylegene/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_StyleGene_Crossover_and_Mutation_of_Region-Level_Facial_Genes_for_Kinship_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "TDqGaL79_pg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MixNeRF: Modeling a Ray With Mixture Density for Novel View Synthesis From Sparse Inputs",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "shawn615/MixNeRF",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Seo_MixNeRF_Modeling_a_Ray_With_Mixture_Density_for_Novel_View_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.08788",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PXljJordbFk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MoStGAN-V: Video Generation With Temporal Motion Styles",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "xiaoqian-shen/MoStGAN-V",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_MoStGAN-V_Video_Generation_With_Temporal_Motion_Styles_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.02777",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hCyaAMh0Kgk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Frame Interpolation Transformer and Uncertainty Guidance",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "zhshi0816/Video-Frame-Interpolation-Transformer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Plack_Frame_Interpolation_Transformer_and_Uncertainty_Guidance_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "9KpZA-tibrU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Towards End-to-End Generative Modeling of Long Videos With Memory-Efficient Bidirectional Transformers",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Ugness/MeBT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yoo_Towards_End-to-End_Generative_Modeling_of_Long_Videos_With_Memory-Efficient_Bidirectional_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.11251",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "QTOJEO5o23k",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "HOLODIFFUSION: Training a 3D Diffusion Model Using 2D Images",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "facebookresearch/holo_diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Karnewar_HOLODIFFUSION_Training_a_3D_Diffusion_Model_Using_2D_Images_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16509",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "F65fEmvUKyc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Neural Texture Synthesis With Guided Correspondence",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "EliotChenKJ/Guided-Correspondence-Loss",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Neural_Texture_Synthesis_With_Guided_Correspondence_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "njB_O08IVCk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360°",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "SizheAn/PanoHead",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/An_PanoHead_Geometry-Aware_3D_Full-Head_Synthesis_in_360deg_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13071",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Y8NXiBOEWoE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "InstructPix2Pix: Learning To Follow Image Editing Instructions",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "timothybrooks/instruct-pix2pix",
    "web_page": "https://www.timothybrooks.com/instruct-pix2pix/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.09800",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "GUvD5W6tBJ4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Unpaired Image-to-Image Translation With Shortest Path Regularization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Mid-Push/santa",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Unpaired_Image-to-Image_Translation_With_Shortest_Path_Regularization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "tdzIUbz1JTQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Freestyle Layout-to-Image Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "essunny310/FreestyleNet",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_Freestyle_Layout-to-Image_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14412",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "EUeV3b3XHe8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "On Distillation of Guided Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Meng_On_Distillation_of_Guided_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2210.03142",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Single Image Backdoor Inversion via Robust Smoothed Classifiers",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "locuslab/smoothinv",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Single_Image_Backdoor_Inversion_via_Robust_Smoothed_Classifiers_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.00215",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "bt1yxznTXrQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Make-a-Story: Visual Memory Conditioned Consistent Story Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ubc-vision/Make-A-Story",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Rahman_Make-a-Story_Visual_Memory_Conditioned_Consistent_Story_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13319",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "BXZ7LAg1sP8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Towards Practical Plug-and-Play Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "riiid/PPAP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Go_Towards_Practical_Plug-and-Play_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.05973",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "mIKEfXJj9Zs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Efficient Scale-Invariant Generator With Column-Row Entangled Pixel Synthesis",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "VinAIResearch/CREPS",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Nguyen_Efficient_Scale-Invariant_Generator_With_Column-Row_Entangled_Pixel_Synthesis_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14157",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_gceZhQMc8U",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Wavelet Diffusion Models Are Fast and Scalable Image Generators",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "VinAIResearch/WaveDiff",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Phung_Wavelet_Diffusion_Models_Are_Fast_and_Scalable_Image_Generators_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.16152",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "KaIMMamhKsU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3D GAN Inversion With Facial Symmetry Prior",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "FeiiYin/SPI",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yin_3D_GAN_Inversion_With_Facial_Symmetry_Prior_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.16927",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "pQF-cOVpQEE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "Sxjdwang/TalkLip",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Seeing_What_You_Said_Talking_Face_Generation_Guided_by_a_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17480",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "LUsRjL02ZsY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "PCT-Net: Full Resolution Image Harmonization Using Pixel-Wise Color Transformations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "rakutentech/PCT-Net-Image-Harmonization",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Guerreiro_PCT-Net_Full_Resolution_Image_Harmonization_Using_Pixel-Wise_Color_Transformations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model With Knowledge-Enhanced Mixture-of-Denoising-Experts",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://wenxin.baidu.com/ernie-vilg",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_ERNIE-ViLG_2.0_Improving_Text-to-Image_Diffusion_Model_With_Knowledge-Enhanced_Mixture-of-Denoising-Experts_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2210.15257",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Video Compression With Entropy-Constrained Neural Representations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Gomes_Video_Compression_With_Entropy-Constrained_Neural_Representations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PyxyYlwQuCw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "UCSB-NLP-Chang/DiffusionDisentanglement",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.08698",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "m3CVMRAt1Q0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CoralStyleCLIP: Co-Optimized Region and Layer Selection for Image Editing",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "JiauZhang/CoralStyleCLIP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Revanur_CoralStyleCLIP_Co-Optimized_Region_and_Layer_Selection_for_Image_Editing_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.05031",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "5LTbVjuErkg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "man805/Diffusion-Video-Autoencoders",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Diffusion_Video_Autoencoders_Toward_Temporally_Consistent_Face_Video_Editing_via_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.02802",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ISawoMRNuRU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Sequential Training of GANs Against GAN-Classifiers Reveals Correlated <code>Knowledge Gaps</code> Present Among Independently Trained GAN Instances",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Pathak_Sequential_Training_of_GANs_Against_GAN-Classifiers_Reveals_Correlated_Knowledge_Gaps_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15533",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "q2yOvUIaz2o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Attribute-Preserving Face Dataset Anonymization via Latent Code Optimization",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "chi0tzp/FALCO",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Barattin_Attribute-Preserving_Face_Dataset_Anonymization_via_Latent_Code_Optimization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.11296",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "qpGecrlK7_8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Shifted Diffusion for Text-to-Image Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "drboog/Shifted_Diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Shifted_Diffusion_for_Text-to-Image_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.15388",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "HandsOff: Labeled Dataset Generation With No Additional Human Annotations",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "austinxu87/handsoff",
    "web_page": null,
    "github_page": "https://austinxu87.github.io/handsoff/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_HandsOff_Labeled_Dataset_Generation_With_No_Additional_Human_Annotations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.12645",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Yn-1QOcrIAQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Lookahead Diffusion Probabilistic Models for Refining Mean Estimation",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "guoqiang-zhang-x/LA-DPM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Lookahead_Diffusion_Probabilistic_Models_for_Refining_Mean_Estimation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.11312",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image Inpainting",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": null,
    "web_page": "https://imagen.research.google/editor/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Imagen_Editor_and_EditBench_Advancing_and_Evaluating_Text-Guided_Image_Inpainting_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.06909",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Re-GAN: Data-Efficient GANs Training via Architectural Reconfiguration",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "IntellicentAI-Lab/Re-GAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Saxena_Re-GAN_Data-Efficient_GANs_Training_via_Architectural_Reconfiguration_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "BBDM: Image-to-Image Translation With Brownian Bridge Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "xuekt98/BBDM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_BBDM_Image-to-Image_Translation_With_Brownian_Bridge_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2205.07680",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZrW88C63Suo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": null,
    "github": "ximinng/VectorFusion-pytorch",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Jain_VectorFusion_Text-to-SVG_by_Abstracting_Pixel-Based_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.11319",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  }
]