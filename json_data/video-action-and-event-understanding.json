[
  {
    "title": "Open Set Action Recognition via Multi-Label Evidential Learning",
    "base_url": null,
    "title_page": null,
    "repo": "charliezhaoyinpeng/mule",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Open_Set_Action_Recognition_via_Multi-Label_Evidential_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12698",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "S185R1vT2Qk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "FLAG3D: A 3D Fitness Activity Dataset with Language Instruction",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": "https://andytang15.github.io/FLAG3D/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_FLAG3D_A_3D_Fitness_Activity_Dataset_With_Language_Instruction_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04638",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "CgdRmk0BVvM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "MoLo: Motion-augmented Long-Short Contrastive Learning for Few-Shot Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "alibaba-mmai-research/MoLo",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_MoLo_Motion-Augmented_Long-Short_Contrastive_Learning_for_Few-Shot_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.00946",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Ig1HGTrrA54",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "The Wisdom of Crowds: Temporal Progressive Attention for Early Action Prediction",
    "base_url": null,
    "title_page": null,
    "repo": "alexandrosstergiou/progressive-action-prediction",
    "web_page": null,
    "github_page": "https://alexandrosstergiou.github.io/project_pages/TemPr/index.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Stergiou_The_Wisdom_of_Crowds_Temporal_Progressive_Attention_for_Early_Action_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2204.13340",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "dcmd8U47BT8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Use Your Head: Improving Long-Tail Video Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "tobyperrett/lmr",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Perrett_Use_Your_Head_Improving_Long-Tail_Video_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.01143",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "TXEMh99Ukmg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Decomposed Cross-Modal Distillation for RGB-based Temporal Action Detection",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Decomposed_Cross-Modal_Distillation_for_RGB-Based_Temporal_Action_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17285",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2upFWX7NVqc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Video Test-Time Adaptation for Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "wlin-at/ViTTA",
    "web_page": null,
    "github_page": "https://wlin-at.github.io/vitta",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Video_Test-Time_Adaptation_for_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.15393",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "RzdYgE1hN2o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "How Can Objects Help Action Recognition?",
    "base_url": null,
    "title_page": null,
    "repo": "google-research/scenic",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_How_Can_Objects_Help_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2306.11726",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4E_X1hCj4yU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Text-Visual Prompting for Efficient 2D Temporal Video Grounding",
    "base_url": null,
    "title_page": null,
    "repo": "intel/TVP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Text-Visual_Prompting_for_Efficient_2D_Temporal_Video_Grounding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.04995",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "zj2s_G3066s",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Enlarging Instance-Specific and Class-Specific Information for Open-Set Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "Jun-CEN/PSL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cen_Enlarging_Instance-Specific_and_Class-Specific_Information_for_Open-Set_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15467",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "SofkzNeymP4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "TimeBalance: Temporally-Invariant and Temporally-Distinctive Video Representations for Semi-Supervised Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "DAVEISHAN/TimeBalance",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dave_TimeBalance_Temporally-Invariant_and_Temporally-Distinctive_Video_Representations_for_Semi-Supervised_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16268",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2c5LM6YqPKQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Video Representations from Large Language Models",
    "base_url": null,
    "title_page": null,
    "repo": "facebookresearch/LaViLa",
    "web_page": null,
    "github_page": "https://facebookresearch.github.io/LaViLa/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Learning_Video_Representations_From_Large_Language_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.04501",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "tbQaP07xQ4c",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Fine-tuned CLIP Models are Efficient Video Learners",
    "base_url": null,
    "title_page": null,
    "repo": "muzairkhattak/ViFi-CLIP",
    "web_page": null,
    "github_page": "https://muzairkhattak.github.io/ViFi-CLIP/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Rasheed_Fine-Tuned_CLIP_Models_Are_Efficient_Video_Learners_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.03640",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "uqPLPIyWBb0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Efficient Movie Scene Detection Using State-Space Transformers",
    "base_url": null,
    "title_page": null,
    "repo": "md-mohaiminul/TranS4mer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Islam_Efficient_Movie_Scene_Detection_Using_State-Space_Transformers_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.14427",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "EOmVAByPQbE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "AdamsFormer for Spatial Action Localization in the Future",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Chi_AdamsFormer_for_Spatial_Action_Localization_in_the_Future_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PK0O-ynPgr0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "A Light Weight Model for Active Speaker Detection",
    "base_url": null,
    "title_page": null,
    "repo": "Junhua-Liao/Light-ASD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Liao_A_Light_Weight_Model_for_Active_Speaker_Detection_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.04439",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "spGacmYdvYs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "System-Status-Aware Adaptive Network for Online Streaming Video Understanding",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Foo_System-Status-Aware_Adaptive_Network_for_Online_Streaming_Video_Understanding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15742",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8DrTkS247xs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "STMixer: A One-Stage Sparse Action Detector",
    "base_url": null,
    "title_page": null,
    "repo": "MCG-NJU/STMixer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Wu_STMixer_A_One-Stage_Sparse_Action_Detector_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.15879",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Sy4jozsQLM0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Revisiting Temporal Modeling for CLIP-Based Image-to-Video Knowledge Transferring",
    "base_url": null,
    "title_page": null,
    "repo": "farewellthree/STAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Liu_Revisiting_Temporal_Modeling_for_CLIP-Based_Image-to-Video_Knowledge_Transferring_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2301.11116",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "kaDItcB1iFw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Distilling Vision-Language Pre-Training To Collaborate With Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "repo": "ju-chen/Efficient-Prompt",
    "web_page": null,
    "github_page": "https://voide1220.github.io/distillation_collaboration/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Ju_Distilling_Vision-Language_Pre-Training_To_Collaborate_With_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.09335",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Real-Time Multi-Person Eyeblink Detection in the Wild for Untrimmed Video",
    "base_url": null,
    "title_page": null,
    "repo": "wenzhengzeng/MPEblink",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zeng_Real-Time_Multi-Person_Eyeblink_Detection_in_the_Wild_for_Untrimmed_Video_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16053",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ngME7dym0Uk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Modeling Video As Stochastic Processes for Fine-Grained Video Representation Learning",
    "base_url": null,
    "title_page": null,
    "repo": "hengRUC/VSP",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhang_Modeling_Video_As_Stochastic_Processes_for_Fine-Grained_Video_Representation_Learning_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Re<sup>2</sup>TAL: <u>Re</u>wiring Pretrained Video Backbones for <u>Re</u>versible <u>T</u>emporal <u>A</u>ction <u>L</u>ocalization",
    "base_url": null,
    "title_page": null,
    "repo": "coolbay/Re2TAL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhao_Re2TAL_Rewiring_Pretrained_Video_Backbones_for_Reversible_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.14053",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Oa29cFo_nMY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Discriminative Representations for Skeleton Based Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "zhysora/FR-Head",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhou_Learning_Discriminative_Representations_for_Skeleton_Based_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.03729",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ix6rADaCjNs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Learning Procedure-Aware Video Representation From Instructional Videos and Their Narrations",
    "base_url": null,
    "title_page": null,
    "repo": "facebookresearch/ProcedureVRL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Yu_Learning_Procedure-Aware_Video_Representation_From_Instructional_Videos_and_Their_Narrations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.17839",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "YPq-rziL8Jo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Collecting Cross-Modal Presence-Absence Evidence for Weakly-Supervised Audio-Visual Event Perception",
    "base_url": null,
    "title_page": null,
    "repo": "MengyuanChen21/CVPR2023-CMPAE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Gao_Collecting_Cross-Modal_Presence-Absence_Evidence_for_Weakly-Supervised_Audio-Visual_Event_Perception_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "PivoTAL: Prior-Driven Supervision for Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Rizve_PivoTAL_Prior-Driven_Supervision_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6kAoQjXfzio",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Cascade Evidential Learning for Open-World Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "repo": "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_Cascade_Evidential_Learning_for_Open-World_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Soft-Landing Strategy for Alleviating the Task Discrepancy Problem in Temporal Action Localization Tasks",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Kang_Soft-Landing_Strategy_for_Alleviating_the_Task_Discrepancy_Problem_in_Temporal_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.06023",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "SVFormer: Semi-Supervised Video Transformer for Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "ChenHsing/SVFormer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Xing_SVFormer_Semi-Supervised_Video_Transformer_for_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.13222",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6kAoQjXfzio",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "AutoAD: Movie Description in Context",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": "https://www.robots.ox.ac.uk/~vgg/research/autoad/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Han_AutoAD_Movie_Description_in_Context_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.16899",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "gMQSoib6lSI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": "zgzxy001/STMT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhu_STMT_A_Spatial-Temporal_Mesh_Transformer_for_MoCap-Based_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.18177",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Boosting Weakly-Supervised Temporal Action Localization With Text Information",
    "base_url": null,
    "title_page": null,
    "repo": "lgzlIlIlI/Boosting-WTAL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Boosting_Weakly-Supervised_Temporal_Action_Localization_With_Text_Information_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.00607",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "n8p4ZU85LXM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Aligning Step-by-Step Instructional Diagrams to Video Demonstrations",
    "base_url": null,
    "title_page": null,
    "repo": "DavidZhang73/AssemblyVideoManualAlignment",
    "web_page": "https://academic.davidz.cn/en/publication/zhang-cvpr-2023/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhang_Aligning_Step-by-Step_Instructional_Diagrams_to_Video_Demonstrations_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.13800",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8iC5QyP8U6o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Improving Weakly Supervised Temporal Action Localization by Bridging Train-Test Gap in Pseudo Labels",
    "base_url": null,
    "title_page": null,
    "repo": "zhou745/GauFuse_WSTAL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhou_Improving_Weakly_Supervised_Temporal_Action_Localization_by_Bridging_Train-Test_Gap_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.07978",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Weakly Supervised Video Representation Learning With Unaligned Text for Sequential Videos",
    "base_url": null,
    "title_page": null,
    "repo": "svip-lab/WeakSVR",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Dong_Weakly_Supervised_Video_Representation_Learning_With_Unaligned_Text_for_Sequential_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12370",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "AqozSRYP7Pc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Dense-Localizing Audio-Visual Events in Untrimmed Videos: A Large-Scale Benchmark and Baseline",
    "base_url": null,
    "title_page": null,
    "repo": "ttgeng233/UnAV",
    "web_page": null,
    "github_page": "https://unav100.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Geng_Dense-Localizing_Audio-Visual_Events_in_Untrimmed_Videos_A_Large-Scale_Benchmark_and_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.12930",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "PPDywLMn1Js",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "LOGO: A Long-Form Video Dataset for Group Action Quality Assessment",
    "base_url": null,
    "title_page": null,
    "repo": "shiyi-zh0408/LOGO",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhang_LOGO_A_Long-Form_Video_Dataset_for_Group_Action_Quality_Assessment_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Search-Map-Search: A Frame Selection Paradigm for Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Zhao_Search-Map-Search_A_Frame_Selection_Paradigm_for_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2304.10316",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Ywdf6di2QWo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "3Mformer: Multi-Order Multi-Mode Transformer for Skeletal Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_3Mformer_Multi-Order_Multi-Mode_Transformer_for_Skeletal_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14474",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_LzrzFIuaNU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "ProTeGe: Untrimmed Pretraining for Video Temporal Grounding by Video Temporal Grounding",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_ProTeGe_Untrimmed_Pretraining_for_Video_Temporal_Grounding_by_Video_Temporal_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Egocentric Video Task Translation",
    "base_url": null,
    "title_page": null,
    "repo": "facebookresearch/EgoT2",
    "web_page": "https://vision.cs.utexas.edu/projects/egot2/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Xue_Egocentric_Video_Task_Translation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.06301",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "HHWLMFIZ5ow",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Look Around for Anomalies: Weakly-Supervised Anomaly Detection via Context-Motion Relational Learning",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Cho_Look_Around_for_Anomalies_Weakly-Supervised_Anomaly_Detection_via_Context-Motion_Relational_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "31ccYdwGDG8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Proposal-Based Multiple Instance Learning for Weakly-Supervised Temporal Action Localization",
    "base_url": null,
    "title_page": null,
    "repo": "RenHuan1999/CVPR2023_P-MIL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Ren_Proposal-Based_Multiple_Instance_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2305.17861",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hfHGlKyOQ68",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "TriDet: Temporal Action Detection With Relative Boundary Modeling",
    "base_url": null,
    "title_page": null,
    "repo": "dingfengshi/TriDet",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Shi_TriDet_Temporal_Action_Detection_With_Relative_Boundary_Modeling_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.07347",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "f1gJkUI6rA4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Actionlet-Dependent Contrastive Learning for Unsupervised Skeleton-Based Action Recognition",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": "https://langlandslin.github.io/projects/ActCLR/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Lin_Actionlet-Dependent_Contrastive_Learning_for_Unsupervised_Skeleton-Based_Action_Recognition_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.10904",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jwX0Zc8s10w",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "EVAL: Explainable Video Anomaly Localization",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Singh_EVAL_Explainable_Video_Anomaly_Localization_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.07900",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6x8GUDWkN68",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  },
  {
    "title": "Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video Learning",
    "base_url": null,
    "title_page": null,
    "repo": "daniel-code/TubeViT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com//content/CVPR2023/papers/Piergiovanni_Rethinking_Video_ViTs_Sparse_Video_Tubes_for_Joint_Image_and_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.03229",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Video: Action and Event Understanding"
  }
]