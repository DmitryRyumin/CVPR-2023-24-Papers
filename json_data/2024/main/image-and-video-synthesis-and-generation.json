[
  {
    "title": "Alchemist: Parametric Control of Material Properties with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sharma_Alchemist_Parametric_Control_of_Material_Properties_with_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://www.prafullsharma.net/alchemist/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sharma_Alchemist_Parametric_Control_of_Material_Properties_with_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02970",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Analyzing and Improving the Training Dynamics of Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Karras_Analyzing_and_Improving_the_Training_Dynamics_of_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "NVlabs/edm2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Karras_Analyzing_and_Improving_the_Training_Dynamics_of_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02696",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Attention Calibration for Disentangled Text-to-Image Personalization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Attention_Calibration_for_Disentangled_Text-to-Image_Personalization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Monalissaa/DisenDiff",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Attention_Calibration_for_Disentangled_Text-to-Image_Personalization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.18551",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FreeU: Free Lunch in Diffusion U-Net",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ChenyangSi/FreeU",
    "web_page": "https://chenyangsi.top/FreeU",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.11497",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-CZ5uWxvX30",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Generative Image Dynamics",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_Generative_Image_Dynamics_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "fltwr/generative-image-dynamics",
    "web_page": null,
    "github_page": "https://generative-dynamics.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_Generative_Image_Dynamics_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.07906",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Instruct-Imagen: Image Generation with Multi-Modal Instruction",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://instruct-imagen.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.01952",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Dalva_NoiseCLR_A_Contrastive_Learning_Approach_for_Unsupervised_Discovery_of_Interpretable_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://noiseclr.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Dalva_NoiseCLR_A_Contrastive_Learning_Approach_for_Unsupervised_Discovery_of_Interpretable_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.05390",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "RA2KzZ25F5I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Feng_Ranni_Taming_Text-to-Image_Diffusion_for_Accurate_Instruction_Following_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/Ranni",
    "web_page": null,
    "github_page": "https://ranni-t2i.github.io/Ranni/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Feng_Ranni_Taming_Text-to-Image_Diffusion_for_Accurate_Instruction_Following_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17002",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "1IIat83Atjk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Style Aligned Image Generation via Shared Attention",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hertz_Style_Aligned_Image_Generation_via_Shared_Attention_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "google/style-aligned",
    "web_page": null,
    "github_page": "https://style-aligned-gen.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hertz_Style_Aligned_Image_Generation_via_Shared_Attention_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02133",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Geng_Visual_Anagrams_Generating_Multi-View_Optical_Illusions_with_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "dangeng/visual_anagrams",
    "web_page": null,
    "github_page": "https://dangeng.github.io/visual_anagrams/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Geng_Visual_Anagrams_Generating_Multi-View_Optical_Illusions_with_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17919",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ling_Align_Your_Gaussians_Text-to-4D_with_Dynamic_3D_Gaussians_and_Composed_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ling_Align_Your_Gaussians_Text-to-4D_with_Dynamic_3D_Gaussians_and_Composed_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.13763",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Amodal Completion via Progressive Mixed Context Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Xu_Amodal_Completion_via_Progressive_Mixed_Context_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "k8xu/amodal",
    "web_page": null,
    "github_page": "https://k8xu.github.io/amodal/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Xu_Amodal_Completion_via_Progressive_Mixed_Context_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.15540",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CLiC: Concept Learning in Context",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Safaee_CLiC_Concept_Learning_in_Context_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Mehdi0xC/clic",
    "web_page": null,
    "github_page": "https://mehdi0xc.github.io/clic/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Safaee_CLiC_Concept_Learning_in_Context_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17083",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8g--nx3RyEQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Clockwork Diffusion: Efficient Generation with Model-Step Distillation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Habibian_Clockwork_Diffusion_Efficient_Generation_With_Model-Step_Distillation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Qualcomm-AI-research/clockwork-diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Habibian_Clockwork_Diffusion_Efficient_Generation_With_Model-Step_Distillation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.08128",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jdpOFQn8zKw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lu_Coarse-to-Fine_Latent_Diffusion_for_Pose-Guided_Person_Image_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "YanzuoLu/CFLD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lu_Coarse-to-Fine_Latent_Diffusion_for_Pose-Guided_Person_Image_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.18078",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZqMdjfzaj-I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CoDeF: Content Deformation Fields for Temporally Consistent Video Processing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ouyang_CoDeF_Content_Deformation_Fields_for_Temporally_Consistent_Video_Processing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "qiuyu96/CoDeF",
    "web_page": null,
    "github_page": "https://qiuyu96.github.io/CoDeF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ouyang_CoDeF_Content_Deformation_Fields_for_Temporally_Consistent_Video_Processing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2308.07926",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Correcting Diffusion Generation through Resampling",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_Correcting_Diffusion_Generation_through_Resampling_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "UCSB-NLP-Chang/diffusion_resampling",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_Correcting_Diffusion_Generation_through_Resampling_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.06038",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CosmicMan: A Text-to-Image Foundation Model for Humans",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_CosmicMan_A_Text-to-Image_Foundation_Model_for_Humans_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "cosmicman-cvpr2024/CosmicMan",
    "web_page": null,
    "github_page": "https://cosmicman-cvpr2024.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/cosmicman/CosmicMan-SDXL",
    "paper_thecvf": "/papers/Li_CosmicMan_A_Text-to-Image_Foundation_Model_for_Humans_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.01294",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "CsZKA27tQDA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "bytedance/DEADiff",
    "web_page": null,
    "github_page": "https://tianhao-qi.github.io/DEADiff/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.06951",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diffusion Handles Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Pandey_Diffusion_Handles_Enabling_3D_Edits_for_Diffusion_Models_by_Lifting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "adobe-research/DiffusionHandles",
    "web_page": null,
    "github_page": "https://diffusionhandles.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Pandey_Diffusion_Handles_Enabling_3D_Edits_for_Diffusion_Models_by_Lifting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02190",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "OxOjiFaTSZg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  }
]