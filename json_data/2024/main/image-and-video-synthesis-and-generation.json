[
  {
    "title": "Alchemist: Parametric Control of Material Properties with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sharma_Alchemist_Parametric_Control_of_Material_Properties_with_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://www.prafullsharma.net/alchemist/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sharma_Alchemist_Parametric_Control_of_Material_Properties_with_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02970",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Analyzing and Improving the Training Dynamics of Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Karras_Analyzing_and_Improving_the_Training_Dynamics_of_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "NVlabs/edm2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Karras_Analyzing_and_Improving_the_Training_Dynamics_of_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02696",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Attention Calibration for Disentangled Text-to-Image Personalization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Attention_Calibration_for_Disentangled_Text-to-Image_Personalization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Monalissaa/DisenDiff",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Attention_Calibration_for_Disentangled_Text-to-Image_Personalization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.18551",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FreeU: Free Lunch in Diffusion U-Net",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ChenyangSi/FreeU",
    "web_page": "https://chenyangsi.top/FreeU",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.11497",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-CZ5uWxvX30",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Generative Image Dynamics",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_Generative_Image_Dynamics_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "fltwr/generative-image-dynamics",
    "web_page": null,
    "github_page": "https://generative-dynamics.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_Generative_Image_Dynamics_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.07906",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Instruct-Imagen: Image Generation with Multi-Modal Instruction",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://instruct-imagen.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.01952",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Dalva_NoiseCLR_A_Contrastive_Learning_Approach_for_Unsupervised_Discovery_of_Interpretable_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://noiseclr.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Dalva_NoiseCLR_A_Contrastive_Learning_Approach_for_Unsupervised_Discovery_of_Interpretable_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.05390",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "RA2KzZ25F5I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Feng_Ranni_Taming_Text-to-Image_Diffusion_for_Accurate_Instruction_Following_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/Ranni",
    "web_page": null,
    "github_page": "https://ranni-t2i.github.io/Ranni/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Feng_Ranni_Taming_Text-to-Image_Diffusion_for_Accurate_Instruction_Following_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17002",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "1IIat83Atjk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Style Aligned Image Generation via Shared Attention",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hertz_Style_Aligned_Image_Generation_via_Shared_Attention_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "google/style-aligned",
    "web_page": null,
    "github_page": "https://style-aligned-gen.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hertz_Style_Aligned_Image_Generation_via_Shared_Attention_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02133",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Geng_Visual_Anagrams_Generating_Multi-View_Optical_Illusions_with_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "dangeng/visual_anagrams",
    "web_page": null,
    "github_page": "https://dangeng.github.io/visual_anagrams/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Geng_Visual_Anagrams_Generating_Multi-View_Optical_Illusions_with_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17919",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ling_Align_Your_Gaussians_Text-to-4D_with_Dynamic_3D_Gaussians_and_Composed_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ling_Align_Your_Gaussians_Text-to-4D_with_Dynamic_3D_Gaussians_and_Composed_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.13763",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Amodal Completion via Progressive Mixed Context Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Xu_Amodal_Completion_via_Progressive_Mixed_Context_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "k8xu/amodal",
    "web_page": null,
    "github_page": "https://k8xu.github.io/amodal/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Xu_Amodal_Completion_via_Progressive_Mixed_Context_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.15540",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CLiC: Concept Learning in Context",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Safaee_CLiC_Concept_Learning_in_Context_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Mehdi0xC/clic",
    "web_page": null,
    "github_page": "https://mehdi0xc.github.io/clic/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Safaee_CLiC_Concept_Learning_in_Context_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17083",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8g--nx3RyEQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Clockwork Diffusion: Efficient Generation with Model-Step Distillation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Habibian_Clockwork_Diffusion_Efficient_Generation_With_Model-Step_Distillation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Qualcomm-AI-research/clockwork-diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Habibian_Clockwork_Diffusion_Efficient_Generation_With_Model-Step_Distillation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.08128",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jdpOFQn8zKw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lu_Coarse-to-Fine_Latent_Diffusion_for_Pose-Guided_Person_Image_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "YanzuoLu/CFLD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lu_Coarse-to-Fine_Latent_Diffusion_for_Pose-Guided_Person_Image_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.18078",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZqMdjfzaj-I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CoDeF: Content Deformation Fields for Temporally Consistent Video Processing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ouyang_CoDeF_Content_Deformation_Fields_for_Temporally_Consistent_Video_Processing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "qiuyu96/CoDeF",
    "web_page": null,
    "github_page": "https://qiuyu96.github.io/CoDeF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ouyang_CoDeF_Content_Deformation_Fields_for_Temporally_Consistent_Video_Processing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2308.07926",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Correcting Diffusion Generation through Resampling",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_Correcting_Diffusion_Generation_through_Resampling_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "UCSB-NLP-Chang/diffusion_resampling",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_Correcting_Diffusion_Generation_through_Resampling_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.06038",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CosmicMan: A Text-to-Image Foundation Model for Humans",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_CosmicMan_A_Text-to-Image_Foundation_Model_for_Humans_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "cosmicman-cvpr2024/CosmicMan",
    "web_page": null,
    "github_page": "https://cosmicman-cvpr2024.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/cosmicman/CosmicMan-SDXL",
    "paper_thecvf": "/papers/Li_CosmicMan_A_Text-to-Image_Foundation_Model_for_Humans_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.01294",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "CsZKA27tQDA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "bytedance/DEADiff",
    "web_page": null,
    "github_page": "https://tianhao-qi.github.io/DEADiff/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.06951",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diffusion Handles Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Pandey_Diffusion_Handles_Enabling_3D_Edits_for_Diffusion_Models_by_Lifting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "adobe-research/DiffusionHandles",
    "web_page": null,
    "github_page": "https://diffusionhandles.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Pandey_Diffusion_Handles_Enabling_3D_Edits_for_Diffusion_Models_by_Lifting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02190",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "OxOjiFaTSZg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_DistriFusion_Distributed_Parallel_Inference_for_High-Resolution_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "mit-han-lab/distrifuser",
    "web_page": "https://hanlab.mit.edu/projects/distrifusion",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_DistriFusion_Distributed_Parallel_Inference_for_High-Resolution_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.19481",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "EZX7srDDmW0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Don't Drop Your Samples! Coherence-Aware Training Benefits Conditional Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Dufour_Dont_Drop_Your_Samples_Coherence-Aware_Training_Benefits_Conditional_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "nicolas-dufour/CAD",
    "web_page": null,
    "github_page": "https://nicolas-dufour.github.io/cad",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Dufour_Dont_Drop_Your_Samples_Coherence-Aware_Training_Benefits_Conditional_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4Tu-x2-Zcxs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Shi_DragDiffusion_Harnessing_Diffusion_Models_for_Interactive_Point-based_Image_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Yujun-Shi/DragDiffusion",
    "web_page": null,
    "github_page": "https://yujun-shi.github.io/projects/dragdiffusion.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Shi_DragDiffusion_Harnessing_Diffusion_Models_for_Interactive_Point-based_Image_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2306.14435",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "rysOFTpDBhc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Dynamic Policy-Driven Adaptive Multi-Instance Learning for whole Slide Image Classification",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zheng_Dynamic_Policy-Driven_Adaptive_Multi-Instance_Learning_for_Whole_Slide_Image_Classification_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "titizheng/PAMIL",
    "web_page": "https://vilab.hit.edu.cn/projects/pamil/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zheng_Dynamic_Policy-Driven_Adaptive_Multi-Instance_Learning_for_Whole_Slide_Image_Classification_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.07939",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ThDuM2tJPzs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Fast ODE-based Sampling for Diffusion Models in Around 5 Steps",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_Fast_ODE-based_Sampling_for_Diffusion_Models_in_Around_5_Steps_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zju-pi/diff-sampler",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_Fast_ODE-based_Sampling_for_Diffusion_Models_in_Around_5_Steps_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.00094",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liang_FlowVid_Taming_Imperfect_Optical_Flows_for_Consistent_Video-to-Video_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Jeff-LiangF/FlowVid",
    "web_page": null,
    "github_page": "https://jeff-liangf.github.io/projects/flowvid/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liang_FlowVid_Taming_Imperfect_Optical_Flows_for_Consistent_Video-to-Video_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.17681",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "y5IlgGl8Y24",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Generative Powers of Ten",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_Generative_Powers_of_Ten_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "aryanmikaeili/generative_powers_of_ten",
    "web_page": null,
    "github_page": "https://powers-of-10.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_Generative_Powers_of_Ten_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02149",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_HumanGaussian_Text-Driven_3D_Human_Generation_with_Gaussian_Splatting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "alvinliu0/HumanGaussian",
    "web_page": null,
    "github_page": "https://alvinliu0.github.io/projects/HumanGaussian",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_HumanGaussian_Text-Driven_3D_Human_Generation_with_Gaussian_Splatting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17061",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "S3djzHoqPKY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Image Neural Field Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Image_Neural_Field_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://yinboc.github.io/infd/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Image_Neural_Field_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2406.07480",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Learning Adaptive Spatial Coherent Correlations for Speech-Preserving Facial Expression Manipulation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Learning_Adaptive_Spatial_Coherent_Correlations_for_Speech-Preserving_Facial_Expression_Manipulation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "jianmanlincjx/ASCCL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Learning_Adaptive_Spatial_Coherent_Correlations_for_Speech-Preserving_Facial_Expression_Manipulation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liang_LucidDreamer_Towards_High-Fidelity_Text-to-3D_Generation_via_Interval_Score_Matching_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "EnVision-Research/LucidDreamer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liang_LucidDreamer_Towards_High-Fidelity_Text-to-3D_Generation_via_Interval_Score_Matching_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.11284",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "zToxGi_hNWs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_MicroCinema_A_Divide-and-Conquer_Approach_for_Text-to-Video_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://wangyanhui666.github.io/MicroCinema.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_MicroCinema_A_Divide-and-Conquer_Approach_for_Text-to-Video_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.18829",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "H7O-Ku_lqPA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_MIGC_Multi-Instance_Generation_Controller_for_Text-to-Image_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "limuloo/MIGC",
    "web_page": null,
    "github_page": "https://migcproject.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_MIGC_Multi-Instance_Generation_Controller_for_Text-to-Image_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.05408",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "One-Dimensional Adapter to Rule them All: Concepts Diffusion Models and Erasing Applications",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lyu_One-dimensional_Adapter_to_Rule_Them_All_Concepts_Diffusion_Models_and_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Con6924/SPM",
    "web_page": null,
    "github_page": "https://lyumengyao.github.io/projects/spm",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lyu_One-dimensional_Adapter_to_Rule_Them_All_Concepts_Diffusion_Models_and_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.16145",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Orthogonal Adaptation for Modular Customization of Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Po_Orthogonal_Adaptation_for_Modular_Customization_of_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://ryanpo.com/ortha/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Po_Orthogonal_Adaptation_for_Modular_Customization_of_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02432",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4lVEFBtYE4A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "PLACE: Adaptive Layout-Semantic Fusion for Semantic Image Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lv_PLACE_Adaptive_Layout-Semantic_Fusion_for_Semantic_Image_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "cszy98/PLACE",
    "web_page": null,
    "github_page": "https://cszy98.github.io/PLACE/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lv_PLACE_Adaptive_Layout-Semantic_Fusion_for_Semantic_Image_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.01852",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "47mMAmclPWw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sheynin_Emu_Edit_Precise_Image_Editing_via_Recognition_and_Generation_Tasks_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://emu-edit.metademolab.com/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sheynin_Emu_Edit_Precise_Image_Editing_via_Recognition_and_Generation_Tasks_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.10089",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "UNDR55ehSYM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Predicated Diffusion: Predicate Logic-based Attention Guidance for Text-to-Image Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sueyoshi_Predicated_Diffusion_Predicate_Logic-Based_Attention_Guidance_for_Text-to-Image_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sueyoshi_Predicated_Diffusion_Predicate_Logic-Based_Attention_Guidance_for_Text-to-Image_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.16117",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kara_RAVE_Randomized_Noise_Shuffling_for_Fast_and_Consistent_Video_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "RehgLab/RAVE",
    "web_page": null,
    "github_page": "https://rave-video.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/ozgurkara/RAVE",
    "paper_thecvf": "/papers/Kara_RAVE_Randomized_Noise_Shuffling_for_Fast_and_Consistent_Video_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.04524",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2hQho5AC9T0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Readout Guidance: Learning Control from Diffusion Features",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Luo_Readout_Guidance_Learning_Control_from_Diffusion_Features_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "google-research/readout_guidance",
    "web_page": null,
    "github_page": "https://readout-guidance.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Luo_Readout_Guidance_Learning_Control_from_Diffusion_Features_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02150",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Real-Time 3D-Aware Portrait Video Relighting",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Cai_Real-time_3D-aware_Portrait_Video_Relighting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "http://geometrylearning.com/VideoRelighting/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Cai_Real-time_3D-aware_Portrait_Video_Relighting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Residual Learning in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Residual_Learning_in_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Residual_Learning_in_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Rethinking FID: Towards a Better Evaluation Metric for Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Jayasumana_Rethinking_FID_Towards_a_Better_Evaluation_Metric_for_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://github.com/google-research/google-research/tree/master/cmmd",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Jayasumana_Rethinking_FID_Towards_a_Better_Evaluation_Metric_for_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.09603",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_Sat2Scene_3D_Urban_Scene_Generation_from_Satellite_Images_with_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_Sat2Scene_3D_Urban_Scene_Generation_from_Satellite_Images_with_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.10786",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "NqFy20zjFHU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Jiang_SCEdit_Efficient_and_Controllable_Image_Diffusion_Generation_via_Skip_Connection_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/SCEdit",
    "web_page": null,
    "github_page": "https://scedit.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Jiang_SCEdit_Efficient_and_Controllable_Image_Diffusion_Generation_via_Skip_Connection_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.11392",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "XJrK3-NgB1Q",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Huang_SmartEdit_Exploring_Complex_Instruction-based_Image_Editing_with_Multimodal_Large_Language_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "TencentARC/SmartEdit",
    "web_page": null,
    "github_page": "https://yuzhou914.github.io/SmartEdit/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Huang_SmartEdit_Exploring_Complex_Instruction-based_Image_Editing_with_Multimodal_Large_Language_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.06739",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Menapace_Snap_Video_Scaled_Spatiotemporal_Transformers_for_Text-to-Video_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://snap-research.github.io/snapvideo/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Menapace_Snap_Video_Scaled_Spatiotemporal_Transformers_for_Text-to-Video_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.14797",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "aL2zq_IKSBg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Style Injection in Diffusion: A Training-Free Approach for Adapting Large-Scale Diffusion Models for Style Transfer",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chung_Style_Injection_in_Diffusion_A_Training-free_Approach_for_Adapting_Large-scale_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "jiwoogit/StyleID",
    "web_page": null,
    "github_page": "https://jiwoogit.github.io/StyleID_site/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chung_Style_Injection_in_Diffusion_A_Training-free_Approach_for_Adapting_Large-scale_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.09008",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Tackling_the_Singularities_at_the_Endpoints_of_Time_Intervals_in_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "PangzeCheung/SingDiffusion",
    "web_page": null,
    "github_page": "https://pangzecheung.github.io/SingDiffusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Tackling_the_Singularities_at_the_Endpoints_of_Time_Intervals_in_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.08381",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "3Rt17MnHEJQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Taming Stable Diffusion for Text to 360 Panorama Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Taming_Stable_Diffusion_for_Text_to_360_Panorama_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "chengzhag/PanFusion",
    "web_page": null,
    "github_page": "https://chengzhag.github.io/publication/panfusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Taming_Stable_Diffusion_for_Text_to_360_Panorama_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.07949",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Huang_TFMQ-DM_Temporal_Feature_Maintenance_Quantization_for_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ModelTC/TFMQ-DM",
    "web_page": null,
    "github_page": "https://modeltc.github.io/TFMQ-DM/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Huang_TFMQ-DM_Temporal_Feature_Maintenance_Quantization_for_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.16503",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Total Selfie: Generating Full-Body Selfies",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Total_Selfie_Generating_Full-Body_Selfies_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ArmastusChen/total_selfie",
    "web_page": "https://homes.cs.washington.edu/~boweiche/project_page/totalselfie/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Total_Selfie_Generating_Full-Body_Selfies_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2308.14740",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Aoq6BLbynWM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Xu_UFOGen_You_Forward_Once_Large_Scale_Text-to-Image_Generation_via_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Xu_UFOGen_You_Forward_Once_Large_Scale_Text-to-Image_Generation_via_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.09257",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "VecFusion: Vector Font Generation with Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Thamizharasan_VecFusion_Vector_Font_Generation_with_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://vikastmz.github.io/VecFusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Thamizharasan_VecFusion_Vector_Font_Generation_with_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.10540",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "w4-h-t7XEKI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kwak_ViVid-1-to-3_Novel_View_Synthesis_with_Video_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ubc-vision/vivid123",
    "web_page": null,
    "github_page": "https://ubc-vision.github.io/vivid123/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Kwak_ViVid-1-to-3_Novel_View_Synthesis_with_Video_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3D Geometry-Aware Deformable Gaussian Splatting for Dynamic View Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lu_3D_Geometry-Aware_Deformable_Gaussian_Splatting_for_Dynamic_View_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://npucvr.github.io/GaGS/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lu_3D_Geometry-Aware_Deformable_Gaussian_Splatting_for_Dynamic_View_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.06270",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "gU0z0k9Ta0Y",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3D Multi-Frame Fusion for Video Stabilization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Peng_3D_Multi-frame_Fusion_for_Video_Stabilization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Peng_3D_Multi-frame_Fusion_for_Video_Stabilization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.12887",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-dpI1CFcM7A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "4D-fy: Text-to-4D Generation using Hybrid Score Distillation Sampling",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Bahmani_4D-fy_Text-to-4D_Generation_Using_Hybrid_Score_Distillation_Sampling_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "sherwinbahmani/4dfy",
    "web_page": null,
    "github_page": "https://sherwinbahmani.github.io/4dfy/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Bahmani_4D-fy_Text-to-4D_Generation_Using_Hybrid_Score_Distillation_Sampling_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_360DVD_Controllable_Panorama_Video_Generation_with_360-Degree_Video_Diffusion_Model_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Akaneqwq/360DVD",
    "web_page": null,
    "github_page": "https://akaneqwq.github.io/360DVD/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_360DVD_Controllable_Panorama_Video_Generation_with_360-Degree_Video_Diffusion_Model_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.06578",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Huang_RealCustom_Narrowing_Real_Text_Word_for_Real-Time_Open-Domain_Text-to-Image_Customization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://corleone-huang.github.io/realcustom/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Huang_RealCustom_Narrowing_Real_Text_Word_for_Real-Time_Open-Domain_Text-to-Image_Customization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.00483",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "<sup>*</sup>: Zero-Shot Style Transfer via Attention Reweighting",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Deng_Z_Zero-shot_Style_Transfer_via_Attention_Reweighting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "HolmesShuan/Zero-shot-Style-Transfer-via-Attention-Rearrangement",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Deng_Z_Zero-shot_Style_Transfer_via_Attention_Reweighting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "A Recipe for Scaling up Text-to-Video Generation with Text-Free Videos",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_A_Recipe_for_Scaling_up_Text-to-Video_Generation_with_Text-free_Videos_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/VGen",
    "web_page": null,
    "github_page": "https://tf-t2v.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_A_Recipe_for_Scaling_up_Text-to-Video_Generation_with_Text-free_Videos_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.15770",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Cx34ky0PxOU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "A Unified Approach for Text- and Image-guided 4D Scene Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zheng_A_Unified_Approach_for_Text-_and_Image-guided_4D_Scene_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "NVlabs/dream-in-4d",
    "web_page": "https://research.nvidia.com/labs/nxp/dream-in-4d/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zheng_A_Unified_Approach_for_Text-_and_Image-guided_4D_Scene_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.16854",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization Inversion for Zero-Shot Video Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_A_Video_is_Worth_256_Bases_Spatial-Temporal_Expectation-Maximization_Inversion_for_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "STEM-Inv/stem-inv",
    "web_page": null,
    "github_page": "https://stem-inv.github.io/page/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_A_Video_is_Worth_256_Bases_Spatial-Temporal_Expectation-Maximization_Inversion_for_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.05856",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "FZnDn4wBPqY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Accelerating Diffusion Sampling with Optimized Time Steps",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Xue_Accelerating_Diffusion_Sampling_with_Optimized_Time_Steps_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "scxue/DM-NonUniform",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Xue_Accelerating_Diffusion_Sampling_with_Optimized_Time_Steps_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.17376",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ACT-Diffusion: Efficient Adversarial Consistency Training for One-Step Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kong_ACT-Diffusion_Efficient_Adversarial_Consistency_Training_for_One-step_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "kong13661/ACT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Kong_ACT-Diffusion_Efficient_Adversarial_Consistency_Training_for_One-step_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.14097",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Adversarial Score Distillation: When Score Distillation Meets GAN",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wei_Adversarial_Score_Distillation_When_score_distillation_meets_GAN_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "2y7c3/ASD",
    "web_page": null,
    "github_page": "https://2y7c3.github.io/ASD/asd.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wei_Adversarial_Score_Distillation_When_score_distillation_meets_GAN_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.00739",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Adversarial Text to Continuous Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Haydarov_Adversarial_Text_to_Continuous_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://kilichbek.github.io/webpage/hypercgan/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Haydarov_Adversarial_Text_to_Continuous_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "AEROBLADE: Training-Free Detection of Latent Diffusion Images using Autoencoder Reconstruction Error",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ricker_AEROBLADE_Training-Free_Detection_of_Latent_Diffusion_Images_Using_Autoencoder_Reconstruction_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "jonasricker/aeroblade",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ricker_AEROBLADE_Training-Free_Detection_of_Latent_Diffusion_Images_Using_Autoencoder_Reconstruction_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.17879",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "P9OvpqQN_Js",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hu_Animate_Anyone_Consistent_and_Controllable_Image-to-Video_Synthesis_for_Character_Animation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "HumanAIGC/AnimateAnyone",
    "web_page": null,
    "github_page": "https://humanaigc.github.io/animate-anyone/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hu_Animate_Anyone_Consistent_and_Controllable_Image-to-Video_Synthesis_for_Character_Animation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17117",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8PCn5hLKNu4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Animating General Image with Large Visual Motion Model",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Animating_General_Image_with_Large_Visual_Motion_Model_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "densechen/LVMM",
    "web_page": null,
    "github_page": "https://densechen.github.io/LVMM/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Animating_General_Image_with_Large_Visual_Motion_Model_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Anomaly Score: Evaluating Generative Models and Individual Generated Images based on Complexity and Vulnerability",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hwang_Anomaly_Score_Evaluating_Generative_Models_and_Individual_Generated_Images_based_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hwang_Anomaly_Score_Evaluating_Generative_Models_and_Individual_Generated_Images_based_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.10634",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "AnyDoor: Zero-Shot Object-Level Image Customization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_AnyDoor_Zero-shot_Object-level_Image_Customization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/AnyDoor",
    "web_page": null,
    "github_page": "https://ali-vilab.github.io/AnyDoor-Page/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/xichenhku/AnyDoor-online",
    "paper_thecvf": "/papers/Chen_AnyDoor_Zero-shot_Object-level_Image_Customization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2307.09481",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "D4Goc3-BmGI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "AnyScene: Customized Image Synthesis with Composited Foreground",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_AnyScene_Customized_Image_Synthesis_with_Composited_Foreground_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_AnyScene_Customized_Image_Synthesis_with_Composited_Foreground_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_EYrW0w7r7U",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion Model and Implicit Neural Decoder",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kim_Arbitrary-Scale_Image_Generation_and_Upsampling_using_Latent_Diffusion_Model_and_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Kim_Arbitrary-Scale_Image_Generation_and_Upsampling_using_Latent_Diffusion_Model_and_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.10255",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ArtAdapter: Text-to-Image Style Transfer using Multi-Level Style Encoder and Explicit Adaptation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_ArtAdapter_Text-to-Image_Style_Transfer_using_Multi-Level_Style_Encoder_and_Explicit_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "cardinalblue/ArtAdapter",
    "web_page": null,
    "github_page": "https://cardinalblue.github.io/artadapter.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_ArtAdapter_Text-to-Image_Style_Transfer_using_Multi-Level_Style_Encoder_and_Explicit_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02109",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6e6TeV7wlRU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "AVID: Any-Length Video Inpainting with Diffusion Model",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_AVID_Any-Length_Video_Inpainting_with_Diffusion_Model_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zhang-zx/AVID",
    "web_page": null,
    "github_page": "https://zhang-zx.github.io/AVID/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_AVID_Any-Length_Video_Inpainting_with_Diffusion_Model_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.03816",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "p8-xTfOe9Tw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Balancing Act: Distribution-Guided Debiasing in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Parihar_Balancing_Act_Distribution-Guided_Debiasing_in_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "rishubhpar/debiasing_gen_models",
    "web_page": null,
    "github_page": "https://ab-34.github.io/balancing_act/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Parihar_Balancing_Act_Distribution-Guided_Debiasing_in_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.18206",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ppkJyw7t_UE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "BerfScene: Bev-Conditioned Equivariant Radiance Fields for Infinite 3D Scene Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_BerfScene_Bev-conditioned_Equivariant_Radiance_Fields_for_Infinite_3D_Scene_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zqh0253/BerfScene",
    "web_page": null,
    "github_page": "https://zqh0253.github.io/BerfScene/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/qihang/BerfScene",
    "paper_thecvf": "/papers/Zhang_BerfScene_Bev-conditioned_Equivariant_Radiance_Fields_for_Infinite_3D_Scene_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02136",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Beyond First-Order Tweedie: Solving Inverse Problems using Latent Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Rout_Beyond_First-Order_Tweedie_Solving_Inverse_Problems_using_Latent_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Rout_Beyond_First-Order_Tweedie_Solving_Inverse_Problems_using_Latent_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.00852",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Beyond Textual Constraints: Learning Novel Diffusion Conditions with Fewer Examples",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Yu_Beyond_Textual_Constraints_Learning_Novel_Diffusion_Conditions_with_Fewer_Examples_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Yuyan9Yu/BeyondTextConstraint",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Yu_Beyond_Textual_Constraints_Learning_Novel_Diffusion_Conditions_with_Fewer_Examples_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "BkJejVktIWs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Shi_BIVDiff_A_Training-Free_Framework_for_General-Purpose_Video_Synthesis_via_Bridging_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "MCG-NJU/BIVDiff",
    "web_page": null,
    "github_page": "https://bivdiff.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Shi_BIVDiff_A_Training-Free_Framework_for_General-Purpose_Video_Synthesis_via_Bridging_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02813",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Boosting Diffusion Models with Moving Average Sampling in Frequency Domain",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Qian_Boosting_Diffusion_Models_with_Moving_Average_Sampling_in_Frequency_Domain_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Qian_Boosting_Diffusion_Models_with_Moving_Average_Sampling_in_Frequency_Domain_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.17870",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "25wh9-MGtYw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "C3: High-Performance and Low-Complexity Neural Compression from a Single Image or Video",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kim_C3_High-Performance_and_Low-Complexity_Neural_Compression_from_a_Single_Image_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "google-deepmind/c3_neural_compression",
    "web_page": null,
    "github_page": "https://c3-neural-compression.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Kim_C3_High-Performance_and_Low-Complexity_Neural_Compression_from_a_Single_Image_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02753",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Cache Me if You Can: Accelerating Diffusion Models through Block Caching",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wimbauer_Cache_Me_if_You_Can_Accelerating_Diffusion_Models_through_Block_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://fwmb.github.io/blockcaching/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wimbauer_Cache_Me_if_You_Can_Accelerating_Diffusion_Models_through_Block_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.03209",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "pQjJmDltIDk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CAMEL: CAusal Motion Enhancement Tailored for Lifting Text-Driven Video Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_CAMEL_CAusal_Motion_Enhancement_Tailored_for_Lifting_Text-driven_Video_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zhangguiwei610/CAMEL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_CAMEL_CAusal_Motion_Enhancement_Tailored_for_Lifting_Text-driven_Video_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "c_TZEz4tj2A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CapHuman: Capture Your Moments in Parallel Universes",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liang_CapHuman_Capture_Your_Moments_in_Parallel_Universes_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "VamosC/CapHuman",
    "web_page": null,
    "github_page": "https://caphuman.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liang_CapHuman_Capture_Your_Moments_in_Parallel_Universes_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.00627",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Carve3D: Improving Multi-View Reconstruction Consistency for Diffusion Models with RL Finetuning",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Xie_Carve3D_Improving_Multi-view_Reconstruction_Consistency_for_Diffusion_Models_with_RL_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "desaixie/carve3d",
    "web_page": null,
    "github_page": "https://desaixie.github.io/carve-3d/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Xie_Carve3D_Improving_Multi-view_Reconstruction_Consistency_for_Diffusion_Models_with_RL_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.13980",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CAT-DM: Controllable Accelerated Virtual Try-On with Diffusion Model",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zeng_CAT-DM_Controllable_Accelerated_Virtual_Try-on_with_Diffusion_Model_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zengjianhao/CAT-DM",
    "web_page": null,
    "github_page": "https://zengjianhao.github.io/CAT-DM/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zeng_CAT-DM_Controllable_Accelerated_Virtual_Try-on_with_Diffusion_Model_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZIkow2fmMNk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CCEdit: Creative and Controllable Video Editing via Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Feng_CCEdit_Creative_and_Controllable_Video_Editing_via_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "RuoyuFeng/CCEdit",
    "web_page": null,
    "github_page": "https://ruoyufeng.github.io/CCEdit.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Feng_CCEdit_Creative_and_Controllable_Video_Editing_via_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.16496",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "UQw4jq-igN4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CDFormer: When Degradation Prediction Embraces Diffusion Model for Blind Image Super-Resolution",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_CDFormer_When_Degradation_Prediction_Embraces_Diffusion_Model_for_Blind_Image_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "I2-Multimedia-Lab/CDFormer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_CDFormer_When_Degradation_Prediction_Embraces_Diffusion_Model_for_Blind_Image_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2405.07648",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CHAIN: Enhancing Generalization in Data-Efficient GANs via lipsCHitz continuity constrAIned Normalization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ni_CHAIN_Enhancing_Generalization_in_Data-Efficient_GANs_via_lipsCHitz_continuity_constrAIned_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "MaxwellYaoNi/CHAIN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ni_CHAIN_Enhancing_Generalization_in_Data-Efficient_GANs_via_lipsCHitz_continuity_constrAIned_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.00521",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_f7X5_zT_lA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Check Locate Rectify: A Training-Free Layout Calibration System for Text-to-Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Gong_Check_Locate_Rectify_A_Training-Free_Layout_Calibration_System_for_Text-to-Image_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://simm-t2i.github.io/SimM/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Gong_Check_Locate_Rectify_A_Training-Free_Layout_Calibration_System_for_Text-to-Image_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.15773",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Cinematic Behavior Transfer via NeRF-based Differentiable Filming",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Jiang_Cinematic_Behavior_Transfer_via_NeRF-based_Differentiable_Filming_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "VirtualFilmStudio/Cinetransfer",
    "web_page": null,
    "github_page": "https://virtualfilmstudio.github.io/projects/cinetransfer/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Jiang_Cinematic_Behavior_Transfer_via_NeRF-based_Differentiable_Filming_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17754",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Codebook Transfer with Part-of-Speech for Vector-Quantized Image Modeling",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Codebook_Transfer_with_Part-of-Speech_for_Vector-Quantized_Image_Modeling_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Codebook_Transfer_with_Part-of-Speech_for_Vector-Quantized_Image_Modeling_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.10071",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "N6M0jcMP9lo",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Mei_CoDi_Conditional_Diffusion_Distillation_for_Higher-Fidelity_and_Faster_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "fast-codi/CoDi",
    "web_page": null,
    "github_page": "https://fast-codi.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Mei_CoDi_Conditional_Diffusion_Distillation_for_Higher-Fidelity_and_Faster_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2310.01407",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Combining Frame and GOP Embeddings for Neural Video Representation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Saethre_Combining_Frame_and_GOP_Embeddings_for_Neural_Video_Representation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Saethre_Combining_Frame_and_GOP_Embeddings_for_Neural_Video_Representation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CommonCanvas: Open Diffusion Models Trained on Creative-Commons Images",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Gokaslan_CommonCanvas_Open_Diffusion_Models_Trained_on_Creative-Commons_Images_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://github.com/mosaicml/diffusion/blob/main/assets/common-canvas.md",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/common-canvas/CommonCanvas",
    "paper_thecvf": "/papers/Gokaslan_CommonCanvas_Open_Diffusion_Models_Trained_on_Creative-Commons_Images_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Concept Weaver: Enabling Multi-Concept Fusion in Text-to-Image Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kwon_Concept_Weaver_Enabling_Multi-Concept_Fusion_in_Text-to-Image_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Kwon_Concept_Weaver_Enabling_Multi-Concept_Fusion_in_Text-to-Image_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.03913",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "zfrZVyiPp2o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Condition-Aware Neural Network for Controlled Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Cai_Condition-Aware_Neural_Network_for_Controlled_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "mit-han-lab/efficientvit",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Cai_Condition-Aware_Neural_Network_for_Controlled_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.01143",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "uYQR06yG_S4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CONFORM: Contrast is All You Need for High-Fidelity Text-to-Image Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Meral_CONFORM_Contrast_is_All_You_Need_for_High-Fidelity_Text-to-Image_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "gemlab-vt/CONFORM",
    "web_page": null,
    "github_page": "https://conform-diffusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Meral_CONFORM_Contrast_is_All_You_Need_for_High-Fidelity_Text-to-Image_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.06059",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ConsistNet: Enforcing 3D Consistency for Multi-View Images Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Yang_ConsistNet_Enforcing_3D_Consistency_for_Multi-view_Images_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "JiayuYANG/ConsistNet",
    "web_page": null,
    "github_page": "https://jiayuyang.github.io/Consist_Net/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Yang_ConsistNet_Enforcing_3D_Consistency_for_Multi-view_Images_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2310.10343",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "yXrtv3yzeks",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Content-Style Decoupling for Unsupervised Makeup Transfer without Generating Pseudo Ground Truth",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sun_Content-Style_Decoupling_for_Unsupervised_Makeup_Transfer_without_Generating_Pseudo_Ground_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Snowfallingplum/CSD-MT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sun_Content-Style_Decoupling_for_Unsupervised_Makeup_Transfer_without_Generating_Pseudo_Ground_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2405.17240",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "_RKWygsMy5g",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Contrastive Denoising Score for Text-Guided Latent Diffusion Image Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Nam_Contrastive_Denoising_Score_for_Text-guided_Latent_Diffusion_Image_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "HyelinNAM/ContrastiveDenoisingScore",
    "web_page": null,
    "github_page": "https://hyelinnam.github.io/CDS/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Nam_Contrastive_Denoising_Score_for_Text-guided_Latent_Diffusion_Image_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.18608",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jLaIOSE9nkw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ControlRoom3D: Room Generation using Semantic Proxy Rooms",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Schult_ControlRoom3D_Room_Generation_using_Semantic_Proxy_Rooms_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://jonasschult.github.io/ControlRoom3D/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Schult_ControlRoom3D_Room_Generation_using_Semantic_Proxy_Rooms_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.05208",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "g1h9f2cjgd8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Cross Initialization for Face Personalization of Text-to-Image Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Pang_Cross_Initialization_for_Face_Personalization_of_Text-to-Image_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "lyuPang/CrossInitialization",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Pang_Cross_Initialization_for_Face_Personalization_of_Text-to-Image_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.15905",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Customization Assistant for Text-to-Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_Customization_Assistant_for_Text-to-Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_Customization_Assistant_for_Text-to-Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.03045",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/He_Customize_your_NeRF_Adaptive_Source_Driven_3D_Scene_Editing_via_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "hrz2000/CustomNeRF",
    "web_page": null,
    "github_page": "https://customnerf.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/He_Customize_your_NeRF_Adaptive_Source_Driven_3D_Scene_Editing_via_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.01663",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "B8dW4Jpwerg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_DanceCamera3D_3D_Camera_Movement_Synthesis_with_Music_and_Dance_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Carmenw1203/DanceCamera3D-Official",
    "web_page": null,
    "github_page": "https://carmenw1203.github.io/DanceCamera3D.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_DanceCamera3D_3D_Camera_Movement_Synthesis_with_Music_and_Dance_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.13667",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "GSUyx1yWjaU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Dancing with Still Images: Video Distillation via Static-Dynamic Disentanglement",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_Dancing_with_Still_Images_Video_Distillation_via_Static-Dynamic_Disentanglement_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "yuz1wan/video_distillation",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_Dancing_with_Still_Images_Video_Distillation_via_Static-Dynamic_Disentanglement_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.00362",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "OMC9WmM_SwE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Deformable One-Shot Face Stylization via DINO Semantic Guidance",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_Deformable_One-shot_Face_Stylization_via_DINO_Semantic_Guidance_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zichongc/DoesFS",
    "web_page": "https://vcc.tech/research/2024/DoesFS",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_Deformable_One-shot_Face_Stylization_via_DINO_Semantic_Guidance_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.00459",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "mzWbVlibYBs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DemoCaricature: Democratising Caricature Generation with a Rough Sketch",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_DemoCaricature_Democratising_Caricature_Generation_with_a_Rough_Sketch_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ChenDarYen/DemoCaricature",
    "web_page": null,
    "github_page": "https://democaricature.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_DemoCaricature_Democratising_Caricature_Generation_with_a_Rough_Sketch_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.04364",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "X5xE7FSOXA4",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DemoFusion: Democratising High-Resolution Image Generation with No $$$",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Du_DemoFusion_Democratising_High-Resolution_Image_Generation_With_No__CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "PRIS-CV/DemoFusion",
    "web_page": null,
    "github_page": "https://ruoyidu.github.io/demofusion/demofusion.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/radames/Enhance-This-DemoFusion-SDXL",
    "paper_thecvf": "/papers/Du_DemoFusion_Democratising_High-Resolution_Image_Generation_With_No__CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.16973",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "VM4xXJRcxwU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_DetDiffusion_Synergizing_Generative_and_Perceptive_Models_for_Enhanced_Data_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_DetDiffusion_Synergizing_Generative_and_Perceptive_Models_for_Enhanced_Data_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.13304",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhao_DiffAgent_Fast_and_Accurate_Text-to-Image_API_Selection_with_Large_Language_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "OpenGVLab/DiffAgent",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhao_DiffAgent_Fast_and_Accurate_Text-to-Image_API_Selection_with_Large_Language_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DiffEditor: Boosting Accuracy and Flexibility on Diffusion-based Image Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Mou_DiffEditor_Boosting_Accuracy_and_Flexibility_on_Diffusion-based_Image_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "MC-E/DragonDiffusion",
    "web_page": null,
    "github_page": "https://mc-e.github.io/project/DragonDiffusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Mou_DiffEditor_Boosting_Accuracy_and_Flexibility_on_Diffusion-based_Image_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.02583",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DiffMorpher: Unleashing the Capability of Diffusion Models for Image Morphing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_DiffMorpher_Unleashing_the_Capability_of_Diffusion_Models_for_Image_Morphing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Kevin-thu/DiffMorpher",
    "web_page": null,
    "github_page": "https://kevin-thu.github.io/DiffMorpher_page/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/Kevin-thu/DiffMorpher",
    "paper_thecvf": "/papers/Zhang_DiffMorpher_Unleashing_the_Capability_of_Diffusion_Models_for_Image_Morphing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.07409",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hv_JgrBIK68",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DiffPerformer: Iterative Learning of Consistent Latent Guidance for Diffusion-based Human Video Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_DiffPerformer_Iterative_Learning_of_Consistent_Latent_Guidance_for_Diffusion-based_Human_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_DiffPerformer_Iterative_Learning_of_Consistent_Latent_Guidance_for_Diffusion-based_Human_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DiffSHEG: A Diffusion-based Approach for Real-Time Speech-Driven Holistic 3D Expression and Gesture Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_DiffSHEG_A_Diffusion-Based_Approach_for_Real-Time_Speech-driven_Holistic_3D_Expression_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "JeremyCJM/DiffSHEG",
    "web_page": null,
    "github_page": "https://jeremycjm.github.io/proj/DiffSHEG/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_DiffSHEG_A_Diffusion-Based_Approach_for_Real-Time_Speech-driven_Holistic_3D_Expression_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.04747",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "HFaSd5do-zI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diffusion Model Alignment using Direct Preference Optimization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wallace_Diffusion_Model_Alignment_Using_Direct_Preference_Optimization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "SalesforceAIResearch/DiffusionDPO",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wallace_Diffusion_Model_Alignment_Using_Direct_Preference_Optimization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.12908",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diffusion Models without Attention",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Yan_Diffusion_Models_Without_Attention_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Yan_Diffusion_Models_Without_Attention_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.18257",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Direct2.5: Diverse Text-to-3D Generation via Multi-View 2.5D Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lu_Direct2.5_Diverse_Text-to-3D_Generation_via_Multi-view_2.5D_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "apple/ml-direct2.5",
    "web_page": null,
    "github_page": "https://nju-3dv.github.io/projects/direct25/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lu_Direct2.5_Diverse_Text-to-3D_Generation_via_Multi-view_2.5D_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.15980",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_DIRECT-3D_Learning_Direct_Text-to-3D_Generation_on_Massive_Noisy_3D_Data_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "qihao067/direct3d",
    "web_page": null,
    "github_page": "https://direct-3d.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_DIRECT-3D_Learning_Direct_Text-to-3D_Generation_on_Massive_Noisy_3D_Data_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2406.04322",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DisCo: Disentangled Control for Realistic Human Dance Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_DisCo_Disentangled_Control_for_Realistic_Human_Dance_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Wangt-CN/DisCo",
    "web_page": null,
    "github_page": "https://disco-dance.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_DisCo_Disentangled_Control_for_Realistic_Human_Dance_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2307.00040",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "D_mPPjUCDjE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Discriminative Probing and Tuning for Text-to-Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Qu_Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "LgQu/DPT-T2I",
    "web_page": null,
    "github_page": "https://dpt-t2i.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Qu_Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.04321",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Distilling ODE Solvers of Diffusion Models into Smaller Steps",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kim_Distilling_ODE_Solvers_of_Diffusion_Models_into_Smaller_Steps_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "kim-sanghwan/D-ODE-Solvers",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Kim_Distilling_ODE_Solvers_of_Diffusion_Models_into_Smaller_Steps_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.16421",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diversity-Aware Channel Pruning for StyleGAN Compression",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chung_Diversity-aware_Channel_Pruning_for_StyleGAN_Compression_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "jiwoogit/DCP-GAN",
    "web_page": null,
    "github_page": "https://jiwoogit.github.io/DCP-GAN_site/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chung_Diversity-aware_Channel_Pruning_for_StyleGAN_Compression_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.13548",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "FM_0xaO0mEI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Don't Look into the Dark: Latent Codes for Pluralistic Image Inpainting",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Dont_Look_into_the_Dark_Latent_Codes_for_Pluralistic_Image_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "nintendops/latent-code-inpainting",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Dont_Look_into_the_Dark_Latent_Codes_for_Pluralistic_Image_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.18186",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "y6O-u6u0oPc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Doubly Abductive Counterfactual Inference for Text-based Image Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Song_Doubly_Abductive_Counterfactual_Inference_for_Text-based_Image_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "xuesong39/DAC",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Song_Doubly_Abductive_Counterfactual_Inference_for_Text-based_Image_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.02981",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "yFdUchtMZnI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Drag Your Noise: Interactive Point-based Editing via Diffusion Semantic Propagation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_Drag_Your_Noise_Interactive_Point-based_Editing_via_Diffusion_Semantic_Propagation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "haofengl/DragNoise",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_Drag_Your_Noise_Interactive_Point-based_Editing_via_Diffusion_Semantic_Propagation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.01050",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "gKq0s_CvCAg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DREAM: Diffusion Rectification and Estimation-Adaptive Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_DREAM_Diffusion_Rectification_and_Estimation-Adaptive_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "jinxinzhou/DREAM",
    "web_page": "https://www.tianyuding.com/projects/DREAM/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_DREAM_Diffusion_Rectification_and_Estimation-Adaptive_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.00210",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DreamComposer: Controllable 3D Object Generation via Multi-View Conditions",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Yang_DreamComposer_Controllable_3D_Object_Generation_via_Multi-View_Conditions_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "yhyang-myron/DreamComposer",
    "web_page": null,
    "github_page": "https://yhyang-myron.github.io/DreamComposer/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Yang_DreamComposer_Controllable_3D_Object_Generation_via_Multi-View_Conditions_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.03611",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Nam_DreamMatcher_Appearance_Matching_Self-Attention_for_Semantically-Consistent_Text-to-Image_Personalization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "KU-CVLAB/DreamMatcher",
    "web_page": null,
    "github_page": "https://ku-cvlab.github.io/DreamMatcher/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Nam_DreamMatcher_Appearance_Matching_Self-Attention_for_Semantically-Consistent_Text-to-Image_Personalization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.09812",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "vtq2muizj-c",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DreamSalon: A Staged Diffusion Framework for Preserving Identity-Context in Editable Face Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lin_DreamSalon_A_Staged_Diffusion_Framework_for_Preserving_Identity-Context_in_Editable_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lin_DreamSalon_A_Staged_Diffusion_Framework_for_Preserving_Identity-Context_in_Editable_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.19235",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DreamVideo: Composing Your Dream Videos with Customized Subject and Motion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wei_DreamVideo_Composing_Your_Dream_Videos_with_Customized_Subject_and_Motion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/VGen",
    "web_page": null,
    "github_page": "https://dreamvideo-t2v.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wei_DreamVideo_Composing_Your_Dream_Videos_with_Customized_Subject_and_Motion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.04433",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "wiuKiVWHd6I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DyBluRF: Dynamic Neural Radiance Fields from Blurry Monocular Video",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sun_DyBluRF_Dynamic_Neural_Radiance_Fields_from_Blurry_Monocular_Video_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "huiqiang-sun/DyBluRF",
    "web_page": null,
    "github_page": "https://huiqiang-sun.github.io/dyblurf/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sun_DyBluRF_Dynamic_Neural_Radiance_Fields_from_Blurry_Monocular_Video_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.10103",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "0cwJyDC40vw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and View-Change Human-Centric Video Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_DynVideo-E_Harnessing_Dynamic_NeRF_for_Large-Scale_Motion-_and_View-Change_Human-Centric_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://showlab.github.io/DynVideo-E/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_DynVideo-E_Harnessing_Dynamic_NeRF_for_Large-Scale_Motion-_and_View-Change_Human-Centric_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2310.10624",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "xiRH4Q6B3Yk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Dysen-VDM: Empowering Dynamics-Aware Text-to-Video Diffusion with LLMs",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Fei_Dysen-VDM_Empowering_Dynamics-aware_Text-to-Video_Diffusion_with_LLMs_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "scofield7419/Dysen",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Fei_Dysen-VDM_Empowering_Dynamics-aware_Text-to-Video_Diffusion_with_LLMs_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ADyBODiIppQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "EasyDrag: Efficient Point-based Manipulation on Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hou_EasyDrag_Efficient_Point-based_Manipulation_on_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Ace-Pegasus/EasyDrag",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hou_EasyDrag_Efficient_Point-based_Manipulation_on_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ECLIPSE: A Resource-Efficient Text-to-Image Prior for Image Generations",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Patel_ECLIPSE_A_Resource-Efficient_Text-to-Image_Prior_for_Image_Generations_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "eclipse-t2i/eclipse-inference",
    "web_page": "https://eclipse-t2i.vercel.app/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/ECLIPSE-Community/ECLIPSE-Kandinsky-v2.2",
    "paper_thecvf": "/papers/Patel_ECLIPSE_A_Resource-Efficient_Text-to-Image_Prior_for_Image_Generations_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.04655",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Edit One for All: Interactive Batch Image Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Nguyen_Edit_One_for_All_Interactive_Batch_Image_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "WisconsinAIVision/edit-one-for-all",
    "web_page": null,
    "github_page": "https://thaoshibe.github.io/edit-one-for-all/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Nguyen_Edit_One_for_All_Interactive_Batch_Image_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.10219",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ElasticDiffusion: Training-free Arbitrary Size Image Generation through Global-Local Content Separation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Haji-Ali_ElasticDiffusion_Training-free_Arbitrary_Size_Image_Generation_through_Global-Local_Content_Separation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "MoayedHajiAli/ElasticDiffusion-official",
    "web_page": null,
    "github_page": "https://elasticdiffusion.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Haji-Ali_ElasticDiffusion_Training-free_Arbitrary_Size_Image_Generation_through_Global-Local_Content_Separation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.18822",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "EmoGen: Emotional Image Content Generation with Text-to-Image Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Yang_EmoGen_Emotional_Image_Content_Generation_with_Text-to-Image_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "JingyuanYY/EmoGen",
    "web_page": "https://vcc.tech/research/2024/EmoGen",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Yang_EmoGen_Emotional_Image_Content_Generation_with_Text-to-Image_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.04608",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "EMOPortraits: Emotion-enhanced Multimodal One-Shot Head Avatars",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Drobyshev_EMOPortraits_Emotion-enhanced_Multimodal_One-shot_Head_Avatars_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "neeek2303/EMOPortraits",
    "web_page": null,
    "github_page": "https://neeek2303.github.io/EMOPortraits/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Drobyshev_EMOPortraits_Emotion-enhanced_Multimodal_One-shot_Head_Avatars_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.19110",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Exact Fusion via Feature Distribution Matching for Few-Shot Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_Exact_Fusion_via_Feature_Distribution_Matching_for_Few-shot_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ZYBOBO/F2DGAN",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_Exact_Fusion_via_Feature_Distribution_Matching_for_Few-shot_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "A4uKRH3g3NE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Exploiting Diffusion Prior for Generalizable Dense Prediction",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lee_Exploiting_Diffusion_Prior_for_Generalizable_Dense_Prediction_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "shinying/dmp",
    "web_page": null,
    "github_page": "https://shinying.github.io/dmp/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lee_Exploiting_Diffusion_Prior_for_Generalizable_Dense_Prediction_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.18832",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "z4W0LmI-4C8",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Face2Diffusion for Fast and Editable Face Personalization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Shiohara_Face2Diffusion_for_Fast_and_Editable_Face_Personalization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "mapooon/Face2Diffusion",
    "web_page": null,
    "github_page": "https://mapooon.github.io/Face2DiffusionPage/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Shiohara_Face2Diffusion_for_Fast_and_Editable_Face_Personalization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.05094",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "O5w5yjXeW2c",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FaceChain-SuDe: Building Derived Class to Inherit Category Attributes for One-Shot Subject-Driven Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Qiao_FaceChain-SuDe_Building_Derived_Class_to_Inherit_Category_Attributes_for_One-shot_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "modelscope/facechain",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Qiao_FaceChain-SuDe_Building_Derived_Class_to_Inherit_Category_Attributes_for_One-shot_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.06775",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Faces that Speak: Jointly Synthesising Talking Face and Speech from Text",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Jang_Faces_that_Speak_Jointly_Synthesising_Talking_Face_and_Speech_from_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://mm.kaist.ac.kr/projects/faces-that-speak/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Jang_Faces_that_Speak_Jointly_Synthesising_Talking_Face_and_Speech_from_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2405.10272",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4NU53iE62f0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Fairy: Fast Parallelized Instruction-Guided Video-to-Video Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wu_Fairy_Fast_Parallelized_Instruction-Guided_Video-to-Video_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://fairy-video2video.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wu_Fairy_Fast_Parallelized_Instruction-Guided_Video-to-Video_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.13834",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Fixed Point Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Bai_Fixed_Point_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "lukemelas/fixed-point-diffusion-models",
    "web_page": null,
    "github_page": "https://lukemelas.github.io/fixed-point-diffusion-models/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Bai_Fixed_Point_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.08741",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Focus on Your Instruction: Fine-grained and Multi-Instruction Image Editing by Attention Modulation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Guo_Focus_on_Your_Instruction_Fine-grained_and_Multi-instruction_Image_Editing_by_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "guoqincode/Focus-on-Your-Instruction",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Guo_Focus_on_Your_Instruction_Fine-grained_and_Multi-instruction_Image_Editing_by_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.10113",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "rPknqOJsxkg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FreeControl: Training-Free Spatial Control of any Text-to-Image Diffusion Model with any Condition",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Mo_FreeControl_Training-Free_Spatial_Control_of_Any_Text-to-Image_Diffusion_Model_with_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "genforce/freecontrol",
    "web_page": null,
    "github_page": "https://genforce.github.io/freecontrol/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Mo_FreeControl_Training-Free_Spatial_Control_of_Any_Text-to-Image_Diffusion_Model_with_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.07536",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ding_FreeCustom_Tuning-Free_Customized_Image_Generation_for_Multi-Concept_Composition_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "aim-uofa/FreeCustom",
    "web_page": null,
    "github_page": "https://aim-uofa.github.io/FreeCustom/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ding_FreeCustom_Tuning-Free_Customized_Image_Generation_for_Multi-Concept_Composition_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2405.13870",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FreeDrag: Feature Dragging for Reliable Point-based Image Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ling_FreeDrag_Feature_Dragging_for_Reliable_Point-based_Image_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "LPengYang/FreeDrag",
    "web_page": "https://lin-chen.site/projects/freedrag/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ling_FreeDrag_Feature_Dragging_for_Reliable_Point-based_Image_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2307.04684",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "dKPqMQG1CeE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Yang_FRESCO_Spatial-Temporal_Correspondence_for_Zero-Shot_Video_Translation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "williamyang1991/FRESCO",
    "web_page": "https://www.mmlab-ntu.com/project/fresco/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/PKUWilliamYang/FRESCO",
    "paper_thecvf": "/papers/Yang_FRESCO_Spatial-Temporal_Correspondence_for_Zero-Shot_Video_Translation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.12962",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jLnGx5H-wLw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FSRT: Facial Scene Representation Transformer for Face Reenactment from Factorized Appearance Head-Pose and Facial Expression Features",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Rochow_FSRT_Facial_Scene_Representation_Transformer_for_Face_Reenactment_from_Factorized_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "andrerochow/fsrt",
    "web_page": null,
    "github_page": "https://andrerochow.github.io/fsrt/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Rochow_FSRT_Facial_Scene_Representation_Transformer_for_Face_Reenactment_from_Factorized_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.09736",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "GIoZ8QoshcM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Gaussian Shell Maps for Efficient 3D Human Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Abdal_Gaussian_Shell_Maps_for_Efficient_3D_Human_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "computational-imaging/GSM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Abdal_Gaussian_Shell_Maps_for_Efficient_3D_Human_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17857",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "WSTBftn7N3s",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Yi_GaussianDreamer_Fast_Generation_from_Text_to_3D_Gaussians_by_Bridging_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "hustvl/GaussianDreamer",
    "web_page": "https://taoranyi.com/gaussiandreamer/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Yi_GaussianDreamer_Fast_Generation_from_Text_to_3D_Gaussians_by_Bridging_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2310.08529",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "GeneAvatar: Generic Expression-Aware Volumetric Head Avatar Editing from a Single Image",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Bao_GeneAvatar_Generic_Expression-Aware_Volumetric_Head_Avatar_Editing_from_a_Single_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zju3dv/GeneAvatar",
    "web_page": null,
    "github_page": "https://zju3dv.github.io/geneavatar/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Bao_GeneAvatar_Generic_Expression-Aware_Volumetric_Head_Avatar_Editing_from_a_Single_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.02152",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4zfbfPivtVU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  }
]