[
  {
    "title": "Alchemist: Parametric Control of Material Properties with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sharma_Alchemist_Parametric_Control_of_Material_Properties_with_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://www.prafullsharma.net/alchemist/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sharma_Alchemist_Parametric_Control_of_Material_Properties_with_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02970",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Analyzing and Improving the Training Dynamics of Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Karras_Analyzing_and_Improving_the_Training_Dynamics_of_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "NVlabs/edm2",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Karras_Analyzing_and_Improving_the_Training_Dynamics_of_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02696",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Attention Calibration for Disentangled Text-to-Image Personalization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Attention_Calibration_for_Disentangled_Text-to-Image_Personalization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Monalissaa/DisenDiff",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Attention_Calibration_for_Disentangled_Text-to-Image_Personalization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.18551",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FreeU: Free Lunch in Diffusion U-Net",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ChenyangSi/FreeU",
    "web_page": "https://chenyangsi.top/FreeU",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Si_FreeU_Free_Lunch_in_Diffusion_U-Net_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.11497",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-CZ5uWxvX30",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Generative Image Dynamics",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_Generative_Image_Dynamics_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "fltwr/generative-image-dynamics",
    "web_page": null,
    "github_page": "https://generative-dynamics.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_Generative_Image_Dynamics_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2309.07906",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Instruct-Imagen: Image Generation with Multi-Modal Instruction",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://instruct-imagen.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hu_Instruct-Imagen_Image_Generation_with_Multi-modal_Instruction_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.01952",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "NoiseCLR: A Contrastive Learning Approach for Unsupervised Discovery of Interpretable Directions in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Dalva_NoiseCLR_A_Contrastive_Learning_Approach_for_Unsupervised_Discovery_of_Interpretable_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://noiseclr.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Dalva_NoiseCLR_A_Contrastive_Learning_Approach_for_Unsupervised_Discovery_of_Interpretable_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.05390",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "RA2KzZ25F5I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Feng_Ranni_Taming_Text-to-Image_Diffusion_for_Accurate_Instruction_Following_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/Ranni",
    "web_page": null,
    "github_page": "https://ranni-t2i.github.io/Ranni/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Feng_Ranni_Taming_Text-to-Image_Diffusion_for_Accurate_Instruction_Following_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17002",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "1IIat83Atjk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Style Aligned Image Generation via Shared Attention",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Hertz_Style_Aligned_Image_Generation_via_Shared_Attention_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "google/style-aligned",
    "web_page": null,
    "github_page": "https://style-aligned-gen.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Hertz_Style_Aligned_Image_Generation_via_Shared_Attention_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02133",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Geng_Visual_Anagrams_Generating_Multi-View_Optical_Illusions_with_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "dangeng/visual_anagrams",
    "web_page": null,
    "github_page": "https://dangeng.github.io/visual_anagrams/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Geng_Visual_Anagrams_Generating_Multi-View_Optical_Illusions_with_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17919",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Align Your Gaussians: Text-to-4D with Dynamic 3D Gaussians and Composed Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ling_Align_Your_Gaussians_Text-to-4D_with_Dynamic_3D_Gaussians_and_Composed_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ling_Align_Your_Gaussians_Text-to-4D_with_Dynamic_3D_Gaussians_and_Composed_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.13763",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Amodal Completion via Progressive Mixed Context Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Xu_Amodal_Completion_via_Progressive_Mixed_Context_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "k8xu/amodal",
    "web_page": null,
    "github_page": "https://k8xu.github.io/amodal/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Xu_Amodal_Completion_via_Progressive_Mixed_Context_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.15540",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CLiC: Concept Learning in Context",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Safaee_CLiC_Concept_Learning_in_Context_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Mehdi0xC/clic",
    "web_page": null,
    "github_page": "https://mehdi0xc.github.io/clic/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Safaee_CLiC_Concept_Learning_in_Context_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17083",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "8g--nx3RyEQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Clockwork Diffusion: Efficient Generation with Model-Step Distillation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Habibian_Clockwork_Diffusion_Efficient_Generation_With_Model-Step_Distillation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Qualcomm-AI-research/clockwork-diffusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Habibian_Clockwork_Diffusion_Efficient_Generation_With_Model-Step_Distillation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.08128",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "jdpOFQn8zKw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lu_Coarse-to-Fine_Latent_Diffusion_for_Pose-Guided_Person_Image_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "YanzuoLu/CFLD",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lu_Coarse-to-Fine_Latent_Diffusion_for_Pose-Guided_Person_Image_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.18078",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ZqMdjfzaj-I",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CoDeF: Content Deformation Fields for Temporally Consistent Video Processing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Ouyang_CoDeF_Content_Deformation_Fields_for_Temporally_Consistent_Video_Processing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "qiuyu96/CoDeF",
    "web_page": null,
    "github_page": "https://qiuyu96.github.io/CoDeF/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Ouyang_CoDeF_Content_Deformation_Fields_for_Temporally_Consistent_Video_Processing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2308.07926",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Correcting Diffusion Generation through Resampling",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_Correcting_Diffusion_Generation_through_Resampling_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "UCSB-NLP-Chang/diffusion_resampling",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_Correcting_Diffusion_Generation_through_Resampling_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.06038",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "CosmicMan: A Text-to-Image Foundation Model for Humans",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_CosmicMan_A_Text-to-Image_Foundation_Model_for_Humans_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "cosmicman-cvpr2024/CosmicMan",
    "web_page": null,
    "github_page": "https://cosmicman-cvpr2024.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/cosmicman/CosmicMan-SDXL",
    "paper_thecvf": "/papers/Li_CosmicMan_A_Text-to-Image_Foundation_Model_for_Humans_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.01294",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "CsZKA27tQDA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "bytedance/DEADiff",
    "web_page": null,
    "github_page": "https://tianhao-qi.github.io/DEADiff/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Qi_DEADiff_An_Efficient_Stylization_Diffusion_Model_with_Disentangled_Representations_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.06951",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Diffusion Handles Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Pandey_Diffusion_Handles_Enabling_3D_Edits_for_Diffusion_Models_by_Lifting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "adobe-research/DiffusionHandles",
    "web_page": null,
    "github_page": "https://diffusionhandles.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Pandey_Diffusion_Handles_Enabling_3D_Edits_for_Diffusion_Models_by_Lifting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02190",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "OxOjiFaTSZg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_DistriFusion_Distributed_Parallel_Inference_for_High-Resolution_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "mit-han-lab/distrifuser",
    "web_page": "https://hanlab.mit.edu/projects/distrifusion",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_DistriFusion_Distributed_Parallel_Inference_for_High-Resolution_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.19481",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "EZX7srDDmW0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Don't Drop Your Samples! Coherence-Aware Training Benefits Conditional Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Dufour_Dont_Drop_Your_Samples_Coherence-Aware_Training_Benefits_Conditional_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "nicolas-dufour/CAD",
    "web_page": null,
    "github_page": "https://nicolas-dufour.github.io/cad",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Dufour_Dont_Drop_Your_Samples_Coherence-Aware_Training_Benefits_Conditional_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4Tu-x2-Zcxs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Shi_DragDiffusion_Harnessing_Diffusion_Models_for_Interactive_Point-based_Image_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Yujun-Shi/DragDiffusion",
    "web_page": null,
    "github_page": "https://yujun-shi.github.io/projects/dragdiffusion.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Shi_DragDiffusion_Harnessing_Diffusion_Models_for_Interactive_Point-based_Image_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2306.14435",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "rysOFTpDBhc",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Dynamic Policy-Driven Adaptive Multi-Instance Learning for whole Slide Image Classification",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zheng_Dynamic_Policy-Driven_Adaptive_Multi-Instance_Learning_for_Whole_Slide_Image_Classification_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "titizheng/PAMIL",
    "web_page": "https://vilab.hit.edu.cn/projects/pamil/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zheng_Dynamic_Policy-Driven_Adaptive_Multi-Instance_Learning_for_Whole_Slide_Image_Classification_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.07939",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "ThDuM2tJPzs",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Fast ODE-based Sampling for Diffusion Models in Around 5 Steps",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_Fast_ODE-based_Sampling_for_Diffusion_Models_in_Around_5_Steps_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "zju-pi/diff-sampler",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_Fast_ODE-based_Sampling_for_Diffusion_Models_in_Around_5_Steps_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.00094",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "FlowVid: Taming Imperfect Optical Flows for Consistent Video-to-Video Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liang_FlowVid_Taming_Imperfect_Optical_Flows_for_Consistent_Video-to-Video_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Jeff-LiangF/FlowVid",
    "web_page": null,
    "github_page": "https://jeff-liangf.github.io/projects/flowvid/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liang_FlowVid_Taming_Imperfect_Optical_Flows_for_Consistent_Video-to-Video_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.17681",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "y5IlgGl8Y24",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Generative Powers of Ten",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_Generative_Powers_of_Ten_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "aryanmikaeili/generative_powers_of_ten",
    "web_page": null,
    "github_page": "https://powers-of-10.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_Generative_Powers_of_Ten_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02149",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liu_HumanGaussian_Text-Driven_3D_Human_Generation_with_Gaussian_Splatting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "alvinliu0/HumanGaussian",
    "web_page": null,
    "github_page": "https://alvinliu0.github.io/projects/HumanGaussian",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liu_HumanGaussian_Text-Driven_3D_Human_Generation_with_Gaussian_Splatting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.17061",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "S3djzHoqPKY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Image Neural Field Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Image_Neural_Field_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://yinboc.github.io/infd/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Image_Neural_Field_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2406.07480",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Learning Adaptive Spatial Coherent Correlations for Speech-Preserving Facial Expression Manipulation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Learning_Adaptive_Spatial_Coherent_Correlations_for_Speech-Preserving_Facial_Expression_Manipulation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "jianmanlincjx/ASCCL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Learning_Adaptive_Spatial_Coherent_Correlations_for_Speech-Preserving_Facial_Expression_Manipulation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Liang_LucidDreamer_Towards_High-Fidelity_Text-to-3D_Generation_via_Interval_Score_Matching_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "EnVision-Research/LucidDreamer",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Liang_LucidDreamer_Towards_High-Fidelity_Text-to-3D_Generation_via_Interval_Score_Matching_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.11284",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_MicroCinema_A_Divide-and-Conquer_Approach_for_Text-to-Video_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://wangyanhui666.github.io/MicroCinema.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_MicroCinema_A_Divide-and-Conquer_Approach_for_Text-to-Video_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.18829",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "H7O-Ku_lqPA",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "MIGC: Multi-Instance Generation Controller for Text-to-Image Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhou_MIGC_Multi-Instance_Generation_Controller_for_Text-to-Image_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "limuloo/MIGC",
    "web_page": null,
    "github_page": "https://migcproject.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhou_MIGC_Multi-Instance_Generation_Controller_for_Text-to-Image_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.05408",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "One-Dimensional Adapter to Rule them All: Concepts Diffusion Models and Erasing Applications",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lyu_One-dimensional_Adapter_to_Rule_Them_All_Concepts_Diffusion_Models_and_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Con6924/SPM",
    "web_page": null,
    "github_page": "https://lyumengyao.github.io/projects/spm",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lyu_One-dimensional_Adapter_to_Rule_Them_All_Concepts_Diffusion_Models_and_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.16145",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Orthogonal Adaptation for Modular Customization of Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Po_Orthogonal_Adaptation_for_Modular_Customization_of_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://ryanpo.com/ortha/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Po_Orthogonal_Adaptation_for_Modular_Customization_of_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02432",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "4lVEFBtYE4A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "PLACE: Adaptive Layout-Semantic Fusion for Semantic Image Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lv_PLACE_Adaptive_Layout-Semantic_Fusion_for_Semantic_Image_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "cszy98/PLACE",
    "web_page": null,
    "github_page": "https://cszy98.github.io/PLACE/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lv_PLACE_Adaptive_Layout-Semantic_Fusion_for_Semantic_Image_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.01852",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "47mMAmclPWw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sheynin_Emu_Edit_Precise_Image_Editing_via_Recognition_and_Generation_Tasks_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "https://emu-edit.metademolab.com/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sheynin_Emu_Edit_Precise_Image_Editing_via_Recognition_and_Generation_Tasks_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.10089",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "UNDR55ehSYM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Predicated Diffusion: Predicate Logic-based Attention Guidance for Text-to-Image Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Sueyoshi_Predicated_Diffusion_Predicate_Logic-Based_Attention_Guidance_for_Text-to-Image_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Sueyoshi_Predicated_Diffusion_Predicate_Logic-Based_Attention_Guidance_for_Text-to-Image_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.16117",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kara_RAVE_Randomized_Noise_Shuffling_for_Fast_and_Consistent_Video_Editing_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "RehgLab/RAVE",
    "web_page": null,
    "github_page": "https://rave-video.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": "https://huggingface.co/spaces/ozgurkara/RAVE",
    "paper_thecvf": "/papers/Kara_RAVE_Randomized_Noise_Shuffling_for_Fast_and_Consistent_Video_Editing_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.04524",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "2hQho5AC9T0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Readout Guidance: Learning Control from Diffusion Features",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Luo_Readout_Guidance_Learning_Control_from_Diffusion_Features_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "google-research/readout_guidance",
    "web_page": null,
    "github_page": "https://readout-guidance.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Luo_Readout_Guidance_Learning_Control_from_Diffusion_Features_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.02150",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Real-Time 3D-Aware Portrait Video Relighting",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Cai_Real-time_3D-aware_Portrait_Video_Relighting_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": "http://geometrylearning.com/VideoRelighting/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Cai_Real-time_3D-aware_Portrait_Video_Relighting_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Residual Learning in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Residual_Learning_in_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Residual_Learning_in_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Rethinking FID: Towards a Better Evaluation Metric for Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Jayasumana_Rethinking_FID_Towards_a_Better_Evaluation_Metric_for_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://github.com/google-research/google-research/tree/master/cmmd",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Jayasumana_Rethinking_FID_Towards_a_Better_Evaluation_Metric_for_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.09603",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Li_Sat2Scene_3D_Urban_Scene_Generation_from_Satellite_Images_with_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Li_Sat2Scene_3D_Urban_Scene_Generation_from_Satellite_Images_with_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.10786",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "NqFy20zjFHU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Jiang_SCEdit_Efficient_and_Controllable_Image_Diffusion_Generation_via_Skip_Connection_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ali-vilab/SCEdit",
    "web_page": null,
    "github_page": "https://scedit.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Jiang_SCEdit_Efficient_and_Controllable_Image_Diffusion_Generation_via_Skip_Connection_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.11392",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "XJrK3-NgB1Q",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Huang_SmartEdit_Exploring_Complex_Instruction-based_Image_Editing_with_Multimodal_Large_Language_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "TencentARC/SmartEdit",
    "web_page": null,
    "github_page": "https://yuzhou914.github.io/SmartEdit/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Huang_SmartEdit_Exploring_Complex_Instruction-based_Image_Editing_with_Multimodal_Large_Language_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.06739",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Menapace_Snap_Video_Scaled_Spatiotemporal_Transformers_for_Text-to-Video_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://snap-research.github.io/snapvideo/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Menapace_Snap_Video_Scaled_Spatiotemporal_Transformers_for_Text-to-Video_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2402.14797",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "aL2zq_IKSBg",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Style Injection in Diffusion: A Training-Free Approach for Adapting Large-Scale Diffusion Models for Style Transfer",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chung_Style_Injection_in_Diffusion_A_Training-free_Approach_for_Adapting_Large-scale_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "jiwoogit/StyleID",
    "web_page": null,
    "github_page": "https://jiwoogit.github.io/StyleID_site/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chung_Style_Injection_in_Diffusion_A_Training-free_Approach_for_Adapting_Large-scale_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.09008",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Tackling the Singularities at the Endpoints of Time Intervals in Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Tackling_the_Singularities_at_the_Endpoints_of_Time_Intervals_in_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "PangzeCheung/SingDiffusion",
    "web_page": null,
    "github_page": "https://pangzecheung.github.io/SingDiffusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Tackling_the_Singularities_at_the_Endpoints_of_Time_Intervals_in_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.08381",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "3Rt17MnHEJQ",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Taming Stable Diffusion for Text to 360 Panorama Image Generation",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Zhang_Taming_Stable_Diffusion_for_Text_to_360_Panorama_Image_Generation_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "chengzhag/PanFusion",
    "web_page": null,
    "github_page": "https://chengzhag.github.io/publication/panfusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Zhang_Taming_Stable_Diffusion_for_Text_to_360_Panorama_Image_Generation_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.07949",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Huang_TFMQ-DM_Temporal_Feature_Maintenance_Quantization_for_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ModelTC/TFMQ-DM",
    "web_page": null,
    "github_page": "https://modeltc.github.io/TFMQ-DM/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Huang_TFMQ-DM_Temporal_Feature_Maintenance_Quantization_for_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.16503",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "Total Selfie: Generating Full-Body Selfies",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Chen_Total_Selfie_Generating_Full-Body_Selfies_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ArmastusChen/total_selfie",
    "web_page": "https://homes.cs.washington.edu/~boweiche/project_page/totalselfie/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Chen_Total_Selfie_Generating_Full-Body_Selfies_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2308.14740",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "Aoq6BLbynWM",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Xu_UFOGen_You_Forward_Once_Large_Scale_Text-to-Image_Generation_via_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Xu_UFOGen_You_Forward_Once_Large_Scale_Text-to-Image_Generation_via_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2311.09257",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "VecFusion: Vector Font Generation with Diffusion",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Thamizharasan_VecFusion_Vector_Font_Generation_with_Diffusion_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://vikastmz.github.io/VecFusion/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Thamizharasan_VecFusion_Vector_Font_Generation_with_Diffusion_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2312.10540",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "w4-h-t7XEKI",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Kwak_ViVid-1-to-3_Novel_View_Synthesis_with_Video_Diffusion_Models_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "ubc-vision/vivid123",
    "web_page": null,
    "github_page": "https://ubc-vision.github.io/vivid123/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Kwak_ViVid-1-to-3_Novel_View_Synthesis_with_Video_Diffusion_Models_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3D Geometry-Aware Deformable Gaussian Splatting for Dynamic View Synthesis",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Lu_3D_Geometry-Aware_Deformable_Gaussian_Splatting_for_Dynamic_View_Synthesis_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://npucvr.github.io/GaGS/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Lu_3D_Geometry-Aware_Deformable_Gaussian_Splatting_for_Dynamic_View_Synthesis_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.06270",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "gU0z0k9Ta0Y",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "3D Multi-Frame Fusion for Video Stabilization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Peng_3D_Multi-frame_Fusion_for_Video_Stabilization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Peng_3D_Multi-frame_Fusion_for_Video_Stabilization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2404.12887",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "-dpI1CFcM7A",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "4D-fy: Text-to-4D Generation using Hybrid Score Distillation Sampling",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Bahmani_4D-fy_Text-to-4D_Generation_Using_Hybrid_Score_Distillation_Sampling_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "sherwinbahmani/4dfy",
    "web_page": null,
    "github_page": "https://sherwinbahmani.github.io/4dfy/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Bahmani_4D-fy_Text-to-4D_Generation_Using_Hybrid_Score_Distillation_Sampling_CVPR_2024_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "360DVD: Controllable Panorama Video Generation with 360-Degree Video Diffusion Model",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Wang_360DVD_Controllable_Panorama_Video_Generation_with_360-Degree_Video_Diffusion_Model_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": "Akaneqwq/360DVD",
    "web_page": null,
    "github_page": "https://akaneqwq.github.io/360DVD/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Wang_360DVD_Controllable_Panorama_Video_Generation_with_360-Degree_Video_Diffusion_Model_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2401.06578",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  },
  {
    "title": "RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization",
    "base_url": "https://openaccess.thecvf.com/content/CVPR2024",
    "title_page": "/html/Huang_RealCustom_Narrowing_Real_Text_Word_for_Real-Time_Open-Domain_Text-to-Image_Customization_CVPR_2024_paper.html",
    "ieee_id": null,
    "github": null,
    "web_page": null,
    "github_page": "https://corleone-huang.github.io/realcustom/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": "/papers/Huang_RealCustom_Narrowing_Real_Text_Word_for_Real-Time_Open-Domain_Text-to-Image_Customization_CVPR_2024_paper.pdf",
    "paper_arxiv_id": "2403.00483",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Image and Video Synthesis and Generation"
  }
]