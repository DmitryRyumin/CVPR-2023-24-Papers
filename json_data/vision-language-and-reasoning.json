[
  {
    "title": "Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": "https://antoyang.github.io/vid2seq.html",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Vid2Seq_Large-Scale_Pretraining_of_a_Visual_Language_Model_for_Dense_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.14115",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "hXP-2fYzq4g",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "Open-Vocabulary Panoptic Segmentation With Text-to-Image Diffusion Models",
    "base_url": null,
    "title_page": null,
    "repo": "NVlabs/ODISE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Open-Vocabulary_Panoptic_Segmentation_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.04803",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "eW2vF8o_7p0",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "Iterative Proposal Refinement for Weakly-Supervised Video Grounding",
    "base_url": null,
    "title_page": null,
    "repo": "ttengwang/Awesome_Long_Term_Video_Understanding",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Iterative_Proposal_Refinement_for_Weakly-Supervised_Video_Grounding_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "BbGvHI_pVXk",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "MetaCLUE: Towards Comprehensive Visual Metaphors Research",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": "https://metaclue.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Akula_MetaCLUE_Towards_Comprehensive_Visual_Metaphors_Research_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.09898",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "V3TmeNETL-o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "PolyFormer: Referring Image Segmentation As Sequential Polygon Generation",
    "base_url": null,
    "title_page": null,
    "repo": "amazon-science/polygon-transformer",
    "web_page": null,
    "github_page": "https://polyformer.github.io/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_PolyFormer_Referring_Image_Segmentation_As_Sequential_Polygon_Generation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2302.07387",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "6LNrqoxQR1M",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "GeneCIS: A Benchmark for General Conditional Image Similarity",
    "base_url": null,
    "title_page": null,
    "repo": "facebookresearch/genecis",
    "web_page": null,
    "github_page": "https://sgvaze.github.io/genecis/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Vaze_GeneCIS_A_Benchmark_for_General_Conditional_Image_Similarity_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2306.07969",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "wu3U2iNGIUw",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion Tasks",
    "base_url": null,
    "title_page": null,
    "repo": "BrandonHanx/FAME-ViL",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Han_FAME-ViL_Multi-Tasking_Vision-Language_Model_for_Heterogeneous_Fashion_Tasks_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.02483",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "Generative Bias for Robust Visual Question Answering",
    "base_url": null,
    "title_page": null,
    "repo": "chojw/genb",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cho_Generative_Bias_for_Robust_Visual_Question_Answering_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2208.00690",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "Advancing Visual Grounding With Scene Knowledge: Benchmark and Method",
    "base_url": null,
    "title_page": null,
    "repo": "zhjohnchan/SK-VG",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Advancing_Visual_Grounding_With_Scene_Knowledge_Benchmark_and_Method_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2307.11558",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "DmmPiseO59o",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "Gloss Attention for Gloss-Free Sign Language Translation",
    "base_url": null,
    "title_page": null,
    "repo": "YinAoXiong/GASLT",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yin_Gloss_Attention_for_Gloss-Free_Sign_Language_Translation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2307.07361",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "NEoWvxkJXfU",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "You Can Ground Earlier Than See: An Effective and Efficient Pipeline for Temporal Sentence Grounding in Compressed Videos",
    "base_url": null,
    "title_page": null,
    "repo": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_You_Can_Ground_Earlier_Than_See_An_Effective_and_Efficient_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.07863",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "Generalized Decoding for Pixel, Image, and Language",
    "base_url": null,
    "title_page": null,
    "repo": "microsoft/X-Decoder",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zou_Generalized_Decoding_for_Pixel_Image_and_Language_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2212.11270",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "wYp6vmyolqE",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "Accelerating Vision-Language Pretraining With Free Language Modeling",
    "base_url": null,
    "title_page": null,
    "repo": "TencentARC/FLM",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Accelerating_Vision-Language_Pretraining_With_Free_Language_Modeling_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2303.14038",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "WbH_5DH_jfY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "GRES: Generalized Referring Expression Segmentation",
    "base_url": null,
    "title_page": null,
    "repo": "henghuiding/ReLA",
    "web_page": null,
    "github_page": "https://henghuiding.github.io/GRES/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_GRES_Generalized_Referring_Expression_Segmentation_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2306.00968",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "eWjAgYUU6Do",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "BUFFER: Balancing Accuracy, Efficiency, and Generalizability in Point Cloud Registration",
    "base_url": null,
    "title_page": null,
    "repo": "The-Learning-And-Vision-Atelier-LAVA/BUFFER",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ao_BUFFER_Balancing_Accuracy_Efficiency_and_Generalizability_in_Point_Cloud_Registration_CVPR_2023_paper.pdf",
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": "STmAkRWuSiY",
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  },
  {
    "title": "RGB No More: Minimally-Decoded JPEG Vision Transformers",
    "base_url": null,
    "title_page": null,
    "repo": "JeongsooP/RGB-no-more",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "zenodo": null,
    "demo_page": null,
    "paper_thecvf": "https://openaccess.thecvf.com/content/CVPR2023/papers/Park_RGB_No_More_Minimally-Decoded_JPEG_Vision_Transformers_CVPR_2023_paper.pdf",
    "paper_arxiv_id": "2211.16421",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Vision, Language, and Reasoning"
  }
]