# CVPR-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/datasets-and-evaluation.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/adversarial-attack-and-defense.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Scene Analysis and Understanding

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| You Only Segment Once: Towards Real-Time Panoptic Segmentation | [![GitHub](https://img.shields.io/github/stars/hujiecpp/YOSO)](https://github.com/hujiecpp/YOSO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_You_Only_Segment_Once_Towards_Real-Time_Panoptic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14651-b31b1b.svg)](http://arxiv.org/abs/2303.14651) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wQCKerE_NmQ) |
| IS-GGT: Iterative Scene Graph Generation with Generative Transformers | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://saakur.github.io/Projects/IS_GGT/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kundu_IS-GGT_Iterative_Scene_Graph_Generation_With_Generative_Transformers_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CZ9aCrqgY9E) |
| Disentangling Orthogonal Planes for Indoor Panoramic Room Layout Estimation with Cross-Scale Distortion Awareness | [![GitHub](https://img.shields.io/github/stars/zhijieshen-bjtu/DOPNet)](https://github.com/zhijieshen-bjtu/DOPNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_Disentangling_Orthogonal_Planes_for_Indoor_Panoramic_Room_Layout_Estimation_With_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00971-b31b1b.svg)](http://arxiv.org/abs/2303.00971) | :heavy_minus_sign: |
| Panoptic Video Scene Graph Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jingkang50.github.io/PVSG/) <br /> [![GitHub](https://img.shields.io/github/stars/LilyDaytoy/OpenPVSG)](https://github.com/LilyDaytoy/OpenPVSG) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Panoptic_Video_Scene_Graph_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.17058-b31b1b.svg)](http://arxiv.org/abs/2311.17058) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZvKeIZ8LHVw) |
| 3D Spatial Multimodal Knowledge Accumulation for Scene Graph Prediction in Point Cloud | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_3D_Spatial_Multimodal_Knowledge_Accumulation_for_Scene_Graph_Prediction_in_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=srvsnfCZTQI) |
| JacobiNeRF: NeRF Shaping with Mutual Information Gradients | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xxm19.github.io/jnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/xxm19/jacobinerf)](https://github.com/xxm19/jacobinerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_JacobiNeRF_NeRF_Shaping_With_Mutual_Information_Gradients_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00341-b31b1b.svg)](http://arxiv.org/abs/2304.00341) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uKU9UdVL6GQ) |
| Learning Geometric-Aware Properties in 2D Representation using Lightweight CAD Models, or Zero Real 3D Pairs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://geoaware2drepusingcad.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Arsomngern_Learning_Geometric-Aware_Properties_in_2D_Representation_Using_Lightweight_CAD_Models_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nTb1RC9T-0I) |
| Learning and Aggregating Lane Graphs for Urban Automated Driving | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://urbanlanegraph.cs.uni-freiburg.de/) <br /> [![GitHub](https://img.shields.io/github/stars/jzuern/lanegnn)](https://github.com/jzuern/lanegnn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Buchner_Learning_and_Aggregating_Lane_Graphs_for_Urban_Automated_Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.06175-b31b1b.svg)](http://arxiv.org/abs/2302.06175) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zHkbF_pjfdg) |
| MIME: Human-Aware 3D Scene Generation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://mime.is.tue.mpg.de/) <br /> [![GitHub](https://img.shields.io/github/stars/yhw-yhw/MIME)](https://github.com/yhw-yhw/MIME) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yi_MIME_Human-Aware_3D_Scene_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04360-b31b1b.svg)](http://arxiv.org/abs/2212.04360) | :heavy_minus_sign: |
| Connecting the Dots: Floorplan Reconstruction using Two-Level Queries | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ywyue.github.io/RoomFormer/) <br /> [![GitHub](https://img.shields.io/github/stars/ywyue/RoomFormer)](https://github.com/ywyue/RoomFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yue_Connecting_the_Dots_Floorplan_Reconstruction_Using_Two-Level_Queries_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.15658-b31b1b.svg)](http://arxiv.org/abs/2211.15658) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yzYe4yVN1NU) |
| NeRF-RPN: A General Framework for Object Detection in NeRFs | [![GitHub](https://img.shields.io/github/stars/lyclyc52/NeRF_RPN)](https://github.com/lyclyc52/NeRF_RPN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_NeRF-RPN_A_General_Framework_for_Object_Detection_in_NeRFs_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11646-b31b1b.svg)](http://arxiv.org/abs/2211.11646) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=M8_4Ih1CJjE) |
| Relational Context Learning for Human-Object Interaction Detection | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvlab.postech.ac.kr/research/MUREN/) <br /> [![GitHub](https://img.shields.io/github/stars/OreoChocolate/MUREN)](https://github.com/OreoChocolate/MUREN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Relational_Context_Learning_for_Human-Object_Interaction_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04997-b31b1b.svg)](http://arxiv.org/abs/2304.04997) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u-5EmiGWbsA) |
| Symmetric Shape-Preserving Autoencoder for Unsupervised Real Scene Point Cloud Completion | [![GitHub](https://img.shields.io/github/stars/murcherful/USSPA)](https://github.com/murcherful/USSPA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_Symmetric_Shape-Preserving_Autoencoder_for_Unsupervised_Real_Scene_Point_Cloud_Completion_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1iWvKcR9DzA) |
| Token Contrast for Weakly-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/rulixiang/ToCo)](https://github.com/rulixiang/ToCo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ru_Token_Contrast_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01267-b31b1b.svg)](http://arxiv.org/abs/2303.01267) | :heavy_minus_sign: |
| MM-3DScene: 3D Scene Understanding by Customizing Masked Modeling with Informative-Preserved Reconstruction and Self-Distilled Consistency | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mingyexu.github.io/mm3dscene/) <br /> [![GitHub](https://img.shields.io/github/stars/MingyeXu/mm-3dscene)](https://github.com/MingyeXu/mm-3dscene) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_MM-3DScene_3D_Scene_Understanding_by_Customizing_Masked_Modeling_With_Informative-Preserved_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.09948-b31b1b.svg)](http://arxiv.org/abs/2212.09948) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MxRJG9EUR5Q) |
| Primitive Generation and Semantic-related Alignment for Universal Zero-Shot Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://henghuiding.github.io/PADing/) <br /> [![GitHub](https://img.shields.io/github/stars/heshuting555/PADing)](https://github.com/heshuting555/PADing) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Primitive_Generation_and_Semantic-Related_Alignment_for_Universal_Zero-Shot_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.11087-b31b1b.svg)](http://arxiv.org/abs/2306.11087) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yZp-i7ZgU_M) |
| CLIP2Scene: Towards Label-Efficient 3D Scene Understanding by CLIP | [![GitHub](https://img.shields.io/github/stars/runnanchen/CLIP2Scene)](https://github.com/runnanchen/CLIP2Scene) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_CLIP2Scene_Towards_Label-Efficient_3D_Scene_Understanding_by_CLIP_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.04926-b31b1b.svg)](http://arxiv.org/abs/2301.04926) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OT6AvAVlNNs) |
| Multispectral Video Semantic Segmentation: A Benchmark Dataset and Baseline | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jiwei0921.github.io/Multispectral-Video-Semantic-Segmentation/) <br /> [![GitHub](https://img.shields.io/github/stars/jiwei0921/MVSS-Baseline)](https://github.com/jiwei0921/MVSS-Baseline) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Multispectral_Video_Semantic_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Optimal Transport Minimization: Crowd Localization on Density Maps for Semi-Supervised Counting |  |  |  |
| Indiscernible Object Counting in Underwater Scenes |  |  |  |
| Long Range Pooling for 3D Large-Scale Scene Understanding |  |  |  |
| Delivering Arbitrary-Modal Semantic Segmentation |  |  |  |
| Images Speak in Images: A Generalist Painter for In-Context Visual Learning |  |  |  |
| SCPNet: Semantic Scene Completion on Point Cloud |  |  |  |
| Content-Aware Token Sharing for Efficient Semantic Segmentation with Vision Transformers |  |  |  |
| OpenScene: 3D Scene Understanding with Open Vocabularies |  |  |  |
| Devil's on the Edges: Selective Quad Attention for Scene Graph Generation |  |  |  |
| Delving into Shape-Aware Zero-Shot Semantic Segmentation |  |  |  |
| Category Query Learning for Human-Object Interaction Classification |  |  |  |
| Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene Representation from 2D Supervision |  |  |  |
| DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction |  |  |  |
| SCOOP: Self-Supervised Correspondence and Optimization-based Scene Flow | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://itailang.github.io/SCOOP/) <br /> [![GitHub](https://img.shields.io/github/stars/itailang/SCOOP)](https://github.com/itailang/SCOOP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lang_SCOOP_Self-Supervised_Correspondence_and_Optimization-Based_Scene_Flow_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14020-b31b1b.svg)](https://arxiv.org/abs/2211.14020) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=b8MVWGU7V4E) |
| Incremental 3D Semantic Scene Graph Prediction from RGB Sequences |  |  |  |
| PanelNet: Understanding 360 Indoor Environment via Panel Representation |  |  |  |
| Perspective Fields for Single Image Camera Calibration |  |  |  |
| Open-Category Human-Object Interaction Pre-Training via Language Modeling Framework |  |  |  |
| Fast Contextual Scene Graph Generation with Unbiased Context Augmentation |  |  |  |
| Diffusion-based Generation, Optimization, and Planning in 3D Scenes |  |  |  |
| TopNet: Transformer-based Object Placement Network for Image Compositing |  |  |  |
| Computational Flash Photography through Intrinsics |  |  |  |
| Probing Neural Representations of Scene Perception in a Hippocampally Dependent Task using Artificial Neural Networks |  |  |  |
| DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text Spotting |  |  |  |
| LEGO-Net: Learning Regular Rearrangements of Objects in Rooms |  |  |  |
| Open-Vocabulary Point-Cloud Object Detection without 3D Annotation |  |  |  |
| Weakly-Supervised Domain Adaptive Semantic Segmentation with Prototypical Contrastive Learning |  |  |  |
| ScanDMM: A Deep Markov Model of Scanpath Prediction for 360&deg; Images |  |  |  |
| Canonical Fields: Self-Supervised Learning of Pose-Canonicalized Neural Fields |  |  |  |
| TempSAL - Uncovering Temporal Information for Deep Saliency Prediction |  |  |  |
| Probabilistic Debiasing of Scene Graphs |  |  |  |
| Towards Unified Scene Text Spotting based on Sequence Generation |  |  |  |
| Learning to Generate Language-Supervised and Open-Vocabulary Scene Graph using Pre-trained Visual-Semantic Space |  |  |  |
| Modular Memorability: Tiered Representations for Video Memorability Prediction |  |  |  |
| Where We Are and What We're Looking At: Query Based Worldwide Image Geo-Localization using Hierarchies and Scenes |  |  |  |
| HRDFuse: Monocular 360&deg; Depth Estimation by Collaboratively Learning Holistic-with-Regional Depth Distributions |  |  |  |
