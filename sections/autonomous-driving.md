# CVPR-2023-Papers

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/video-action-and-event-understanding.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/self-supervised-or-unsupervised-representation-learning.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
  </a>
</div>

## Autonomous Driving

![Section Papers](https://img.shields.io/badge/Section%20Papers-69-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-54-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-47-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-53-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| GraVoS: Voxel Selection for 3D Point-Cloud Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shrout_GraVoS_Voxel_Selection_for_3D_Point-Cloud_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.08780-b31b1b.svg)](http://arxiv.org/abs/2208.08780) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8rVLxIT-2wQ) |
| BEV@DC: Bird's-Eye View Assisted Training for Depth Completion | :heavy_minus_sign: |[![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_BEVDC_Birds-Eye_View_Assisted_Training_for_Depth_Completion_CVPR_2023_paper.pdf) |[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IvhaqXL1NNY) |
| Are we Ready for Vision-Centric Driving Streaming Perception? The ASAP Benchmark | [![GitHub](https://img.shields.io/github/stars/JeffWang987/ASAP)](https://github.com/JeffWang987/ASAP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Are_We_Ready_for_Vision-Centric_Driving_Streaming_Perception_The_ASAP_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.08914-b31b1b.svg)](http://arxiv.org/abs/2212.08914) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YjNkmvm83ww) |
| PVT-SSD: Single-Stage 3D Object Detector with Point-Voxel Transformer | [![GitHub](https://img.shields.io/github/stars/Nightmare-n/PVT-SSD)](https://github.com/Nightmare-n/PVT-SSD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_PVT-SSD_Single-Stage_3D_Object_Detector_With_Point-Voxel_Transformer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.06621-b31b1b.svg)](https://arxiv.org/abs/2305.06621) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=J1FVUpmW9JA) |
| End-to-End Vectorized HD-Map Construction with Piecewise Bezier Curve | [![GitHub](https://img.shields.io/github/stars/er-muyue/BeMapNet)](https://github.com/er-muyue/BeMapNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qiao_End-to-End_Vectorized_HD-Map_Construction_With_Piecewise_Bezier_Curve_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.09700-b31b1b.svg)](https://arxiv.org/abs/2306.09700) | :heavy_minus_sign: |
| MoDAR: Using Motion Forecasting for 3D Object Detection in Point Cloud Sequences | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MoDAR_Using_Motion_Forecasting_for_3D_Object_Detection_in_Point_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.03206-b31b1b.svg)](https://arxiv.org/abs/2306.03206) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xIPWjmGzaqU) |
| LaserMix for Semi-Supervised LiDAR Semantic Segmentation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ldkong.com/LaserMix) <br /> [![GitHub](https://img.shields.io/github/stars/ldkong1205/LaserMix)](https://github.com/ldkong1205/LaserMix) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_LaserMix_for_Semi-Supervised_LiDAR_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.00026-b31b1b.svg)](http://arxiv.org/abs/2207.00026) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7-zvIHKqkl0) |
| MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth Seeds for 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/SxJyJay/MSMDFusion)](https://github.com/SxJyJay/MSMDFusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiao_MSMDFusion_Fusing_LiDAR_and_Camera_at_Multiple_Scales_With_Multi-Depth_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.03102-b31b1b.svg)](http://arxiv.org/abs/2209.03102) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5mkacK_wsqY) |
| LiDAR2Map: In Defense of LiDAR-based Semantic Map Construction using Online Camera Distillation | [![GitHub](https://img.shields.io/github/stars/songw-zju/LiDAR2Map)](https://github.com/songw-zju/LiDAR2Map) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_LiDAR2Map_In_Defense_of_LiDAR-Based_Semantic_Map_Construction_Using_Online_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11379-b31b1b.svg)](http://arxiv.org/abs/2304.11379) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nr25xFZbx8U) |
| Think Twice Before Driving: Towards Scalable Decoders for End-to-End Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/ThinkTwice)](https://github.com/OpenDriveLab/ThinkTwice) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jia_Think_Twice_Before_Driving_Towards_Scalable_Decoders_for_End-to-End_Autonomous_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.06242-b31b1b.svg)](http://arxiv.org/abs/2305.06242) | :heavy_minus_sign: |
| Planning-Oriented Autonomous Driving <br /> ![CVPR - Award](https://img.shields.io/badge/CVPR-Award-294A7C) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://opendrivelab.github.io/UniAD/) <br /> [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/UniAD)](https://github.com/OpenDriveLab/UniAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Planning-Oriented_Autonomous_Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10156-b31b1b.svg)](http://arxiv.org/abs/2212.10156) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=R4iuq3zDBL4) |
| Distilling Focal Knowledge from Imperfect Expert for 3D Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/OpenDriveLab/Birds-eye-view-Perception/blob/master/nuScenes_playground/FocalDistiller/README.md) <br /> [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/Birds-eye-view-Perception)](https://github.com/OpenDriveLab/Birds-eye-view-Perception) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_Distilling_Focal_Knowledge_From_Imperfect_Expert_for_3D_Object_Detection_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Np9_pEzleG4) |
| Anchor3DLane: Learning to Regress 3D Anchors for Monocular 3D Lane Detection | [![GitHub](https://img.shields.io/github/stars/tusen-ai/Anchor3DLane)](https://github.com/tusen-ai/Anchor3DLane) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Anchor3DLane_Learning_To_Regress_3D_Anchors_for_Monocular_3D_Lane_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.02371-b31b1b.svg)](http://arxiv.org/abs/2301.02371) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5ceKZ6q5TVc) |
| SliceMatch: Geometry-Guided Aggregation for Cross-View Pose Estimation | [![GitHub](https://img.shields.io/github/stars/tudelft-iv/SliceMatch)](https://github.com/tudelft-iv/SliceMatch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lentsch_SliceMatch_Geometry-Guided_Aggregation_for_Cross-View_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14651-b31b1b.svg)](http://arxiv.org/abs/2211.14651) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gql1dkQQNrA) |
| Azimuth Super-Resolution for FMCW Radar in Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/yujheli/Pitt-Radar)](https://github.com/yujheli/Pitt-Radar) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Azimuth_Super-Resolution_for_FMCW_Radar_in_Autonomous_Driving_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| V2V4Real: A Real-World Large-Scale Dataset for Vehicle-to-Vehicle Cooperative Perception | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://mobility-lab.seas.ucla.edu/v2v4real/) <br /> [![GitHub](https://img.shields.io/github/stars/ucla-mobility/V2V4Real)](https://github.com/ucla-mobility/V2V4Real) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_V2V4Real_A_Real-World_Large-Scale_Dataset_for_Vehicle-to-Vehicle_Cooperative_Perception_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07601-b31b1b.svg)](http://arxiv.org/abs/2303.07601) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=67N0epSAvRA) |
| Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://waabi.ai/implicito/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Agro_Implicit_Occupancy_Flow_Fields_for_Perception_and_Prediction_in_Self-Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01471-b31b1b.svg)](https://arxiv.org/abs/2308.01471) | :heavy_minus_sign: |
| Coaching a Teachable Student <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://catdrive.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/h2xlab/CaT)](https://github.com/h2xlab/CaT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Coaching_a_Teachable_Student_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.10014-b31b1b.svg)](https://arxiv.org/abs/2306.10014) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5tmkDHfgqvU) |
| BEV-SAN: Accurate BEV 3D Object Detection via Slice Attention Networks | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chi_BEV-SAN_Accurate_BEV_3D_Object_Detection_via_Slice_Attention_Networks_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01231-b31b1b.svg)](https://arxiv.org/abs/2212.01231) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UYGZoi490GI) |
| Center Focusing Network for Real-Time LiDAR Panoptic Segmentation | [![GitHub](https://img.shields.io/github/stars/gangzhang842/cfnet)](https://github.com/gangzhang842/cfnet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Center_Focusing_Network_for_Real-Time_LiDAR_Panoptic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.09499-b31b1b.svg)](https://arxiv.org/abs/2311.09499) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LHaQhrVysDo) |
| IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint Multi-Agent Trajectory Prediction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_IPCC-TP_Utilizing_Incremental_Pearson_Correlation_Coefficient_for_Joint_Multi-Agent_Trajectory_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00575-b31b1b.svg)](https://arxiv.org/abs/2303.00575) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0eQUiil3AXs) |
| Weakly Supervised Monocular 3D Object Detection using Multi-View Projection and Direction Consistency | [![GitHub](https://img.shields.io/github/stars/weakmono3d/weakmono3d)](https://github.com/weakmono3d/weakmono3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tao_Weakly_Supervised_Monocular_3D_Object_Detection_Using_Multi-View_Projection_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08686-b31b1b.svg)](http://arxiv.org/abs/2303.08686) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AXBa5Rn58j4) |
| CXTrack: Improving 3D Point Cloud Tracking with Contextual Information | [![GitHub](https://img.shields.io/github/stars/slothfulxtx/cxtrack3d)](https://github.com/slothfulxtx/cxtrack3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_CXTrack_Improving_3D_Point_Cloud_Tracking_With_Contextual_Information_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.08542-b31b1b.svg)](http://arxiv.org/abs/2211.08542) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9CbtQt4umws) |
| ReasonNet: End-to-End Driving with Temporal and Global Reasoning | [![GitHub](https://img.shields.io/github/stars/opendilab/DOS)](https://github.com/opendilab/DOS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shao_ReasonNet_End-to-End_Driving_With_Temporal_and_Global_Reasoning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10507-b31b1b.svg)](https://arxiv.org/abs/2305.10507) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=59wCGdrHGE4) |
| Seeing with Sound: Long-Range Acoustic Beamforming for Multimodal Scene Understanding | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://light.princeton.edu/publication/seeingwithsound/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chakravarthula_Seeing_With_Sound_Long-range_Acoustic_Beamforming_for_Multimodal_Scene_Understanding_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=N5QinjRhKYQ) |
| LinK: Linear Kernel for LiDAR-based 3D Perception | [![GitHub](https://img.shields.io/github/stars/MCG-NJU/LinK)](https://github.com/MCG-NJU/LinK) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_LinK_Linear_Kernel_for_LiDAR-Based_3D_Perception_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16094-b31b1b.svg)](http://arxiv.org/abs/2303.16094) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UM2W7rHE6V4) |
| Understanding the Robustness of 3D Object Detection with Bird's-Eye-View Representations in Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/zzj403/BEV_Robust)](https://github.com/zzj403/BEV_Robust) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Understanding_the_Robustness_of_3D_Object_Detection_With_Birds-Eye-View_Representations_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17297-b31b1b.svg)](https://arxiv.org/abs/2303.17297) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TqoR7gwzTXQ) |
| Tri-Perspective View for Vision-based 3D Semantic Occupancy Prediction |  [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://wzzheng.net/TPVFormer/) <br /> [![GitHub](https://img.shields.io/github/stars/wzzheng/TPVFormer)](https://github.com/wzzheng/TPVFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Tri-Perspective_View_for_Vision-Based_3D_Semantic_Occupancy_Prediction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.07817-b31b1b.svg)](http://arxiv.org/abs/2302.07817) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XWVNn0_6iJg) |
| SkyEye: Self-Supervised Bird's-Eye-View Semantic Mapping using Monocular Frontal View Images | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://skyeye.cs.uni-freiburg.de/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gosala_SkyEye_Self-Supervised_Birds-Eye-View_Semantic_Mapping_Using_Monocular_Frontal_View_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.04233-b31b1b.svg)](https://arxiv.org/abs/2302.04233) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PGne5XG4f_8) |
| BEV-LaneDet: An Efficient 3D Lane Detection based on Virtual Camera via Key-Points | [![GitHub](https://img.shields.io/github/stars/gigo-team/bev_lane_det)](https://github.com/gigo-team/bev_lane_det) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_BEV-LaneDet_An_Efficient_3D_Lane_Detection_Based_on_Virtual_Camera_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.06006-b31b1b.svg)](https://arxiv.org/abs/2210.06006) | :heavy_minus_sign: |
| OcTr: Octree-based Transformer for 3D Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_OcTr_Octree-Based_Transformer_for_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12621-b31b1b.svg)](http://arxiv.org/abs/2303.12621) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NgCI8s7Kh8M) |
| Instant Domain Augmentation for LiDAR Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/kwonyoung9120/LiDomAug)](https://github.com/kwonyoung9120/LiDomAug) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ryu_Instant_Domain_Augmentation_for_LiDAR_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14378-b31b1b.svg)](http://arxiv.org/abs/2303.14378) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tnheIfyQkqc) |
| ViP3D: End-to-End Visual Trajectory Prediction via 3D Agent Queries | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tsinghua-mars-lab.github.io/ViP3D/) <br /> [![GitHub](https://img.shields.io/github/stars/Tsinghua-MARS-Lab/ViP3D)](https://github.com/Tsinghua-MARS-Lab/ViP3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gu_ViP3D_End-to-End_Visual_Trajectory_Prediction_via_3D_Agent_Queries_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.01582-b31b1b.svg)](http://arxiv.org/abs/2208.01582) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1apYGKgeWdc) |
| UniSim: A Neural Closed-Loop Sensor Simulator <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://waabi.ai/unisim/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_UniSim_A_Neural_Closed-Loop_Sensor_Simulator_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01898-b31b1b.svg)](https://arxiv.org/abs/2308.01898) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3OwjE1Mv_3I) |
| Learning Compact Representations for LiDAR Completion and Generation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://waabi.ai/ultralidar/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiong_Learning_Compact_Representations_for_LiDAR_Completion_and_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.01448-b31b1b.svg)](https://arxiv.org/abs/2311.01448) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CWOfT3Wrxh4) |
| Towards Unsupervised Object Detection from LiDAR Point Clouds | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://waabi.ai/research/oyster) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Towards_Unsupervised_Object_Detection_From_LiDAR_Point_Clouds_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02007-b31b1b.svg)](https://arxiv.org/abs/2311.02007) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gUQZmIhCxVM) |
| Standing Between Past and Future: Spatio-Temporal Modeling for Multi-Camera 3D Multi-Object Tracking | [![GitHub](https://img.shields.io/github/stars/TRI-ML/PF-Track)](https://github.com/TRI-ML/PF-Track) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pang_Standing_Between_Past_and_Future_Spatio-Temporal_Modeling_for_Multi-Camera_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.03802-b31b1b.svg)](http://arxiv.org/abs/2302.03802) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AP46BbkJ7vY) |
| Benchmarking Robustness of 3D Object Detection to Common Corruptions in Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/thu-ml/3D_Corruptions_AD)](https://github.com/thu-ml/3D_Corruptions_AD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_Benchmarking_Robustness_of_3D_Object_Detection_to_Common_Corruptions_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11040-b31b1b.svg)](http://arxiv.org/abs/2303.11040) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xIRQhg3I1-A) |
| X<sup>3</sup>KD: Knowledge Distillation Across Modalities, Tasks and Stages for Multi-Camera 3D Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Klingner_X3KD_Knowledge_Distillation_Across_Modalities_Tasks_and_Stages_for_Multi-Camera_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.02203-b31b1b.svg)](https://arxiv.org/abs/2303.02203) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1do9DPFmr38) |
| PeakConv: Learning Peak Receptive Field for Radar Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/zlw9161/PKC)](https://github.com/zlw9161/PKC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_PeakConv_Learning_Peak_Receptive_Field_for_Radar_Semantic_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| GD-MAE: Generative Decoder for MAE Pre-Training on LiDAR Point Clouds | [![GitHub](https://img.shields.io/github/stars/Nightmare-n/GD-MAE)](https://github.com/Nightmare-n/GD-MAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_GD-MAE_Generative_Decoder_for_MAE_Pre-Training_on_LiDAR_Point_Clouds_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03010-b31b1b.svg)](https://arxiv.org/abs/2212.03010) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=k8JE6CDjyng) |
| Neural Map Prior for Autonomous Driving | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tsinghua-mars-lab.github.io/neural_map_prior/) </br> [![GitHub](https://img.shields.io/github/stars/Tsinghua-MARS-Lab/neural_map_prior)](https://github.com/Tsinghua-MARS-Lab/neural_map_prior) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiong_Neural_Map_Prior_for_Autonomous_Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08481-b31b1b.svg)](http://arxiv.org/abs/2304.08481) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FpzxaBVw3L0) |
| Lift3D: Synthesize 3D Training Data by Lifting 2D GAN to 3D Generative Radiance Field | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://len-li.github.io/lift3d-web/) </br> [![GitHub](https://img.shields.io/github/stars/Len-Li/Lift3D)](https://github.com/Len-Li/Lift3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Lift3D_Synthesize_3D_Training_Data_by_Lifting_2D_GAN_to_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03526-b31b1b.svg)](http://arxiv.org/abs/2304.03526) | :heavy_minus_sign: |
| Continuous Pseudo-Label Rectified Domain Adaptive Semantic Segmentation with Implicit Neural Representations | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gong_Continuous_Pseudo-Label_Rectified_Domain_Adaptive_Semantic_Segmentation_With_Implicit_Neural_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Single Domain Generalization for LiDAR Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/gzgzys9887/DGLSS)](https://github.com/gzgzys9887/DGLSS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Single_Domain_Generalization_for_LiDAR_Semantic_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XUe-N3p5btc) |
| Uncertainty-Aware Vision-based Metric Cross-View Geolocalization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fferflo.github.io/projects/vismetcvgl23/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fervers_Uncertainty-Aware_Vision-Based_Metric_Cross-View_Geolocalization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12145-b31b1b.svg)](http://arxiv.org/abs/2211.12145) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1vHFiA0prL0) |
| MixSim: A Hierarchical Framework for Mixed Reality Traffic Simulation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://waabi.ai/mixsim/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Suo_MixSim_A_Hierarchical_Framework_for_Mixed_Reality_Traffic_Simulation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| PillarNeXt: Rethinking Network Designs for 3D Object Detection in LiDAR Point Clouds | [![GitHub](https://img.shields.io/github/stars/qcraftai/pillarnext)](https://github.com/qcraftai/pillarnext) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_PillarNeXt_Rethinking_Network_Designs_for_3D_Object_Detection_in_LiDAR_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.04925-b31b1b.svg)](http://arxiv.org/abs/2305.04925) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zdMSqNvi-KM) |
| Uni3D: A Unified Baseline for Multi-Dataset 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/3DTrans)](https://github.com/PJLab-ADG/3DTrans) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Uni3D_A_Unified_Baseline_for_Multi-Dataset_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06880-b31b1b.svg)](http://arxiv.org/abs/2303.06880) | :heavy_minus_sign: |
| CAPE: Camera View Position Embedding for Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/kaixinbear/CAPE)](https://github.com/kaixinbear/CAPE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiong_CAPE_Camera_View_Position_Embedding_for_Multi-View_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10209-b31b1b.svg)](http://arxiv.org/abs/2303.10209) | :heavy_minus_sign: |
| LiDAR-in-the-Loop Hyperparameter Optimization | [![GitHub](https://img.shields.io/github/stars/princeton-computational-imaging/LITL-Optimization)](https://github.com/princeton-computational-imaging/LITL-Optimization) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Goudreault_LiDAR-in-the-Loop_Hyperparameter_Optimization_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8IjqoctJgOs) |
| Bi3D: Bi-Domain Active Learning for Cross-Domain 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/3DTrans)](https://github.com/PJLab-ADG/3DTrans) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yuan_Bi3D_Bi-Domain_Active_Learning_for_Cross-Domain_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05886-b31b1b.svg)](http://arxiv.org/abs/2303.05886) | :heavy_minus_sign: |
| FEND: A Future Enhanced Distribution-Aware Contrastive Learning Framework for Long-Tail Trajectory Prediction | [![GitHub](https://img.shields.io/github/stars/ynw2021/FEND)](https://github.com/ynw2021/FEND) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_FEND_A_Future_Enhanced_Distribution-Aware_Contrastive_Learning_Framework_for_Long-Tail_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16574-b31b1b.svg)](http://arxiv.org/abs/2303.16574) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=31Put0T54qI) |
| Temporal Consistent 3D LiDAR Representation Learning for Semantic Perception in Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/PRBonn/TARL)](https://github.com/PRBonn/TARL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Nunes_Temporal_Consistent_3D_LiDAR_Representation_Learning_for_Semantic_Perception_in_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0CtDbwRYLeo) |
| Density-Insensitive Unsupervised Domain Adaption on 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/WoodwindHu/DTS)](https://github.com/WoodwindHu/DTS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Density-Insensitive_Unsupervised_Domain_Adaption_on_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.09446-b31b1b.svg)](http://arxiv.org/abs/2304.09446) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Zb020nG6sD0) |
| SGLoc: Scene Geometry Encoding for Outdoor LiDAR Localization | :heavy_minus_sign: |[![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_SGLoc_Scene_Geometry_Encoding_for_Outdoor_LiDAR_Localization_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Tek6yA20N7M) |
| TBP-Former: Learning Temporal Bird's-Eye-View Pyramid for Joint Perception and Prediction in Vision-Centric Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/MediaBrain-SJTU/TBP-Former)](https://github.com/MediaBrain-SJTU/TBP-Former) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_TBP-Former_Learning_Temporal_Birds-Eye-View_Pyramid_for_Joint_Perception_and_Prediction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09998-b31b1b.svg)](https://arxiv.org/abs/2303.09998) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RlS2rDlaM9w) |
| Localized Semantic Feature Mixers for Efficient Pedestrian Detection in Autonomous Driving | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Khan_Localized_Semantic_Feature_Mixers_for_Efficient_Pedestrian_Detection_in_Autonomous_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4jSlqKnTemw) |
| Deep Dive Into Gradients: Better Optimization for 3D Object Detection with Gradient-Corrected IoU Supervision | [![GitHub](https://img.shields.io/github/stars/ming71/GCIoU-loss)](https://github.com/ming71/GCIoU-loss) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ming_Deep_Dive_Into_Gradients_Better_Optimization_for_3D_Object_Detection_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| ProphNet: Efficient Agent-Centric Motion Forecasting with Anchor-Informed Proposals <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_ProphNet_Efficient_Agent-Centric_Motion_Forecasting_With_Anchor-Informed_Proposals_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12071-b31b1b.svg)](http://arxiv.org/abs/2303.12071) | :heavy_minus_sign: |
| BEVHeight: A Robust Framework for Vision-based Roadside 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/ADLab-AutoDrive/BEVHeight)](https://github.com/ADLab-AutoDrive/BEVHeight) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_BEVHeight_A_Robust_Framework_for_Vision-Based_Roadside_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08498-b31b1b.svg)](http://arxiv.org/abs/2303.08498) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=W-y-MIrdXQc) |
| VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/NVlabs/VoxFormer)](https://github.com/NVlabs/VoxFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_VoxFormer_Sparse_Voxel_Transformer_for_Camera-Based_3D_Semantic_Scene_Completion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.12251-b31b1b.svg)](http://arxiv.org/abs/2302.12251) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L0M9ayR316g) |
| Hidden Gems: 4D Radar Scene Flow Learning using Cross-Modal Supervision <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/Toytiny/CMFlow)](https://github.com/Toytiny/CMFlow) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_Hidden_Gems_4D_Radar_Scene_Flow_Learning_Using_Cross-Modal_Supervision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00462-b31b1b.svg)](http://arxiv.org/abs/2303.00462) | :heavy_minus_sign: |
| Self-Supervised Image-to-Point Distillation via Semantically Tolerant Contrastive Loss | :heavy_minus_sign: |[![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mahmoud_Self-Supervised_Image-to-Point_Distillation_via_Semantically_Tolerant_Contrastive_Loss_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.05709-b31b1b.svg)](http://arxiv.org/abs/2301.05709)| :heavy_minus_sign: |
| Query-Centric Trajectory Prediction | [![GitHub](https://img.shields.io/github/stars/ZikangZhou/QCNet)](https://github.com/ZikangZhou/QCNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Query-Centric_Trajectory_Prediction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=i46Sj0PUwyI) |
| Efficient Hierarchical Entropy Model for Learned Point Cloud Compression | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Efficient_Hierarchical_Entropy_Model_for_Learned_Point_Cloud_Compression_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MSnZRJ94CM8) |
| Novel Class Discovery for 3D Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/LuigiRiz/NOPS)](https://github.com/LuigiRiz/NOPS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Riz_Novel_Class_Discovery_for_3D_Point_Cloud_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11610-b31b1b.svg)](http://arxiv.org/abs/2303.11610) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kRp1F-_emj8) |
| MotionDiffuser: Controllable Multi-Agent Motion Prediction using Diffusion <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_MotionDiffuser_Controllable_Multi-Agent_Motion_Prediction_Using_Diffusion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.03083-b31b1b.svg)](https://arxiv.org/abs/2306.03083) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IfGTZwm1abg) |
| FJMP: Factorized Joint Multi-Agent Motion Prediction Over Learned Directed Acyclic Interaction Graphs | [![GitHub](https://img.shields.io/github/stars/RLuke22/FJMP)](https://github.com/RLuke22/FJMP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rowe_FJMP_Factorized_Joint_Multi-Agent_Motion_Prediction_Over_Learned_Directed_Acyclic_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16197-b31b1b.svg)](http://arxiv.org/abs/2211.16197) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=asmCOhPQuNw) |
