# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/multimodal-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/medical-and-biological-vision-cell-microscopy.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 3D from Single Images

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| 3D-Aware Multi-Class Image-to-Image Translation With NeRFs | [![GitHub](https://img.shields.io/github/stars/sen-mao/3di2i-translation?style=flat)](https://github.com/sen-mao/3di2i-translation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_3D-Aware_Multi-Class_Image-to-Image_Translation_With_NeRFs_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15012-b31b1b.svg)](http://arxiv.org/abs/2303.15012) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CjBPP2l9Bjg) |
| DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-Aware Scene Synthesis <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://snap-research.github.io/discoscene/) <br /> [![GitHub](https://img.shields.io/github/stars/snap-research/discoscene?style=flat)](https://github.com/snap-research/discoscene) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_DisCoScene_Spatially_Disentangled_Generative_Radiance_Fields_for_Controllable_3D-Aware_Scene_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.11984-b31b1b.svg)](http://arxiv.org/abs/2212.11984) | :heavy_minus_sign: |
| MagicPony: Learning Articulated 3D Animals in the Wild | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3dmagicpony.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/elliottwu/MagicPony?style=flat)](https://github.com/elliottwu/MagicPony) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_MagicPony_Learning_Articulated_3D_Animals_in_the_Wild_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12497-b31b1b.svg)](http://arxiv.org/abs/2211.12497) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KoLzpESstLk) |
| Seeing a Rose in Five Thousand Ways | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ai.stanford.edu/~yzzhang/projects/rose/) <br /> [![GitHub](https://img.shields.io/github/stars/zzyunzhi/object-intrinsics?style=flat)](https://github.com/zzyunzhi/object-intrinsics) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Seeing_a_Rose_in_Five_Thousand_Ways_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04965-b31b1b.svg)](http://arxiv.org/abs/2212.04965) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oe5N3sNDp2w) |
| FitMe: Deep Photorealistic 3D Morphable Model Avatars | [![GitHub](https://img.shields.io/github/stars/lattas/FitMe?style=flat)](https://github.com/lattas/FitMe) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lattas_FitMe_Deep_Photorealistic_3D_Morphable_Model_Avatars_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.09641-b31b1b.svg)](https://arxiv.org/abs/2305.09641) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=73ZFDkZRRCk) |
| Scalable, Detailed and Mask-Free Universal Photometric Stereo <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]() | [![GitHub](https://img.shields.io/github/stars/satoshi-ikehata/SDM-UniPS-CVPR2023?style=flat)](https://github.com/satoshi-ikehata/SDM-UniPS-CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ikehata_Scalable_Detailed_and_Mask-Free_Universal_Photometric_Stereo_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15724-b31b1b.svg)](http://arxiv.org/abs/2303.15724) | :heavy_minus_sign: |
| Spatio-Focal Bidirectional Disparity Estimation From a Dual-Pixel Image | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vclab.kaist.ac.kr/cvpr2023p1/) <br /> [![GitHub](https://img.shields.io/github/stars/KAIST-VCLAB/dual-pixel-disparity?style=flat)](https://github.com/KAIST-VCLAB/dual-pixel-disparity) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Kim_Spatio-Focal_Bidirectional_Disparity_Estimation_From_a_Dual-Pixel_Image_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SIoWF8phDp0) |
| ShapeClipper: Scalable 3D Shape Learning From Single-View Images via Geometric and CLIP-Based Consistency | [![GitHub](https://img.shields.io/github/stars/zxhuang1698/ShapeClipper?style=flat)](https://github.com/zxhuang1698/ShapeClipper) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Huang_ShapeClipper_Scalable_3D_Shape_Learning_From_Single-View_Images_via_Geometric_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06247-b31b1b.svg)](http://arxiv.org/abs/2304.06247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=BxTGVjXoXu8) |
| High-Fidelity Clothed Avatar Reconstruction From a Single Image | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tingtingliao.github.io/CAR/) <br /> [![GitHub](https://img.shields.io/github/stars/TingtingLiao/CAR?style=flat)](https://github.com/TingtingLiao/CAR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liao_High-Fidelity_Clothed_Avatar_Reconstruction_From_a_Single_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03903-b31b1b.svg)](http://arxiv.org/abs/2304.03903) | :heavy_minus_sign: |
| TexPose: Neural Texture Learning for Self-Supervised 6D Object Pose Estimation | [![GitHub](https://img.shields.io/github/stars/HanzhiC/TexPose?style=flat)](https://github.com/HanzhiC/TexPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_TexPose_Neural_Texture_Learning_for_Self-Supervised_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.12902-b31b1b.svg)](http://arxiv.org/abs/2212.12902) | :heavy_minus_sign: |
| Behind the Scenes: Density Fields for Single View Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fwmb.github.io/bts/) <br /> [![GitHub](https://img.shields.io/github/stars/Brummi/BehindTheScenes?style=flat)](https://github.com/Brummi/BehindTheScenes) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wimbauer_Behind_the_Scenes_Density_Fields_for_Single_View_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.07668-b31b1b.svg)](http://arxiv.org/abs/2301.07668) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0VGKPmomrR8) |
| Reconstructing Animatable Categories From Videos | [![GitHub](https://img.shields.io/github/stars/gengshan-y/rac?style=flat)](https://github.com/gengshan-y/rac) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Yang_Reconstructing_Animatable_Categories_From_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.06351-b31b1b.svg)](http://arxiv.org/abs/2305.06351) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V6S1WuPDEZE) |
| RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation | [![GitHub](https://img.shields.io/github/stars/Anciukevicius/RenderDiffusion?style=flat)](https://github.com/Anciukevicius/RenderDiffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Anciukevicius_RenderDiffusion_Image_Diffusion_for_3D_Reconstruction_Inpainting_and_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09869-b31b1b.svg)](https://arxiv.org/abs/2211.09869) | :heavy_minus_sign: |
| Self-Supervised Geometry-Aware Encoder for Style-Based 3D GAN Inversion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nirvanalan.github.io/projects/E3DGE/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/NIRVANALAN/CVPR23-E3DGE?style=flat)](https://github.com/NIRVANALAN/CVPR23-E3DGE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lan_Self-Supervised_Geometry-Aware_Encoder_for_Style-Based_3D_GAN_Inversion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07409-b31b1b.svg)](http://arxiv.org/abs/2212.07409) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s9uCZwqjfsA) |
| 3D Cinemagraphy From a Single Image | [![GitHub](https://img.shields.io/github/stars/xingyi-li/3d-cinemagraphy?style=flat)](https://github.com/xingyi-li/3d-cinemagraphy) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_3D_Cinemagraphy_From_a_Single_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05724-b31b1b.svg)](http://arxiv.org/abs/2303.05724) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sqCy7ffTEEY) |
| NeuralLift-360: Lifting an In-the-Wild 2D Photo to a 3D Object With 360Â° Views | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vita-group.github.io/NeuralLift-360/) <br /> [![GitHub](https://img.shields.io/github/stars/VITA-Group/NeuralLift-360?style=flat)](https://github.com/VITA-Group/NeuralLift-360) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Xu_NeuralLift-360_Lifting_an_In-the-Wild_2D_Photo_to_a_3D_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16431-b31b1b.svg)](https://arxiv.org/abs/2211.16431) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=knNNwF-J_ow) |
| iDisc: Internal Discretization for Monocular Depth Estimation | [![GitHub](https://img.shields.io/github/stars/SysCV/idisc?style=flat)](https://github.com/SysCV/idisc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Piccinelli_iDisc_Internal_Discretization_for_Monocular_Depth_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06334-b31b1b.svg)](http://arxiv.org/abs/2304.06334) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u4bgu9kR8ZM) |
| HairStep: Transfer Synthetic to Real Using Strand and Depth Maps for Single-View 3D Hair Modeling <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]() | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://paulyzheng.github.io/research/hairstep/) <br /> [![GitHub](https://img.shields.io/github/stars/GAP-LAB-CUHK-SZ/HairStep?style=flat)](https://github.com/GAP-LAB-CUHK-SZ/HairStep) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zheng_HairStep_Transfer_Synthetic_to_Real_Using_Strand_and_Depth_Maps_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.02700-b31b1b.svg)](http://arxiv.org/abs/2303.02700) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WkG73DTSyUg) |
| NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-Shot Real Image Animation | [![GitHub](https://img.shields.io/github/stars/YuYin1/NeRFInvertor?style=flat)](https://github.com/YuYin1/NeRFInvertor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Yin_NeRFInvertor_High_Fidelity_NeRF-GAN_Inversion_for_Single-Shot_Real_Image_Animation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.17235-b31b1b.svg)](http://arxiv.org/abs/2211.17235) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tFD0fH06JQg) |
| NeurOCS: Neural NOCS Supervision for Monocular 3D Object Localization| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Min_NeurOCS_Neural_NOCS_Supervision_for_Monocular_3D_Object_Localization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.17763-b31b1b.svg)](https://arxiv.org/abs/2305.17763) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TrE4NGyc4SQ) |
| Multiview Compressive Coding for 3D Reconstruction | [![GitHub](https://img.shields.io/github/stars/facebookresearch/MCC?style=flat)](https://github.com/facebookresearch/MCC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wu_Multiview_Compressive_Coding_for_3D_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.08247-b31b1b.svg)](http://arxiv.org/abs/2301.08247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f4lPEqigHuM) |
| FaceLit: Neural 3D Relightable Faces | [![GitHub](https://img.shields.io/github/stars/apple/ml-facelit?style=flat)](https://github.com/apple/ml-facelit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ranjan_FaceLit_Neural_3D_Relightable_Faces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15437-b31b1b.svg)](http://arxiv.org/abs/2303.15437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PH1PZEutMbw) |
| Rigidity-Aware Detection for 6D Object Pose Estimation |  |  |  |
| Shape-Constraint Recurrent Flow for 6D Object Pose Estimation |  |  |  |
| Bringing Inputs to Shared Domains for 3D Interacting Hands Recovery in the Wild |  |  |  |
| Ref-NPR: Reference-based Non-Photorealistic Radiance Fields for Controllable Scene Stylization |  |  |  |
| DiffPose: Toward More Reliable 3D Pose Estimation |  |  |  |
| High-Fidelity 3D GAN Inversion by Pseudo-Multi-View Optimization |  |  |  |
| Semantic Scene Completion with Cleaner Self |  |  |  |
| Learned Two-Plane Perspective Prior based Image Resampling for Efficient Object Detection |  |  |  |
| Mask3D: Pre-Training 2D Vision Transformers by Learning Masked 3D Priors |  |  |  |
| Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild |  |  |  |
| Masked Scene Contrast: A Scalable Framework for Unsupervised 3D Representation Learning |  |  |  |
| Paired-Point Lifting for Enhanced Privacy-Preserving Visual Localization |  |  |  |
| Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation |  |  |  |
| gSDF: Geometry-Driven Signed Distance Functions for 3D Hand-Object Reconstruction |  |  |  |
| Accidental Light Probes |  |  |  |
| Learning to Predict Scene-Level Implicit 3D from Posed RGBD Data |  |  |  |
| DPF: Learning <u>D</u>ense <u>P</u>rediction <u>F</u>ields with Weak Supervision |  |  |  |
| DIFu: Depth-guided Implicit Function for Clothed Human Reconstruction |  |  |  |
| OrienterNet: Visual Localization in 2D Public Maps with Neural Matching |  |  |  |
| Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes |  |  |  |
| Structured 3D Features for Reconstructing Controllable Avatars |  |  |  |
| Delving into Discrete Normalizing Flows on SO(3) Manifold for Probabilistic Rotation Modeling |  |  |  |
| High-Fidelity 3D Human Digitization from Single 2K Resolution Images |  |  |  |
| Learning 3D-Aware Image Synthesis with Unknown Pose Distribution |  |  |  |
| DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors |  |  |  |
| Recovering 3D Hand Mesh Sequence from a Single Blurry Image: A New Dataset and Temporal Unfolding |  |  |  |
| Visibility Aware Human-Object Interaction Tracking from Single RGB Camera |  |  |  |
| SMOC-Net: Leveraging Camera Pose for Self-Supervised Monocular Object Pose Estimation |  |  |  |
| Curricular Object Manipulation in LiDAR-based Object Detection |  |  |  |
| SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human Reconstruction |  |  |  |
| MonoATT: Online Monocular 3D Object Detection with Adaptive Token Transformer |  |  |  |
| Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion |  |  |  |
| High Fidelity 3D Hand Shape Reconstruction via Scalable Graph Frequency Decomposition |  |  |  |
| NeRDi: Single-View NeRF Synthesis with Language-guided Diffusion as General Image Priors |  |  |  |
| ACL-SPC: Adaptive Closed-Loop System for Self-Supervised Point Cloud Completion |  |  |  |
| Self-Positioning Point-based Transformer for Point Cloud Understanding |  |  |  |
| H2ONet: Hand-Occlusion-and-Orientation-Aware Network for Real-Time 3D Hand Mesh Reconstruction |  |  |  |
| A Probabilistic Attention Model with Occlusion-Aware Texture Regression for 3D Hand Reconstruction from a Single RGB Image |  |  |  |
| Neural Voting Field for Camera-Space 3D Hand Pose Estimation |  |  |  |
| PLIKS: A Pseudo-Linear Inverse Kinematic Solver for 3D Human Body Estimation |  |  |  |
| Distilling Neural Fields for Real-Time Articulated Shape Reconstruction |  |  |  |
| Power Bundle Adjustment for Large-Scale 3D Reconstruction |  |  |  |
| What You Can Reconstruct from a Shadow |  |  |  |
| SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction |  |  |  |
| Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand Disentanglement |  |  |  |
| Trap Attention: Monocular Depth Estimation with Manual Traps |  |  |  |
| Crowd3D: Towards Hundreds of People Reconstruction from a Single Image |  |  |  |
| PAniC-3D: Stylized Single-View 3D Reconstruction from Portraits of Anime Characters |  |  |  |
| HS-Pose: Hybrid Scope Feature Extraction for Category-Level Object Pose Estimation |  |  |  |
| A Hierarchical Representation Network for Accurate and Detailed Face Reconstruction from In-the-Wild Images |  |  |  |
| Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation |  |  |  |
| SfM-TTR: Using Structure from Motion for Test-Time Refinement of Single-View Depth Networks |  |  |  |
| BITE: Beyond Priors for Improved Three-D Dog Pose Estimation |  |  |  |
| SinGRAF: Learning a 3D Generative Radiance Field for a Single Scene |  |  |  |
| Flow Supervision for Deformable NeRF |  |  |  |
| Single Image Depth Prediction Made Better: A Multivariate Gaussian Take |  |  |  |
| CARTO: Category and Joint Agnostic Reconstruction of ARTiculated Objects |  |  |  |
| PanoSwin: A Pano-Style Swin Transformer for Panorama Understanding |  |  |  |
| CP<sup>3</sup>: Channel Pruning Plug-In for Point-based Networks |  |  |  |
| PC<sup>2</sup>: Projection-Conditioned Point Cloud Diffusion for Single-Image 3D Reconstruction |  |  |  |
| On the Importance of Accurate Geometry Data for Dense 3D Vision Tasks |  |  |  |
| Cross-Domain 3D Hand Pose Estimation with Dual Modalities |  |  |  |
| RealFusion 360&deg; Reconstruction of Any Object from a Single Image |  |  |  |
| Sampling is Matter: Point-guided 3D Human Mesh Reconstruction |  |  |  |
| Knowledge Distillation for 6D Pose Estimation by Aligning Distributions of Local Predictions |  |  |  |
| BAAM: Monocular 3D Pose and Shape Reconstruction with Bi-Contextual Attention Module and Attention-guided Modeling |  |  |  |
| Single View Scene Scale Estimation using Scale Field |  |  |  |
| Learning Articulated Shape with Keypoint Pseudo-Labels from Web Images |  |  |  |
| Deformable Mesh Transformer for 3D Human Mesh Recovery |  |  |  |
