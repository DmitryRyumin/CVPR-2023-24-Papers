# CVPR-2023-Papers

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/vision-and-graphics.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/transparency-fairness-accountability-privacy-ethics-in-vision.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
  </a>
</div>

## Robotics

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Object-Goal Visual Navigation via Effective Exploration of Relations among Historical Navigation States | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Object-Goal_Visual_Navigation_via_Effective_Exploration_of_Relations_Among_Historical_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| TTA-COPE: Test-Time Adaptation for Category-Level Object Pose Estimation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/taeyeop-lee/ttacope) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_TTA-COPE_Test-Time_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16730-b31b1b.svg)](http://arxiv.org/abs/2303.16730) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MUgQ0yithis) |
| Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation using Scene Object Spectrum Grounding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rllab-snu.github.io/projects/Meta-Explore/doc.html) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hwang_Meta-Explore_Exploratory_Hierarchical_Vision-and-Language_Navigation_Using_Scene_Object_Spectrum_Grounding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.04077-b31b1b.svg)](http://arxiv.org/abs/2303.04077) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nxWUedX5VpQ) |
| Learning Human-to-Robot Handovers from Point Clouds | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://handover-sim2real.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/NVlabs/handover-sim2real)](https://github.com/NVlabs/handover-sim2real) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Christen_Learning_Human-to-Robot_Handovers_From_Point_Clouds_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17592-b31b1b.svg)](http://arxiv.org/abs/2303.17592) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IsjCdoIAA7s) |
| Robot Structure Prior Guided Temporal Attention for Camera-to-Robot Pose Estimation from Image Sequence | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/sgtapose) <br /> [![GitHub](https://img.shields.io/github/stars/Nimolty/SGTAPose)](https://github.com/Nimolty/SGTAPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Robot_Structure_Prior_Guided_Temporal_Attention_for_Camera-to-Robot_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12106-b31b1b.svg)](http://arxiv.org/abs/2307.12106) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5fQp-yBubZs) |
| PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pku-epic.github.io/PartManip/) <br /> [![GitHub](https://img.shields.io/github/stars/PKU-EPIC/PartManip)](https://github.com/PKU-EPIC/PartManip) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Geng_PartManip_Learning_Cross-Category_Generalizable_Part_Manipulation_Policy_From_Point_Cloud_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16958-b31b1b.svg)](http://arxiv.org/abs/2303.16958) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=k0LbcO1B-ac) |
| DexArt: Benchmarking Generalizable Dexterous Manipulation with Articulated Objects | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.chenbao.tech/dexart/) <br /> [![GitHub](https://img.shields.io/github/stars/Kami-code/dexart-release)](https://github.com/Kami-code/dexart-release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_DexArt_Benchmarking_Generalizable_Dexterous_Manipulation_With_Articulated_Objects_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.05706-b31b1b.svg)](http://arxiv.org/abs/2305.05706) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V_EYQJO1W_U) |
| PyPose: A Library for Robot Learning with Physics-based Optimization | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://pypose.org/) <br /> [![GitHub](https://img.shields.io/github/stars/pypose/pypose)](https://github.com/pypose/pypose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_PyPose_A_Library_for_Robot_Learning_With_Physics-Based_Optimization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.15428-b31b1b.svg)](http://arxiv.org/abs/2209.15428) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XDtUDIWuGng) |
| Target-Referenced Reactive Grasping for Dynamic Objects | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://graspnet.net/reactive) <br /> [![GitHub](https://img.shields.io/github/stars/Todibo99/Target-referenced-Reactive-Grasping-for-Dynamic-Objects)](https://github.com/Todibo99/Target-referenced-Reactive-Grasping-for-Dynamic-Objects) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Target-Referenced_Reactive_Grasping_for_Dynamic_Objects_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Autonomous Manipulation Learning for Similar Deformable Objects via only One Demonstration | [![GitHub](https://img.shields.io/github/stars/renyu2016/DLCDO)](https://github.com/renyu2016/DLCDO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_Autonomous_Manipulation_Learning_for_Similar_Deformable_Objects_via_Only_One_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y0FD0ihdEN0) |
| Renderable Neural Radiance Map for Visual Navigation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rllab-snu.github.io/projects/RNR-Map/) <br /> [![GitHub](https://img.shields.io/github/stars/rllab-snu/RNR-Map)](https://github.com/rllab-snu/RNR-Map) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kwon_Renderable_Neural_Radiance_Map_for_Visual_Navigation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00304-b31b1b.svg)](http://arxiv.org/abs/2303.00304) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1SF8_6BsA1c) |
| Efficient Map Sparsification based on 2D and 3D Discretized Grids | [![GitHub](https://img.shields.io/github/stars/fishmarch/SLAM_Map_Compression)](https://github.com/fishmarch/SLAM_Map_Compression) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Efficient_Map_Sparsification_Based_on_2D_and_3D_Discretized_Grids_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10882-b31b1b.svg)](http://arxiv.org/abs/2303.10882) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gG1nFddFf-s) |
| Policy Adaptation from Foundation Model Feedback | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://geyuying.github.io/PAFF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ge_Policy_Adaptation_From_Foundation_Model_Feedback_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07398-b31b1b.svg)](http://arxiv.org/abs/2212.07398) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5IZkbUFB2cM) |
| NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://bland.website/spartn/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_NeRF_in_the_Palm_of_Your_Hand_Corrective_Augmentation_for_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.08556-b31b1b.svg)](http://arxiv.org/abs/2301.08556) | :heavy_minus_sign: |
| Markerless Camera-to-Robot Pose Estimation via Self-Supervised Sim-to-Real Transfer | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Markerless_Camera-to-Robot_Pose_Estimation_via_Self-Supervised_Sim-to-Real_Transfer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14332-b31b1b.svg)](http://arxiv.org/abs/2302.14332) | :heavy_minus_sign: |
| Affordances from Human Videos as a Versatile Representation for Robotics |  |  |  |
| DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization |  |  |  |
| GrowSP: Unsupervised Semantic Segmentation of 3D Point Clouds |  |  |  |
| Neural Volumetric Memory for Visual Locomotion Control |  |  |  |
| Multi-Object Manipulation via Object-Centric Neural Scattering Functions |  |  |  |
| Local-guided Global: Paired Similarity Representation for Visual Reinforcement Learning |  |  |  |
| HypLiLoc: Towards Effective LiDAR Pose Regression with Hyperbolic Fusion |  |  |  |
| Imitation Learning as State Matching via Differentiable Physics |  |  |  |
