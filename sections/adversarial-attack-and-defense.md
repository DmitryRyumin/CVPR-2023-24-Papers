# CVPR-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/scene-analysis-and-understanding.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/efficient-and-scalable-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" />
    </a>
</div>

## Adversarial Attack and Defense

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| TWINS: A Fine-Tuning Framework for Improved Transferability of Adversarial Robustness and Generalization |  |  |  |
| Sibling-Attack: Rethinking Transferable Adversarial Attacks Against Face Recognition |  |  |  |
| T-SEA: Transfer-based Self-Ensemble Attack on Object Detection |  |  |  |
| The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for Improving Adversarial Training |  |  |  |
| Trade-Off between Robustness and Accuracy of Vision Transformers |  |  |  |
| Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling |  |  |  |
| Proximal Splitting Adversarial Attack for Semantic Segmentation |  |  |  |
| Feature Separation and Recalibration for Adversarial Robustness |  |  |  |
| Enhancing the Self-Universality for Transferable Targeted Attacks |  |  |  |
| Backdoor Defense via Adaptively Splitting Poisoned Dataset |  |  |  |
| Dynamic Generative Targeted Attacks with Pattern Injection |  |  |  |
| Exploring the Relationship between Architectural Design and Adversarially Robust Generalization |  |  |  |
| Discrete Point-Wise Attack Is Not Enough: Generalized Manifold Adversarial Attack for Face Recognition |  |  |  |
| Towards Benchmarking and Assessing Visual Naturalness of Physical World Adversarial Attacks |  |  |  |
| MaLP: Manipulation Localization using a Proactive Scheme |  |  |  |
| TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets |  |  |  |
| Minimizing Maximum Model Discrepancy for Transferable Black-Box Targeted Attacks |  |  |  |
| Improving Robust Generalization by Direct PAC-Bayesian Bound Minimization |  |  |  |
| AGAIN: Adversarial Training with Attribution Span Enlargement and Hybrid Feature Fusion |  |  |  |
| Backdoor Defense via Deconfounded Representation Learning |  |  |  |
| Adversarially Robust Neural Architecture Search for Graph Neural Networks |  |  |  |
| PointCert: Point Cloud Classification with Deterministic Certified Robustness Guarantees |  |  |  |
| Towards Compositional Adversarial Robustness: Generalizing Adversarial Training to Composite Semantic Perturbations |  |  |  |
| Physically Adversarial Infrared Patches with Learnable Shapes and Locations |  |  |  |
| Color Backdoor: A Robust Poisoning Attack in Color Space |  |  |  |
| Towards Effective Adversarial Textured 3D Meshes on Physical Face Recognition |  |  |  |
| Turning Strengths into Weaknesses: A Certified Robustness Inspired Attack Framework Against Graph Neural Networks |  |  |  |
| Randomized Adversarial Training via Taylor Expansion |  |  |  |
| Backdoor Cleansing with Unlabeled Data |  |  |  |
| The Best Defense is a Good Offense: Adversarial Augmentation Against Adversarial Attacks |  |  |  |
| Ensemble-based Blackbox Attacks on Dense Prediction |  |  |  |
| Defending Against Patch-based Backdoor Attacks on Self-Supervised Learning |  |  |  |
| Adversarial Robustness via Random Projection Filters |  |  |  |
| Boundary Unlearning: Rapid Forgetting of Deep Networks via Shifting the Decision Boundary |  |  |  |
| Physical-World Optical Adversarial Attacks on 3D Face Recognition |  |  |  |
| Black-Box Sparse Adversarial Attack via Multi-Objective Optimisation CVPR Proceedings |  |  |  |
| How to Backdoor Diffusion Models? |  |  |  |
| The Resource Problem of using Linear Layer Leakage Attack in Federated Learning |  |  |  |
| Efficient Loss Function by Minimizing the Detrimental Effect of Floating-Point Errors on Gradient-based Attacks |  |  |  |
| Detecting Backdoors in Pre-trained Encoders |  |  |  |
| Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders |  |  |  |
| CFA: Class-Wise Calibrated Fair Adversarial Training |  |  |  |
| Towards Transferable Targeted Adversarial Examples |  |  |  |
| Hierarchical Fine-grained Image Forgery Detection and Localization |  |  |  |
| RIATIG: Reliable and Imperceptible Adversarial Text-to-Image Generation with Natural Prompts |  |  |  |
| SlowLiDAR: Increasing the Latency of LiDAR-based Detection using Adversarial Examples |  |  |  |
| Progressive Backdoor Erasing via Connecting Backdoor and Adversarial Attacks |  |  |  |
| Improving the Transferability of Adversarial Samples by Path-Augmented Method |  |  |  |
| Boosting Accuracy and Robustness of Student Models via Adaptive Adversarial Distillation |  |  |  |
| StyLess: Boosting the Transferability of Adversarial Examples |  |  |  |
| Introducing Competition to Boost the Transferability of Targeted Adversarial Examples through Clean Feature Mixup |  |  |  |
| Transferable Adversarial Attacks on Vision Transformers with Token Gradient Regularization |  |  |  |
| Jedi: Entropy-based Localization and Removal of Adversarial Patches |  |  |  |
| Seasoning Model Soups for Robustness to Adversarial and Natural Distribution Shifts |  |  |  |
| CUDA: Convolution-based Unlearnable Datasets |  |  |  |
| Demystifying Causal Features on Adversarial Examples and Causal Inoculation for Robust Network by Adversarial Instrumental Variable Regression |  |  |  |
| Generalist: Decoupling Natural and Robust Generalization |  |  |  |
| The Dark Side of Dynamic Routing Neural Networks: Towards Efficiency Backdoor Injection |  |  |  |
| Revisiting Residual Networks for Adversarial Robustness |  |  |  |
| Detecting Backdoors During the Inference Stage based on Corruption Robustness Consistency |  |  |  |
| Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets |  |  |  |
