# CVPR-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/scene-analysis-and-understanding.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/efficient-and-scalable-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Adversarial Attack and Defense

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| TWINS: A Fine-Tuning Framework for Improved Transferability of Adversarial Robustness and Generalization | [![GitHub](https://img.shields.io/github/stars/ziquanliu/CVPR2023-TWINS)](https://github.com/ziquanliu/CVPR2023-TWINS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_TWINS_A_Fine-Tuning_Framework_for_Improved_Transferability_of_Adversarial_Robustness_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11135-b31b1b.svg)](http://arxiv.org/abs/2303.11135) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wI0KfALYIeI) |
| Sibling-Attack: Rethinking Transferable Adversarial Attacks Against Face Recognition | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Sibling-Attack_Rethinking_Transferable_Adversarial_Attacks_Against_Face_Recognition_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12512-b31b1b.svg)](http://arxiv.org/abs/2303.12512) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=a3f2_7S2uWA) |
| T-SEA: Transfer-based Self-Ensemble Attack on Object Detection | [![GitHub](https://img.shields.io/github/stars/VDIGPKU/T-SEA)](https://github.com/VDIGPKU/T-SEA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_T-SEA_Transfer-Based_Self-Ensemble_Attack_on_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09773-b31b1b.svg)](http://arxiv.org/abs/2211.09773) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1rkwIvv1KJ0) |
| The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for Improving Adversarial Training | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_The_Enemy_of_My_Enemy_Is_My_Friend_Exploring_Inverse_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.00525-b31b1b.svg)](http://arxiv.org/abs/2211.00525) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rNoto-p2k0o) |
| Trade-Off between Robustness and Accuracy of Vision Transformers | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Trade-Off_Between_Robustness_and_Accuracy_of_Vision_Transformers_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Physically_Realizable_Natural-Looking_Clothing_Textures_Evade_Person_Detectors_via_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.01778-b31b1b.svg)](http://arxiv.org/abs/2307.01778) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jUif0yYeSb0) |
| Proximal Splitting Adversarial Attack for Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/jeromerony/alma_prox_segmentation)](https://github.com/jeromerony/alma_prox_segmentation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rony_Proximal_Splitting_Adversarial_Attack_for_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.07179-b31b1b.svg)](http://arxiv.org/abs/2206.07179) | :heavy_minus_sign: |
| Feature Separation and Recalibration for Adversarial Robustness | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sgvr.kaist.ac.kr/~wjkim/FSR/) <br /> [![GitHub](https://img.shields.io/github/stars/wkim97/FSR)](https://github.com/wkim97/FSR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Feature_Separation_and_Recalibration_for_Adversarial_Robustness_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13846-b31b1b.svg)](http://arxiv.org/abs/2303.13846) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PcnGZ0JYyNQ) |
| Enhancing the Self-Universality for Transferable Targeted Attacks | [![GitHub](https://img.shields.io/github/stars/zhipeng-wei/Self-Universality)](https://github.com/zhipeng-wei/Self-Universality) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Enhancing_the_Self-Universality_for_Transferable_Targeted_Attacks_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.03716-b31b1b.svg)](http://arxiv.org/abs/2209.03716) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-JFDxqcTM3A) |
| Backdoor Defense via Adaptively Splitting Poisoned Dataset | [![GitHub](https://img.shields.io/github/stars/KuofengGao/ASD)](https://github.com/KuofengGao/ASD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Backdoor_Defense_via_Adaptively_Splitting_Poisoned_Dataset_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12993-b31b1b.svg)](http://arxiv.org/abs/2303.12993) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s_r7SLduKVY) |
| Dynamic Generative Targeted Attacks with Pattern Injection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Dynamic_Generative_Targeted_Attacks_With_Pattern_Injection_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L37AqVQCpVc) |
| Exploring the Relationship between Architectural Design and Adversarially Robust Generalization |  |  |  |
| Discrete Point-Wise Attack Is Not Enough: Generalized Manifold Adversarial Attack for Face Recognition |  |  |  |
| Towards Benchmarking and Assessing Visual Naturalness of Physical World Adversarial Attacks |  |  |  |
| MaLP: Manipulation Localization using a Proactive Scheme |  |  |  |
| TrojDiff: Trojan Attacks on Diffusion Models with Diverse Targets |  |  |  |
| Minimizing Maximum Model Discrepancy for Transferable Black-Box Targeted Attacks |  |  |  |
| Improving Robust Generalization by Direct PAC-Bayesian Bound Minimization |  |  |  |
| AGAIN: Adversarial Training with Attribution Span Enlargement and Hybrid Feature Fusion |  |  |  |
| Backdoor Defense via Deconfounded Representation Learning |  |  |  |
| Adversarially Robust Neural Architecture Search for Graph Neural Networks |  |  |  |
| PointCert: Point Cloud Classification with Deterministic Certified Robustness Guarantees |  |  |  |
| Towards Compositional Adversarial Robustness: Generalizing Adversarial Training to Composite Semantic Perturbations |  |  |  |
| Physically Adversarial Infrared Patches with Learnable Shapes and Locations |  |  |  |
| Color Backdoor: A Robust Poisoning Attack in Color Space |  |  |  |
| Towards Effective Adversarial Textured 3D Meshes on Physical Face Recognition |  |  |  |
| Turning Strengths into Weaknesses: A Certified Robustness Inspired Attack Framework Against Graph Neural Networks |  |  |  |
| Randomized Adversarial Training via Taylor Expansion |  |  |  |
| Backdoor Cleansing with Unlabeled Data |  |  |  |
| The Best Defense is a Good Offense: Adversarial Augmentation Against Adversarial Attacks |  |  |  |
| Ensemble-based Blackbox Attacks on Dense Prediction |  |  |  |
| Defending Against Patch-based Backdoor Attacks on Self-Supervised Learning |  |  |  |
| Adversarial Robustness via Random Projection Filters |  |  |  |
| Boundary Unlearning: Rapid Forgetting of Deep Networks via Shifting the Decision Boundary |  |  |  |
| Physical-World Optical Adversarial Attacks on 3D Face Recognition |  |  |  |
| Black-Box Sparse Adversarial Attack via Multi-Objective Optimisation CVPR Proceedings |  |  |  |
| How to Backdoor Diffusion Models? |  |  |  |
| The Resource Problem of using Linear Layer Leakage Attack in Federated Learning |  |  |  |
| Efficient Loss Function by Minimizing the Detrimental Effect of Floating-Point Errors on Gradient-based Attacks |  |  |  |
| Detecting Backdoors in Pre-trained Encoders |  |  |  |
| Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders |  |  |  |
| CFA: Class-Wise Calibrated Fair Adversarial Training |  |  |  |
| Towards Transferable Targeted Adversarial Examples |  |  |  |
| Hierarchical Fine-grained Image Forgery Detection and Localization |  |  |  |
| RIATIG: Reliable and Imperceptible Adversarial Text-to-Image Generation with Natural Prompts |  |  |  |
| SlowLiDAR: Increasing the Latency of LiDAR-based Detection using Adversarial Examples |  |  |  |
| Progressive Backdoor Erasing via Connecting Backdoor and Adversarial Attacks |  |  |  |
| Improving the Transferability of Adversarial Samples by Path-Augmented Method |  |  |  |
| Boosting Accuracy and Robustness of Student Models via Adaptive Adversarial Distillation |  |  |  |
| StyLess: Boosting the Transferability of Adversarial Examples |  |  |  |
| Introducing Competition to Boost the Transferability of Targeted Adversarial Examples through Clean Feature Mixup |  |  |  |
| Transferable Adversarial Attacks on Vision Transformers with Token Gradient Regularization |  |  |  |
| Jedi: Entropy-based Localization and Removal of Adversarial Patches |  |  |  |
| Seasoning Model Soups for Robustness to Adversarial and Natural Distribution Shifts |  |  |  |
| CUDA: Convolution-based Unlearnable Datasets |  |  |  |
| Demystifying Causal Features on Adversarial Examples and Causal Inoculation for Robust Network by Adversarial Instrumental Variable Regression |  |  |  |
| Generalist: Decoupling Natural and Robust Generalization |  |  |  |
| The Dark Side of Dynamic Routing Neural Networks: Towards Efficiency Backdoor Injection |  |  |  |
| Revisiting Residual Networks for Adversarial Robustness |  |  |  |
| Detecting Backdoors During the Inference Stage based on Corruption Robustness Consistency |  |  |  |
| Cooperation or Competition: Avoiding Player Domination for Multi-Target Robustness via Adaptive Budgets |  |  |  |
