# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/vision-applications-and-systems.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/robotics.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
  </a>
</div>

## Vision and Graphics

![Section Papers](https://img.shields.io/badge/Section%20Papers-32-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-28-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-22-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-27-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| NeUDF: Leaning Neural Unsigned Distance Fields with Volume Rendering | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://geometrylearning.com/neudf/) <br /> [![GitHub](https://img.shields.io/github/stars/IGLICT/NeUDF?style=flat)](https://github.com/IGLICT/NeUDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_NeUDF_Leaning_Neural_Unsigned_Distance_Fields_With_Volume_Rendering_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10080-b31b1b.svg)](http://arxiv.org/abs/2304.10080) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4GPjRm7PX9I) |
| <i>RaBit</i>: Pa<i>ra</i>metric Modeling of 3D <i>Bi</i>ped Car<i>t</i>oon Characters with a Topological-Consistent Dataset | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://gaplab.cuhk.edu.cn/projects/RaBit/) <br /> [![GitHub](https://img.shields.io/github/stars/zhongjinluo/RaBit?style=flat)](https://github.com/zhongjinluo/RaBit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_RaBit_Parametric_Modeling_of_3D_Biped_Cartoon_Characters_With_a_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12564-b31b1b.svg)](http://arxiv.org/abs/2303.12564) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sxQWx-6e4hA) |
| DualVector: Unsupervised Vector Font Synthesis with Dual-Part Representation | [![GitHub](https://img.shields.io/github/stars/thuliu-yt16/dualvector?style=flat)](https://github.com/thuliu-yt16/dualvector) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_DualVector_Unsupervised_Vector_Font_Synthesis_With_Dual-Part_Representation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10462-b31b1b.svg)](http://arxiv.org/abs/2305.10462) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=13fpqGBg0-A) |
| Magic3D: High-Resolution Text-to-3D Content Creation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/dir/magic3d/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Magic3D_High-Resolution_Text-to-3D_Content_Creation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10440-b31b1b.svg)](http://arxiv.org/abs/2211.10440) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=F1ZNshgvWOA) |
| Pointersect: Neural Rendering with Cloud-Ray Intersection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chang_Pointersect_Neural_Rendering_With_Cloud-Ray_Intersection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12390-b31b1b.svg)](http://arxiv.org/abs/2304.12390) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7gbhc7ImCps) |
| Humans as Light Bulbs: 3D Human Reconstruction from Thermal Reflection | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://thermal.cs.columbia.edu/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Humans_As_Light_Bulbs_3D_Human_Reconstruction_From_Thermal_Reflection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.01652-b31b1b.svg)](http://arxiv.org/abs/2305.01652) | :heavy_minus_sign: |
| ABLE-NeRF: Attention-based Rendering with Learnable Embeddings for Neural Radiance Field | [![GitHub](https://img.shields.io/github/stars/TangZJ/able-nerf?style=flat)](https://github.com/TangZJ/able-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_ABLE-NeRF_Attention-Based_Rendering_With_Learnable_Embeddings_for_Neural_Radiance_Field_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13817-b31b1b.svg)](http://arxiv.org/abs/2303.13817) | :heavy_minus_sign: |
| JAWS: Just A Wild Shot for Cinematic Transfer in Neural Radiance Fields | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.lix.polytechnique.fr/vista/projects/2023_cvpr_wang/) <br /> [![GitHub](https://img.shields.io/github/stars/robincourant/jaws?style=flat)](https://github.com/robincourant/jaws) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_JAWS_Just_a_Wild_Shot_for_Cinematic_Transfer_in_Neural_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15427-b31b1b.svg)](http://arxiv.org/abs/2303.15427) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=d0XtVqa5bdY) |
| LayoutDM: Discrete Diffusion Model for Controllable Layout Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cyberagentailab.github.io/layout-dm/) <br /> [![GitHub](https://img.shields.io/github/stars/CyberAgentAILab/layout-dm?style=flat)](https://github.com/CyberAgentAILab/layout-dm) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Inoue_LayoutDM_Discrete_Diffusion_Model_for_Controllable_Layout_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08137-b31b1b.svg)](http://arxiv.org/abs/2303.08137) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bJOpJnvhw3s) |
| LightPainter: Interactive Portrait Relighting with Freehand Scribble | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mei_LightPainter_Interactive_Portrait_Relighting_With_Freehand_Scribble_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12950-b31b1b.svg)](http://arxiv.org/abs/2303.12950) | :heavy_minus_sign: |
| RODIN: A Generative Model for Sculpting 3D Digital Avatars using Diffusion | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://3d-avatar-diffusion.microsoft.com/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_RODIN_A_Generative_Model_for_Sculpting_3D_Digital_Avatars_Using_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06135-b31b1b.svg)](http://arxiv.org/abs/2212.06135) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KW_EXWMjS4c) |
| NerVE: Neural Volumetric Edges for Parametric Curve Extraction from Point Cloud | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dongdu3.github.io/projects/2023/NerVE/) <br /> [![GitHub](https://img.shields.io/github/stars/uhzoaix/NerVE?style=flat)](https://github.com/uhzoaix/NerVE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_NerVE_Neural_Volumetric_Edges_for_Parametric_Curve_Extraction_From_Point_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16465-b31b1b.svg)](http://arxiv.org/abs/2303.16465) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tAwC23uybTM) |
| CAMS: CAnonicalized Manipulation Spaces for Category-Level Functional Hand-Object Manipulation Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cams-hoi.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/cams-hoi/CAMS?style=flat)](https://github.com/cams-hoi/CAMS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_CAMS_CAnonicalized_Manipulation_Spaces_for_Category-Level_Functional_Hand-Object_Manipulation_Synthesis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15469-b31b1b.svg)](http://arxiv.org/abs/2303.15469) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KEfhwICagcM) |
| VecFontSDF: Learning to Reconstruct and Synthesize High-Quality Vector Fonts via Signed Distance Functions | [![GitHub](https://img.shields.io/github/stars/ymxbj/VecFontSDF?style=flat)](https://github.com/ymxbj/VecFontSDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xia_VecFontSDF_Learning_To_Reconstruct_and_Synthesize_High-Quality_Vector_Fonts_via_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12675-b31b1b.svg)](http://arxiv.org/abs/2303.12675) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HyOubSJMyf0) |
| Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process | [![GitHub](https://img.shields.io/github/stars/colorful-liyu/3DQD?style=flat)](https://github.com/colorful-liyu/3DQD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Generalized_Deep_3D_Shape_Prior_via_Part-Discretized_Diffusion_Process_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10406-b31b1b.svg)](https://arxiv.org/abs/2303.10406) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3NEM4Sjlb9E) |
| Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures | [![GitHub](https://img.shields.io/github/stars/eladrich/latent-nerf?style=flat)](https://github.com/eladrich/latent-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Metzer_Latent-NeRF_for_Shape-Guided_Generation_of_3D_Shapes_and_Textures_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.07600-b31b1b.svg)](https://arxiv.org/abs/2211.07600) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WwOXzWvGNdc) |
| Parts2Words: Learning Joint Embedding of Point Clouds and Texts by Bidirectional Matching between Parts and Words | [![GitHub](https://img.shields.io/github/stars/JLUtangchuan/Parts2Words?style=flat)](https://github.com/JLUtangchuan/Parts2Words) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Parts2Words_Learning_Joint_Embedding_of_Point_Clouds_and_Texts_by_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2107.01872-b31b1b.svg)](https://arxiv.org/abs/2107.01872) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cZ76xXEY6mY) |
| Multiplicative Fourier Level of Detail <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)  | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dou_Multiplicative_Fourier_Level_of_Detail_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8DakAzpxecI) |
| SECAD-Net: Self-Supervised CAD Reconstruction by Learning Sketch-Extrude Operations | [![GitHub](https://img.shields.io/github/stars/BunnySoCrazy/SECAD-Net?style=flat)](https://github.com/BunnySoCrazy/SECAD-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_SECAD-Net_Self-Supervised_CAD_Reconstruction_by_Learning_Sketch-Extrude_Operations_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10613-b31b1b.svg)](https://arxiv.org/abs/2303.10613) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=953PCsY5L98) |
| Transfer4D: A Framework for Frugal Motion Capture and Deformation Transfer | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://transfer4d.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Maheshwari_Transfer4D_A_Framework_for_Frugal_Motion_Capture_and_Deformation_Transfer_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=a1-cUxHwvo8) |
| Plateau-Reduced Differentiable Path Tracing | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mfischer-ucl.github.io/prdpt/) <br /> [![GitHub](https://img.shields.io/github/stars/mfischer-ucl/prdpt?style=flat)](https://github.com/mfischer-ucl/prdpt) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fischer_Plateau-Reduced_Differentiable_Path_Tracing_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.17263-b31b1b.svg)](https://arxiv.org/abs/2211.17263) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KJlJbqJ4wwY) |
| 3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://threedle.github.io/3DHighlighter/) <br /> [![GitHub](https://img.shields.io/github/stars/threedle/3DHighlighter?style=flat)](https://github.com/threedle/3DHighlighter) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Decatur_3D_Highlighter_Localizing_Regions_on_3D_Shapes_via_Text_Descriptions_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.11263-b31b1b.svg)](https://arxiv.org/abs/2212.11263) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OKPySDDCdd0) |
| Differentiable Shadow Mapping for Efficient Inverse Graphics | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mworchel.github.io/differentiable-shadow-mapping/) <br /> [![GitHub](https://img.shields.io/github/stars/mworchel/differentiable-shadow-mapping?style=flat)](https://github.com/mworchel/differentiable-shadow-mapping) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Worchel_Differentiable_Shadow_Mapping_for_Efficient_Inverse_Graphics_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10896-b31b1b.svg)](https://arxiv.org/abs/2308.10896) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=474Ix9ASbNA) |
| Inverse Rendering of Translucent Objects using Physical and Neural Renderers | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ligoudaner377.github.io/homo_translucent/) <br /> [![GitHub](https://img.shields.io/github/stars/ligoudaner377/homo_translucent?style=flat)](https://github.com/ligoudaner377/homo_translucent) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Inverse_Rendering_of_Translucent_Objects_Using_Physical_and_Neural_Renderers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.08336-b31b1b.svg)](https://arxiv.org/abs/2305.08336) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rWZLU_YqacE) |
| MAIR: Multi-View Attention Inverse Rendering with 3D Spatially-Varying Lighting Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://bring728.github.io/mair.project/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_MAIR_Multi-View_Attention_Inverse_Rendering_With_3D_Spatially-Varying_Lighting_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12368-b31b1b.svg)](https://arxiv.org/abs/2303.12368) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=58ql5xJfN3M) |
| Neural Fourier Filter Bank | [![GitHub](https://img.shields.io/github/stars/ubc-vision/NFFB?style=flat)](https://github.com/ubc-vision/NFFB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Neural_Fourier_Filter_Bank_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01735-b31b1b.svg)](https://arxiv.org/abs/2212.01735) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uO3MxxZY6XI) |
| UMat: Uncertainty-Aware Single Image High Resolution Material Capture | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://carlosrodriguezpardo.es/projects/UMat/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rodriguez-Pardo_UMat_Uncertainty-Aware_Single_Image_High_Resolution_Material_Capture_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16312-b31b1b.svg)](https://arxiv.org/abs/2305.16312) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ULbGvHFrJx4) |
| Neural Congealing: Aligning Images to a Joint Semantic Atlas | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://neural-congealing.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/dolev104/neural_congealing?style=flat)](https://github.com/dolev104/neural_congealing) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ofri-Amar_Neural_Congealing_Aligning_Images_to_a_Joint_Semantic_Atlas_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.03956-b31b1b.svg)](https://arxiv.org/abs/2302.03956) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=dlzkVB3680Q) |
| PlenVDB: Memory Efficient VDB-based Radiance Fields for Fast Training and Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://plenvdb.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/wolfball/PlenVDB?style=flat)](https://github.com/wolfball/PlenVDB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_PlenVDB_Memory_Efficient_VDB-Based_Radiance_Fields_for_Fast_Training_and_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=y0DNT0Hahic) |
| VectorFloorSeg: Two-Stream Graph Attention Network for Vectorized Roughcast Floorplan Segmentation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/DrZiji/VecFloorSeg?style=flat)](https://github.com/DrZiji/VecFloorSeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_VectorFloorSeg_Two-Stream_Graph_Attention_Network_for_Vectorized_Roughcast_Floorplan_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wkZoF5EBoiY) |
| Learning to Render Novel Views from Wide-Baseline Stereo Pairs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yilundu.github.io/wide_baseline/) <br /> [![GitHub](https://img.shields.io/github/stars/yilundu/cross_attention_renderer?style=flat)](https://github.com/yilundu/cross_attention_renderer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Learning_To_Render_Novel_Views_From_Wide-Baseline_Stereo_Pairs_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08463-b31b1b.svg)](https://arxiv.org/abs/2304.08463) | :heavy_minus_sign: |
| CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ivl.cs.brown.edu/research/clip-sculptor.html) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sanghi_CLIP-Sculptor_Zero-Shot_Generation_of_High-Fidelity_and_Diverse_Shapes_From_Natural_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.01427-b31b1b.svg)](https://arxiv.org/abs/2211.01427) | :heavy_minus_sign: |
