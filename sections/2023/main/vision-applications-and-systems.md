# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>New collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
                <img src="http://img.shields.io/badge/CVPR-2024-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/video-low-level-analysis-motion-and-tracking.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/vision-and-graphics.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
  </a>
</div>

## Vision Applications and Systems

![Section Papers](https://img.shields.io/badge/Section%20Papers-35-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-27-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-26-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-29-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Context De-confounded Emotion Recognition | [![GitHub](https://img.shields.io/github/stars/ydk122024/CCIM?style=flat)](https://github.com/ydk122024/CCIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Context_De-Confounded_Emotion_Recognition_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11921-b31b1b.svg)](http://arxiv.org/abs/2303.11921) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TGnI4U504Vg) |
| Intrinsic Physical Concepts Discovery with Object-Centric Predictive Models | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Intrinsic_Physical_Concepts_Discovery_With_Object-Centric_Predictive_Models_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01869-b31b1b.svg)](http://arxiv.org/abs/2303.01869) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=N3_YAcRPf38) |
| Automatic High Resolution Wire Segmentation and Removal | [![GitHub](https://img.shields.io/github/stars/adobe-research/auto-wire-removal?style=flat)](https://github.com/adobe-research/auto-wire-removal) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chiu_Automatic_High_Resolution_Wire_Segmentation_and_Removal_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00221-b31b1b.svg)](http://arxiv.org/abs/2304.00221) | :heavy_minus_sign: |
| Class Balanced Adaptive Pseudo Labeling for Federated Semi-Supervised Learning | [![GitHub](https://img.shields.io/github/stars/minglllli/CBAFed?style=flat)](https://github.com/minglllli/CBAFed) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Class_Balanced_Adaptive_Pseudo_Labeling_for_Federated_Semi-Supervised_Learning_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f8Ekx-cnNsA) |
| Weakly Supervised Video Emotion Detection and Prediction via Cross-Modal Temporal Erasing Network | [![GitHub](https://img.shields.io/github/stars/nku-zhichengzhang/CTEN?style=flat)](https://github.com/nku-zhichengzhang/CTEN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Weakly_Supervised_Video_Emotion_Detection_and_Prediction_via_Cross-Modal_Temporal_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ebD_xNQLuCY) |
| Probing Sentiment-Oriented Pre-Training Inspired by Human Sentiment Perception Mechanism | [![GitHub](https://img.shields.io/github/stars/tinglyfeng/sentiment_pretraining?style=flat)](https://github.com/tinglyfeng/sentiment_pretraining) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Probing_Sentiment-Oriented_Pre-Training_Inspired_by_Human_Sentiment_Perception_Mechanism_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wyDbpXxCbKs) |
| DIP: Dual Incongruity Perceiving Network for Sarcasm Detection | [![GitHub](https://img.shields.io/github/stars/downdric/MSD?style=flat)](https://github.com/downdric/MSD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_DIP_Dual_Incongruity_Perceiving_Network_for_Sarcasm_Detection_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AM94eSC-_zA) |
| Adaptive Human Matting for Dynamic Videos | [![GitHub](https://img.shields.io/github/stars/microsoft/AdaM?style=flat)](https://github.com/microsoft/AdaM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Adaptive_Human_Matting_for_Dynamic_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06018-b31b1b.svg)](http://arxiv.org/abs/2304.06018) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0yL6mQNUDUs) |
| LayoutFormer++: Conditional Graphic Layout Generation via Constraint Serialization and Decoding Space Restriction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_LayoutFormer_Conditional_Graphic_Layout_Generation_via_Constraint_Serialization_and_Decoding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.08037-b31b1b.svg)](http://arxiv.org/abs/2208.08037) | :heavy_minus_sign: |
| Prototypical Residual Networks for Anomaly Detection and Localization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Prototypical_Residual_Networks_for_Anomaly_Detection_and_Localization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02031-b31b1b.svg)](http://arxiv.org/abs/2212.02031) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ugnl25vg6K8) |
| Are Binary Annotations Sufficient? Video Moment Retrieval via Hierarchical Uncertainty-based Active Learning | [![GitHub](https://img.shields.io/github/stars/renjie-liang/HUAL?style=flat)](https://github.com/renjie-liang/HUAL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Are_Binary_Annotations_Sufficient_Video_Moment_Retrieval_via_Hierarchical_Uncertainty-Based_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Affordance Grounding from Demonstration Video to Target Image | [![GitHub](https://img.shields.io/github/stars/showlab/afformer?style=flat)](https://github.com/showlab/afformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Affordance_Grounding_From_Demonstration_Video_To_Target_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14644-b31b1b.svg)](http://arxiv.org/abs/2303.14644) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ER7RtmJX8SM) |
| Natural Language-Assisted Sign Language Recognition | [![GitHub](https://img.shields.io/github/stars/FangyunWei/SLRT?style=flat)](https://github.com/FangyunWei/SLRT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zuo_Natural_Language-Assisted_Sign_Language_Recognition_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12080-b31b1b.svg)](http://arxiv.org/abs/2303.12080) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tvvT7AdxjvQ) |
| CiCo: Domain-Aware Sign Language Retrieval via Cross-Lingual Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/FangyunWei/SLRT?style=flat)](https://github.com/FangyunWei/SLRT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_CiCo_Domain-Aware_Sign_Language_Retrieval_via_Cross-Lingual_Contrastive_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12793-b31b1b.svg)](http://arxiv.org/abs/2303.12793) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G4sgfXU27Sw) |
| Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/MaskDINO?style=flat)](https://github.com/IDEA-Research/MaskDINO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Mask_DINO_Towards_a_Unified_Transformer-Based_Framework_for_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.02777-b31b1b.svg)](http://arxiv.org/abs/2206.02777) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ankel5cLZP4) |
| Collaborative Noisy Label Cleaner: Learning Scene-Aware Trailers for Multi-Modal Highlight Detection in Movies | [![GitHub](https://img.shields.io/github/stars/TencentYoutuResearch/HighlightDetection-CLC?style=flat)](https://github.com/TencentYoutuResearch/HighlightDetection-CLC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gan_Collaborative_Noisy_Label_Cleaner_Learning_Scene-Aware_Trailers_for_Multi-Modal_Highlight_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14768-b31b1b.svg)](http://arxiv.org/abs/2303.14768) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Pr2A0JmyKVc) |
| Open-Set Fine-grained Retrieval via Prompting Vision-Language Evaluator | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Open-Set_Fine-Grained_Retrieval_via_Prompting_Vision-Language_Evaluator_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=a81Ws3_0Hag) |
| Observation-Centric SORT: Rethinking SORT for Robust Multi-Object Tracking | [![GitHub](https://img.shields.io/github/stars/noahcao/OC_SORT?style=flat)](https://github.com/noahcao/OC_SORT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Observation-Centric_SORT_Rethinking_SORT_for_Robust_Multi-Object_Tracking_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.14360-b31b1b.svg)](http://arxiv.org/abs/2203.14360) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rRE8xv4pPus) |
| Visual Exemplar Driven Task-Prompting for Unified Perception in Autonomous Driving | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liang_Visual_Exemplar_Driven_Task-Prompting_for_Unified_Perception_in_Autonomous_Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01788-b31b1b.svg)](http://arxiv.org/abs/2303.01788) | :heavy_minus_sign: |
| Exploiting Unlabelled Photos for Stronger Fine-grained SBIR | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aneeshan95.github.io/Sketch_PVT/) <br /> [![GitHub](https://img.shields.io/github/stars/aneeshan95/Sketch_PVT?style=flat)](https://github.com/aneeshan95/Sketch_PVT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sain_Exploiting_Unlabelled_Photos_for_Stronger_Fine-Grained_SBIR_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13779-b31b1b.svg)](http://arxiv.org/abs/2303.13779) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LyM-Mw9yPHE) |
| What Can Human Sketches Do for Object Detection? <br /> ![CVPR - Award](https://img.shields.io/badge/CVPR-Award-294A7C) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.pinakinathc.me/sketch-detect/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chowdhury_What_Can_Human_Sketches_Do_for_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15149-b31b1b.svg)](http://arxiv.org/abs/2303.15149) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MglzpOCC-3c) |
| Dynamic Conceptional Contrastive Learning for Generalized Category Discovery | [![GitHub](https://img.shields.io/github/stars/TPCD/DCCL?style=flat)](https://github.com/TPCD/DCCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pu_Dynamic_Conceptional_Contrastive_Learning_for_Generalized_Category_Discovery_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17393-b31b1b.svg)](http://arxiv.org/abs/2303.17393) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G6ZdySsOri4) |
| Balanced Energy Regularization Loss for Out-of-Distribution Detection | [![GitHub](https://img.shields.io/github/stars/hyunjunChhoi/Balanced_Energy?style=flat)](https://github.com/hyunjunChhoi/Balanced_Energy) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_Balanced_Energy_Regularization_Loss_for_Out-of-Distribution_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.10485-b31b1b.svg)](http://arxiv.org/abs/2306.10485) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=l53KOKb1Ovg) |
| Lite DETR: An Interleaved Multi-Scale Encoder for Efficient DETR | [![GitHub](https://img.shields.io/github/stars/IDEA-Research/Lite-DETR?style=flat)](https://github.com/IDEA-Research/Lite-DETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Lite_DETR_An_Interleaved_Multi-Scale_Encoder_for_Efficient_DETR_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07335-b31b1b.svg)](http://arxiv.org/abs/2303.07335) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LSBkpIY8CV4) |
| CLIP for All Things Zero-Shot Sketch-based Image Retrieval, Fine-grained or Not | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aneeshan95.github.io/Sketch_LVM/) <br /> [![GitHub](https://img.shields.io/github/stars/aneeshan95/Sketch_LVM?style=flat)](https://github.com/aneeshan95/Sketch_LVM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sain_CLIP_for_All_Things_Zero-Shot_Sketch-Based_Image_Retrieval_Fine-Grained_or_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13440-b31b1b.svg)](http://arxiv.org/abs/2303.13440) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ImcQFsS1SfE) |
| PosterLayout: A New Benchmark and Approach for Content-Aware Visual-Textual Presentation Layout | [![GitHub](https://img.shields.io/github/stars/PKU-ICST-MIPL/PosterLayout-CVPR2023?style=flat)](https://github.com/PKU-ICST-MIPL/PosterLayout-CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hsu_PosterLayout_A_New_Benchmark_and_Approach_for_Content-Aware_Visual-Textual_Presentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15937-b31b1b.svg)](http://arxiv.org/abs/2303.15937) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WyfkbmEPh1s) |
| Re-Thinking Federated Active Learning based on Inter-Class Diversity | [![GitHub](https://img.shields.io/github/stars/raymin0223/LoGo?style=flat)](https://github.com/raymin0223/LoGo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Re-Thinking_Federated_Active_Learning_Based_on_Inter-Class_Diversity_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12317-b31b1b.svg)](http://arxiv.org/abs/2303.12317) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gAoKIAE-a9o) |
| Consistent-Teacher: Towards Reducing Inconsistent Pseudo-Targets in Semi-Supervised Object Detection <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://adamdad.github.io/consistentteacher/) <br /> [![GitHub](https://img.shields.io/github/stars/Adamdad/ConsistentTeacher?style=flat)](https://github.com/Adamdad/ConsistentTeacher) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Consistent-Teacher_Towards_Reducing_Inconsistent_Pseudo-Targets_in_Semi-Supervised_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.01589-b31b1b.svg)](http://arxiv.org/abs/2209.01589) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZCyM6ygGdo4) |
| Cloud-Device Collaborative Adaptation to Continual Changing Environments in the Real-World | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Cloud-Device_Collaborative_Adaptation_to_Continual_Changing_Environments_in_the_Real-World_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00972-b31b1b.svg)](http://arxiv.org/abs/2212.00972) | :heavy_minus_sign: |
| Bridging Precision and Confidence: A Train-Time Loss for Calibrating Object Detection | [![GitHub](https://img.shields.io/github/stars/akhtarvision/bpc_calibration?style=flat)](https://github.com/akhtarvision/bpc_calibration) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Munir_Bridging_Precision_and_Confidence_A_Train-Time_Loss_for_Calibrating_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14404-b31b1b.svg)](http://arxiv.org/abs/2303.14404) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=qsY2m0WOoiE) |
| AccelIR: Task-Aware Image Compression for Accelerating Neural Restoration | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_AccelIR_Task-Aware_Image_Compression_for_Accelerating_Neural_Restoration_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Multiclass Confidence and Localization Calibration for Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://bimsarapathiraja.github.io/mccl-project-page/) <br /> [![GitHub](https://img.shields.io/github/stars/bimsarapathiraja/MCCL?style=flat)](https://github.com/bimsarapathiraja/MCCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pathiraja_Multiclass_Confidence_and_Localization_Calibration_for_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.08271-b31b1b.svg)](http://arxiv.org/abs/2306.08271) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WGaeUSxMS3E) |
| Auto-CARD: Efficient and Robust Codec Avatar Driving for Real-Time Mobile Telepresence | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_Auto-CARD_Efficient_and_Robust_Codec_Avatar_Driving_for_Real-Time_Mobile_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11835-b31b1b.svg)](http://arxiv.org/abs/2304.11835) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XJP5G4GqjzE) |
| Deep Random Projector: Accelerated Deep Image Prior | [![GitHub](https://img.shields.io/github/stars/sun-umn/Deep-Random-Projector?style=flat)](https://github.com/sun-umn/Deep-Random-Projector) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Deep_Random_Projector_Accelerated_Deep_Image_Prior_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=agXKHhjl1J4) |
| SIEDOB: Semantic Image Editing by Disentangling Object and Background <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/WuyangLuo/SIEDOB?style=flat)](https://github.com/WuyangLuo/SIEDOB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_SIEDOB_Semantic_Image_Editing_by_Disentangling_Object_and_Background_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13062-b31b1b.svg)](http://arxiv.org/abs/2303.13062) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=o56SR0m5MUA) |
