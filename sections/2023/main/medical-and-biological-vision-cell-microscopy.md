# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>New collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
                <img src="http://img.shields.io/badge/CVPR-2024-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/3d-from-single-images.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/video-action-and-event-understanding.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Medical and Biological Vision; Cell Microscopy

![Section Papers](https://img.shields.io/badge/Section%20Papers-52-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-39-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-37-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-36-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Decoupled Semantic Prototypes Enable Learning from Diverse Annotation Types for Semi-Weakly Segmentation in Expert-Driven Domains | [![GitHub](https://img.shields.io/github/stars/Simael/DSP?style=flat)](https://github.com/Simael/DSP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Reiss_Decoupled_Semantic_Prototypes_Enable_Learning_From_Diverse_Annotation_Types_for_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Geometric Visual Similarity Learning in 3D Medical Image Self-Supervised Pre-Training | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://x-ark.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/YutingHe-list/GVSL?style=flat)](https://github.com/YutingHe-list/GVSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Geometric_Visual_Similarity_Learning_in_3D_Medical_Image_Self-Supervised_Pre-Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00874-b31b1b.svg)](http://arxiv.org/abs/2303.00874)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vS0BhOpjErY) |
| Flexible-C<sup>m</sup> GAN: Towards Precise 3D Dose Prediction in Radiotherapy| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Flexible-Cm_GAN_Towards_Precise_3D_Dose_Prediction_in_Radiotherapy_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jGlW1uvBF7M) |
| Bidirectional Copy-Paste for Semi-Supervised Medical Image Segmentation | [![GitHub](https://img.shields.io/github/stars/DeepMed-Lab-ECNU/BCP?style=flat)](https://github.com/DeepMed-Lab-ECNU/BCP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bai_Bidirectional_Copy-Paste_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.00673-b31b1b.svg)](http://arxiv.org/abs/2305.00673) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lQ3UTN-SZLM) |
| <i>MagicNet</i>: Semi-Supervised Multi-Organ Segmentation via Magic-Cube Partition and Recovery | [![GitHub](https://img.shields.io/github/stars/DeepMed-Lab-ECNU/MagicNet?style=flat)](https://github.com/DeepMed-Lab-ECNU/MagicNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_MagicNet_Semi-Supervised_Multi-Organ_Segmentation_via_Magic-Cube_Partition_and_Recovery_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.14310-b31b1b.svg)](http://arxiv.org/abs/2212.14310) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=C1xiG8SS2iw) |
| Visual Language Pretrained Multiple Instance Zero-Shot Transfer for Histopathology Images | [![GitHub](https://img.shields.io/github/stars/mahmoodlab/MI-Zero?style=flat)](https://github.com/mahmoodlab/MI-Zero) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Visual_Language_Pretrained_Multiple_Instance_Zero-Shot_Transfer_for_Histopathology_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07831-b31b1b.svg)](https://arxiv.org/abs/2306.07831) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=x8Ch5wsCJRw) |
| Label-Free Liver Tumor Segmentation | [![GitHub](https://img.shields.io/github/stars/MrGiovanni/SyntheticTumors?style=flat)](https://github.com/MrGiovanni/SyntheticTumors) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Label-Free_Liver_Tumor_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14869-b31b1b.svg)](http://arxiv.org/abs/2303.14869) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DhZzAp7gxxw) |
| Devil is in the Queries: Advancing Mask Transformers for Real-World Medical Image Segmentation and Out-of-Distribution Localization <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) |:heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yuan_Devil_Is_in_the_Queries_Advancing_Mask_Transformers_for_Real-World_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00212-b31b1b.svg)](http://arxiv.org/abs/2304.00212) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xzNxXKlYHYA) |
| DoNet: Deep De-Overlapping Network for Cytology Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/DeepDoNet/DoNet?style=flat)](https://github.com/DeepDoNet/DoNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_DoNet_Deep_De-Overlapping_Network_for_Cytology_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14373-b31b1b.svg)](http://arxiv.org/abs/2303.14373) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bEW4kUmClCI) |
| SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection | [![GitHub](https://img.shields.io/github/stars/tiangexiang/SQUID?style=flat)](https://github.com/tiangexiang/SQUID) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiang_SQUID_Deep_Feature_In-Painting_for_Unsupervised_Anomaly_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2111.13495-b31b1b.svg)](http://arxiv.org/abs/2111.13495) | :heavy_minus_sign: |
| Learning Federated Visual Prompt in Null Space for MRI Reconstruction | [![GitHub](https://img.shields.io/github/stars/chunmeifeng/FedPR?style=flat)](https://github.com/chunmeifeng/FedPR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Learning_Federated_Visual_Prompt_in_Null_Space_for_MRI_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16181-b31b1b.svg)](http://arxiv.org/abs/2303.16181) | :heavy_minus_sign: |
| Pseudo-Label Guided Contrastive Learning for Semi-Supervised Medical Image Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Basak_Pseudo-Label_Guided_Contrastive_Learning_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Image Quality-Aware Diagnosis via Meta-Knowledge Co-Embedding | [![GitHub](https://img.shields.io/github/stars/chehx/MKCNet?style=flat)](https://github.com/chehx/MKCNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Che_Image_Quality-Aware_Diagnosis_via_Meta-Knowledge_Co-Embedding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15038-b31b1b.svg)](http://arxiv.org/abs/2303.15038) | :heavy_minus_sign: |
| Iterative Next Boundary Detection for Instance Segmentation of Tree Rings in Microscopy Images of Shrub Cross Sections | [![GitHub](https://img.shields.io/github/stars/alexander-g/INBD?style=flat)](https://github.com/alexander-g/INBD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gillert_Iterative_Next_Boundary_Detection_for_Instance_Segmentation_of_Tree_Rings_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03022-b31b1b.svg)](http://arxiv.org/abs/2212.03022) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HciQxL2K8_E) |
| Dynamic Graph Enhanced Contrastive Learning for Chest X-Ray Report Generation | [![GitHub](https://img.shields.io/github/stars/mlii0117/DCL?style=flat)](https://github.com/mlii0117/DCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Dynamic_Graph_Enhanced_Contrastive_Learning_for_Chest_X-Ray_Report_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10323-b31b1b.svg)](https://arxiv.org/abs/2303.10323) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aBUQbYmcp-k) |
| Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mind-vis.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/zjc062/mind-vis?style=flat)](https://github.com/zjc062/mind-vis) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Seeing_Beyond_the_Brain_Conditional_Diffusion_Model_With_Sparse_Masked_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06956-b31b1b.svg)](http://arxiv.org/abs/2211.06956) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Oh7XG_hoX34) |
| Bi-Directional Feature Fusion Generative Adversarial Network for Ultra-High Resolution Pathological Image Virtual Re-Staining | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Bi-Directional_Feature_Fusion_Generative_Adversarial_Network_for_Ultra-High_Resolution_Pathological_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| KiUT: Knowledge-Injected U-Transformer for Radiology Report Generation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_KiUT_Knowledge-Injected_U-Transformer_for_Radiology_Report_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.11345-b31b1b.svg)](https://arxiv.org/abs/2306.11345) | :heavy_minus_sign: |
| Weakly Supervised Segmentation with Point Annotations for Histopathology Images via Contrast-based Variational Model | [![GitHub](https://img.shields.io/github/stars/huiqu18/WeaklySegPointAnno?style=flat)](https://github.com/huiqu18/WeaklySegPointAnno) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Weakly_Supervised_Segmentation_With_Point_Annotations_for_Histopathology_Images_via_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03572-b31b1b.svg)](http://arxiv.org/abs/2304.03572) | :heavy_minus_sign: |
| Ambiguous Medical Image Segmentation using Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aimansnigdha.github.io/cimd/) <br /> [![GitHub](https://img.shields.io/github/stars/aimansnigdha/Ambiguous-Medical-Image-Segmentation-using-Diffusion-Models?style=flat)](https://github.com/aimansnigdha/Ambiguous-Medical-Image-Segmentation-using-Diffusion-Models) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rahman_Ambiguous_Medical_Image_Segmentation_Using_Diffusion_Models_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04745-b31b1b.svg)](http://arxiv.org/abs/2304.04745) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3gVn0-IFOKs) |
| Causally-Aware Intraoperative Imputation for Overall Survival Time Prediction | [![GitHub](https://img.shields.io/github/stars/ChrisXLi/CaDAG?style=flat)](https://github.com/ChrisXLi/CaDAG) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Causally-Aware_Intraoperative_Imputation_for_Overall_Survival_Time_Prediction_CVPR_2023_paper.pdf) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SrsttIKzL84) |
| Best of Both Worlds: Multimodal Contrastive Learning with Tabular and Imaging Data | [![GitHub](https://img.shields.io/github/stars/paulhager/MMCL-Tabular-Imaging?style=flat)](https://github.com/paulhager/MMCL-Tabular-Imaging) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hager_Best_of_Both_Worlds_Multimodal_Contrastive_Learning_With_Tabular_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14080-b31b1b.svg)](http://arxiv.org/abs/2303.14080) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iHVPSMEM6WM) |
| GradICON: Approximate Diffeomorphisms via Gradient Inverse Consistency | [![GitHub](https://img.shields.io/github/stars/uncbiag/ICON?style=flat)](https://github.com/uncbiag/ICON) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_GradICON_Approximate_Diffeomorphisms_via_Gradient_Inverse_Consistency_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.05897-b31b1b.svg)](https://arxiv.org/abs/2206.05897) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bt-nAYbwcW8) |
| Fair Federated Medical Image Segmentation via Client Contribution Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/NVIDIA/NVFlare/tree/main/research/fed-ce) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Fair_Federated_Medical_Image_Segmentation_via_Client_Contribution_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16520-b31b1b.svg)](http://arxiv.org/abs/2303.16520) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zV4as47EWzg) |
| Histopathology whole Slide Image Analysis with Heterogeneous Graph Representation Learning | [![GitHub](https://img.shields.io/github/stars/HKU-MedAI/WSI-HGNN?style=flat)](https://github.com/HKU-MedAI/WSI-HGNN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chan_Histopathology_Whole_Slide_Image_Analysis_With_Heterogeneous_Graph_Representation_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.04189-b31b1b.svg)](https://arxiv.org/abs/2307.04189) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=F47ureXZ7fo) |
| Unsupervised Contour Tracking of Live Cells by Mechanical and Cycle Consistency Losses | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://junbongjang.github.io/projects/contour-tracking/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/JunbongJang/contour-tracking?style=flat)](https://github.com/JunbongJang/contour-tracking) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jang_Unsupervised_Contour_Tracking_of_Live_Cells_by_Mechanical_and_Cycle_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08364-b31b1b.svg)](http://arxiv.org/abs/2303.08364) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lA9lUx9mriM) |
| Learning to Exploit the Sequence-Specific Prior Knowledge for Image Processing Pipelines Optimization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_Learning_To_Exploit_the_Sequence-Specific_Prior_Knowledge_for_Image_Processing_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Oh-kgpe-S_Y) |
| RepMode: Learning to Re-Parameterize Diverse Experts for Subcellular Structure Prediction <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://correr-zhou.github.io/RepMode/) <br /> [![GitHub](https://img.shields.io/github/stars/Correr-Zhou/RepMode?style=flat)](https://github.com/Correr-Zhou/RepMode) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_RepMode_Learning_to_Re-Parameterize_Diverse_Experts_for_Subcellular_Structure_Prediction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10066-b31b1b.svg)](http://arxiv.org/abs/2212.10066) | :heavy_minus_sign: |
| Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_Towards_Trustable_Skin_Cancer_Diagnosis_via_Rewriting_Models_Decision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00885-b31b1b.svg)](https://arxiv.org/abs/2303.00885) | :heavy_minus_sign: |
| Task-Specific Fine-Tuning via Variational Information Bottleneck for Weakly-Supervised Pathology whole Slide Image Classification | [![GitHub](https://img.shields.io/github/stars/invoker-LL/WSI-finetuning?style=flat)](https://github.com/invoker-LL/WSI-finetuning) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Task-Specific_Fine-Tuning_via_Variational_Information_Bottleneck_for_Weakly-Supervised_Pathology_Whole_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08446-b31b1b.svg)](http://arxiv.org/abs/2303.08446) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fSLcO_Knt6Q) |
| TINC: Tree-Structured Implicit Neural Compression | [![GitHub](https://img.shields.io/github/stars/RichealYoung/TINC?style=flat)](https://github.com/RichealYoung/TINC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_TINC_Tree-Structured_Implicit_Neural_Compression_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06689-b31b1b.svg)](http://arxiv.org/abs/2211.06689) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7UZ1YOsCtrU) |
| Topology-Guided Multi-Class Cell Context Generation for Digital Pathology | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Abousamra_Topology-Guided_Multi-Class_Cell_Context_Generation_for_Digital_Pathology_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02255-b31b1b.svg)](http://arxiv.org/abs/2304.02255) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3a5Mi6W5Vcw) |
| Directional Connectivity-based Segmentation of Medical Images | [![GitHub](https://img.shields.io/github/stars/Zyun-Y/DconnNet?style=flat)](https://github.com/Zyun-Y/DconnNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Directional_Connectivity-Based_Segmentation_of_Medical_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00145-b31b1b.svg)](http://arxiv.org/abs/2304.00145) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=C3xCL8nbEU4) |
| A Soma Segmentation Benchmark in Full Adult Fly Brain | [![GitHub](https://img.shields.io/github/stars/liuxy1103/EMADS?style=flat)](https://github.com/liuxy1103/EMADS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_A_Soma_Segmentation_Benchmark_in_Full_Adult_Fly_Brain_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Constrained Evolutionary Diffusion Filter for Monocular Endoscope Tracking | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Constrained_Evolutionary_Diffusion_Filter_for_Monocular_Endoscope_Tracking_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Benchmarking Self-Supervised Learning on Diverse Pathology Datasets | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lunit-io.github.io/research/publications/pathology_ssl/) <br /> [![GitHub](https://img.shields.io/github/stars/lunit-io/benchmark-ssl-pathology?style=flat)](https://github.com/lunit-io/benchmark-ssl-pathology) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Benchmarking_Self-Supervised_Learning_on_Diverse_Pathology_Datasets_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04690-b31b1b.svg)](http://arxiv.org/abs/2212.04690) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yjIY0Xf0naU) |
| DualRel: Semi-Supervised Mitochondria Segmentation from a Prototype Perspective |  :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mai_DualRel_Semi-Supervised_Mitochondria_Segmentation_From_a_Prototype_Perspective_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=un00jmcBAbQ) |
| SDC-UDA: Volumetric Unsupervised Domain Adaptation Framework for Slice-Direction Continuous Cross-Modality Medical Image Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shin_SDC-UDA_Volumetric_Unsupervised_Domain_Adaptation_Framework_for_Slice-Direction_Continuous_Cross-Modality_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.11012-b31b1b.svg)](https://arxiv.org/abs/2305.11012) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=R2c8sxEdjN4) |
| OCELOT: Overlapped Cell on Tissue Dataset for Histopathology | [![GitHub](https://img.shields.io/github/stars/lunit-io/ocelot23algo?style=flat)](https://github.com/lunit-io/ocelot23algo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ryu_OCELOT_Overlapped_Cell_on_Tissue_Dataset_for_Histopathology_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13110-b31b1b.svg)](http://arxiv.org/abs/2303.13110) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V9RjvV9JrM8) |
| Orthogonal Annotation Benefits Barely-Supervised Medical Image Segmentation | [![GitHub](https://img.shields.io/github/stars/HengCai-NJU/DeSCO?style=flat)](https://github.com/HengCai-NJU/DeSCO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cai_Orthogonal_Annotation_Benefits_Barely-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13090-b31b1b.svg)](http://arxiv.org/abs/2303.13090) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UjFFGfUDpkc) |
| DeGPR: Deep Guided Posterior Regularization for Multi-Class Cell Detection and Counting | [![GitHub](https://img.shields.io/github/stars/dair-iitd/DeGPR?style=flat)](https://github.com/dair-iitd/DeGPR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tyagi_DeGPR_Deep_Guided_Posterior_Regularization_for_Multi-Class_Cell_Detection_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00741-b31b1b.svg)](http://arxiv.org/abs/2304.00741)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=d8TYNA8nE9c) |
| Interactive and Explainable Region-Guided Radiology Report Generation | [![GitHub](https://img.shields.io/github/stars/ttanida/rgrg?style=flat)](https://github.com/ttanida/rgrg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tanida_Interactive_and_Explainable_Region-Guided_Radiology_Report_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08295-b31b1b.svg)](https://arxiv.org/abs/2304.08295)| :heavy_minus_sign: |
| A Loopback Network for Explainable Microvascular Invasion Classification | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_A_Loopback_Network_for_Explainable_Microvascular_Invasion_Classification_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1FOadcF7Tlg) |
| Interventional Bag Multi-Instance Learning on Whole-Slide Pathological Images <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/HHHedo/IBMIL?style=flat)](https://github.com/HHHedo/IBMIL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Interventional_Bag_Multi-Instance_Learning_on_Whole-Slide_Pathological_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06873-b31b1b.svg)](http://arxiv.org/abs/2303.06873)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7UjvDaFxiIQ) |
| MAESTER: Masked Autoencoder Guided Segmentation at Pixel Resolution for Accurate, Self-Supervised Subcellular Structure Recognition <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/bowang-lab/MAESTER?style=flat)](https://github.com/bowang-lab/MAESTER) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_MAESTER_Masked_Autoencoder_Guided_Segmentation_at_Pixel_Resolution_for_Accurate_CVPR_2023_paper.pdf) |:heavy_minus_sign: |
| Neuralizer: General Neuroimage Analysis without Re-Training | [![GitHub](https://img.shields.io/github/stars/SteffenCzolbe/neuralizer?style=flat)](https://github.com/SteffenCzolbe/neuralizer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Czolbe_Neuralizer_General_Neuroimage_Analysis_Without_Re-Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.02644-b31b1b.svg)](http://arxiv.org/abs/2305.02644)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_wgCESDwjZI) |
| Why is the Winner the Best? | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Eisenmann_Why_Is_the_Winner_the_Best_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17719-b31b1b.svg)](http://arxiv.org/abs/2303.17719) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aURkx61EDjo) |
| Rethinking Few-Shot Medical Segmentation: A Vector Quantization View | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Rethinking_Few-Shot_Medical_Segmentation_A_Vector_Quantization_View_CVPR_2023_paper.pdf) |:heavy_minus_sign: |
| PEFAT: Boosting Semi-Supervised Medical Image Classification via Pseudo-Loss Estimation and Feature Adversarial Training <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/maxwell0027/PEFAT?style=flat)](https://github.com/maxwell0027/PEFAT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_PEFAT_Boosting_Semi-Supervised_Medical_Image_Classification_via_Pseudo-Loss_Estimation_and_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tPOTyXY1khA) |
| Indescribable Multi-Modal Spatial Evaluator | [![GitHub](https://img.shields.io/github/stars/Kid-Liet/IMSE?style=flat)](https://github.com/Kid-Liet/IMSE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Indescribable_Multi-Modal_Spatial_Evaluator_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00369-b31b1b.svg)](http://arxiv.org/abs/2303.00369)| :heavy_minus_sign: |
| Multiple Instance Learning via Iterative Self-Paced Supervised Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/Kangningthu/ItS2CLR?style=flat)](https://github.com/Kangningthu/ItS2CLR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Multiple_Instance_Learning_via_Iterative_Self-Paced_Supervised_Contrastive_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.09452-b31b1b.svg)](http://arxiv.org/abs/2210.09452)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iDlII2RshIw) |
| Hierarchical Discriminative Learning Improves Visual Representations of Biomedical Microscopy <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://hidisc.mlins.org/) <br /> [![GitHub](https://img.shields.io/github/stars/MLNeurosurg/hidisc?style=flat)](https://github.com/MLNeurosurg/hidisc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Hierarchical_Discriminative_Learning_Improves_Visual_Representations_of_Biomedical_Microscopy_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01605-b31b1b.svg)](http://arxiv.org/abs/2303.01605)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PkXki83vQqg) |
