# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/2023/main/transfer-meta-low-shot-continual-or-long-tail-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/2023/main/vision-language-and-reasoning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Recognition: Categorization, Detection, Retrieval

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| <i>R<sup>2</sup></i>Former: Unified Retrieval and Reranking Transformer for Place Recognition | [![GitHub](https://img.shields.io/github/stars/Jeff-Zilence/R2Former?style=flat)](https://github.com/Jeff-Zilence/R2Former)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhu_R2Former_Unified_Retrieval_and_Reranking_Transformer_for_Place_Recognition_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03410-b31b1b.svg)](https://arxiv.org/abs/2304.03410)  | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=suF-Yc2yxY4&list=PLd3hlSJsX_Ikm5jUWxEWUHAmUUq55lJDQ&index=8) |
| Mask-Free OVIS: Open-Vocabulary Instance Segmentation Without Manual Mask Annotations | [![GitHub](https://img.shields.io/github/stars/Vibashan/Maskfree-OVIS?style=flat)](https://github.com/Vibashan/Maskfree-OVIS)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/VS_Mask-Free_OVIS_Open-Vocabulary_Instance_Segmentation_Without_Manual_Mask_Annotations_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16891-b31b1b.svg)](http://arxiv.org/abs/2303.16891) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7P7PX3gd14I) |
| StructVPR: Distill Structural Knowledge With Weighting Samples for Visual Place Recognition| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Shen_StructVPR_Distill_Structural_Knowledge_With_Weighting_Samples_for_Visual_Place_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00937-b31b1b.svg)](http://arxiv.org/abs/2212.00937) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LgdWnBv8Nc4) |
| MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining | [![GitHub](https://img.shields.io/github/stars/LightDXY/MaskCLIP?style=flat)](https://github.com/LightDXY/MaskCLIP)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Dong_MaskCLIP_Masked_Self-Distillation_Advances_Contrastive_Language-Image_Pretraining_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.12262-b31b1b.svg)](http://arxiv.org/abs/2208.12262) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2PPiLDTtVzQ) |
| One-to-Few Label Assignment for End-to-End Dense Detection | [![GitHub](https://img.shields.io/github/stars/strongwolf/o2f?style=flat)](https://github.com/strongwolf/o2f)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_One-to-Few_Label_Assignment_for_End-to-End_Dense_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11567-b31b1b.svg)](http://arxiv.org/abs/2303.11567) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2v7i-1TltBs) |
| Where Is My Wallet? Modeling Object Proposal Sets for Egocentric Visual Query Localization | [![GitHub](https://img.shields.io/github/stars/facebookresearch/vq2d_cvpr?style=flat)](https://github.com/facebookresearch/vq2d_cvpr)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Xu_Where_Is_My_Wallet_Modeling_Object_Proposal_Sets_for_Egocentric_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10528-b31b1b.svg)](http://arxiv.org/abs/2211.10528) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2TU4TWD6FmM) |
| Semi-DETR: Semi-Supervised Object Detection With Detection Transformers | [![GitHub](https://img.shields.io/github/stars/JCZ404/Semi-DETR?style=flat)](https://github.com/JCZ404/Semi-DETR)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhang_Semi-DETR_Semi-Supervised_Object_Detection_With_Detection_Transformers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08095-b31b1b.svg)](https://arxiv.org/abs/2307.08095) | :heavy_minus_sign: |
| Universal Instance Perception As Object Discovery and Retrieval | [![GitHub](https://img.shields.io/github/stars/MasterBin-IIAU/UNINEXT?style=flat)](https://github.com/MasterBin-IIAU/UNINEXT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Yan_Universal_Instance_Perception_As_Object_Discovery_and_Retrieval_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06674-b31b1b.svg)](http://arxiv.org/abs/2303.06674) | :heavy_minus_sign: |
| CAT: LoCalization and IdentificAtion Cascade Detection Transformer for Open-World Object Detection| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ma_CAT_LoCalization_and_IdentificAtion_Cascade_Detection_Transformer_for_Open-World_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01970-b31b1b.svg)](http://arxiv.org/abs/2301.01970) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pYiWsGlg_n8) |
| Phase-Shifting Coder: Predicting Accurate Orientation in Oriented Object Detection|  [![GitHub](https://img.shields.io/github/stars/open-mmlab/mmrotate?style=flat)](https://github.com/open-mmlab/mmrotate)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Yu_Phase-Shifting_Coder_Predicting_Accurate_Orientation_in_Oriented_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06368-b31b1b.svg)](http://arxiv.org/abs/2211.06368) | :heavy_minus_sign: |
| FrustumFormer: Adaptive Instance-Aware Resampling for Multi-View 3D Detection | [![GitHub](https://img.shields.io/github/stars/Robertwyq/Frustum?style=flat)](https://github.com/Robertwyq/Frustum)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_FrustumFormer_Adaptive_Instance-Aware_Resampling_for_Multi-View_3D_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.04467-b31b1b.svg)](http://arxiv.org/abs/2301.04467) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vQTxzc3Z5uQ) | |
| Box-Level Active Detection |  |  |  |
| Learning with Noisy Labels via Self-Supervised Adversarial Noisy Masking |  |  |  |
| Ambiguity-Resistant Semi-Supervised Learning for Dense Object Detection |  |  |  |
| Aligning Bag of Regions for Open-Vocabulary Object Detection |  |  |  |
| Asymmetric Feature Fusion for Image Retrieval |  |  |  |
| 3D Video Object Detection with Learnable Object-Centric Global Optimization |  |  |  |
| Enhanced Training of Query-based Object Detection via Selective Query Recollection |  |  |  |
| Dense Distinct Query for End-to-End Object Detection |  |  |  |
| On-the-Fly Category Discovery |  |  |  |
| ProD: Prompting-to-Disentangle Domain Knowledge for Cross-Domain Few-Shot Image Classification |  |  |  |
| Q-DETR: An Efficient Low-Bit Quantized Detection Transformer |  |  |  |
| SAP-DETR: Bridging the Gap between Salient Points and Queries-based Transformer Detector for Fast Model Convergency |  |  |  |
| An Erudite Fine-grained Visual Classification Model |  |  |  |
| Self-Supervised Implicit Glyph Attention for Text Recognition |  |  |  |
| Multi-View Adversarial Discriminator: Mine the Non-Causal Factors for Object Detection in Unseen Domains |  |  |  |
| HIER: Metric Learning Beyond Class Labels via Hierarchical Regularization |  |  |  |
| DSVT: Dynamic Sparse Voxel Transformer with Rotated Sets |  |  |  |
| Progressive Semantic-Visual Mutual Adaption for Generalized Zero-Shot Learning |  |  |  |
| Fake it Till You make it: Learning Transferable Representations from Synthetic ImageNet Clones |  |  |  |
| FFF: Fragment-guided Flexible Fitting for Building Complete Protein Structures |  |  |  |
| Revisiting Self-Similarity: Structural Embedding for Image Retrieval |  |  |  |
| Neural Koopman Pooling: Control-Inspired Temporal Dynamics Encoding for Skeleton-based Action Recognition |  |  |  |
| MixTeacher: Mining Promising Labels with Mixed Scale Teacher for Semi-Supervised Object Detection |  |  |  |
| Learning Attention as Disentangler for Compositional Zero-Shot Learning |  |  |  |
| Towards Building Self-Aware Object Detectors via Reliable Uncertainty Quantification and Calibration |  |  |  |
| Object-Aware Distillation Pyramid for Open-Vocabulary Object Detection |  |  |  |
| SOOD: Towards Semi-Supervised Oriented Object Detection |  |  |  |
| Bias-Eliminating Augmentation Learning for Debiased Federated Learning |  |  |  |
| Towards Efficient use of Multi-Scale Features in Transformer-based Object Detectors |  |  |  |
| AsyFOD: An Asymmetric Adaptation Paradigm for Few-Shot Domain Adaptive Object Detection |  |  |  |
| CORA: Adapting CLIP for Open-Vocabulary Detection with Region Prompting and Anchor Pre-Matching |  |  |  |
| Explicit Boundary Guided Semi-Push-Pull Contrastive Learning for Supervised Anomaly Detection |  |  |  |
| Disentangled Representation Learning for Unsupervised Neural Quantization |  |  |  |
| YOLOv7: Trainable Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors |  |  |  |
| Virtual Sparse Convolution for Multimodal 3D Object Detection |  |  |  |
| TranSG: Transformer-based Skeleton Graph Prototype Contrastive Learning with Structure-Trajectory Prompted Reconstruction for Person Re-Identification |  |  |  |
| Adaptive Sparse Pairwise Loss for Object Re-Identification |  |  |  |
| Multi-Granularity Archaeological Dating of Chinese Bronze Dings based on a Knowledge-guided Relation Graph |  |  |  |
| Event-guided Person Re-Identification via Sparse-Dense Complementary Learning |  |  |  |
| Vector Quantization with Self-Attention for Quality-Independent Representation Learning |  |  |  |
| Siamese Image Modeling for Self-Supervised Vision Representation Learning |  |  |  |
| FCC: Feature Clusters Compression for Long-tailed Visual Recognition |  |  |  |
| Towards All-in-One Pre-Training via Maximizing Multi-Modal Mutual Information |  |  |  |
| Soft Augmentation for Image Classification |  |  |  |
| Correspondence Transformers with Asymmetric Feature Learning and Matching Flow Super-Resolution |  |  |  |
| Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with Multimodal Models |  |  |  |
| Out-of-Distributed Semantic Pruning for Robust Semi-Supervised Learning |  |  |  |
| Glocal Energy-based Learning for Few-Shot Open-Set Recognition |  |  |  |
| Improving Image Recognition by Retrieving from Web-Scale Image-Text Data |  |  |  |
| Deep Factorized Metric Learning |  |  |  |
| Learning to Detect and Segment for Open Vocabulary Object Detection |  |  |  |
| ConQueR: Query Contrast Voxel-DETR for 3D Object Detection |  |  |  |
| Photo Pre-Training, But for Sketch |  |  |  |
| InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions |  |  |  |
| Detecting Everything in the Open World: Towards Universal Object Detection |  |  |  |
| Twin Contrastive Learning with Noisy Labels |  |  |  |
| Feature Aggregated Queries for Transformer-based Video Object Detectors |  |  |  |
| Learning on Gradients: Generalized Artifacts Representation for GAN-Generated Images Detection |  |  |  |
| Deep Hashing with Minimal-Distance-Separated Hash Centers |  |  |  |
| Knowledge Combination to Learn Rotated Detection without Rotated Annotation |  |  |  |
| Good is Bad: Causality Inspired Cloth-Debiasing for Cloth-Changing Person Re-Identification |  |  |  |
| Discriminating Known from Unknown Objects via Structure-Enhanced Recurrent Variational AutoEncoder |  |  |  |
| 2PCNet: Two-Phase Consistency Training for Day-to-Night Unsupervised Domain Adaptive Object Detection |  |  |  |
| LINe: Out-of-Distribution Detection by Leveraging Important Neurons |  |  |  |
| Progressive Transformation Learning for Leveraging Virtual Images in Training |  |  |  |
| Instance Relation Graph Guided Source-Free Domain Adaptive Object Detection |  |  |  |
| Decoupling MaxLogit for Out-of-Distribution Detection |  |  |  |
| Pixels, Regions, and Objects: Multiple Enhancement for Salient Object Detection |  |  |  |
| Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding |  |  |  |
| BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision |  |  |  |
| D<sup>2</sup>Former: Jointly Learning Hierarchical Detectors and Contextual Descriptors via Agent-based Transformers |  |  |  |
| CapDet: Unifying Dense Captioning and Open-World Detection Pretraining |  |  |  |
| Mapping Degeneration Meets Label Evolution: Learning Infrared Small Target Detection with Single Point Supervision |  |  |  |
| Generalized UAV Object Detection via Frequency Domain Disentanglement |  |  |  |
| Deep Frequency Filtering for Domain Generalization |  |  |  |
| Adaptive Sparse Convolutional Networks with Global Context Enhancement for Faster Object Detection on Drone Images |  |  |  |
| Improved Test-Time Adaptation for Domain Generalization |  |  |  |
| Matching Is Not Enough: A Two-Stage Framework for Category-Agnostic Pose Estimation |  |  |  |
| Recurrence without Recurrence: Stable Video Landmark Detection with Deep Equilibrium Models |  |  |  |
| VLPD: Context-Aware Pedestrian Detection via Vision-Language Semantic Self-Supervision |  |  |  |
| DETRs with Hybrid Matching |  |  |  |
| Query-Dependent Video Representation for Moment Retrieval and Highlight Detection |  |  |  |
| Clothing-Change Feature Augmentation for Person Re-Identification |  |  |  |
| Learning Attribute and Class-Specific Representation Duet for Fine-grained Fashion Analysis |  |  |  |
| Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks |  |  |  |
| Optimal Proposal Learning for Deployable End-to-End Pedestrian Detection |  |  |  |
| DynamicDet: A Unified Dynamic Architecture for Object Detection |  |  |  |
| Switchable Representation Learning Framework with Self-Compatibility |  |  |  |
| DATE: Domain Adaptive Product Seeker for E-Commerce |  |  |  |
| PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for Generalized Novel Category Discovery |  |  |  |
| Dynamic Neural Network for Multi-Task Learning Searching across Diverse Network Topologies |  |  |  |
| OvarNet: Towards Open-Vocabulary Object Attribute Recognition |  |  |  |
| HOICLIP: Efficient Knowledge Transfer for HOI Detection with Vision-Language Models |  |  |  |
| Learning from Noisy Labels with Decoupled Meta Label Purifier |  |  |  |
| A Light Touch Approach to Teaching Transformers Multi-View Geometry |  |  |  |
| OpenMix: Exploring Outlier Samples for Misclassification Detection |  |  |  |
| Revisiting Reverse Distillation for Anomaly Detection |  |  |  |
| PROB: Probabilistic Objectness for Open World Object Detection |  |  |  |
| Equiangular Basis Vectors |  |  |  |
| Weakly Supervised Posture Mining for Fine-grained Classification |  |  |  |
| An Actor-Centric Causality Graph for Asynchronous Temporal Inference in Group Activity |  |  |  |
| Weak-Shot Object Detection through Mutual Knowledge Transfer |  |  |  |
| Zero-Shot Everything Sketch-based Image Retrieval, and in Explainable Style |  |  |  |
| Exploring Structured Semantic Prior for Multi Label Recognition with Incomplete Labels |  |  |  |
| Learning Partial Correlation based Deep Visual Representation for Image Classification |  |  |  |
| Boundary-aware Backward-Compatible Representation via Adversarial Learning in Image Retrieval |  |  |  |
| PHA: Patch-Wise High-Frequency Augmentation for Transformer-based Person Re-Identification |  |  |  |
| Unknown Sniffer for Object Detection: Don't Turn a Blind Eye to Unknown Objects |  |  |  |
| BoxTeacher: Exploring High-Quality Pseudo Labels for Weakly Supervised Instance Segmentation |  |  |  |
| Annealing-based Label-Transfer Learning for Open World Object Detection |  |  |  |
| Diversity-Measurable Anomaly Detection |  |  |  |
| Recurrent Vision Transformers for Object Detection with Event Cameras |  |  |  |
| AShapeFormer: Semantics-guided Object-Level Active Shape Encoding for 3D Object Detection via Transformers |  |  |  |
| Ranking Regularization for Critical Rare Classes: Minimizing False Positives at a High True Positive Rate |  |  |  |
| Contrastive Mean Teacher for Domain Adaptive Object Detectors |  |  |  |
| Bridging the Gap between Model Explanations in Partially Annotated Multi-Label Classification |  |  |  |
| PartMix: Regularization Strategy to Learn Part Discovery for Visible-Infrared Person Re-Identification |  |  |  |
| BiasAdv: Bias-Adversarial Augmentation for Model Debiasing |  |  |  |
| ViPLO: Vision Transformer based Pose-Conditioned Self-Loop Graph for Human-Object Interaction Detection |  |  |  |
| Robust 3D Shape Classification via Non-Local Graph Attention Network |  |  |  |
| Two-Way Multi-Label Loss |  |  |  |
| Normalizing Flow based Feature Synthesis for Outlier-Aware Object Detection |  |  |  |
| Object Detection with Self-Supervised Scene Adaptation |  |  |  |
| Data-Efficient Large Scale Place Recognition with Graded Similarity Supervision |  |  |  |
| Generating Features with Increased Crop-related Diversity for Few-Shot Object Detection |  |  |  |
| Recognizing Rigid Patterns of Unlabeled Point Clouds by Complete and Continuous Isometry Invariants with no False Negatives and no False Positives |  |  |  |
| Deep Semi-Supervised Metric Learning with Mixed Label Propagation |  |  |  |
| Fine-grained Classification with Noisy Labels |  |  |  |
