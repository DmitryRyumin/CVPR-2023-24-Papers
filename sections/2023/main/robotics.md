# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>New collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
                <img src="http://img.shields.io/badge/CVPR-2024-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/vision-and-graphics.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/transparency-fairness-accountability-privacy-ethics-in-vision.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
  </a>
</div>

## Robotics

![Section Papers](https://img.shields.io/badge/Section%20Papers-23-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-18-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-13-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-18-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Object-Goal Visual Navigation via Effective Exploration of Relations among Historical Navigation States | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Object-Goal_Visual_Navigation_via_Effective_Exploration_of_Relations_Among_Historical_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| TTA-COPE: Test-Time Adaptation for Category-Level Object Pose Estimation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/taeyeop-lee/ttacope) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_TTA-COPE_Test-Time_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16730-b31b1b.svg)](http://arxiv.org/abs/2303.16730) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MUgQ0yithis) |
| Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation using Scene Object Spectrum Grounding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rllab-snu.github.io/projects/Meta-Explore/doc.html) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hwang_Meta-Explore_Exploratory_Hierarchical_Vision-and-Language_Navigation_Using_Scene_Object_Spectrum_Grounding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.04077-b31b1b.svg)](http://arxiv.org/abs/2303.04077) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nxWUedX5VpQ) |
| Learning Human-to-Robot Handovers from Point Clouds <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://handover-sim2real.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/NVlabs/handover-sim2real?style=flat)](https://github.com/NVlabs/handover-sim2real) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Christen_Learning_Human-to-Robot_Handovers_From_Point_Clouds_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17592-b31b1b.svg)](http://arxiv.org/abs/2303.17592) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IsjCdoIAA7s) |
| Robot Structure Prior Guided Temporal Attention for Camera-to-Robot Pose Estimation from Image Sequence | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/sgtapose) <br /> [![GitHub](https://img.shields.io/github/stars/Nimolty/SGTAPose?style=flat)](https://github.com/Nimolty/SGTAPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Robot_Structure_Prior_Guided_Temporal_Attention_for_Camera-to-Robot_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.12106-b31b1b.svg)](http://arxiv.org/abs/2307.12106) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5fQp-yBubZs) |
| PartManip: Learning Cross-Category Generalizable Part Manipulation Policy from Point Cloud Observations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pku-epic.github.io/PartManip/) <br /> [![GitHub](https://img.shields.io/github/stars/PKU-EPIC/PartManip?style=flat)](https://github.com/PKU-EPIC/PartManip) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Geng_PartManip_Learning_Cross-Category_Generalizable_Part_Manipulation_Policy_From_Point_Cloud_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16958-b31b1b.svg)](http://arxiv.org/abs/2303.16958) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=k0LbcO1B-ac) |
| DexArt: Benchmarking Generalizable Dexterous Manipulation with Articulated Objects | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.chenbao.tech/dexart/) <br /> [![GitHub](https://img.shields.io/github/stars/Kami-code/dexart-release?style=flat)](https://github.com/Kami-code/dexart-release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_DexArt_Benchmarking_Generalizable_Dexterous_Manipulation_With_Articulated_Objects_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.05706-b31b1b.svg)](http://arxiv.org/abs/2305.05706) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V_EYQJO1W_U) |
| PyPose: A Library for Robot Learning with Physics-based Optimization | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://pypose.org/) <br /> [![GitHub](https://img.shields.io/github/stars/pypose/pypose?style=flat)](https://github.com/pypose/pypose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_PyPose_A_Library_for_Robot_Learning_With_Physics-Based_Optimization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.15428-b31b1b.svg)](http://arxiv.org/abs/2209.15428) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XDtUDIWuGng) |
| Target-Referenced Reactive Grasping for Dynamic Objects | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://graspnet.net/reactive) <br /> [![GitHub](https://img.shields.io/github/stars/Todibo99/Target-referenced-Reactive-Grasping-for-Dynamic-Objects?style=flat)](https://github.com/Todibo99/Target-referenced-Reactive-Grasping-for-Dynamic-Objects) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Target-Referenced_Reactive_Grasping_for_Dynamic_Objects_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Autonomous Manipulation Learning for Similar Deformable Objects via only One Demonstration | [![GitHub](https://img.shields.io/github/stars/renyu2016/DLCDO?style=flat)](https://github.com/renyu2016/DLCDO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_Autonomous_Manipulation_Learning_for_Similar_Deformable_Objects_via_Only_One_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y0FD0ihdEN0) |
| Renderable Neural Radiance Map for Visual Navigation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rllab-snu.github.io/projects/RNR-Map/) <br /> [![GitHub](https://img.shields.io/github/stars/rllab-snu/RNR-Map?style=flat)](https://github.com/rllab-snu/RNR-Map) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kwon_Renderable_Neural_Radiance_Map_for_Visual_Navigation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00304-b31b1b.svg)](http://arxiv.org/abs/2303.00304) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1SF8_6BsA1c) |
| Efficient Map Sparsification based on 2D and 3D Discretized Grids | [![GitHub](https://img.shields.io/github/stars/fishmarch/SLAM_Map_Compression?style=flat)](https://github.com/fishmarch/SLAM_Map_Compression) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Efficient_Map_Sparsification_Based_on_2D_and_3D_Discretized_Grids_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10882-b31b1b.svg)](http://arxiv.org/abs/2303.10882) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gG1nFddFf-s) |
| Policy Adaptation from Foundation Model Feedback | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://geyuying.github.io/PAFF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ge_Policy_Adaptation_From_Foundation_Model_Feedback_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07398-b31b1b.svg)](http://arxiv.org/abs/2212.07398) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5IZkbUFB2cM) |
| NeRF in the Palm of Your Hand: Corrective Augmentation for Robotics via Novel-View Synthesis | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://bland.website/spartn/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_NeRF_in_the_Palm_of_Your_Hand_Corrective_Augmentation_for_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.08556-b31b1b.svg)](http://arxiv.org/abs/2301.08556) | :heavy_minus_sign: |
| Markerless Camera-to-Robot Pose Estimation via Self-Supervised Sim-to-Real Transfer | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Markerless_Camera-to-Robot_Pose_Estimation_via_Self-Supervised_Sim-to-Real_Transfer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14332-b31b1b.svg)](http://arxiv.org/abs/2302.14332) | :heavy_minus_sign: |
| Affordances from Human Videos as a Versatile Representation for Robotics | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vision-robotics-bridge.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bahl_Affordances_From_Human_Videos_as_a_Versatile_Representation_for_Robotics_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08488-b31b1b.svg)](http://arxiv.org/abs/2304.08488) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WdMYGESu8Ak) |
| DeepMapping2: Self-Supervised Large-Scale LiDAR Map Optimization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ai4ce.github.io/DeepMapping2/) <br /> [![GitHub](https://img.shields.io/github/stars/ai4ce/DeepMapping2?style=flat)](https://github.com/ai4ce/DeepMapping2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_DeepMapping2_Self-Supervised_Large-Scale_LiDAR_Map_Optimization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06331-b31b1b.svg)](http://arxiv.org/abs/2212.06331) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2NJ81JwY48o) |
| GrowSP: Unsupervised Semantic Segmentation of 3D Point Clouds | [![GitHub](https://img.shields.io/github/stars/vLAR-group/GrowSP?style=flat)](https://github.com/vLAR-group/GrowSP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_GrowSP_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16404-b31b1b.svg)](http://arxiv.org/abs/2305.16404) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=x_UW7hU3Ows) |
| Neural Volumetric Memory for Visual Locomotion Control <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rchalyang.github.io/NVM/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Neural_Volumetric_Memory_for_Visual_Locomotion_Control_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01201-b31b1b.svg)](http://arxiv.org/abs/2304.01201) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vJdt610GSGk) |
| Multi-Object Manipulation via Object-Centric Neural Scattering Functions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://s-tian.github.io/projects/actionosf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Multi-Object_Manipulation_via_Object-Centric_Neural_Scattering_Functions_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.08748-b31b1b.svg)](http://arxiv.org/abs/2306.08748) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yRZ2YVJHhGY) |
| Local-Guided Global: Paired Similarity Representation for Visual Reinforcement Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_Local-Guided_Global_Paired_Similarity_Representation_for_Visual_Reinforcement_Learning_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| HypLiLoc: Towards Effective LiDAR Pose Regression with Hyperbolic Fusion | [![GitHub](https://img.shields.io/github/stars/sijieaaa/HypLiLoc?style=flat)](https://github.com/sijieaaa/HypLiLoc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_HypLiLoc_Towards_Effective_LiDAR_Pose_Regression_With_Hyperbolic_Fusion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00932-b31b1b.svg)](http://arxiv.org/abs/2304.00932) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=d8FMbENBmBA) |
| Imitation Learning as State Matching via Differentiable Physics | [![GitHub](https://img.shields.io/github/stars/sail-sg/ILD?style=flat)](https://github.com/sail-sg/ILD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Imitation_Learning_As_State_Matching_via_Differentiable_Physics_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=6iNFJHPO8Hc) |
