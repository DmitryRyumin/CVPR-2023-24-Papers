# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>New collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
                <img src="http://img.shields.io/badge/CVPR-2024-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/multimodal-learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/medical-and-biological-vision-cell-microscopy.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 3D from Single Images

![Section Papers](https://img.shields.io/badge/Section%20Papers-91-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-78-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-80-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-70-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| 3D-Aware Multi-Class Image-to-Image Translation with NeRFs | [![GitHub](https://img.shields.io/github/stars/sen-mao/3di2i-translation?style=flat)](https://github.com/sen-mao/3di2i-translation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_3D-Aware_Multi-Class_Image-to-Image_Translation_With_NeRFs_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15012-b31b1b.svg)](http://arxiv.org/abs/2303.15012) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CjBPP2l9Bjg) |
| DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-Aware Scene Synthesis <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://snap-research.github.io/discoscene/) <br /> [![GitHub](https://img.shields.io/github/stars/snap-research/discoscene?style=flat)](https://github.com/snap-research/discoscene) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_DisCoScene_Spatially_Disentangled_Generative_Radiance_Fields_for_Controllable_3D-Aware_Scene_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.11984-b31b1b.svg)](http://arxiv.org/abs/2212.11984) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Fvenkw7yeok) |
| MagicPony: Learning Articulated 3D Animals in the Wild | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3dmagicpony.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/elliottwu/MagicPony?style=flat)](https://github.com/elliottwu/MagicPony) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_MagicPony_Learning_Articulated_3D_Animals_in_the_Wild_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12497-b31b1b.svg)](http://arxiv.org/abs/2211.12497) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KoLzpESstLk) |
| Seeing a Rose in Five Thousand Ways | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ai.stanford.edu/~yzzhang/projects/rose/) <br /> [![GitHub](https://img.shields.io/github/stars/zzyunzhi/object-intrinsics?style=flat)](https://github.com/zzyunzhi/object-intrinsics) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Seeing_a_Rose_in_Five_Thousand_Ways_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04965-b31b1b.svg)](http://arxiv.org/abs/2212.04965) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oe5N3sNDp2w) |
| FitMe: Deep Photorealistic 3D Morphable Model Avatars | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://alexlattas.com/fitme) <br /> [![GitHub](https://img.shields.io/github/stars/lattas/FitMe?style=flat)](https://github.com/lattas/FitMe) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lattas_FitMe_Deep_Photorealistic_3D_Morphable_Model_Avatars_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.09641-b31b1b.svg)](https://arxiv.org/abs/2305.09641) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=73ZFDkZRRCk) |
| Scalable, Detailed and Mask-Free Universal Photometric Stereo <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/satoshi-ikehata/SDM-UniPS-CVPR2023?style=flat)](https://github.com/satoshi-ikehata/SDM-UniPS-CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ikehata_Scalable_Detailed_and_Mask-Free_Universal_Photometric_Stereo_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15724-b31b1b.svg)](http://arxiv.org/abs/2303.15724) | :heavy_minus_sign: |
| Spatio-Focal Bidirectional Disparity Estimation from a Dual-Pixel Image | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vclab.kaist.ac.kr/cvpr2023p1/) <br /> [![GitHub](https://img.shields.io/github/stars/KAIST-VCLAB/dual-pixel-disparity?style=flat)](https://github.com/KAIST-VCLAB/dual-pixel-disparity) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Spatio-Focal_Bidirectional_Disparity_Estimation_From_a_Dual-Pixel_Image_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SIoWF8phDp0) |
| ShapeClipper: Scalable 3D Shape Learning from Single-View Images via Geometric and CLIP-based Consistency | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://zixuanh.com/projects/shapeclipper.html) <br /> [![GitHub](https://img.shields.io/github/stars/zxhuang1698/ShapeClipper?style=flat)](https://github.com/zxhuang1698/ShapeClipper) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_ShapeClipper_Scalable_3D_Shape_Learning_From_Single-View_Images_via_Geometric_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06247-b31b1b.svg)](http://arxiv.org/abs/2304.06247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=BxTGVjXoXu8) |
| High-Fidelity Clothed Avatar Reconstruction from a Single Image | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tingtingliao.github.io/CAR/) <br /> [![GitHub](https://img.shields.io/github/stars/TingtingLiao/CAR?style=flat)](https://github.com/TingtingLiao/CAR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liao_High-Fidelity_Clothed_Avatar_Reconstruction_From_a_Single_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03903-b31b1b.svg)](http://arxiv.org/abs/2304.03903) | :heavy_minus_sign: |
| TexPose: Neural Texture Learning for Self-Supervised 6D Object Pose Estimation | [![GitHub](https://img.shields.io/github/stars/HanzhiC/TexPose?style=flat)](https://github.com/HanzhiC/TexPose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_TexPose_Neural_Texture_Learning_for_Self-Supervised_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.12902-b31b1b.svg)](http://arxiv.org/abs/2212.12902) | :heavy_minus_sign: |
| Behind the Scenes: Density Fields for Single View Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fwmb.github.io/bts/) <br /> [![GitHub](https://img.shields.io/github/stars/Brummi/BehindTheScenes?style=flat)](https://github.com/Brummi/BehindTheScenes) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wimbauer_Behind_the_Scenes_Density_Fields_for_Single_View_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.07668-b31b1b.svg)](http://arxiv.org/abs/2301.07668) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0VGKPmomrR8) |
| Reconstructing Animatable Categories from Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://gengshan-y.github.io/rac-www/) <br /> [![GitHub](https://img.shields.io/github/stars/gengshan-y/rac?style=flat)](https://github.com/gengshan-y/rac) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Reconstructing_Animatable_Categories_From_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.06351-b31b1b.svg)](http://arxiv.org/abs/2305.06351) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V6S1WuPDEZE) |
| RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation | [![GitHub](https://img.shields.io/github/stars/Anciukevicius/RenderDiffusion?style=flat)](https://github.com/Anciukevicius/RenderDiffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Anciukevicius_RenderDiffusion_Image_Diffusion_for_3D_Reconstruction_Inpainting_and_Generation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09869-b31b1b.svg)](https://arxiv.org/abs/2211.09869) | :heavy_minus_sign: |
| Self-Supervised Geometry-Aware Encoder for Style-based 3D GAN Inversion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nirvanalan.github.io/projects/E3DGE/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/NIRVANALAN/CVPR23-E3DGE?style=flat)](https://github.com/NIRVANALAN/CVPR23-E3DGE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lan_Self-Supervised_Geometry-Aware_Encoder_for_Style-Based_3D_GAN_Inversion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07409-b31b1b.svg)](http://arxiv.org/abs/2212.07409) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s9uCZwqjfsA) |
| 3D Cinemagraphy from a Single Image | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xingyi-li.github.io/3d-cinemagraphy/) <br /> [![GitHub](https://img.shields.io/github/stars/xingyi-li/3d-cinemagraphy?style=flat)](https://github.com/xingyi-li/3d-cinemagraphy) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_3D_Cinemagraphy_From_a_Single_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05724-b31b1b.svg)](http://arxiv.org/abs/2303.05724) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sqCy7ffTEEY) |
| NeuralLift-360: Lifting an In-the-Wild 2D Photo to a 3D Object with 360&deg; Views | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vita-group.github.io/NeuralLift-360/) <br /> [![GitHub](https://img.shields.io/github/stars/VITA-Group/NeuralLift-360?style=flat)](https://github.com/VITA-Group/NeuralLift-360) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_NeuralLift-360_Lifting_an_In-the-Wild_2D_Photo_to_a_3D_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16431-b31b1b.svg)](https://arxiv.org/abs/2211.16431) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=knNNwF-J_ow) |
| iDisc: Internal Discretization for Monocular Depth Estimation | [![GitHub](https://img.shields.io/github/stars/SysCV/idisc?style=flat)](https://github.com/SysCV/idisc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Piccinelli_iDisc_Internal_Discretization_for_Monocular_Depth_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06334-b31b1b.svg)](http://arxiv.org/abs/2304.06334) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u4bgu9kR8ZM) |
| HairStep: Transfer Synthetic to Real using Strand and Depth Maps for Single-View 3D Hair Modeling <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://paulyzheng.github.io/research/hairstep/) <br /> [![GitHub](https://img.shields.io/github/stars/GAP-LAB-CUHK-SZ/HairStep?style=flat)](https://github.com/GAP-LAB-CUHK-SZ/HairStep) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_HairStep_Transfer_Synthetic_to_Real_Using_Strand_and_Depth_Maps_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.02700-b31b1b.svg)](http://arxiv.org/abs/2303.02700) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WkG73DTSyUg) |
| NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-Shot Real Image Animation | [![GitHub](https://img.shields.io/github/stars/YuYin1/NeRFInvertor?style=flat)](https://github.com/YuYin1/NeRFInvertor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yin_NeRFInvertor_High_Fidelity_NeRF-GAN_Inversion_for_Single-Shot_Real_Image_Animation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.17235-b31b1b.svg)](http://arxiv.org/abs/2211.17235) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tFD0fH06JQg) |
| NeurOCS: Neural NOCS Supervision for Monocular 3D Object Localization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Min_NeurOCS_Neural_NOCS_Supervision_for_Monocular_3D_Object_Localization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.17763-b31b1b.svg)](https://arxiv.org/abs/2305.17763) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TrE4NGyc4SQ) |
| Multiview Compressive Coding for 3D Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mcc3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/MCC?style=flat)](https://github.com/facebookresearch/MCC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Multiview_Compressive_Coding_for_3D_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.08247-b31b1b.svg)](http://arxiv.org/abs/2301.08247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f4lPEqigHuM) |
| FaceLit: Neural 3D Relightable Faces | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://machinelearning.apple.com/research/neural-3d-relightable) <br /> [![GitHub](https://img.shields.io/github/stars/apple/ml-facelit?style=flat)](https://github.com/apple/ml-facelit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ranjan_FaceLit_Neural_3D_Relightable_Faces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15437-b31b1b.svg)](http://arxiv.org/abs/2303.15437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PH1PZEutMbw) |
| Rigidity-Aware Detection for 6D Object Pose Estimation | [![GitHub](https://img.shields.io/github/stars/YangHai-1218/RADet?style=flat)](https://github.com/YangHai-1218/RADet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hai_Rigidity-Aware_Detection_for_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12396-b31b1b.svg)](http://arxiv.org/abs/2303.12396) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XgDFmE8AL_Y) |
| Shape-Constraint Recurrent Flow for 6D Object Pose Estimation | [![GitHub](https://img.shields.io/github/stars/YangHai-1218/SCFlow?style=flat)](https://github.com/YangHai-1218/SCFlow) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hai_Shape-Constraint_Recurrent_Flow_for_6D_Object_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.13266-b31b1b.svg)](http://arxiv.org/abs/2306.13266) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wLba5ED_TS4) |
| Bringing Inputs to Shared Domains for 3D Interacting Hands Recovery in the Wild | [![GitHub](https://img.shields.io/github/stars/facebookresearch/InterWild?style=flat)](https://github.com/facebookresearch/InterWild) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Moon_Bringing_Inputs_to_Shared_Domains_for_3D_Interacting_Hands_Recovery_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13652-b31b1b.svg)](http://arxiv.org/abs/2303.13652) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Wxhsyx1IqEo) |
| Ref-NPR: Reference-based Non-Photorealistic Radiance Fields for Controllable Scene Stylization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ref-npr.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/dvlab-research/Ref-NPR?style=flat)](https://github.com/dvlab-research/Ref-NPR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Ref-NPR_Reference-Based_Non-Photorealistic_Radiance_Fields_for_Controllable_Scene_Stylization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02766-b31b1b.svg)](https://arxiv.org/abs/2212.02766) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jnsnrTwVSBw) |
| DiffPose: Toward more Reliable 3D Pose Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gongjia0208.github.io/Diffpose/) <br /> [![GitHub](https://img.shields.io/github/stars/GONGJIA0208/Diffpose?style=flat)](https://github.com/GONGJIA0208/Diffpose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gong_DiffPose_Toward_More_Reliable_3D_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16940-b31b1b.svg)](http://arxiv.org/abs/2211.16940) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ttlnm6TePoY) |
| High-Fidelity 3D GAN Inversion by Pseudo-Multi-View Optimization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ken-ouyang.github.io/HFGI3D/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/jiaxinxie97/HFGI3D?style=flat)](https://github.com/jiaxinxie97/HFGI3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_High-Fidelity_3D_GAN_Inversion_by_Pseudo-Multi-View_Optimization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.15662-b31b1b.svg)](http://arxiv.org/abs/2211.15662) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7UUb0uYJaG8) |
| Semantic Scene Completion with Cleaner Self | [![GitHub](https://img.shields.io/github/stars/fereenwong/CleanerS?style=flat)](https://github.com/fereenwong/CleanerS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Semantic_Scene_Completion_With_Cleaner_Self_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09977-b31b1b.svg)](http://arxiv.org/abs/2303.09977) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mYzLYAEdcbU) |
| Learned Two-Plane Perspective Prior based Image Resampling for Efficient Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://geometriczoom.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/geometriczoom/two-plane-prior?style=flat)](https://github.com/geometriczoom/two-plane-prior) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ghosh_Learned_Two-Plane_Perspective_Prior_Based_Image_Resampling_for_Efficient_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14311-b31b1b.svg)](http://arxiv.org/abs/2303.14311) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gUcC0JU1bmg) |
| Mask3D: Pre-Training 2D Vision Transformers by Learning Masked 3D Priors | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hou_Mask3D_Pre-Training_2D_Vision_Transformers_by_Learning_Masked_3D_Priors_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14746-b31b1b.svg)](http://arxiv.org/abs/2302.14746) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s0ITbsdekl4) |
| Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://omni3d.garrickbrazil.com/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/omni3d?style=flat)](https://github.com/facebookresearch/omni3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Brazil_Omni3D_A_Large_Benchmark_and_Model_for_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.10660-b31b1b.svg)](http://arxiv.org/abs/2207.10660) | :heavy_minus_sign: |
| Masked Scene Contrast: A Scalable Framework for Unsupervised 3D Representation Learning | [![GitHub](https://img.shields.io/github/stars/Pointcept/Pointcept?style=flat)](https://github.com/Pointcept/Pointcept) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Masked_Scene_Contrast_A_Scalable_Framework_for_Unsupervised_3D_Representation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14191-b31b1b.svg)](http://arxiv.org/abs/2303.14191) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1FgNw8YjjHs) |
| Paired-Point Lifting for Enhanced Privacy-Preserving Visual Localization | [![GitHub](https://img.shields.io/github/stars/Fusroda-h/ppl?style=flat)](https://github.com/Fusroda-h/ppl) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Paired-Point_Lifting_for_Enhanced_Privacy-Preserving_Visual_Localization_CVPR_2023_paper.pdf) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PAaRZjsTyFc) |
| Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://pals.ttic.edu/p/score-jacobian-chaining) <br /> [![GitHub](https://img.shields.io/github/stars/pals-ttic/sjc?style=flat)](https://github.com/pals-ttic/sjc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Score_Jacobian_Chaining_Lifting_Pretrained_2D_Diffusion_Models_for_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00774-b31b1b.svg)](http://arxiv.org/abs/2212.00774) | :heavy_minus_sign: |
| gSDF: Geometry-Driven Signed Distance Functions for 3D Hand-Object Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zerchen.github.io/projects/gsdf.html) <br /> [![GitHub](https://img.shields.io/github/stars/zerchen/gSDF?style=flat)](https://github.com/zerchen/gSDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_gSDF_Geometry-Driven_Signed_Distance_Functions_for_3D_Hand-Object_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11970-b31b1b.svg)](http://arxiv.org/abs/2304.11970) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cchVcU32Zlo) |
| Accidental Light Probes | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://kovenyu.com/alp/) <br /> [![GitHub](https://img.shields.io/github/stars/KovenYu/ALP?style=flat)](https://github.com/KovenYu/ALP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Accidental_Light_Probes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.05211-b31b1b.svg)](http://arxiv.org/abs/2301.05211) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WxfuC1GTnJ8) |
| Learning to Predict Scene-Level Implicit 3D from Posed RGBD Data | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nileshkulkarni.github.io/d2drdf/) <br /> [![GitHub](https://img.shields.io/github/stars/nileshkulkarni/d2drdf?style=flat)](https://github.com/nileshkulkarni/d2drdf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kulkarni_Learning_To_Predict_Scene-Level_Implicit_3D_From_Posed_RGBD_Data_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.08671-b31b1b.svg)](https://arxiv.org/abs/2306.08671) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cp7iMF9JWHM) |
| DPF: Learning Dense Prediction Fields with Weak Supervision | [![GitHub](https://img.shields.io/github/stars/cxx226/DPF?style=flat)](https://github.com/cxx226/DPF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_DPF_Learning_Dense_Prediction_Fields_With_Weak_Supervision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16890-b31b1b.svg)](http://arxiv.org/abs/2303.16890) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LUruPFAimZk) |
| DIFu: Depth-Guided Implicit Function for Clothed Human Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eadcat.github.io/DIFu/) <br /> [![GitHub](https://img.shields.io/github/stars/EadCat/DIFu?style=flat)](https://github.com/EadCat/DIFu) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_DIFu_Depth-Guided_Implicit_Function_for_Clothed_Human_Reconstruction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uNMnCeBVWak) |
| OrienterNet: Visual Localization in 2D Public Maps with Neural Matching | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://psarlin.com/orienternet/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/OrienterNet?style=flat)](https://github.com/facebookresearch/OrienterNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sarlin_OrienterNet_Visual_Localization_in_2D_Public_Maps_With_Neural_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02009-b31b1b.svg)](http://arxiv.org/abs/2304.02009) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wglW8jnupSs) |
| Im2Hands: Learning Attentive Implicit Representation of Interacting Two-Hand Shapes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jyunlee.github.io/projects/implicit-two-hands/) <br /> [![GitHub](https://img.shields.io/github/stars/jyunlee/Im2Hands?style=flat)](https://github.com/jyunlee/Im2Hands) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Im2Hands_Learning_Attentive_Implicit_Representation_of_Interacting_Two-Hand_Shapes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14348-b31b1b.svg)](http://arxiv.org/abs/2302.14348) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hBSeN222Um4) |
| Structured 3D Features for Reconstructing Controllable Avatars | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://enriccorona.github.io/s3f/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Corona_Structured_3D_Features_for_Reconstructing_Controllable_Avatars_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06820-b31b1b.svg)](http://arxiv.org/abs/2212.06820) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mcZGcQ6L-2s) |
| Delving Into Discrete Normalizing Flows on SO(3) Manifold for Probabilistic Rotation Modeling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pku-epic.github.io/RotationNormFlow/) <br /> [![GitHub](https://img.shields.io/github/stars/PKU-EPIC/RotationNormFlow?style=flat)](https://github.com/PKU-EPIC/RotationNormFlow) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Delving_Into_Discrete_Normalizing_Flows_on_SO3_Manifold_for_Probabilistic_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03937-b31b1b.svg)](http://arxiv.org/abs/2304.03937) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0t_GyLGsmV8) |
| High-Fidelity 3D Human Digitization from Single 2K Resolution Images <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sanghunhan92.github.io/conference/2K2K/) <br /> [![GitHub](https://img.shields.io/github/stars/SangHunHan92/2K2K?style=flat)](https://github.com/SangHunHan92/2K2K) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Han_High-Fidelity_3D_Human_Digitization_From_Single_2K_Resolution_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15108-b31b1b.svg)](http://arxiv.org/abs/2303.15108) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2IE0NMxFBOU) |
| Learning 3D-Aware Image Synthesis with Unknown Pose Distribution | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vivianszf.github.io/pof3d/) <br /> [![GitHub](https://img.shields.io/github/stars/VivianSZF/pof3d?style=flat)](https://github.com/VivianSZF/pof3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shi_Learning_3D-Aware_Image_Synthesis_With_Unknown_Pose_Distribution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.07702-b31b1b.svg)](http://arxiv.org/abs/2301.07702) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9igv1GJZ5b0) |
| DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dogyoonlee.github.io/dpnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/dogyoonlee/DP-NeRF?style=flat)](https://github.com/dogyoonlee/DP-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_DP-NeRF_Deblurred_Neural_Radiance_Field_With_Physical_Scene_Priors_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12046-b31b1b.svg)](https://arxiv.org/abs/2211.12046) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tj6dJGvO3zI) |
| Recovering 3D Hand Mesh Sequence from a Single Blurry Image: A New Dataset and Temporal Unfolding | [![GitHub](https://img.shields.io/github/stars/JaehaKim97/BlurHand_RELEASE?style=flat)](https://github.com/JaehaKim97/BlurHand_RELEASE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Oh_Recovering_3D_Hand_Mesh_Sequence_From_a_Single_Blurry_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15417-b31b1b.svg)](http://arxiv.org/abs/2303.15417) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iRmsXhqsoys) |
| Visibility Aware Human-Object Interaction Tracking from Single RGB Camera | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://virtualhumans.mpi-inf.mpg.de/VisTracker/) <br /> [![GitHub](https://img.shields.io/github/stars/xiexh20/VisTracker?style=flat)](https://github.com/xiexh20/VisTracker) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Visibility_Aware_Human-Object_Interaction_Tracking_From_Single_RGB_Camera_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16479-b31b1b.svg)](http://arxiv.org/abs/2303.16479) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YzLkOJdvRRE) |
| SMOC-Net: Leveraging Camera Pose for Self-Supervised Monocular Object Pose Estimation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_SMOC-Net_Leveraging_Camera_Pose_for_Self-Supervised_Monocular_Object_Pose_Estimation_CVPR_2023_paper.pdf) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NkWq5WBJtRY) |
| Curricular Object Manipulation in LiDAR-based Object Detection | [![GitHub](https://img.shields.io/github/stars/ZZY816/COM?style=flat)](https://github.com/ZZY816/COM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Curricular_Object_Manipulation_in_LiDAR-Based_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04248-b31b1b.svg)](http://arxiv.org/abs/2304.04248) | :heavy_minus_sign: |
| SeSDF: Self-Evolved Signed Distance Field for Implicit 3D Clothed Human Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yukangcao.github.io/SeSDF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_SeSDF_Self-Evolved_Signed_Distance_Field_for_Implicit_3D_Clothed_Human_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00359-b31b1b.svg)](http://arxiv.org/abs/2304.00359) | :heavy_minus_sign: |
| MonoATT: Online Monocular 3D Object Detection with Adaptive Token Transformer | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_MonoATT_Online_Monocular_3D_Object_Detection_With_Adaptive_Token_Transformer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13018-b31b1b.svg)](http://arxiv.org/abs/2303.13018) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=U0Nb85dUw4E) |
| Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion | [![GitHub](https://img.shields.io/github/stars/google-research/nerf-from-image?style=flat)](https://github.com/google-research/nerf-from-image) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pavllo_Shape_Pose_and_Appearance_From_a_Single_Image_via_Bootstrapped_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11674-b31b1b.svg)](http://arxiv.org/abs/2211.11674) | :heavy_minus_sign: |
| High Fidelity 3D Hand Shape Reconstruction via Scalable Graph Frequency Decomposition | [![GitHub](https://img.shields.io/github/stars/tyluann/FreqHand?style=flat)](https://github.com/tyluann/FreqHand) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Luan_High_Fidelity_3D_Hand_Shape_Reconstruction_via_Scalable_Graph_Frequency_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.05541-b31b1b.svg)](http://arxiv.org/abs/2307.05541) | :heavy_minus_sign: |
| NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_NeRDi_Single-View_NeRF_Synthesis_With_Language-Guided_Diffusion_As_General_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03267-b31b1b.svg)](http://arxiv.org/abs/2212.03267) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=K0IcBBfEwCc) |
| ACL-SPC: Adaptive Closed-Loop System for Self-Supervised Point Cloud Completion | [![GitHub](https://img.shields.io/github/stars/Sangminhong/ACL-SPC_PyTorch?style=flat)](https://github.com/Sangminhong/ACL-SPC_PyTorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hong_ACL-SPC_Adaptive_Closed-Loop_System_for_Self-Supervised_Point_Cloud_Completion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01979-b31b1b.svg)](https://arxiv.org/abs/2303.01979) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Hg5re5hkR5M) |
| Self-Positioning Point-based Transformer for Point Cloud Understanding | [![GitHub](https://img.shields.io/github/stars/mlvlab/SPoTr?style=flat)](https://github.com/mlvlab/SPoTr) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Self-Positioning_Point-Based_Transformer_for_Point_Cloud_Understanding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16450-b31b1b.svg)](http://arxiv.org/abs/2303.16450) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-C6d83rXm1I) |
| H2ONet: Hand-Occlusion-and-Orientation-Aware Network for Real-Time 3D Hand Mesh Reconstruction | [![GitHub](https://img.shields.io/github/stars/hxwork/H2ONet_Pytorch?style=flat)](https://github.com/hxwork/H2ONet_Pytorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_H2ONet_Hand-Occlusion-and-Orientation-Aware_Network_for_Real-Time_3D_Hand_Mesh_Reconstruction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JN-G8ePC3Mk) |
| A Probabilistic Attention Model with Occlusion-Aware Texture Regression for 3D Hand Reconstruction from a Single RGB Image | [![GitHub](https://img.shields.io/github/stars/ZhehengJiangLancaster/AMVUR?style=flat)](https://github.com/ZhehengJiangLancaster/AMVUR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_A_Probabilistic_Attention_Model_With_Occlusion-Aware_Texture_Regression_for_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14299-b31b1b.svg)](http://arxiv.org/abs/2304.14299) | :heavy_minus_sign: |
| Neural Voting Field for Camera-Space 3D Hand Pose Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://linhuang17.github.io/NVF/) <br /> [![GitHub](https://img.shields.io/github/stars/LinHuang17/NVF-code?style=flat)](https://github.com/LinHuang17/NVF-code) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Neural_Voting_Field_for_Camera-Space_3D_Hand_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.04328-b31b1b.svg)](http://arxiv.org/abs/2305.04328) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L2ROmnsr5uE) |
| PLIKS: A Pseudo-Linear Inverse Kinematic Solver for 3D Human Body Estimation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/karShetty/PLIKS?style=flat)](https://github.com/karShetty/PLIKS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shetty_PLIKS_A_Pseudo-Linear_Inverse_Kinematic_Solver_for_3D_Human_Body_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11734-b31b1b.svg)](http://arxiv.org/abs/2211.11734) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=71k_WLn32UM) |
| Distilling Neural Fields for Real-Time Articulated Shape Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jefftan969.github.io/dasr/) <br /> [![GitHub](https://img.shields.io/github/stars/jefftan969/dasr?style=flat)](https://github.com/jefftan969/dasr) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_Distilling_Neural_Fields_for_Real-Time_Articulated_Shape_Reconstruction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=taUtXtW8b3Q) |
| Power Bundle Adjustment for Large-Scale 3D Reconstruction | [![GitHub](https://img.shields.io/github/stars/NikolausDemmel/rootba?style=flat)](https://github.com/NikolausDemmel/rootba) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Weber_Power_Bundle_Adjustment_for_Large-Scale_3D_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.12834-b31b1b.svg)](http://arxiv.org/abs/2204.12834) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2DXJvJM2ExQ) |
| What You Can Reconstruct from a Shadow | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_What_You_Can_Reconstruct_From_a_Shadow_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| SparseFusion: Distilling View-Conditioned Diffusion for 3D Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sparsefusion.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/zhizdev/sparsefusion?style=flat)](https://github.com/zhizdev/sparsefusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_SparseFusion_Distilling_View-Conditioned_Diffusion_for_3D_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00792-b31b1b.svg)](http://arxiv.org/abs/2212.00792) | :heavy_minus_sign: |
| Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand Disentanglement | [![GitHub](https://img.shields.io/github/stars/XingqunQi-lab/Diverse-3D-Hand-Gesture-Prediction?style=flat)](https://github.com/XingqunQi-lab/Diverse-3D-Hand-Gesture-Prediction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qi_Diverse_3D_Hand_Gesture_Prediction_From_Body_Dynamics_by_Bilateral_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01765-b31b1b.svg)](http://arxiv.org/abs/2303.01765) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=i0pIlbdIh60) |
| Trap Attention: Monocular Depth Estimation with Manual Traps | [![GitHub](https://img.shields.io/github/stars/ICSResearch/TrapAttention?style=flat)](https://github.com/ICSResearch/TrapAttention) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ning_Trap_Attention_Monocular_Depth_Estimation_With_Manual_Traps_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Crowd3D: Towards Hundreds of People Reconstruction from a Single Image | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://cic.tju.edu.cn/faculty/likun/projects/Crowd3D/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/1020244018/Crowd3D?style=flat)](https://github.com/1020244018/Crowd3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_Crowd3D_Towards_Hundreds_of_People_Reconstruction_From_a_Single_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.09376-b31b1b.svg)](http://arxiv.org/abs/2301.09376) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4kInUqPHiDU) |
| PAniC-3D: Stylized Single-View 3D Reconstruction from Portraits of Anime Characters | [![GitHub](https://img.shields.io/github/stars/ShuhongChen/panic3d-anime-reconstruction?style=flat)](https://github.com/ShuhongChen/panic3d-anime-reconstruction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_PAniC-3D_Stylized_Single-View_3D_Reconstruction_From_Portraits_of_Anime_Characters_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14587-b31b1b.svg)](https://arxiv.org/abs/2303.14587) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7NosmLieg6A) |
| HS-Pose: Hybrid Scope Feature Extraction for Category-Level Object Pose Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lynne-zheng-linfang.github.io/hspose.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Lynne-Zheng-Linfang/HS-Pose?style=flat)](https://github.com/Lynne-Zheng-Linfang/HS-Pose) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_HS-Pose_Hybrid_Scope_Feature_Extraction_for_Category-Level_Object_Pose_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15743-b31b1b.svg)](https://arxiv.org/abs/2303.15743) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ctCuALHDk0Y) |
| A Hierarchical Representation Network for Accurate and Detailed Face Reconstruction from In-the-Wild Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://younglbw.github.io/HRN-homepage/) <br /> [![GitHub](https://img.shields.io/github/stars/youngLBW/HRN?style=flat)](https://github.com/youngLBW/HRN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lei_A_Hierarchical_Representation_Network_for_Accurate_and_Detailed_Face_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14434-b31b1b.svg)](http://arxiv.org/abs/2302.14434) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YAE0hVR3fQg) |
| Lite-Mono: A Lightweight CNN and Transformer Architecture for Self-Supervised Monocular Depth Estimation | [![GitHub](https://img.shields.io/github/stars/noahzn/Lite-Mono?style=flat)](https://github.com/noahzn/Lite-Mono) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Lite-Mono_A_Lightweight_CNN_and_Transformer_Architecture_for_Self-Supervised_Monocular_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13202-b31b1b.svg)](https://arxiv.org/abs/2211.13202) | :heavy_minus_sign: |
| SfM-TTR: Using Structure from Motion for Test-Time Refinement of Single-View Depth Networks | [![GitHub](https://img.shields.io/github/stars/serizba/SfM-TTR?style=flat)](https://github.com/serizba/SfM-TTR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Izquierdo_SfM-TTR_Using_Structure_From_Motion_for_Test-Time_Refinement_of_Single-View_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13551-b31b1b.svg)](https://arxiv.org/abs/2211.13551) | :heavy_minus_sign: |
| BITE: Beyond Priors for Improved Three-D Dog Pose Estimation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://bite.is.tue.mpg.de/) <br /> [![GitHub](https://img.shields.io/github/stars/runa91/bite_release?style=flat)](https://github.com/runa91/bite_release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ruegg_BITE_Beyond_Priors_for_Improved_Three-D_Dog_Pose_Estimation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mOeLtNk070E) |
| SinGRAF: Learning a 3D Generative Radiance Field for a Single Scene | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.computationalimaging.org/publications/singraf/) <br /> [![GitHub](https://img.shields.io/github/stars/SAITPublic/SinGRAF?style=flat)](https://github.com/SAITPublic/SinGRAF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Son_SinGRAF_Learning_a_3D_Generative_Radiance_Field_for_a_Single_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.17260-b31b1b.svg)](http://arxiv.org/abs/2211.17260) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Mmz_kloOcN4) |
| Flow Supervision for Deformable NeRF <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mightychaos.github.io/projects/fsdnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/MightyChaos/fsdnerf?style=flat)](https://github.com/MightyChaos/fsdnerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Flow_Supervision_for_Deformable_NeRF_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16333-b31b1b.svg)](http://arxiv.org/abs/2303.16333) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-fCMDXOjg-o) |
| Single Image Depth Prediction Made Better: A Multivariate Gaussian Take | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Single_Image_Depth_Prediction_Made_Better_A_Multivariate_Gaussian_Take_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.18164-b31b1b.svg)](http://arxiv.org/abs/2303.18164) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8m3HaRLGghs) |
| CARTO: Category and Joint Agnostic Reconstruction of ARTiculated Objects | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://carto.cs.uni-freiburg.de/) <br /> [![GitHub](https://img.shields.io/github/stars/robot-learning-freiburg/CARTO?style=flat)](https://github.com/robot-learning-freiburg/CARTO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Heppert_CARTO_Category_and_Joint_Agnostic_Reconstruction_of_ARTiculated_Objects_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15782-b31b1b.svg)](http://arxiv.org/abs/2303.15782) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nqImGPO5pn0) |
| PanoSwin: A Pano-Style Swin Transformer for Panorama Understanding | [![GitHub](https://img.shields.io/github/stars/1069066484/PanoSwinTransformerObjectDetection?style=flat)](https://github.com/1069066484/PanoSwinTransformerObjectDetection) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ling_PanoSwin_A_Pano-Style_Swin_Transformer_for_Panorama_Understanding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14726-b31b1b.svg)](https://arxiv.org/abs/2308.14726) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=R1IfttFJ5Q4) |
| CP<sup>3</sup>: Channel Pruning Plug-In for Point-based Networks | [![GitHub](https://img.shields.io/github/stars/midea-ai/CP3?style=flat)](https://github.com/midea-ai/CP3) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_CP3_Channel_Pruning_Plug-In_for_Point-Based_Networks_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13097-b31b1b.svg)](https://arxiv.org/abs/2303.13097) | :heavy_minus_sign: |
| PC<sup>2</sup>: Projection-Conditioned Point Cloud Diffusion for Single-Image 3D Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lukemelas.github.io/projection-conditioned-point-cloud-diffusion/) <br /> [![GitHub](https://img.shields.io/github/stars/lukemelas/projection-conditioned-point-cloud-diffusion?style=flat)](https://github.com/lukemelas/projection-conditioned-point-cloud-diffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Melas-Kyriazi_PC2_Projection-Conditioned_Point_Cloud_Diffusion_for_Single-Image_3D_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.10668-b31b1b.svg)](https://arxiv.org/abs/2302.10668) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kAkwpsT1pRA) |
| On the Importance of Accurate Geometry Data for Dense 3D Vision Tasks | [![GitHub](https://img.shields.io/github/stars/Junggy/HAMMER-dataset?style=flat)](https://github.com/Junggy/HAMMER-dataset) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jung_On_the_Importance_of_Accurate_Geometry_Data_for_Dense_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14840-b31b1b.svg)](http://arxiv.org/abs/2303.14840) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pCRoRuMmaSA) |
| Cross-Domain 3D Hand Pose Estimation with Dual Modalities | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Cross-Domain_3D_Hand_Pose_Estimation_With_Dual_Modalities_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7vAg44jjIlg) |
| RealFusion 360&deg; Reconstruction of Any Object from a Single Image | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lukemelas.github.io/realfusion) <br /> [![GitHub](https://img.shields.io/github/stars/lukemelas/realfusion?style=flat)](https://github.com/lukemelas/realfusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Melas-Kyriazi_RealFusion_360deg_Reconstruction_of_Any_Object_From_a_Single_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.10663-b31b1b.svg)](https://arxiv.org/abs/2302.10663) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EExD5zaxctE) |
| Sampling Is Matter: Point-Guided 3D Human Mesh Reconstruction | [![GitHub](https://img.shields.io/github/stars/DCVL-3D/PointHMR_release?style=flat)](https://github.com/DCVL-3D/PointHMR_release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Sampling_Is_Matter_Point-Guided_3D_Human_Mesh_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.09502-b31b1b.svg)](http://arxiv.org/abs/2304.09502) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VZA5Y0xgtBg) |
| Knowledge Distillation for 6D Pose Estimation by Aligning Distributions of Local Predictions | [![GitHub](https://img.shields.io/github/stars/GUOShuxuan/kd-6d-pose-adlp?style=flat)](https://github.com/GUOShuxuan/kd-6d-pose-adlp) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Knowledge_Distillation_for_6D_Pose_Estimation_by_Aligning_Distributions_of_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.14971-b31b1b.svg)](http://arxiv.org/abs/2205.14971) | :heavy_minus_sign: |
| BAAM: Monocular 3D Pose and Shape Reconstruction with Bi-Contextual Attention Module and Attention-Guided Modeling | [![GitHub](https://img.shields.io/github/stars/gywns6287/BAAM?style=flat)](https://github.com/gywns6287/BAAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_BAAM_Monocular_3D_Pose_and_Shape_Reconstruction_With_Bi-Contextual_Attention_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Single View Scene Scale Estimation using Scale Field | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Single_View_Scene_Scale_Estimation_Using_Scale_Field_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Learning Articulated Shape with Keypoint Pseudo-Labels from Web Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://statho.github.io/projects/animals3d/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/statho/animals3d?style=flat)](https://github.com/statho/animals3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Stathopoulos_Learning_Articulated_Shape_With_Keypoint_Pseudo-Labels_From_Web_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14396-b31b1b.svg)](http://arxiv.org/abs/2304.14396) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tbFrsnW9XhY) |
| Deformable Mesh Transformer for 3D Human Mesh Recovery | [![GitHub](https://img.shields.io/github/stars/yusukey03012/DeFormer?style=flat)](https://github.com/yusukey03012/DeFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yoshiyasu_Deformable_Mesh_Transformer_for_3D_Human_Mesh_Recovery_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
