# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>New collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
                <img src="http://img.shields.io/badge/CVPR-2024-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/low-level-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/deep-learning-architectures-and-techniques.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Segmentation, Grouping and Shape Analysis

![Section Papers](https://img.shields.io/badge/Section%20Papers-111-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-79-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-84-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-81-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Efficient Semantic Segmentation by Altering Resolutions for Compressed Videos | [![GitHub](https://img.shields.io/github/stars/THU-LYJ-Lab/AR-Seg?style=flat)](https://github.com/THU-LYJ-Lab/AR-Seg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Efficient_Semantic_Segmentation_by_Altering_Resolutions_for_Compressed_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07224-b31b1b.svg)](http://arxiv.org/abs/2303.07224) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WN9ok0xd0po) |
| Vision Transformers are Good Mask Auto-Labelers | [![GitHub](https://img.shields.io/github/stars/NVlabs/mask-auto-labeler?style=flat)](https://github.com/NVlabs/mask-auto-labeler) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lan_Vision_Transformers_Are_Good_Mask_Auto-Labelers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.03992-b31b1b.svg)](http://arxiv.org/abs/2301.03992) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=n9cmRYzKNVc) |
| Visual Recognition by Request | [![GitHub](https://img.shields.io/github/stars/chufengt/Visual-Recognition-by-Request?style=flat)](https://github.com/chufengt/Visual-Recognition-by-Request) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Visual_Recognition_by_Request_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.14227-b31b1b.svg)](http://arxiv.org/abs/2207.14227) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0wuVwYPcSQg) |
| Ultra-High Resolution Segmentation with Ultra-Rich Context: A Novel Benchmark | [![GitHub](https://img.shields.io/github/stars/jankyee/URUR?style=flat)](https://github.com/jankyee/URUR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Ultra-High_Resolution_Segmentation_With_Ultra-Rich_Context_A_Novel_Benchmark_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10899-b31b1b.svg)](http://arxiv.org/abs/2305.10899) | :heavy_minus_sign: |
| AttentionShift: Iteratively Estimated Part-based Attention Map for Pointly Supervised Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/MingXiangL/AttentionShift?style=flat)](https://github.com/MingXiangL/AttentionShift) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liao_AttentionShift_Iteratively_Estimated_Part-Based_Attention_Map_for_Pointly_Supervised_Instance_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| MDQE: Mining Discriminative Query Embeddings to Segment Occluded Instances on Challenging Videos | [![GitHub](https://img.shields.io/github/stars/MinghanLi/MDQE_CVPR2023?style=flat)](https://github.com/MinghanLi/MDQE_CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MDQE_Mining_Discriminative_Query_Embeddings_To_Segment_Occluded_Instances_on_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14395-b31b1b.svg)](http://arxiv.org/abs/2303.14395) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cK1SvHJgYYc) |
| Look Before You Match: Instance Understanding Matters in Video Object Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Look_Before_You_Match_Instance_Understanding_Matters_in_Video_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06826-b31b1b.svg)](http://arxiv.org/abs/2212.06826) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Sd7iS5Icf30) |
| SIM: Semantic-Aware Instance Mask Generation for Box-Supervised Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/lslrh/SIM?style=flat)](https://github.com/lslrh/SIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_SIM_Semantic-Aware_Instance_Mask_Generation_for_Box-Supervised_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08578-b31b1b.svg)](http://arxiv.org/abs/2303.08578) | :heavy_minus_sign: |
| EFEM: Equivariant Neural Field Expectation Maximization for 3D Object Segmentation without Scene Supervision | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.cis.upenn.edu/~leijh/projects/efem/) <br /> [![GitHub](https://img.shields.io/github/stars/JiahuiLei/EFEM?style=flat)](https://github.com/JiahuiLei/EFEM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lei_EFEM_Equivariant_Neural_Field_Expectation_Maximization_for_3D_Object_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15440-b31b1b.svg)](http://arxiv.org/abs/2303.15440) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=chPX8_iUxEw) |
| Camouflaged Object Detection with Feature Decomposition and Edge Reconstruction | [![GitHub](https://img.shields.io/github/stars/ChunmingHe/FEDER?style=flat)](https://github.com/ChunmingHe/FEDER) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Camouflaged_Object_Detection_With_Feature_Decomposition_and_Edge_Reconstruction_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| LOCATE: Localize and Transfer Object Parts for Weakly Supervised Affordance Grounding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://reagan1311.github.io/locate/) <br /> [![GitHub](https://img.shields.io/github/stars/Reagan1311/LOCATE?style=flat)](https://github.com/Reagan1311/LOCATE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_LOCATE_Localize_and_Transfer_Object_Parts_for_Weakly_Supervised_Affordance_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09665-b31b1b.svg)](http://arxiv.org/abs/2303.09665) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RLHansdFxII) |
| OneFormer: One Transformer to Rule Universal Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://praeclarumjj3.github.io/oneformer/) <br /> [![GitHub](https://img.shields.io/github/stars/SHI-Labs/OneFormer?style=flat)](https://github.com/SHI-Labs/OneFormer) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-demo-FFD21F.svg)](https://huggingface.co/spaces/shi-labs/OneFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jain_OneFormer_One_Transformer_To_Rule_Universal_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06220-b31b1b.svg)](http://arxiv.org/abs/2211.06220) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CIU3udcaoW4) |
| Mask-Free Video Instance Segmentation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.vis.xyz/pub/maskfreevis/) <br /> [![GitHub](https://img.shields.io/github/stars/SysCV/MaskFreeVIS?style=flat)](https://github.com/SysCV/MaskFreeVIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ke_Mask-Free_Video_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15904-b31b1b.svg)](http://arxiv.org/abs/2303.15904) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7P7PX3gd14I) |
| Less is more: Reducing Task and Model Complexity for 3D Point Cloud Semantic Segmentation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://project.luisli.org/lim3d/) <br /> [![GitHub](https://img.shields.io/github/stars/l1997i/lim3d?style=flat)](https://github.com/l1997i/lim3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Less_Is_More_Reducing_Task_and_Model_Complexity_for_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11203-b31b1b.svg)](http://arxiv.org/abs/2303.11203) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5f-waFfjsOY) |
| InstMove: Instance Motion for Object-Centric Video Segmentation | [![GitHub](https://img.shields.io/github/stars/wjf5203/VNext?style=flat)](https://github.com/wjf5203/VNext) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_InstMove_Instance_Motion_for_Object-Centric_Video_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08132-b31b1b.svg)](http://arxiv.org/abs/2303.08132) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GzH8hLteEIY) |
| The Devil is in the Points: Weakly Semi-Supervised Instance Segmentation via Point-Guided Mask Representation | [![GitHub](https://img.shields.io/github/stars/clovaai/PointWSSIS?style=flat)](https://github.com/clovaai/PointWSSIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_The_Devil_Is_in_the_Points_Weakly_Semi-Supervised_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15062-b31b1b.svg)](http://arxiv.org/abs/2303.15062) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iGlDjXFO6TY) |
| Edge-Aware Regional Message Passing Controller for Image Forgery Localization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Edge-Aware_Regional_Message_Passing_Controller_for_Image_Forgery_Localization_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2pDR-hOFcQw) |
| Interactive Segmentation as Gaussion Process Classification <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/zmhhmz/GPCIS_CVPR2023?style=flat)](https://github.com/zmhhmz/GPCIS_CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Interactive_Segmentation_As_Gaussion_Process_Classification_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14578-b31b1b.svg)](https://arxiv.org/abs/2302.14578) |[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mapyH-WujhY) |
| Semantic-Promoted Debiasing and Background Disambiguation for Zero-Shot Instance Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://henghuiding.github.io/D2Zero/) <br /> [![GitHub](https://img.shields.io/github/stars/heshuting555/D2Zero?style=flat)](https://github.com/heshuting555/D2Zero) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Semantic-Promoted_Debiasing_and_Background_Disambiguation_for_Zero-Shot_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.13173-b31b1b.svg)](https://arxiv.org/abs/2305.13173) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-Wci6cJAyRE) |
| Adversarially Masking Synthetic to Mimic Real: Adaptive Noise Injection for Point Cloud Segmentation Adaptation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Adversarially_Masking_Synthetic_To_Mimic_Real_Adaptive_Noise_Injection_for_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L0z2SOw2Yvg) |
| Generative Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/fudan-zvg/GSS?style=flat)](https://github.com/fudan-zvg/GSS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Generative_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11316-b31b1b.svg)](http://arxiv.org/abs/2303.11316) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bw5z5RU91ps) |
| Modeling the Distributional Uncertainty for Salient Object Detection Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://npucvr.github.io/Distributional_uncer/) <br /> [![GitHub](https://img.shields.io/github/stars/txynwpu/Distributional_uncertainty_SOD?style=flat)](https://github.com/txynwpu/Distributional_uncertainty_SOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Modeling_the_Distributional_Uncertainty_for_Salient_Object_Detection_Models_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4S5tWc2uMKo) |
| Simultaneously Short- and Long-Term Temporal Modeling for Semi-Supervised Video Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lao_Simultaneously_Short-_and_Long-Term_Temporal_Modeling_for_Semi-Supervised_Video_Semantic_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OqkRQJoh4d0) |
| Out-of-Candidate Rectification for Weakly Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/sennnnn/Out-of-Candidate-Rectification?style=flat)](https://github.com/sennnnn/Out-of-Candidate-Rectification) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cheng_Out-of-Candidate_Rectification_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12268-b31b1b.svg)](http://arxiv.org/abs/2211.12268) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JQajrSReXkU) |
| DynaMask: Dynamic Mask Selection for Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/lslrh/DynaMask?style=flat)](https://github.com/lslrh/DynaMask) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_DynaMask_Dynamic_Mask_Selection_for_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07868-b31b1b.svg)](http://arxiv.org/abs/2303.07868) | :heavy_minus_sign: |
| MSeg3D: Multi-Modal 3D Semantic Segmentation for Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/jialeli1/lidarseg3d?style=flat)](https://github.com/jialeli1/lidarseg3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MSeg3D_Multi-Modal_3D_Semantic_Segmentation_for_Autonomous_Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08600-b31b1b.svg)](http://arxiv.org/abs/2303.08600) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lRLxOfHrfmI) |
| Generalizable Local Feature Pre-Training for Deformable Shape Analysis <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/pvnieo/vader?style=flat)](https://github.com/pvnieo/vader) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Attaiki_Generalizable_Local_Feature_Pre-Training_for_Deformable_Shape_Analysis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15104-b31b1b.svg)](http://arxiv.org/abs/2303.15104) | :heavy_minus_sign: |
| Understanding and Improving Features Learned in Deep Functional Maps <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/pvnieo/clover?style=flat)](https://github.com/pvnieo/clover) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Attaiki_Understanding_and_Improving_Features_Learned_in_Deep_Functional_Maps_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16527-b31b1b.svg)](http://arxiv.org/abs/2303.16527) | :heavy_minus_sign: |
| G-MSM: Unsupervised Multi-Shape Matching with Graph-based Affinity Priors | [![GitHub](https://img.shields.io/github/stars/marvin-eisenberger/gmsm-matching?style=flat)](https://github.com/marvin-eisenberger/gmsm-matching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Eisenberger_G-MSM_Unsupervised_Multi-Shape_Matching_With_Graph-Based_Affinity_Priors_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02910-b31b1b.svg)](https://arxiv.org/abs/2212.02910) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vEE9gQ6RFoU) |
| Continual Semantic Segmentation with Automatic Memory Sample Selection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Continual_Semantic_Segmentation_With_Automatic_Memory_Sample_Selection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05015-b31b1b.svg)](http://arxiv.org/abs/2304.05015) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Bcrh9_76PTY) |
| FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://freeseg.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/bytedance/FreeSeg?style=flat)](https://github.com/bytedance/FreeSeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_FreeSeg_Unified_Universal_and_Open-Vocabulary_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17225-b31b1b.svg)](http://arxiv.org/abs/2303.17225) | :heavy_minus_sign: |
| Object Discovery from Motion-Guided Tokens | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zpbao.github.io/projects/MoTok/) <br /> [![GitHub](https://img.shields.io/github/stars/zpbao/MoTok?style=flat)](https://github.com/zpbao/MoTok/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_Object_Discovery_From_Motion-Guided_Tokens_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15555-b31b1b.svg)](http://arxiv.org/abs/2303.15555) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VgTrLMQIdgg) |
| Efficient Mask Correction for Click-based Interactive Image Segmentation | [![GitHub](https://img.shields.io/github/stars/feiaxyt/EMC-Click?style=flat)](https://github.com/feiaxyt/EMC-Click) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Efficient_Mask_Correction_for_Click-Based_Interactive_Image_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Balancing Logit Variation for Long-Tailed Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/grantword8/BLV?style=flat)](https://github.com/grantword8/BLV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Balancing_Logit_Variation_for_Long-Tailed_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.02061-b31b1b.svg)](https://arxiv.org/abs/2306.02061) | :heavy_minus_sign: |
| Fuzzy Positive Learning for Semi-Supervised Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qiao_Fuzzy_Positive_Learning_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.08519-b31b1b.svg)](http://arxiv.org/abs/2210.08519) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PVZRs1E2pWI) |
| Learning Open-Vocabulary Semantic Segmentation Models from Natural Language Supervision | [![GitHub](https://img.shields.io/github/stars/Jazzcharles/OVSegmentor?style=flat)](https://github.com/Jazzcharles/OVSegmentor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Learning_Open-Vocabulary_Semantic_Segmentation_Models_From_Natural_Language_Supervision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.09121-b31b1b.svg)](http://arxiv.org/abs/2301.09121)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=j4FSgpEP4XM) |
| Improving Graph Representation for Point Cloud Segmentation via Attentive Filtering | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Improving_Graph_Representation_for_Point_Cloud_Segmentation_via_Attentive_Filtering_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| BUOL: A Bottom-Up Framework with Occupancy-Aware Lifting for Panoptic 3D Scene Reconstruction from a Single Image | [![GitHub](https://img.shields.io/github/stars/chtsy/buol?style=flat)](https://github.com/chtsy/buol) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chu_BUOL_A_Bottom-Up_Framework_With_Occupancy-Aware_Lifting_for_Panoptic_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.00965-b31b1b.svg)](http://arxiv.org/abs/2306.00965)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pOZq5YbtBww) |
| ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lkhl.github.io/ACSeg/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_ACSeg_Adaptive_Conceptualization_for_Unsupervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.05944-b31b1b.svg)](http://arxiv.org/abs/2210.05944) | :heavy_minus_sign: |
| CCuantuMM: Cycle-Consistent Quantum-Hybrid Matching of Multiple Shapes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://4dqv.mpi-inf.mpg.de/CCuantuMM/) <br /> [![GitHub](https://img.shields.io/github/stars/HarshilBhatia/CCuantuMM?style=flat)](https://github.com/HarshilBhatia/CCuantuMM/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bhatia_CCuantuMM_Cycle-Consistent_Quantum-Hybrid_Matching_of_Multiple_Shapes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16202-b31b1b.svg)](https://arxiv.org/abs/2303.16202) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gwBhXkJ5W3k) |
| Hierarchical Dense Correlation Distillation for Few-Shot Segmentation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/Pbihao/HDMNet?style=flat)](https://github.com/Pbihao/HDMNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Peng_Hierarchical_Dense_Correlation_Distillation_for_Few-Shot_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14652-b31b1b.svg)](http://arxiv.org/abs/2303.14652)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nFYTxfngUY0) |
| UniDAformer: Unified Domain Adaptive Panoptic Segmentation Transformer via Hierarchical Mask Calibration | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_UniDAformer_Unified_Domain_Adaptive_Panoptic_Segmentation_Transformer_via_Hierarchical_Mask_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.15083-b31b1b.svg)](http://arxiv.org/abs/2206.15083)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1k3bSwyaPEw) |
| FedSeg: Class-Heterogeneous Federated Learning for Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Miao_FedSeg_Class-Heterogeneous_Federated_Learning_for_Semantic_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=v834xUST26c) |
| Understanding Imbalanced Semantic Segmentation through Neural Collapse | [![GitHub](https://img.shields.io/github/stars/NeuralCollapseApplications/Semantic-Segmentation?style=flat)](https://github.com/NeuralCollapseApplications/Semantic-Segmentation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhong_Understanding_Imbalanced_Semantic_Segmentation_Through_Neural_Collapse_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01100-b31b1b.svg)](http://arxiv.org/abs/2301.01100) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0ZMfyRY5zjE) |
| Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/LiheYoung/UniMatch?style=flat)](https://github.com/LiheYoung/UniMatch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Revisiting_Weak-to-Strong_Consistency_in_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.09910-b31b1b.svg)](http://arxiv.org/abs/2208.09910) | :heavy_minus_sign: |
| PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://colin97.github.io/PartSLIP_page/) <br /> [![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)](https://drive.google.com/drive/u/3/folders/19j6PZfW8TDQ1ifHZwHIhn6X4BHjYRFCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_PartSLIP_Low-Shot_Part_Segmentation_for_3D_Point_Clouds_via_Pretrained_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01558-b31b1b.svg)](http://arxiv.org/abs/2212.01558)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VGORtR2mJog) |
| PartDistillation: Learning Parts from Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/facebookresearch/PartDistillation?style=flat)](https://github.com/facebookresearch/PartDistillation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cho_PartDistillation_Learning_Parts_From_Instance_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5T5Z0F1J8oY) |
| Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ayankumarbhunia.github.io/Sketch2Saliency/) <br /> [![GitHub](https://img.shields.io/github/stars/AyanKumarBhunia/Sketch2Saliency?style=flat)](https://github.com/AyanKumarBhunia/Sketch2Saliency) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bhunia_Sketch2Saliency_Learning_To_Detect_Salient_Objects_From_Human_Drawings_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11502-b31b1b.svg)](http://arxiv.org/abs/2303.11502)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IsbE365ByYI) |
| FastInst: A Simple Query-based Model for Real-Time Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/junjiehe96/FastInst?style=flat)](https://github.com/junjiehe96/FastInst) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_FastInst_A_Simple_Query-Based_Model_for_Real-Time_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08594-b31b1b.svg)](http://arxiv.org/abs/2303.08594) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JxHuMMu6N50) |
| SemiCVT: Semi-Supervised Convolutional Vision Transformer for Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_SemiCVT_Semi-Supervised_Convolutional_Vision_Transformer_for_Semantic_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Semantic Human Parsing via Scalable Semantic Transfer Over Multiple Label Domains | [![GitHub](https://img.shields.io/github/stars/yangjie-cv/SST?style=flat)](https://github.com/yangjie-cv/SST) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Semantic_Human_Parsing_via_Scalable_Semantic_Transfer_Over_Multiple_Label_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04140-b31b1b.svg)](http://arxiv.org/abs/2304.04140) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PHRVCSAYEHU) |
| Open-Set Semantic Segmentation for Point Clouds via Adversarial Prototype Framework | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Open-Set_Semantic_Segmentation_for_Point_Clouds_via_Adversarial_Prototype_Framework_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_wV90rUkfhU) |
| Hunting Sparsity: Density-Guided Contrastive Learning for Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/Gavinwxy/DGCL?style=flat)](https://github.com/Gavinwxy/DGCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Hunting_Sparsity_Density-Guided_Contrastive_Learning_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| A Generalized Framework for Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/miranheo/GenVIS?style=flat)](https://github.com/miranheo/GenVIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Heo_A_Generalized_Framework_for_Video_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.08834-b31b1b.svg)](http://arxiv.org/abs/2211.08834) | :heavy_minus_sign: |
| SimpSON: Simplifying Photo Cleanup with Single-Click Distracting Object Segmentation Network | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://simpson-cvpr23.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/hmchuong/SimpSON?style=flat)](https://github.com/hmchuong/SimpSON) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huynh_SimpSON_Simplifying_Photo_Cleanup_With_Single-Click_Distracting_Object_Segmentation_Network_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.17624-b31b1b.svg)](https://arxiv.org/abs/2305.17624) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m4eIkwJUDfo) |
| Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud Sequence Representation Learning | [![GitHub](https://img.shields.io/github/stars/dongyh20/C2P?style=flat)](https://github.com/dongyh20/C2P) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Complete-to-Partial_4D_Distillation_for_Self-Supervised_Point_Cloud_Sequence_Representation_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05330-b31b1b.svg)](http://arxiv.org/abs/2212.05330) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_4C7vmLN0nM) |
| Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/dongliangcao/Self-Supervised-Multimodal-Shape-Matching?style=flat)](https://github.com/dongliangcao/Self-Supervised-Multimodal-Shape-Matching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Self-Supervised_Learning_for_Multimodal_Non-Rigid_3D_Shape_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10971-b31b1b.svg)](http://arxiv.org/abs/2303.10971) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cQX1OOne0bk) |
| Ultrahigh Resolution Image/Video Matting with Spatio-Temporal Sparsity | [![GitHub](https://img.shields.io/github/stars/nowsyn/sparsemat?style=flat)](https://github.com/nowsyn/sparsemat) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Ultrahigh_Resolution_ImageVideo_Matting_With_Spatio-Temporal_Sparsity_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Style Projected Clustering for Domain Generalized Semantic Segmentation | [![Gitee](https://gitee.com/mindspore/models/badge/star.svg?theme=dark)](https://gitee.com/mindspore/models/tree/master/research/cv/SPC-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Style_Projected_Clustering_for_Domain_Generalized_Semantic_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FVFvc8TH5eI) |
| MarS3D: A Plug-and-Play Motion-Aware Model for Semantic Segmentation on Multi-Scan 3D Point Clouds | [![GitHub](https://img.shields.io/github/stars/CVMI-Lab/MarS3D?style=flat)](https://github.com/CVMI-Lab/MarS3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_MarS3D_A_Plug-and-Play_Motion-Aware_Model_for_Semantic_Segmentation_on_Multi-Scan_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09316-b31b1b.svg)](https://arxiv.org/abs/2307.09316) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PPPyZkwvsvs) |
| Compositor: Bottom-Up Clustering and Compositing for Robust Part and Object Segmentation | [![GitHub](https://img.shields.io/github/stars/TACJu/Compositor?style=flat)](https://github.com/TACJu/Compositor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Compositor_Bottom-Up_Clustering_and_Compositing_for_Robust_Part_and_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07404-b31b1b.svg)](https://arxiv.org/abs/2306.07404) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SQlrky70y9A) |
| Dynamic Focus-Aware Positional Queries for Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/ziplab/FASeg?style=flat)](https://github.com/ziplab/FASeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Dynamic_Focus-Aware_Positional_Queries_for_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.01244-b31b1b.svg)](http://arxiv.org/abs/2204.01244) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LAut7f4mxsA) |
| HGFormer: Hierarchical Grouping Transformer for Domain Generalized Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/dingjiansw101/HGFormer?style=flat)](https://github.com/dingjiansw101/HGFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_HGFormer_Hierarchical_Grouping_Transformer_for_Domain_Generalized_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.13031-b31b1b.svg)](http://arxiv.org/abs/2305.13031) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tKMTUZAH0q0) |
| Marching-Primitives: Shape Abstraction from Signed Distance Function <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/ChirikjianLab/Marching-Primitives?style=flat)](https://github.com/ChirikjianLab/Marching-Primitives) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Marching-Primitives_Shape_Abstraction_From_Signed_Distance_Function_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13190-b31b1b.svg)](https://arxiv.org/abs/2303.13190) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SeiGaEcbOUA) |
| Multimodal Industrial Anomaly Detection via Hybrid Fusion | [![GitHub](https://img.shields.io/github/stars/nomewang/M3DM?style=flat)](https://github.com/nomewang/M3DM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Multimodal_Industrial_Anomaly_Detection_via_Hybrid_Fusion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00601-b31b1b.svg)](http://arxiv.org/abs/2303.00601) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=byZznDijY0U) |
| CLIP is also an Efficient Segmenter: A Text-Driven Approach for Weakly Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/linyq2117/CLIP-ES?style=flat)](https://github.com/linyq2117/CLIP-ES) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_CLIP_Is_Also_an_Efficient_Segmenter_A_Text-Driven_Approach_for_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.09506-b31b1b.svg)](http://arxiv.org/abs/2212.09506) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=a0mm9irbeoQ) |
| Weakly Supervised Semantic Segmentation via Adversarial Learning of Classifier and Reconstructor | [![GitHub](https://img.shields.io/github/stars/sangrockEG/ACR?style=flat)](https://github.com/sangrockEG/ACR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kweon_Weakly_Supervised_Semantic_Segmentation_via_Adversarial_Learning_of_Classifier_and_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Conjugate Product Graphs for Globally Optimal 2D-3D Shape Matching | [![GitHub](https://img.shields.io/github/stars/paul0noah/sm-2D3D?style=flat)](https://github.com/paul0noah/sm-2D3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Roetzer_Conjugate_Product_Graphs_for_Globally_Optimal_2D-3D_Shape_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11589-b31b1b.svg)](https://arxiv.org/abs/2211.11589) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=qr_-n8NHWC4) |
| Interactive Segmentation of Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rahul-goel.github.io/isrf) <br /> [![GitHub](https://img.shields.io/github/stars/rahul-goel/isrf_code?style=flat)](https://github.com/rahul-goel/isrf_code) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Goel_Interactive_Segmentation_of_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.13545-b31b1b.svg)](http://arxiv.org/abs/2212.13545) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fPW-fPRiW24) |
| Boundary-Enhanced Co-Training for Weakly Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/ShenghaiRong/BECO?style=flat)](https://github.com/ShenghaiRong/BECO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rong_Boundary-Enhanced_Co-Training_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=q3kJ532lbdc) |
| Learning Multi-Modal Class-Specific Tokens for Weakly Supervised Dense Object Localization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Learning_Multi-Modal_Class-Specific_Tokens_for_Weakly_Supervised_Dense_Object_Localization_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Quantum Multi-Model Fitting <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/FarinaMatteo/qmmf?style=flat)](https://github.com/FarinaMatteo/qmmf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Farina_Quantum_Multi-Model_Fitting_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15444-b31b1b.svg)](http://arxiv.org/abs/2303.15444) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m0QMGM-Awj8) |
| Two-Shot Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/yk-pku/Two-shot-Video-Object-Segmentation?style=flat)](https://github.com/yk-pku/Two-shot-Video-Object-Segmentation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_Two-Shot_Video_Object_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12078-b31b1b.svg)](http://arxiv.org/abs/2303.12078) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UMNUONtqRD0) |
| End-to-End Video Matting with Trimap Propagation | [![GitHub](https://img.shields.io/github/stars/csvt32745/FTP-VM?style=flat)](https://github.com/csvt32745/FTP-VM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_End-to-End_Video_Matting_With_Trimap_Propagation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3jjA4nvUc8c) |
| ISBNet: A 3D Point Cloud Instance Segmentation Network with Instance-Aware Sampling and Box-Aware Dynamic Convolution | [![GitHub](https://img.shields.io/github/stars/VinAIResearch/ISBNet?style=flat)](https://github.com/VinAIResearch/ISBNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ngo_ISBNet_A_3D_Point_Cloud_Instance_Segmentation_Network_With_Instance-Aware_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00246-b31b1b.svg)](http://arxiv.org/abs/2303.00246) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uoOApyX-NUY) |
| On Calibrating Semantic Segmentation Models: Analyses and an Algorithm | [![GitHub](https://img.shields.io/github/stars/dwang181/selectivecal?style=flat)](https://github.com/dwang181/selectivecal) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_On_Calibrating_Semantic_Segmentation_Models_Analyses_and_an_Algorithm_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.12053-b31b1b.svg)](http://arxiv.org/abs/2212.12053)| :heavy_minus_sign: |
| Explicit Visual Prompting for Low-Level Structure Segmentations | [![GitHub](https://img.shields.io/github/stars/NiFangBaAGe/Explicit-Visual-Prompt?style=flat)](https://github.com/NiFangBaAGe/Explicit-Visual-Prompt) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Explicit_Visual_Prompting_for_Low-Level_Structure_Segmentations_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10883-b31b1b.svg)](http://arxiv.org/abs/2303.10883)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9DdnQz4Y16E) |
| Neural Intrinsic Embedding for Non-Rigid Point Cloud Matching | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Neural_Intrinsic_Embedding_for_Non-Rigid_Point_Cloud_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01038-b31b1b.svg)](http://arxiv.org/abs/2303.01038)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O6mhyFw3HLQ) |
| Incrementer: Transformer for Class-Incremental Semantic Segmentation with Knowledge Distillation Focusing on Old Class <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shang_Incrementer_Transformer_for_Class-Incremental_Semantic_Segmentation_With_Knowledge_Distillation_Focusing_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yV7XO-G-dto) |
| Camouflaged Instance Segmentation via Explicit De-Camouflaging <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/USTCL/DCNet?style=flat)](https://github.com/USTCL/DCNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Camouflaged_Instance_Segmentation_via_Explicit_De-Camouflaging_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hUaBKw-coiM) |
| Leveraging Hidden Positives for Unsupervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/hynnsk/HP?style=flat)](https://github.com/hynnsk/HP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Seong_Leveraging_Hidden_Positives_for_Unsupervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15014-b31b1b.svg)](http://arxiv.org/abs/2303.15014) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4wFyPEhYTxE) |
| Rethinking the Correlation in Few-Shot Segmentation: A Buoys View | [![GitHub](https://img.shields.io/github/stars/mrkshllr/FewTURE?style=flat)](https://github.com/mrkshllr/FewTURE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Rethinking_the_Correlation_in_Few-Shot_Segmentation_A_Buoys_View_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DYGAG-Ga2FI) |
| Sparsely Annotated Semantic Segmentation with Adaptive Gaussian Mixtures | [![GitHub](https://img.shields.io/github/stars/Luffy03/AGMM-SASS?style=flat)](https://github.com/Luffy03/AGMM-SASS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Sparsely_Annotated_Semantic_Segmentation_With_Adaptive_Gaussian_Mixtures_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XNvGrh5BNgA) |
| Mask-Guided Matting in the Wild | [![GitHub](https://img.shields.io/github/stars/yucornetto/MGMatting?style=flat)](https://github.com/yucornetto/MGMatting) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Mask-Guided_Matting_in_the_Wild_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Visual Dependency Transformers: Dependency Tree Emerges from Reversed Attention | [![GitHub](https://img.shields.io/github/stars/dingmyu/DependencyViT?style=flat)](https://github.com/dingmyu/DependencyViT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_Visual_Dependency_Transformers_Dependency_Tree_Emerges_From_Reversed_Attention_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03282-b31b1b.svg)](http://arxiv.org/abs/2304.03282) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IBZiMgsex1c) |
| Conflict-based Cross-View Consistency for Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/xiaoyao3302/CCVC?style=flat)](https://github.com/xiaoyao3302/CCVC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Conflict-Based_Cross-View_Consistency_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01276-b31b1b.svg)](http://arxiv.org/abs/2303.01276) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=g7QRZ85zMkQ) |
| Augmentation Matters: A Simple-Yet-Effective Approach to Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/ZhenZHAO/AugSeg?style=flat)](https://github.com/ZhenZHAO/AugSeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Augmentation_Matters_A_Simple-Yet-Effective_Approach_to_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04976-b31b1b.svg)](http://arxiv.org/abs/2212.04976) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SY1lKHraa2o) |
| Attention-based Point Cloud Edge Sampling <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Attention-Based_Point_Cloud_Edge_Sampling_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14673-b31b1b.svg)](http://arxiv.org/abs/2302.14673)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LI33vU72BZo) |
| DA Wand: Distortion-Aware Selection using Neural Mesh Parameterization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://threedle.github.io/DA-Wand/) <br /> [![GitHub](https://img.shields.io/github/stars/threedle/DA-Wand?style=flat)](https://github.com/threedle/DA-Wand) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_DA_Wand_Distortion-Aware_Selection_Using_Neural_Mesh_Parameterization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06344-b31b1b.svg)](http://arxiv.org/abs/2212.06344) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=BmmdMlAWaf4) |
| Extracting Class Activation Maps from Non-Discriminative Features as Well | [![GitHub](https://img.shields.io/github/stars/zhaozhengChen/LPCAM?style=flat)](https://github.com/zhaozhengChen/LPCAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Extracting_Class_Activation_Maps_From_Non-Discriminative_Features_As_Well_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10334-b31b1b.svg)](http://arxiv.org/abs/2303.10334) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OuTvIgO0Rhg) |
| Focused and Collaborative Feedback Integration for Interactive Image Segmentation | [![GitHub](https://img.shields.io/github/stars/veizgyauzgyauz/FCFI?style=flat)](https://github.com/veizgyauzgyauz/FCFI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Focused_and_Collaborative_Feedback_Integration_for_Interactive_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11880-b31b1b.svg)](http://arxiv.org/abs/2303.11880) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jotYi4Sho0Q) |
| Boosting Low-Data Instance Segmentation by Unsupervised Pre-Training with Saliency Prompt | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Boosting_Low-Data_Instance_Segmentation_by_Unsupervised_Pre-Training_With_Saliency_Prompt_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.01171-b31b1b.svg)](http://arxiv.org/abs/2302.01171) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NkcyeEY4Rco) |
| Unsupervised 3D Shape Reconstruction by Part Retrieval and Assembly | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Unsupervised_3D_Shape_Reconstruction_by_Part_Retrieval_and_Assembly_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01999-b31b1b.svg)](http://arxiv.org/abs/2303.01999) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O7SrKYBwD6k) |
| MobileVOS: Real-Time Video Object Segmentation Contrastive Learning Meets Knowledge Distillation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Miles_MobileVOS_Real-Time_Video_Object_Segmentation_Contrastive_Learning_Meets_Knowledge_Distillation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07815-b31b1b.svg)](http://arxiv.org/abs/2303.07815) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1ilo8SYCJww) |
| Transformer Scale Gate for Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shi_Transformer_Scale_Gate_for_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.07056-b31b1b.svg)](http://arxiv.org/abs/2205.07056) | :heavy_minus_sign: |
| PIDNet: A Real-Time Semantic Segmentation Network Inspired by PID Controllers | [![GitHub](https://img.shields.io/github/stars/XuJiacong/PIDNet?style=flat)](https://github.com/XuJiacong/PIDNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_PIDNet_A_Real-Time_Semantic_Segmentation_Network_Inspired_by_PID_Controllers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.02066-b31b1b.svg)](http://arxiv.org/abs/2206.02066) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=encrBD8yLGw) |
| Side Adapter Network for Open-Vocabulary Semantic Segmentation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mendelxu.github.io/SAN/) <br /> [![GitHub](https://img.shields.io/github/stars/MendelXu/SAN?style=flat)](https://github.com/MendelXu/SAN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Side_Adapter_Network_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.12242-b31b1b.svg)](http://arxiv.org/abs/2302.12242) | :heavy_minus_sign: |
| Test Time Adaptation with Regularized Loss for Weakly Supervised Salient Object Detection | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Veksler_Test_Time_Adaptation_With_Regularized_Loss_for_Weakly_Supervised_Salient_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Feature Shrinkage Pyramid for Camouflaged Object Detection with Transformers | [![GitHub](https://img.shields.io/github/stars/ZhouHuang23/FSPNet?style=flat)](https://github.com/ZhouHuang23/FSPNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Feature_Shrinkage_Pyramid_for_Camouflaged_Object_Detection_With_Transformers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14816-b31b1b.svg)](http://arxiv.org/abs/2303.14816) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=M0Ucp2OBEKM) |
| Reliability in Semantic Segmentation: Are we on the Right Track? | [![GitHub](https://img.shields.io/github/stars/naver/relis?style=flat)](https://github.com/naver/relis) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/de_Jorge_Reliability_in_Semantic_Segmentation_Are_We_on_the_Right_Track_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11298-b31b1b.svg)](http://arxiv.org/abs/2303.11298) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QbLv83vlNkc) |
| Beyond mAP: Towards Better Evaluation of Instance Segmentation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jena_Beyond_mAP_Towards_Better_Evaluation_of_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.01614-b31b1b.svg)](http://arxiv.org/abs/2207.01614) | :heavy_minus_sign: |
| Heat Diffusion based Multi-Scale and Geometric Structure-Aware Transformer for Mesh Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wong_Heat_Diffusion_Based_Multi-Scale_and_Geometric_Structure-Aware_Transformer_for_Mesh_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Tree Instance Segmentation with Temporal Contour Graph | [![GitHub](https://img.shields.io/github/stars/adnan0819/Tree-Instance-Segmentation-using-Temporal-Structured-Images?style=flat)](https://github.com/adnan0819/Tree-Instance-Segmentation-using-Temporal-Structured-Images) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Firoze_Tree_Instance_Segmentation_With_Temporal_Contour_Graph_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Exemplar-FreeSOLO: Enhancing Unsupervised Instance Segmentation with Exemplars | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ishtiak_Exemplar-FreeSOLO_Enhancing_Unsupervised_Instance_Segmentation_With_Exemplars_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=l5sMTrswceQ) |
| Omnimatte3D: Associating Objects and their Effects in Unconstrained Monocular Video | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Suhail_Omnimatte3D_Associating_Objects_and_Their_Effects_in_Unconstrained_Monocular_Video_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zx-h4f2RXTA) |
| Learning Orthogonal Prototypes for Generalized Few-Shot Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/lsa1997/POP?style=flat)](https://github.com/lsa1997/POP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Learning_Orthogonal_Prototypes_for_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Instance-Specific and Model-Adaptive Supervision for Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/ZhenZHAO/iMAS?style=flat)](https://github.com/ZhenZHAO/iMAS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Instance-Specific_and_Model-Adaptive_Supervision_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11335-b31b1b.svg)](http://arxiv.org/abs/2211.11335) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fsCC4z1qoeU) |
| Improving Robustness of Semantic Segmentation to Motion-Blur using Class-Centric Augmentation | [![GitHub](https://img.shields.io/github/stars/aka-discover/CCMBA_CVPR23?style=flat)](https://github.com/aka-discover/CCMBA_CVPR23) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Aakanksha_Improving_Robustness_of_Semantic_Segmentation_to_Motion-Blur_Using_Class-Centric_Augmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=haypy30_jG4) |
| IFSeg: Image-Free Semantic Segmentation via Vision-Language Model | [![GitHub](https://img.shields.io/github/stars/alinlab/ifseg?style=flat)](https://github.com/alinlab/ifseg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yun_IFSeg_Image-Free_Semantic_Segmentation_via_Vision-Language_Model_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14396-b31b1b.svg)](http://arxiv.org/abs/2303.14396) | :heavy_minus_sign: |
| CLIP-S4: Language-Guided Self-Supervised Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_CLIP-S4_Language-Guided_Self-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.01040-b31b1b.svg)](https://arxiv.org/abs/2305.01040) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rx0XvzFsI10) |
| Pruning Parameterization with Bi-Level Optimization for Efficient Semantic Segmentation on the Edge | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Pruning_Parameterization_With_Bi-Level_Optimization_for_Efficient_Semantic_Segmentation_on_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
