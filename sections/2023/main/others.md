# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/2023/main/computer-vision-for-social-good.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
</div>

## Others

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-5-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-9-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-7-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| A Bag-of-Prototypes Representation for Dataset-Level Applications | [![GitHub](https://img.shields.io/github/stars/Klaus-Tu/Bag-of-Prototypes?style=flat)](https://github.com/Klaus-Tu/Bag-of-Prototypes) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tu_A_Bag-of-Prototypes_Representation_for_Dataset-Level_Applications_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13251-b31b1b.svg)](http://arxiv.org/abs/2303.13251) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kSB0GO9pEYE) |
| Learning to Retain While Acquiring: Combating Distribution-Shift in Adversarial Data-Free Knowledge Distillation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Patel_Learning_To_Retain_While_Acquiring_Combating_Distribution-Shift_in_Adversarial_Data-Free_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14290-b31b1b.svg)](http://arxiv.org/abs/2302.14290) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VwEKrqMym4k) |
| Label Information Bottleneck for Label Enhancement | [![GitHub](https://img.shields.io/github/stars/qinghai-zheng/LIBLE?style=flat)](https://github.com/qinghai-zheng/LIBLE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Label_Information_Bottleneck_for_Label_Enhancement_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06836-b31b1b.svg)](http://arxiv.org/abs/2303.06836) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YGWGU3m4whc) |
| DISC: Learning from Noisy Labels via Dynamic Instance-Specific Selection and Correction | [![GitHub](https://img.shields.io/github/stars/JackYFL/DISC?style=flat)](https://github.com/JackYFL/DISC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_DISC_Learning_From_Noisy_Labels_via_Dynamic_Instance-Specific_Selection_and_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YGWGU3m4whc) |
| Restoration of Hand-Drawn Architectural Drawings using Latent Space Mapping with Degradation Generator | [![GitHub](https://img.shields.io/github/stars/Nakkwan/pytorch-Restoration-Floorplan?style=flat)](https://github.com/Nakkwan/pytorch-Restoration-Floorplan) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_Restoration_of_Hand-Drawn_Architectural_Drawings_Using_Latent_Space_Mapping_With_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| DaFKD: Domain-Aware Federated Knowledge Distillation | [![GitHub](https://img.shields.io/github/stars/haozhaowang/DaFKD2023?style=flat)](https://github.com/haozhaowang/DaFKD2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_DaFKD_Domain-Aware_Federated_Knowledge_Distillation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NxmLN6uWUBA) |
| Enhanced Stable View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://suryanshkumar.github.io/Enhanced_Stable_View_Synthesis/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jain_Enhanced_Stable_View_Synthesis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17094-b31b1b.svg)](http://arxiv.org/abs/2303.17094) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CZW6HLDQRD4) |
| ScaleFL: Resource-Adaptive Federated Learning with Heterogeneous Clients | [![GitHub](https://img.shields.io/github/stars/git-disl/scale-fl?style=flat)](https://github.com/git-disl/scale-fl) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ilhan_ScaleFL_Resource-Adaptive_Federated_Learning_With_Heterogeneous_Clients_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| GradMA: A Gradient-Memory-based Accelerated Federated Learning with Alleviated Catastrophic Forgetting <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/lkyddd/GradMA?style=flat)](https://github.com/lkyddd/GradMA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_GradMA_A_Gradient-Memory-Based_Accelerated_Federated_Learning_With_Alleviated_Catastrophic_Forgetting_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14307-b31b1b.svg)](http://arxiv.org/abs/2302.14307) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kzZH_5eSsZ4) |
| High-Resolution Image Reconstruction with Latent Diffusion Models from Human Brain Activity | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/stablediffusion-with-brain/) <br /> [![GitHub](https://img.shields.io/github/stars/yu-takagi/StableDiffusionReconstruction?style=flat)](https://github.com/yu-takagi/StableDiffusionReconstruction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Takagi_High-Resolution_Image_Reconstruction_With_Latent_Diffusion_Models_From_Human_Brain_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| A Unified Knowledge Distillation Framework for Deep Directed Graphical Models | [![GitHub](https://img.shields.io/github/stars/YizhuoChen99/KD4DGM-CVPR?style=flat)](https://github.com/YizhuoChen99/KD4DGM-CVPR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_A_Unified_Knowledge_Distillation_Framework_for_Deep_Directed_Graphical_Models_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| How to Prevent the Poor Performance Clients for Personalized Federated Learning? | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qu_How_To_Prevent_the_Poor_Performance_Clients_for_Personalized_Federated_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
