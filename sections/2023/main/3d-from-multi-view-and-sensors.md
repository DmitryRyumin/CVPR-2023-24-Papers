# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>New collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
                <img src="http://img.shields.io/badge/CVPR-2024-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/image-and-video-synthesis-and-generation.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 3D from Multi-View and Sensors

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| NeuMap: Neural Coordinate Mapping by Auto-Transdecoder for Camera Localization | [![GitHub](https://img.shields.io/github/stars/Tangshitao/NeuMap?style=flat)](https://github.com/Tangshitao/NeuMap) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_NeuMap_Neural_Coordinate_Mapping_by_Auto-Transdecoder_for_Camera_Localization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11177-b31b1b.svg)](https://arxiv.org/abs/2211.11177) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=u4DGwkXuJXA) |
| Object Pose Estimation with Statistical Guarantees: Conformal Keypoint Detection and Geometric Uncertainty Propagation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/NVlabs/ConformalKeypoint?style=flat)](https://github.com/NVlabs/ConformalKeypoint) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Object_Pose_Estimation_With_Statistical_Guarantees_Conformal_Keypoint_Detection_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12246-b31b1b.svg)](https://arxiv.org/abs/2303.12246) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NWUf4hd571E) |
| NeuralUDF: Learning Unsigned Distance Fields for Multi-View Reconstruction of Surfaces with Arbitrary Topologies | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.xxlong.site/NeuralUDF/) <br /> [![GitHub](https://img.shields.io/github/stars/xxlong0/NeuralUDF?style=flat)](https://github.com/xxlong0/NeuralUDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Long_NeuralUDF_Learning_Unsigned_Distance_Fields_for_Multi-View_Reconstruction_of_Surfaces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14173-b31b1b.svg)](https://arxiv.org/abs/2211.14173) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JnaXx7qyYQY) |
| NEF: Neural Edge Fields for 3D Parametric Curve Reconstruction from Multi-View Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yunfan1202.github.io/NEF/) <br /> [![GitHub](https://img.shields.io/github/stars/yunfan1202/NEF_code?style=flat)](https://github.com/yunfan1202/NEF_code) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_NEF_Neural_Edge_Fields_for_3D_Parametric_Curve_Reconstruction_From_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07653-b31b1b.svg)](https://arxiv.org/abs/2303.07653) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_F4EnZ1I_2g) |
| Looking through the Glass: Neural Surface Reconstruction Against High Specular Reflections | [![GitHub](https://img.shields.io/github/stars/JiaxiongQ/NeuS-HSR?style=flat)](https://github.com/JiaxiongQ/NeuS-HSR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_Looking_Through_the_Glass_Neural_Surface_Reconstruction_Against_High_Specular_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08706-b31b1b.svg)](https://arxiv.org/abs/2304.08706) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lwHd-GJAmMA) |
| Multi-View Azimuth Stereo via Tangent Space Consistency | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xucao-42.github.io/mvas_homepage/) <br /> [![GitHub](https://img.shields.io/github/stars/xucao-42/mvas?style=flat)](https://github.com/xucao-42/mvas) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Multi-View_Azimuth_Stereo_via_Tangent_Space_Consistency_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16447-b31b1b.svg)](https://arxiv.org/abs/2303.16447) | :heavy_minus_sign: |
| Instant Multi-View Head Capture through Learnable Registration | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://tempeh.is.tue.mpg.de/) <br /> [![GitHub](https://img.shields.io/github/stars/TimoBolkart/TEMPEH?style=flat)](https://github.com/TimoBolkart/TEMPEH) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bolkart_Instant_Multi-View_Head_Capture_Through_Learnable_Registration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07437-b31b1b.svg)](https://arxiv.org/abs/2306.07437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AolpvKpmjEw) |
| EditableNeRF: Editing Topologically Varying Neural Radiance Fields by Key Points | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chengwei-zheng.github.io/EditableNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/chengwei-zheng/EditableNeRF_cvpr23?style=flat)](https://github.com/chengwei-zheng/EditableNeRF_cvpr23) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_EditableNeRF_Editing_Topologically_Varying_Neural_Radiance_Fields_by_Key_Points_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04247-b31b1b.svg)](https://arxiv.org/abs/2212.04247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Eu2twgbg4kI) |
| Iterative Geometry Encoding Volume for Stereo Matching | [![GitHub](https://img.shields.io/github/stars/gangweiX/IGEV?style=flat)](https://github.com/gangweiX/IGEV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Iterative_Geometry_Encoding_Volume_for_Stereo_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06615-b31b1b.svg)](https://arxiv.org/abs/2303.06615) | :heavy_minus_sign: |
| Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery from Sparse Image Ensemble | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chhankyao.github.io/hi-lassie/) <br /> [![GitHub](https://img.shields.io/github/stars/google/hi-lassie?style=flat)](https://github.com/google/hi-lassie) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Hi-LASSIE_High-Fidelity_Articulated_Shape_and_Skeleton_Discovery_From_Sparse_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.11042-b31b1b.svg)](https://arxiv.org/abs/2212.11042) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s9FWABEm0WU) |
| VDN-NeRF: Resolving Shape-Radiance Ambiguity via View-Dependence Normalization | [![GitHub](https://img.shields.io/github/stars/BoifZ/VDN-NeRF?style=flat)](https://github.com/BoifZ/VDN-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_VDN-NeRF_Resolving_Shape-Radiance_Ambiguity_via_View-Dependence_Normalization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17968-b31b1b.svg)](https://arxiv.org/abs/2303.17968) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yXPlqxEScK4) |
| Neuralangelo: High-Fidelity Neural Surface Reconstruction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/dir/neuralangelo/) <br /> [![GitHub](https://img.shields.io/github/stars/nvlabs/neuralangelo?style=flat)](https://github.com/nvlabs/neuralangelo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Neuralangelo_High-Fidelity_Neural_Surface_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.03092-b31b1b.svg)](https://arxiv.org/abs/2306.03092) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Qpdw3SW54kI) |
| In-Hand 3D Object Scanning from an RGB Sequence | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rgbinhandscanning.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hampali_In-Hand_3D_Object_Scanning_From_an_RGB_Sequence_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16193-b31b1b.svg)](https://arxiv.org/abs/2211.16193) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OaBKtUBbn3M) |
| SHS-Net: Learning Signed Hyper Surfaces for Oriented Normal Estimation of Point Clouds | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://leoqli.github.io/SHS-Net/) <br /> [![GitHub](https://img.shields.io/github/stars/LeoQLi/SHS-Net?style=flat)](https://github.com/LeoQLi/SHS-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_SHS-Net_Learning_Signed_Hyper_Surfaces_for_Oriented_Normal_Estimation_of_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.05873-b31b1b.svg)](https://arxiv.org/abs/2305.05873) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9DHAkjsnVYo) |
| FAC: 3D Representation Learning via Foreground Aware Feature Contrast | [![GitHub](https://img.shields.io/github/stars/KangchengLiu/FAC_Foreground_Aware_Contrast?style=flat)](https://github.com/KangchengLiu/FAC_Foreground_Aware_Contrast) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_FAC_3D_Representation_Learning_via_Foreground_Aware_Feature_Contrast_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06388-b31b1b.svg)](https://arxiv.org/abs/2303.06388) | :heavy_minus_sign: |
| Neural Kernel Surface Reconstruction <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/toronto-ai/NKSR/) <br /> [![GitHub](https://img.shields.io/github/stars/nv-tlabs/nksr?style=flat)](https://github.com/nv-tlabs/nksr) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Neural_Kernel_Surface_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.19590-b31b1b.svg)](https://arxiv.org/abs/2305.19590) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=J1V5F2z-dWY) |
| NeRFVS: Neural Radiance Fields for Free View Synthesis via Geometry Scaffolds | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_NeRFVS_Neural_Radiance_Fields_for_Free_View_Synthesis_via_Geometry_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06287-b31b1b.svg)](https://arxiv.org/abs/2304.06287) | :heavy_minus_sign: |
| HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of Indoor Scenes with Iterative Intertwined Regularization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lzhnb.github.io/project-pages/helixsurf.html) <br /> [![GitHub](https://img.shields.io/github/stars/Gorilla-Lab-SCUT/HelixSurf?style=flat)](https://github.com/Gorilla-Lab-SCUT/HelixSurf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liang_HelixSurf_A_Robust_and_Efficient_Neural_Implicit_Surface_Learning_of_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14340-b31b1b.svg)](https://arxiv.org/abs/2302.14340) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=eS5HjmX-l-w) |
| Multi-Space Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zx-yin.github.io/msnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/ZX-Yin/ms-nerf?style=flat)](https://github.com/ZX-Yin/ms-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yin_Multi-Space_Neural_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.04268-b31b1b.svg)](https://arxiv.org/abs/2305.04268) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mknOiuT7rVo) |
| MSF: Motion-guided Sequential Fusion for Efficient 3D Object Detection from Point Cloud Sequences | [![GitHub](https://img.shields.io/github/stars/skyhehe123/MSF?style=flat)](https://github.com/skyhehe123/MSF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_MSF_Motion-Guided_Sequential_Fusion_for_Efficient_3D_Object_Detection_From_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08316-b31b1b.svg)](https://arxiv.org/abs/2303.08316) | :heavy_minus_sign: |
| PVO: Panoptic Visual Odometry | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/pvo/) <br /> [![GitHub](https://img.shields.io/github/stars/zju3dv/pvo?style=flat)](https://github.com/zju3dv/pvo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_PVO_Panoptic_Visual_Odometry_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.01610-b31b1b.svg)](https://arxiv.org/abs/2207.01610) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=j8iJdh_lPH4) |
| Diffusion-SDF: Text-to-Shape via Voxelized Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ttlmh.github.io/DiffusionSDF/) <br /> [![GitHub](https://img.shields.io/github/stars/ttlmh/Diffusion-SDF?style=flat)](https://github.com/ttlmh/Diffusion-SDF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Diffusion-SDF_Text-To-Shape_via_Voxelized_Diffusion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03293-b31b1b.svg)](https://arxiv.org/abs/2212.03293) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FF2ZYKEFmIY) |
| Rotation-Invariant Transformer for Point Cloud Matching | [![GitHub](https://img.shields.io/github/stars/haoyu94/RoITr?style=flat)](https://github.com/haoyu94/RoITr) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Rotation-Invariant_Transformer_for_Point_Cloud_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08231-b31b1b.svg)](https://arxiv.org/abs/2303.08231) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GH8tz4Ng3dI) |
| HexPlane: A Fast Representation for Dynamic Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://caoang327.github.io/HexPlane/) <br /> [![GitHub](https://img.shields.io/github/stars/Caoang327/HexPlane?style=flat)](https://github.com/Caoang327/HexPlane) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_HexPlane_A_Fast_Representation_for_Dynamic_Scenes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.09632-b31b1b.svg)](https://arxiv.org/abs/2301.09632) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=y-i_jMjnBII) |
| Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders | [![GitHub](https://img.shields.io/github/stars/ZrrSkywalker/I2P-MAE?style=flat)](https://github.com/ZrrSkywalker/I2P-MAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Learning_3D_Representations_From_2D_Pre-Trained_Models_via_Image-to-Point_Masked_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06785-b31b1b.svg)](https://arxiv.org/abs/2212.06785) | :heavy_minus_sign: |
| Progressive Neighbor Consistency Mining for Correspondence Pruning | [![GitHub](https://img.shields.io/github/stars/xinliu29/NCMNet?style=flat)](https://github.com/xinliu29/NCMNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Progressive_Neighbor_Consistency_Mining_for_Correspondence_Pruning_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Z-j7o-2AoBg) |
| SCoDA: Domain Adaptive Shape Completion for Real Scans | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yushuang-wu.github.io/SCoDA/) <br /> [![GitHub](https://img.shields.io/github/stars/yushuang-wu/SCoDA?style=flat)](https://github.com/yushuang-wu/SCoDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_SCoDA_Domain_Adaptive_Shape_Completion_for_Real_Scans_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10179-b31b1b.svg)](https://arxiv.org/abs/2304.10179) | :heavy_minus_sign: |
| Adaptive Patch Deformation for Textureless-Resilient Multi-View Stereo | [![GitHub](https://img.shields.io/github/stars/whoiszzj/APD-MVS?style=flat)](https://github.com/whoiszzj/APD-MVS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Adaptive_Patch_Deformation_for_Textureless-Resilient_Multi-View_Stereo_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s3Y8Ty-8X_I) |
| Level-S<sup>2</sup>fM: Structure from Motion on Neural Level Set of Implicit Surfaces | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://henry123-boy.github.io/level-s2fm/) <br /> [![GitHub](https://img.shields.io/github/stars/henry123-boy/Level-S2FM_official?style=flat)](https://github.com/henry123-boy/Level-S2FM_official) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_Level-S2fM_Structure_From_Motion_on_Neural_Level_Set_of_Implicit_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12018-b31b1b.svg)](https://arxiv.org/abs/2211.12018) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yK8nt--Nl64) |
| PLA: Language-Driven Open-Vocabulary 3D Scene Understanding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dingry.github.io/projects/PLA) <br /> [![GitHub](https://img.shields.io/github/stars/CVMI-Lab/PLA?style=flat)](https://github.com/CVMI-Lab/PLA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_PLA_Language-Driven_Open-Vocabulary_3D_Scene_Understanding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16312-b31b1b.svg)](https://arxiv.org/abs/2211.16312) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2VWANzUJ4DM) |
| SUDS: Scalable Urban Dynamic Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://haithemturki.com/suds/) <br /> [![GitHub](https://img.shields.io/github/stars/hturki/suds?style=flat)](https://github.com/hturki/suds) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Turki_SUDS_Scalable_Urban_Dynamic_Scenes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14536-b31b1b.svg)](https://arxiv.org/abs/2303.14536) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fcdEGt_ymeE) |
| 3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds | [![GitHub](https://img.shields.io/github/stars/xiaoaoran/SemanticSTF?style=flat)](https://github.com/xiaoaoran/SemanticSTF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_3D_Semantic_Segmentation_in_the_Wild_Learning_Generalized_Models_for_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00690-b31b1b.svg)](https://arxiv.org/abs/2304.00690) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HhbdhKoRz6c) |
| BAEFormer: Bi-Directional and Early Interaction Transformers for Bird's Eye View Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_BAEFormer_Bi-Directional_and_Early_Interaction_Transformers_for_Birds_Eye_View_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Dionysus: Recovering Scene Structures by Dividing into Semantic Pieces | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Dionysus_Recovering_Scene_Structures_by_Dividing_Into_Semantic_Pieces_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| LP-DIF: Learning Local Pattern-Specific Deep Implicit Function for 3D Objects and Scenes | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_LP-DIF_Learning_Local_Pattern-Specific_Deep_Implicit_Function_for_3D_Objects_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Neural Kaleidoscopic Space Sculpting | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://imaging.cs.cmu.edu/neural_kaleidoscopic_space_sculpting/) <br /> [![GitHub](https://img.shields.io/github/stars/ByeongjooAhn/neural_kaleidoscopic_space_sculpting?style=flat)](https://github.com/ByeongjooAhn/neural_kaleidoscopic_space_sculpting) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ahn_Neural_Kaleidoscopic_Space_Sculpting_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_u19SOAEwzU) |
| Starting from Non-Parametric Networks for 3D Point Cloud Analysis | [![GitHub](https://img.shields.io/github/stars/ZrrSkywalker/Point-NN?style=flat)](https://github.com/ZrrSkywalker/Point-NN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Starting_From_Non-Parametric_Networks_for_3D_Point_Cloud_Analysis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08134-b31b1b.svg)](https://arxiv.org/abs/2303.08134) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ddfZVawhPEY) |
| Panoptic Compositional Feature Field for Editable Scene Rendering with Network-Inferred Labels via Metric Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cheng_Panoptic_Compositional_Feature_Field_for_Editable_Scene_Rendering_With_Network-Inferred_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Robust Dynamic Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://robust-dynrf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/robust-dynrf?style=flat)](https://github.com/facebookresearch/robust-dynrf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Robust_Dynamic_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.02239-b31b1b.svg)](https://arxiv.org/abs/2301.02239) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=38S56ottFQ4) |
| BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wangpeng000.github.io/BAD-NeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/WU-CVGL/BAD-NeRF?style=flat)](https://github.com/WU-CVGL/BAD-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_BAD-NeRF_Bundle_Adjusted_Deblur_Neural_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12853-b31b1b.svg)](https://arxiv.org/abs/2211.12853) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xoES4eONYoA) |
| Consistent Direct Time-of-Flight Video Depth Super-Resolution | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zhsun0357.github.io/consistent_dtof_video/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/DVSR?style=flat)](https://github.com/facebookresearch/DVSR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Consistent_Direct_Time-of-Flight_Video_Depth_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.08658-b31b1b.svg)](https://arxiv.org/abs/2211.08658) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=77LTIDqhBjA) |
| Patch-based 3D Natural Scene Generation from a Single Example | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://weiyuli.xyz/Sin3DGen/) <br /> [![GitHub](https://img.shields.io/github/stars/wyysf-98/Sin3DGen?style=flat)](https://github.com/wyysf-98/Sin3DGen) <br /> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wyysf-98/Sin3DGen/blob/main/colab_demo.ipynb) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Patch-Based_3D_Natural_Scene_Generation_From_a_Single_Example_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12670-b31b1b.svg)](https://arxiv.org/abs/2304.12670) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-buKPdBmLWo) |
| 3D Video Loops from Asynchronous Input | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://limacv.github.io/VideoLoop3D_web/) <br /> [![GitHub](https://img.shields.io/github/stars/limacv/VideoLoop3D?style=flat)](https://github.com/limacv/VideoLoop3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_3D_Video_Loops_From_Asynchronous_Input_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05312-b31b1b.svg)](https://arxiv.org/abs/2303.05312) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Z_Zs1NLPACk) |
| UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in Bird's-Eye View <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/megvii-research/CVPR2023-UniDistill?style=flat)](https://github.com/megvii-research/CVPR2023-UniDistill) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_UniDistill_A_Universal_Cross-Modality_Knowledge_Distillation_Framework_for_3D_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15083-b31b1b.svg)](https://arxiv.org/abs/2303.15083) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_DW32YG7SSE) |
| Neural Scene Chronology | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/neusc/) <br /> [![GitHub](https://img.shields.io/github/stars/zju3dv/NeuSC?style=flat)](https://github.com/zju3dv/NeuSC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Neural_Scene_Chronology_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07970-b31b1b.svg)](https://arxiv.org/abs/2306.07970) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ak47wEZH1kY) |
| RUST: Latent Neural Scene Representations from Unposed Imagery <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rust-paper.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sajjadi_RUST_Latent_Neural_Scene_Representations_From_Unposed_Imagery_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14306-b31b1b.svg)](https://arxiv.org/abs/2211.14306) | :heavy_minus_sign: |
| Painting 3D Nature in 2D: View Synthesis of Natural Scenes from a Single Semantic Mask | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/paintingnature/) <br /> [![GitHub](https://img.shields.io/github/stars/zhanghe3z/PaintingNature?style=flat)](https://github.com/zhanghe3z/PaintingNature) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Painting_3D_Nature_in_2D_View_Synthesis_of_Natural_Scenes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.07224-b31b1b.svg)](https://arxiv.org/abs/2302.07224) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-ipSXuzSs2A) |
| F<sup>2</sup>-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://totoro97.github.io/projects/f2-nerf/) <br /> [![GitHub](https://img.shields.io/github/stars/totoro97/f2-nerf?style=flat)](https://github.com/totoro97/f2-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_F2-NeRF_Fast_Neural_Radiance_Field_Training_With_Free_Camera_Trajectories_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15951-b31b1b.svg)](https://arxiv.org/abs/2303.15951) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JWQYAucCNl0) |
| VL-SAT: Visual-Linguistic Semantics Assisted Training for 3D Semantic Scene Graph Prediction in Point Cloud <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/wz7in/CVPR2023-VLSAT?style=flat)](https://github.com/wz7in/CVPR2023-VLSAT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_VL-SAT_Visual-Linguistic_Semantics_Assisted_Training_for_3D_Semantic_Scene_Graph_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14408-b31b1b.svg)](https://arxiv.org/abs/2303.14408) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YKicx1B5f7c) |
| REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lingtengqiu.github.io/2023/REC-MV/) <br /> [![GitHub](https://img.shields.io/github/stars/GAP-LAB-CUHK-SZ/REC-MV?style=flat)](https://github.com/GAP-LAB-CUHK-SZ/REC-MV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_REC-MV_REconstructing_3D_Dynamic_Cloth_From_Monocular_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.14236-b31b1b.svg)](https://arxiv.org/abs/2305.14236) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=agZ1qOEM1pA&t=17s) |
| MVImgNet: A Large-Scale Dataset of Multi-View Images | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://gaplab.cuhk.edu.cn/projects/MVImgNet/) <br /> [![GitHub](https://img.shields.io/github/stars/GAP-LAB-CUHK-SZ/MVImgNet?style=flat)](https://github.com/GAP-LAB-CUHK-SZ/MVImgNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_MVImgNet_A_Large-Scale_Dataset_of_Multi-View_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06042-b31b1b.svg)](https://arxiv.org/abs/2303.06042) | :heavy_minus_sign: |
| Shakes on a Plane: Unsupervised Depth Estimation from Unstabilized Photography | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://light.princeton.edu/publication/soap/) <br /> [![GitHub](https://img.shields.io/github/stars/princeton-computational-imaging/SoaP?style=flat)](https://github.com/princeton-computational-imaging/SoaP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chugunov_Shakes_on_a_Plane_Unsupervised_Depth_Estimation_From_Unstabilized_Photography_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.12324-b31b1b.svg)](https://arxiv.org/abs/2212.12324) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=6Chkn8nW6bk) |
| GINA-3D: Learning to Generate Implicit Neural Assets in the Wild | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_GINA-3D_Learning_To_Generate_Implicit_Neural_Assets_in_the_Wild_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02163-b31b1b.svg)](https://arxiv.org/abs/2304.02163) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aCAik8icuLI) |
| MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures <br /> ![CVPR - Award](https://img.shields.io/badge/CVPR-Award-294A7C) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mobile-nerf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/google-research/jax3d?style=flat)](https://github.com/google-research/jax3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_MobileNeRF_Exploiting_the_Polygon_Rasterization_Pipeline_for_Efficient_Neural_Field_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.00277-b31b1b.svg)](https://arxiv.org/abs/2208.00277) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=C1rULzOcjuw) |
| DynIBaR: Neural Dynamic Image-based Rendering <br /> ![CVPR - Award](https://img.shields.io/badge/CVPR-Award-294A7C) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dynibar.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/google/dynibar?style=flat)](https://github.com/google/dynibar) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_DynIBaR_Neural_Dynamic_Image-Based_Rendering_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11082-b31b1b.svg)](https://arxiv.org/abs/2211.11082) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SCFfqYBGXt0) |
| IMP: Iterative Matching and Pose Estimation with Adaptive Pooling | [![GitHub](https://img.shields.io/github/stars/feixue94/imp-release?style=flat)](https://github.com/feixue94/imp-release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_IMP_Iterative_Matching_and_Pose_Estimation_With_Adaptive_Pooling_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14837-b31b1b.svg)](https://arxiv.org/abs/2304.14837) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yH3d-AzyTGo) |
| Learning the Distribution of Errors in Stereo Matching for Joint Disparity and Uncertainty Estimation | [![GitHub](https://img.shields.io/github/stars/lly00412/SEDNet?style=flat)](https://github.com/lly00412/SEDNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Learning_the_Distribution_of_Errors_in_Stereo_Matching_for_Joint_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00152-b31b1b.svg)](https://arxiv.org/abs/2304.00152) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5Y6Vo69SiLQ) |
| NeAT: Learning Neural Implicit Surfaces with Arbitrary Topologies from Multi-View Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xmeng525.github.io/xiaoxumeng.github.io/projects/cvpr23_neat) <br /> [![GitHub](https://img.shields.io/github/stars/xmeng525/NeAT?style=flat)](https://github.com/xmeng525/NeAT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Meng_NeAT_Learning_Neural_Implicit_Surfaces_With_Arbitrary_Topologies_From_Multi-View_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12012-b31b1b.svg)](https://arxiv.org/abs/2303.12012) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GQNaW8GZOsM) |
| ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gerwang.github.io/shadowneus/) <br /> [![GitHub](https://img.shields.io/github/stars/gerwang/ShadowNeuS?style=flat)](https://github.com/gerwang/ShadowNeuS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ling_ShadowNeuS_Neural_SDF_Reconstruction_by_Shadow_Ray_Supervision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14086-b31b1b.svg)](https://arxiv.org/abs/2211.14086) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jvxJ7bVuTBk) |
| Bi-LRFusion: Bi-Directional LiDAR-Radar Fusion for 3D Dynamic Object Detection | [![GitHub](https://img.shields.io/github/stars/JessieW0806/Bi-LRFusion?style=flat)](https://github.com/JessieW0806/Bi-LRFusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Bi-LRFusion_Bi-Directional_LiDAR-Radar_Fusion_for_3D_Dynamic_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.01438-b31b1b.svg)](https://arxiv.org/abs/2306.01438) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mVm8x09SqHs) |
| NeRF-DS: Neural Radiance Fields for Dynamic Specular Objects | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jokeryan.github.io/projects/nerf-ds/) <br /> [![GitHub](https://img.shields.io/github/stars/JokerYan/NeRF-DS?style=flat)](https://github.com/JokerYan/NeRF-DS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_NeRF-DS_Neural_Radiance_Fields_for_Dynamic_Specular_Objects_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14435-b31b1b.svg)](https://arxiv.org/abs/2303.14435) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VQShDzJ4NvI) |
| LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion | [![GitHub](https://img.shields.io/github/stars/PJLab-ADG/LoGoNet?style=flat)](https://github.com/PJLab-ADG/LoGoNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_LoGoNet_Towards_Accurate_3D_Object_Detection_With_Local-to-Global_Cross-Modal_Fusion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.03595-b31b1b.svg)](https://arxiv.org/abs/2303.03595) | :heavy_minus_sign: |
| 3D Registration with Maximal Cliques <br /> ![CVPR - Award](https://img.shields.io/badge/CVPR-Award-294A7C) | [![GitHub](https://img.shields.io/github/stars/zhangxy0517/3D-Registration-with-Maximal-Cliques?style=flat)](https://github.com/zhangxy0517/3D-Registration-with-Maximal-Cliques) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_3D_Registration_With_Maximal_Cliques_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10854-b31b1b.svg)](https://arxiv.org/abs/2305.10854) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LhALRCQo400) |
| OmniObject3D: Large-Vocabulary 3D Object Dataset for Realistic Perception, Reconstruction and Generation <br /> ![CVPR - Award](https://img.shields.io/badge/CVPR-Award-294A7C) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://omniobject3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/omniobject3d/OmniObject3D?style=flat)](https://github.com/omniobject3d/OmniObject3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_OmniObject3D_Large-Vocabulary_3D_Object_Dataset_for_Realistic_Perception_Reconstruction_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.07525-b31b1b.svg)](https://arxiv.org/abs/2301.07525) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3rK9gVWxwS0) |
| Progressive Spatio-Temporal Alignment for Efficient Event-based Motion Estimation | [![GitHub](https://img.shields.io/github/stars/huangxueyan/PEME?style=flat)](https://github.com/huangxueyan/PEME) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Progressive_Spatio-Temporal_Alignment_for_Efficient_Event-Based_Motion_Estimation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hEMm-Fkim7M) |
| RefSR-NeRF: Towards High Fidelity and Super Resolution View Synthesis | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_RefSR-NeRF_Towards_High_Fidelity_and_Super_Resolution_View_Synthesis_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| NoPe-NeRF: Optimising Neural Radiance Field with no Pose Prior <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://nope-nerf.active.vision/) <br /> [![GitHub](https://img.shields.io/github/stars/ActiveVisionLab/nope-nerf?style=flat)](https://github.com/ActiveVisionLab/nope-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bian_NoPe-NeRF_Optimising_Neural_Radiance_Field_With_No_Pose_Prior_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07388-b31b1b.svg)](https://arxiv.org/abs/2212.07388) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DVFbxol_mdA) |
| Spherical Transformer for LiDAR-based 3D Recognition | [![GitHub](https://img.shields.io/github/stars/dvlab-research/SphereFormer?style=flat)](https://github.com/dvlab-research/SphereFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lai_Spherical_Transformer_for_LiDAR-Based_3D_Recognition_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12766-b31b1b.svg)](https://arxiv.org/abs/2303.12766) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=b3p_7yin5Qk) |
| Progressively Optimized Local Radiance Fields for Robust View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://localrf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/localrf?style=flat)](https://github.com/facebookresearch/localrf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Meuleman_Progressively_Optimized_Local_Radiance_Fields_for_Robust_View_Synthesis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13791-b31b1b.svg)](https://arxiv.org/abs/2303.13791) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GfXAHDxUY4M) |
| PersonNeRF: Personalized Reconstruction from Photo Collections | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://grail.cs.washington.edu/projects/personnerf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Weng_PersonNeRF_Personalized_Reconstruction_From_Photo_Collections_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.08504-b31b1b.svg)](https://arxiv.org/abs/2302.08504) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XbkSYQw_dUE) |
| NeuWigs: A Neural Dynamic Model for Volumetric Hair Capture and Animation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ziyanw1.github.io/neuwigs/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_NeuWigs_A_Neural_Dynamic_Model_for_Volumetric_Hair_Capture_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00613-b31b1b.svg)](http://arxiv.org/abs/2212.00613) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=I6Lz4fgTt0c) |
| Representing Volumetric Videos as Dynamic MLP Maps | [![GitHub](https://img.shields.io/github/stars/zju3dv/mlp_maps?style=flat)](https://github.com/zju3dv/mlp_maps) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Peng_Representing_Volumetric_Videos_As_Dynamic_MLP_Maps_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06717-b31b1b.svg)](http://arxiv.org/abs/2304.06717) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s-ZSokF61iY) |
| Rethinking the Approximation Error in 3D Surface Fitting for Point Cloud Normal Estimation | [![GitHub](https://img.shields.io/github/stars/hikvision-research/3DVision?style=flat)](https://github.com/hikvision-research/3DVision) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Rethinking_the_Approximation_Error_in_3D_Surface_Fitting_for_Point_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17167-b31b1b.svg)](http://arxiv.org/abs/2303.17167) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0Hjzf0UCtq4) |
| A Practical Stereo Depth System for Smart Glasses | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_A_Practical_Stereo_Depth_System_for_Smart_Glasses_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10551-b31b1b.svg)](http://arxiv.org/abs/2211.10551) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jRh2qlclJ8w) |
| Compressing Volumetric Radiance Fields to 1 MB | [![GitHub](https://img.shields.io/github/stars/AlgoHunt/VQRF?style=flat)](https://github.com/AlgoHunt/VQRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Compressing_Volumetric_Radiance_Fields_to_1_MB_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16386-b31b1b.svg)](http://arxiv.org/abs/2211.16386) | :heavy_minus_sign: |
| HyperReel: High-Fidelity 6-DoF Video with Ray-Conditioned Sampling <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/facebookresearch/hyperreel?style=flat)](https://github.com/facebookresearch/hyperreel) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Attal_HyperReel_High-Fidelity_6-DoF_Video_With_Ray-Conditioned_Sampling_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.02238-b31b1b.svg)](https://arxiv.org/abs/2301.02238) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hBjJQ1lpR0k) |
| Point2Pix: Photo-Realistic Point Cloud Rendering via Neural Radiance Fields | :heavy_minus_sign:|[![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Point2Pix_Photo-Realistic_Point_Cloud_Rendering_via_Neural_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16482-b31b1b.svg)](http://arxiv.org/abs/2303.16482) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XmGJ8VfCxPQ) |
| Command-Driven Articulated Object Understanding and Manipulation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chu_Command-Driven_Articulated_Object_Understanding_and_Manipulation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-UJBvLH93uM) |
| SCADE: NeRFs from Space Carving with Ambiguity-Aware Depth Estimates | [![GitHub](https://img.shields.io/github/stars/mikacuy/scade?style=flat)](https://github.com/mikacuy/scade) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Uy_SCADE_NeRFs_from_Space_Carving_With_Ambiguity-Aware_Depth_Estimates_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13582-b31b1b.svg)](http://arxiv.org/abs/2303.13582) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5XwWZn-kjBU) |
| Panoptic Lifting for 3D Scene Understanding with Neural Fields <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/nihalsid/panoptic-lifting?style=flat)](https://github.com/nihalsid/panoptic-lifting) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Siddiqui_Panoptic_Lifting_for_3D_Scene_Understanding_With_Neural_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.09802-b31b1b.svg)](https://arxiv.org/abs/2212.09802) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://youtu.be/QtsiL-6rSuM) |
| PaletteNeRF: Palette-based Appearance Editing of Neural Radiance Fields | [![GitHub](https://img.shields.io/github/stars/zfkuang/PaletteNeRF?style=flat)](https://github.com/zfkuang/PaletteNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kuang_PaletteNeRF_Palette-Based_Appearance_Editing_of_Neural_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10699-b31b1b.svg)](http://arxiv.org/abs/2212.10699)| :heavy_minus_sign: |
| NeRFLix: High-Quality Neural View Synthesis by Learning a Degradation-Driven Inter-Viewpoint MiXer | [![GitHub](https://img.shields.io/github/stars/redrock303/NeRFLiX_CVPR2023?style=flat)](https://github.com/redrock303/NeRFLiX_CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_NeRFLix_High-Quality_Neural_View_Synthesis_by_Learning_a_Degradation-Driven_Inter-Viewpoint_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06919-b31b1b.svg)](http://arxiv.org/abs/2303.06919)| :heavy_minus_sign: |
| SegLoc: Learning Segmentation-based Representations for Privacy-Preserving Visual Localization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pietrantoni_SegLoc_Learning_Segmentation-Based_Representations_for_Privacy-Preserving_Visual_Localization_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| expOSE: Accurate Initialization-Free Projective Factorization using Exponential Regularization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Iglesias_expOSE_Accurate_Initialization-Free_Projective_Factorization_Using_Exponential_Regularization_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Neural Vector Fields: Implicit Representation by Explicit Learning | [![GitHub](https://img.shields.io/github/stars/Wi-sc/NVF?style=flat)](https://github.com/Wi-sc/NVF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Neural_Vector_Fields_Implicit_Representation_by_Explicit_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.04341-b31b1b.svg)](http://arxiv.org/abs/2303.04341) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GMXKoJfmHrU) |
| Unsupervised Inference of Signed Distance Functions from Single Sparse Point Clouds without Learning Priors | [![GitHub](https://img.shields.io/github/stars/chenchao15/NeuralTPS?style=flat)](https://github.com/chenchao15/NeuralTPS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Unsupervised_Inference_of_Signed_Distance_Functions_From_Single_Sparse_Point_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14505-b31b1b.svg)](http://arxiv.org/abs/2303.14505) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MxwpvWaw3_Q) |
| Learning to Measure the Point Cloud Reconstruction Loss in a Representation Space | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Learning_To_Measure_the_Point_Cloud_Reconstruction_Loss_in_a_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Grad-PU: Arbitrary-Scale Point Cloud Upsampling via Gradient Descent with Learned Distance Functions | [![GitHub](https://img.shields.io/github/stars/yunhe20/Grad-PU?style=flat)](https://github.com/yunhe20/Grad-PU) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Grad-PU_Arbitrary-Scale_Point_Cloud_Upsampling_via_Gradient_Descent_With_Learned_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VIDgUohCakc) |
| TensoIR: Tensorial Inverse Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://haian-jin.github.io/TensoIR/) <br /> [![GitHub](https://img.shields.io/github/stars/Haian-Jin/TensoIR?style=flat)](https://github.com/Haian-Jin/TensoIR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_TensoIR_Tensorial_Inverse_Rendering_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12461-b31b1b.svg)](http://arxiv.org/abs/2304.12461) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WMzTRwmDMgo) |
| Multi-View Inverse Rendering for Large-Scale Real-World Indoor Scenes | [![GitHub](https://img.shields.io/github/stars/LZleejean/TexIR_code?style=flat)](https://github.com/LZleejean/TexIR_code) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Multi-View_Inverse_Rendering_for_Large-Scale_Real-World_Indoor_Scenes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.10206-b31b1b.svg)](http://arxiv.org/abs/2211.10206) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lDKxJxg9o94) |
| Frequency-Modulated Point Cloud Rendering with Easy Editing <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/yizhangphd/FreqPCR?style=flat)](https://github.com/yizhangphd/FreqPCR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Frequency-Modulated_Point_Cloud_Rendering_With_Easy_Editing_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07596-b31b1b.svg)](http://arxiv.org/abs/2303.07596) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7gpKPyZb6ZY) |
| VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking | [![GitHub](https://img.shields.io/github/stars/dvlab-research/VoxelNeXt?style=flat)](https://github.com/dvlab-research/VoxelNeXt) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_VoxelNeXt_Fully_Sparse_VoxelNet_for_3D_Object_Detection_and_Tracking_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11301-b31b1b.svg)](http://arxiv.org/abs/2303.11301) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sXw71BCGWEo) |
| RGBD2: Generative Scene Synthesis via Incremental View Inpainting using RGBD Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jblei.site/proj/rgbd-diffusion) <br /> [![GitHub](https://img.shields.io/github/stars/Karbo123/RGBD-Diffusion?style=flat)](https://github.com/Karbo123/RGBD-Diffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lei_RGBD2_Generative_Scene_Synthesis_via_Incremental_View_Inpainting_Using_RGBD_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05993-b31b1b.svg)](http://arxiv.org/abs/2212.05993) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lxR5gMvw_Aw) |
| Multi-View Stereo Representation Revist: Region-Aware MVSNet | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Multi-View_Stereo_Representation_Revist_Region-Aware_MVSNet_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.13614-b31b1b.svg)](https://arxiv.org/abs/2304.13614) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NsTPmmdZNPE) |
| AutoRecon: Automated 3D Object Discovery and Reconstruction <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/autorecon/) <br /> [![GitHub](https://img.shields.io/github/stars/zju3dv/AutoRecon?style=flat)](https://github.com/zju3dv/AutoRecon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_AutoRecon_Automated_3D_Object_Discovery_and_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.08810-b31b1b.svg)](http://arxiv.org/abs/2305.08810) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yPZa9zIngAU) |
| Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sinha_Common_Pets_in_3D_Dynamic_New-View_Synthesis_of_Real-Life_Deformable_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.03889-b31b1b.svg)](http://arxiv.org/abs/2211.03889) | :heavy_minus_sign: |
| Binarizing Sparse Convolutional Networks for Efficient Point Cloud Analysis |  :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Binarizing_Sparse_Convolutional_Networks_for_Efficient_Point_Cloud_Analysis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15493-b31b1b.svg)](http://arxiv.org/abs/2303.15493) | :heavy_minus_sign: |
| LargeKernel3D: Scaling Up Kernels in 3D Sparse CNNs | [![GitHub](https://img.shields.io/github/stars/dvlab-research/LargeKernel3D?style=flat)](https://github.com/dvlab-research/LargeKernel3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_LargeKernel3D_Scaling_Up_Kernels_in_3D_Sparse_CNNs_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.10555-b31b1b.svg)](http://arxiv.org/abs/2206.10555) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=07Y_m-2YbU0) |
| Learning 3D Scene Priors With 2D Supervision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yinyunie.github.io/sceneprior-page/) <br /> [![GitHub](https://img.shields.io/github/stars/yinyunie/ScenePriors?style=flat)](https://github.com/yinyunie/ScenePriors) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Nie_Learning_3D_Scene_Priors_With_2D_Supervision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14157-b31b1b.svg)](http://arxiv.org/abs/2211.14157) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YT7MEdygRoY) |
| NeuralEditor: Editing Neural Radiance Fields via Manipulating Point Clouds | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://immortalco.github.io/NeuralEditor/) <br /> [![GitHub](https://img.shields.io/github/stars/immortalCO/NeuralEditor?style=flat)](https://github.com/immortalCO/NeuralEditor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_NeuralEditor_Editing_Neural_Radiance_Fields_via_Manipulating_Point_Clouds_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.03049-b31b1b.svg)](http://arxiv.org/abs/2305.03049) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1bsCUEkYcDw) |
| NeuralPCI: Spatio-Temporal Neural Field for 3D Point Cloud Multi-Frame Non-Linear Interpolation | [![GitHub](https://img.shields.io/github/stars/ispc-lab/NeuralPCI?style=flat)](https://github.com/ispc-lab/NeuralPCI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_NeuralPCI_Spatio-Temporal_Neural_Field_for_3D_Point_Cloud_Multi-Frame_Non-Linear_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15126-b31b1b.svg)](http://arxiv.org/abs/2303.15126) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KXPkEwBGzOI) |
| Two-View Geometry Scoring Without Correspondences | [![GitHub](https://img.shields.io/github/stars/nianticlabs/scoring-without-correspondences?style=flat)](https://github.com/nianticlabs/scoring-without-correspondences) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Barroso-Laguna_Two-View_Geometry_Scoring_Without_Correspondences_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.01596-b31b1b.svg)](https://arxiv.org/abs/2306.01596) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZlT5h3uuU1k) |
| Deep Graph-Based Spatial Consistency for Robust Non-Rigid Point Cloud Registration | [![GitHub](https://img.shields.io/github/stars/qinzheng93/GraphSCNet?style=flat)](https://github.com/qinzheng93/GraphSCNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_Deep_Graph-Based_Spatial_Consistency_for_Robust_Non-Rigid_Point_Cloud_Registration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09950-b31b1b.svg)](http://arxiv.org/abs/2303.09950) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FOSYLtbAlKc) |
| RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cai_RIAV-MVS_Recurrent-Indexing_an_Asymmetric_Volume_for_Multi-View_Stereo_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.14320-b31b1b.svg)](https://arxiv.org/abs/2205.14320) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7nvtlz0Caso) |
| Depth Estimation From Camera Image and mmWave Radar Point Cloud | [![GitHub](https://img.shields.io/github/stars/nesl/radar-camera-fusion-depth?style=flat)](https://github.com/nesl/radar-camera-fusion-depth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_Depth_Estimation_From_Camera_Image_and_mmWave_Radar_Point_Cloud_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Hierarchical Supervision and Shuffle Data Augmentation for 3D Semi-Supervised Object Detection | [![GitHub](https://img.shields.io/github/stars/azhuantou/HSSDA?style=flat)](https://github.com/azhuantou/HSSDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Hierarchical_Supervision_and_Shuffle_Data_Augmentation_for_3D_Semi-Supervised_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01464-b31b1b.svg)](http://arxiv.org/abs/2304.01464) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=h0z16Po6y28) |
| Multiscale Tensor Decomposition and Rendering Equation Encoding for View Synthesis | [![GitHub](https://img.shields.io/github/stars/imkanghan/nrff?style=flat)](https://github.com/imkanghan/nrff) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Han_Multiscale_Tensor_Decomposition_and_Rendering_Equation_Encoding_for_View_Synthesis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.03808-b31b1b.svg)](http://arxiv.org/abs/2303.03808) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Sj095PTUUC8) |
| PATS: Patch Area Transportation With Subdivision for Local Feature Matching | [![GitHub](https://img.shields.io/github/stars/zju3dv/pats?style=flat)](https://github.com/zju3dv/pats) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ni_PATS_Patch_Area_Transportation_With_Subdivision_for_Local_Feature_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07700-b31b1b.svg)](http://arxiv.org/abs/2303.07700) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=c5iTnc9cjvc) |
| Depth Estimation From Indoor Panoramas With Neural Scene Representation | [![GitHub](https://img.shields.io/github/stars/WJ-Chang-42/IndoorPanoDepth?style=flat)](https://github.com/WJ-Chang-42/IndoorPanoDepth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chang_Depth_Estimation_From_Indoor_Panoramas_With_Neural_Scene_Representation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hxFzpgLNCDI) |
| Masked Representation Learning for Domain Generalized Stereo Matching | [![GitHub](https://img.shields.io/github/stars/jiaw-z/FCStereo?style=flat)](https://github.com/jiaw-z/FCStereo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rao_Masked_Representation_Learning_for_Domain_Generalized_Stereo_Matching_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KNT9FjS-C0U) |
| GANHead: Towards Generative Animatable Neural Head Avatars | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wsj-sjtu.github.io/GANHead/) <br /> [![GitHub](https://img.shields.io/github/stars/wsj-sjtu/GANHead?style=flat)](https://github.com/wsj-sjtu/GANHead) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_GANHead_Towards_Generative_Animatable_Neural_Head_Avatars_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03950-b31b1b.svg)](http://arxiv.org/abs/2304.03950) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Cg0ubzo7DXk) |
| Visual-Tactile Sensing for In-Hand Object Reconstruction | [![GitHub](https://img.shields.io/github/stars/jeffsonyu/VTacO?style=flat)](https://github.com/jeffsonyu/VTacO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Visual-Tactile_Sensing_for_In-Hand_Object_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14498-b31b1b.svg)](http://arxiv.org/abs/2303.14498) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3Dd6L9i3MAg) |
| IterativePFN: True Iterative Point Cloud Filtering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ddsediri.github.io/projects/IterativePFN/) <br /> [![GitHub](https://img.shields.io/github/stars/ddsediri/IterativePFN?style=flat)](https://github.com/ddsediri/IterativePFN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/de_Silva_Edirimuni_IterativePFN_True_Iterative_Point_Cloud_Filtering_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01529-b31b1b.svg)](http://arxiv.org/abs/2304.01529) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iH9GSUIOzhU) |
| Towards Better Gradient Consistency for Neural Signed Distance Functions via Level Set Alignment | [![GitHub](https://img.shields.io/github/stars/mabaorui/TowardsBetterGradient?style=flat)](https://github.com/mabaorui/TowardsBetterGradient) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_Towards_Better_Gradient_Consistency_for_Neural_Signed_Distance_Functions_via_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.11601-b31b1b.svg)](https://arxiv.org/abs/2305.11601) | :heavy_minus_sign: |
| GarmentTracking: Category-Level Garment Pose Tracking | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://garment-tracking.robotflow.ai/) <br /> [![GitHub](https://img.shields.io/github/stars/xiaoxiaoxh/GarmentTracking?style=flat)](https://github.com/xiaoxiaoxh/GarmentTracking) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_GarmentTracking_Category-Level_Garment_Pose_Tracking_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13913-b31b1b.svg)](http://arxiv.org/abs/2303.13913) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WJU1r5YrW-o) |
| Learning Transformation-Predictive Representations for Detection and Description of Local Features | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Learning_Transformation-Predictive_Representations_for_Detection_and_Description_of_Local_Features_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Local Implicit Ray Function for Generalizable Radiance Field Representation | [![GitHub](https://img.shields.io/github/stars/xhuangcv/lirf?style=flat)](https://github.com/xhuangcv/lirf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Local_Implicit_Ray_Function_for_Generalizable_Radiance_Field_Representation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12746-b31b1b.svg)](http://arxiv.org/abs/2304.12746) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=41__UC1eU5U) |
| Grid-Guided Neural Radiance Fields for Large Urban Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://city-super.github.io/gridnerf/) <br /> [![GitHub](https://img.shields.io/github/stars/InternLandMark/LandMark?style=flat)](https://github.com/InternLandMark/LandMark) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Grid-Guided_Neural_Radiance_Fields_for_Large_Urban_Scenes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14001-b31b1b.svg)](http://arxiv.org/abs/2303.14001) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uZxSnX5nXd4) |
| EventNeRF: Neural Radiance Fields From a Single Colour Event Camera | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://4dqv.mpi-inf.mpg.de/EventNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/r00tman/EventNeRF?style=flat)](https://github.com/r00tman/EventNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rudnev_EventNeRF_Neural_Radiance_Fields_From_a_Single_Colour_Event_Camera_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.11896-b31b1b.svg)](http://arxiv.org/abs/2206.11896) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AjtljRfIn68) |
| Learning Optical Expansion From Scale Matching | [![GitHub](https://img.shields.io/github/stars/HanLingsgjk/TPCV?style=flat)](https://github.com/HanLingsgjk/TPCV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ling_Learning_Optical_Expansion_From_Scale_Matching_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wfFJKgRu_oY) |
| Self-Supervised 3D Scene Flow Estimation Guided by Superpoints | [![GitHub](https://img.shields.io/github/stars/supersyq/SPFlowNet?style=flat)](https://github.com/supersyq/SPFlowNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_Self-Supervised_3D_Scene_Flow_Estimation_Guided_by_Superpoints_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.02528-b31b1b.svg)](http://arxiv.org/abs/2305.02528) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jD3eRRGvkRE) |
| Adaptive Annealing for Robust Geometric Estimation| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sidhartha_Adaptive_Annealing_for_Robust_Geometric_Estimation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oKMlJSdYYEI) |
| SurfelNeRF: Neural Surfel Radiance Fields for Online Photorealistic Reconstruction of Indoor Scenes | [![GitHub](https://img.shields.io/github/stars/TencentARC/SurfelNeRF?style=flat)](https://github.com/TencentARC/SurfelNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_SurfelNeRF_Neural_Surfel_Radiance_Fields_for_Online_Photorealistic_Reconstruction_of_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08971-b31b1b.svg)](http://arxiv.org/abs/2304.08971) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=K8sKg0s5SFo) |
| PlaneDepth: Self-Supervised Depth Estimation via Orthogonal Planes | [![GitHub](https://img.shields.io/github/stars/svip-lab/PlaneDepth?style=flat)](https://github.com/svip-lab/PlaneDepth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_PlaneDepth_Self-Supervised_Depth_Estimation_via_Orthogonal_Planes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.01612-b31b1b.svg)](http://arxiv.org/abs/2210.01612) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_qW5RB1fG-E) |
| High-Res Facial Appearance Capture From Polarized Smartphone Images | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dazinovic.github.io/polface/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Azinovic_High-Res_Facial_Appearance_Capture_From_Polarized_Smartphone_Images_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01160-b31b1b.svg)](https://arxiv.org/abs/2212.01160) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jnb4V0qURtc) |
| Tensor4D: Efficient Neural 4D Decomposition for High-Fidelity Dynamic Reconstruction and Rendering | [![GitHub](https://img.shields.io/github/stars/DSaurus/Tensor4D?style=flat)](https://github.com/DSaurus/Tensor4D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shao_Tensor4D_Efficient_Neural_4D_Decomposition_for_High-Fidelity_Dynamic_Reconstruction_and_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11610-b31b1b.svg)](http://arxiv.org/abs/2211.11610) | :heavy_minus_sign: |
| Fully Self-Supervised Depth Estimation From Defocus Clue | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ehzoahis.github.io/DEReD/) <br /> [![GitHub](https://img.shields.io/github/stars/Ehzoahis/DEReD?style=flat)](https://github.com/Ehzoahis/DEReD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Si_Fully_Self-Supervised_Depth_Estimation_From_Defocus_Clue_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10752-b31b1b.svg)](http://arxiv.org/abs/2303.10752) | :heavy_minus_sign: |
| Adaptive Assignment for Geometry Aware Local Feature Matching | [![GitHub](https://img.shields.io/github/stars/AbyssGaze/AdaMatcher?style=flat)](https://github.com/AbyssGaze/AdaMatcher) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Adaptive_Assignment_for_Geometry_Aware_Local_Feature_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.08427-b31b1b.svg)](http://arxiv.org/abs/2207.08427) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=qReq_GhzLG8) |
| Efficient Second-Order Plane Adjustment <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Efficient_Second-Order_Plane_Adjustment_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11542-b31b1b.svg)](http://arxiv.org/abs/2211.11542) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=THRpAzEdVfg) |
| Learning Adaptive Dense Event Stereo From the Image Domain | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cho_Learning_Adaptive_Dense_Event_Stereo_From_the_Image_Domain_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=THRpAzEdVfg) |
| FreeNeRF: Improving Few-Shot Neural Rendering With Free Frequency Regularization | [![GitHub](https://img.shields.io/github/stars/Jiawei-Yang/FreeNeRF?style=flat)](https://github.com/Jiawei-Yang/FreeNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_FreeNeRF_Improving_Few-Shot_Neural_Rendering_With_Free_Frequency_Regularization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07418-b31b1b.svg)](http://arxiv.org/abs/2303.07418) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JL4umtVIEvw) |
| SteerNeRF: Accelerating NeRF Rendering via Smooth Viewpoint Trajectory | [![GitHub](https://img.shields.io/github/stars/JasonLSC/SteerNeRF_official?style=flat)](https://github.com/JasonLSC/SteerNeRF_official) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_SteerNeRF_Accelerating_NeRF_Rendering_via_Smooth_Viewpoint_Trajectory_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.08476-b31b1b.svg)](http://arxiv.org/abs/2212.08476) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=J2KAdxPo1tY) |
| Cross-Guided Optimization of Radiance Fields With Multi-View Image Super-Resolution for High-Resolution Novel View Synthesis | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yoon_Cross-Guided_Optimization_of_Radiance_Fields_With_Multi-View_Image_Super-Resolution_for_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GuqnhO9IdGw) |
| AeDet: Azimuth-Invariant Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/fcjian/AeDet?style=flat)](https://github.com/fcjian/AeDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_AeDet_Azimuth-Invariant_Multi-View_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12501-b31b1b.svg)](http://arxiv.org/abs/2211.12501) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?app=desktop&v=DXO346EZjLk&embeds_referring_euri=https%3A%2F%2Fcvpr2023.thecvf.com%2F&feature=emb_imp_woyt) |
| Local-to-Global Registration for Bundle-Adjusting Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rover-xingyu.github.io/L2G-NeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/rover-xingyu/L2G-NeRF?style=flat)](https://github.com/rover-xingyu/L2G-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Local-to-Global_Registration_for_Bundle-Adjusting_Neural_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11505-b31b1b.svg)](http://arxiv.org/abs/2211.11505) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=y8XP9Umt6Mw) |
| DKM: Dense Kernelized Feature Matching for Geometry Estimation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://parskatt.github.io/DKM/) <br /> [![GitHub](https://img.shields.io/github/stars/Parskatt/DKM?style=flat)](https://github.com/Parskatt/DKM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Edstedt_DKM_Dense_Kernelized_Feature_Matching_for_Geometry_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2202.00667-b31b1b.svg)](https://arxiv.org/abs/2202.00667) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DEyHakUf8Ug) |
| DINER: Depth-Aware Image-Based NEural Radiance Fields | [![GitHub](https://img.shields.io/github/stars/malteprinzler/diner?style=flat)](https://github.com/malteprinzler/diner) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Prinzler_DINER_Depth-Aware_Image-Based_NEural_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16630-b31b1b.svg)](http://arxiv.org/abs/2211.16630) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iI_fpjY5k8Y) |
| HGNet: Learning Hierarchical Geometry From Points, Edges, and Surfaces | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_HGNet_Learning_Hierarchical_Geometry_From_Points_Edges_and_Surfaces_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kMKQNxr0sHY) |
| Instant Volumetric Head Avatars | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zielon.github.io/insta/) <br /> [![GitHub](https://img.shields.io/github/stars/Zielon/INSTA?style=flat)](https://github.com/Zielon/INSTA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zielonka_Instant_Volumetric_Head_Avatars_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12499-b31b1b.svg)](http://arxiv.org/abs/2211.12499) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HOgaeWTih7Q) |
| 3D Line Mapping Revisited <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/cvg/limap?style=flat)](https://github.com/cvg/limap) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_3D_Line_Mapping_Revisited_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17504-b31b1b.svg)](http://arxiv.org/abs/2303.17504) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=c2rqLWXQtvA) |
| Learning To Fuse Monocular and Multi-View Cues for Multi-Frame Depth Estimation in Dynamic Scenes | [![GitHub](https://img.shields.io/github/stars/ruili3/dynamic-multiframe-depth?style=flat)](https://github.com/ruili3/dynamic-multiframe-depth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_To_Fuse_Monocular_and_Multi-View_Cues_for_Multi-Frame_Depth_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08993-b31b1b.svg)](http://arxiv.org/abs/2304.08993) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0ViYXt2bpuM) |
| ESLAM: Efficient Dense SLAM System Based on Hybrid Representation of Signed Distance Fields <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://www.idiap.ch/paper/eslam/) <br /> [![GitHub](https://img.shields.io/github/stars/idiap/ESLAM?style=flat)](https://github.com/idiap/ESLAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Johari_ESLAM_Efficient_Dense_SLAM_System_Based_on_Hybrid_Representation_of_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11704-b31b1b.svg)](http://arxiv.org/abs/2211.11704) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=g7awmsDKDnw) |
| Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://www.cs.cmu.edu/~tkhurana/ff4d/index.html) <br /> [![GitHub](https://img.shields.io/github/stars/tarashakhurana/4d-occ-forecasting?style=flat)](https://github.com/tarashakhurana/4d-occ-forecasting) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Khurana_Point_Cloud_Forecasting_as_a_Proxy_for_4D_Occupancy_Forecasting_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.13130-b31b1b.svg)](http://arxiv.org/abs/2302.13130) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=v9rmkYEYmh8) |
| SparsePose: Sparse-View Camera Pose Regression and Refinement| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sinha_SparsePose_Sparse-View_Camera_Pose_Regression_and_Refinement_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16991-b31b1b.svg)](http://arxiv.org/abs/2211.16991) | :heavy_minus_sign: |
| Controllable Mesh Generation Through Sparse Latent Point Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://liuff19.github.io/S-Ray/) <br /> [![GitHub](https://img.shields.io/github/stars/SLIDE-3D/SLIDE?style=flat)](https://github.com/SLIDE-3D/SLIDE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lyu_Controllable_Mesh_Generation_Through_Sparse_Latent_Point_Diffusion_Models_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07938-b31b1b.svg)](http://arxiv.org/abs/2303.07938) | :heavy_minus_sign: |
| ARO-Net: Learning Implicit Fields From Anchored Radial Observations | [![GitHub](https://img.shields.io/github/stars/yizhiwang96/ARO-Net?style=flat)](https://github.com/yizhiwang96/ARO-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_ARO-Net_Learning_Implicit_Fields_From_Anchored_Radial_Observations_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10275-b31b1b.svg)](https://arxiv.org/abs/2212.10275) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RVoOkgbi9lk) |
| Semantic Ray: Learning a Generalizable Semantic Field With Cross-Reprojection Attention | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://liuff19.github.io/S-Ray/) <br /> [![GitHub](https://img.shields.io/github/stars/liuff19/Semantic-Ray?style=flat)](https://github.com/liuff19/Semantic-Ray) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Semantic_Ray_Learning_a_Generalizable_Semantic_Field_With_Cross-Reprojection_Attention_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13014-b31b1b.svg)](http://arxiv.org/abs/2303.13014) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aP3iwNE71rc) |
| Sphere-Guided Training of Neural Implicit Surfaces | [![GitHub](https://img.shields.io/github/stars/AndreeaDogaru/SphereGuided?style=flat)](https://github.com/AndreeaDogaru/SphereGuided) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dogaru_Sphere-Guided_Training_of_Neural_Implicit_Surfaces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.15511-b31b1b.svg)](http://arxiv.org/abs/2209.15511) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G6CTF1kAxik) |
| Finding Geometric Models by Clustering in the Consensus Space| [![GitHub](https://img.shields.io/github/stars/danini/clustering-in-consensus-space?style=flat)](https://github.com/danini/clustering-in-consensus-space) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Barath_Finding_Geometric_Models_by_Clustering_in_the_Consensus_Space_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2103.13875-b31b1b.svg)](https://arxiv.org/abs/2103.13875) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=dV8D8jqzSc0) |
| NeuralDome: A Neural Modeling Pipeline on Multi-View Human-Object Interactions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://juzezhang.github.io/NeuralDome/) <br /> [![GitHub](https://img.shields.io/github/stars/Juzezhang/NeuralDome_Toolbox?style=flat)](https://github.com/liuff19/Semantic-Ray) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_NeuralDome_A_Neural_Modeling_Pipeline_on_Multi-View_Human-Object_Interactions_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07626-b31b1b.svg)](http://arxiv.org/abs/2212.07626) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Nb82f5dm2GE) |
| Privacy-Preserving Representations Are Not Enough: Recovering Scene Content From Camera Poses| [![GitHub](https://img.shields.io/github/stars/kunalchelani/ObjectPositioningFromPoses?style=flat)](https://github.com/kunalchelani/ObjectPositioningFromPoses) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chelani_Privacy-Preserving_Representations_Are_Not_Enough_Recovering_Scene_Content_From_Camera_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.04603-b31b1b.svg)](https://arxiv.org/abs/2305.04603) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8qmkkrMayZo) |
| Robust Multiview Point Cloud Registration With Reliable Pose Graph Initialization and History Reweighting | [![GitHub](https://img.shields.io/github/stars/WHU-USI3DV/SGHR?style=flat)](https://github.com/WHU-USI3DV/SGHR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Robust_Multiview_Point_Cloud_Registration_With_Reliable_Pose_Graph_Initialization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00467-b31b1b.svg)](http://arxiv.org/abs/2304.00467) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3Afg6Tx-k68) |
| Neural Part Priors: Learning To Optimize Part-Based Object Completion in RGB-D Scans <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://alexeybokhovkin.github.io/neural-part-priors/) <br /> [![GitHub](https://img.shields.io/github/stars/alexeybokhovkin/neural-part-priors?style=flat)](https://github.com/alexeybokhovkin/neural-part-priors) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bokhovkin_Neural_Part_Priors_Learning_To_Optimize_Part-Based_Object_Completion_in_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.09375-b31b1b.svg)](https://arxiv.org/abs/2203.09375) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rWgFcFOy4LM) |
| Accelerated Coordinate Encoding: Learning to Relocalize in Minutes Using RGB and Poses <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nianticlabs.github.io/ace/) <br /> [![GitHub](https://img.shields.io/github/stars/nianticlabs/ace?style=flat)](https://github.com/nianticlabs/ace) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Brachmann_Accelerated_Coordinate_Encoding_Learning_to_Relocalize_in_Minutes_Using_RGB_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.14059-b31b1b.svg)](https://arxiv.org/abs/2305.14059) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=eDRBolkokC0) |
| Gated Stereo: Joint Depth Estimation From Gated and Wide-Baseline Active Stereo Cues <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://light.princeton.edu/publication/gatedstereo/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Walz_Gated_Stereo_Joint_Depth_Estimation_From_Gated_and_Wide-Baseline_Active_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.12955-b31b1b.svg)](https://arxiv.org/abs/2305.12955) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=llVHHcJFSn4) |
| Revisiting Rotation Averaging: Uncertainties and Robust Losses | [![GitHub](https://img.shields.io/github/stars/zhangganlin/GlobalSfMpy?style=flat)](https://github.com/zhangganlin/GlobalSfMpy) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Revisiting_Rotation_Averaging_Uncertainties_and_Robust_Losses_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05195-b31b1b.svg)](http://arxiv.org/abs/2303.05195) | :heavy_minus_sign: |
| NeRF-Supervised Deep Stereo | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nerfstereo.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/fabiotosi92/NeRF-Supervised-Deep-Stereo?style=flat)](https://github.com/fabiotosi92/NeRF-Supervised-Deep-Stereo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tosi_NeRF-Supervised_Deep_Stereo_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17603-b31b1b.svg)](http://arxiv.org/abs/2303.17603) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m7dqHkxb4yg) |
| POEM: Reconstructing Hand in a Point Embedded Multi-View Stereo | [![GitHub](https://img.shields.io/github/stars/lixiny/POEM?style=flat)](https://github.com/lixiny/POEM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_POEM_Reconstructing_Hand_in_a_Point_Embedded_Multi-View_Stereo_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04038-b31b1b.svg)](http://arxiv.org/abs/2304.04038) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=C_7koL1XfN0) |
| vMAP: Vectorised Object Mapping for Neural Field SLAM | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kxhit.github.io/vMAP) <br /> [![GitHub](https://img.shields.io/github/stars/kxhit/vMAP?style=flat)](https://github.com/kxhit/vMAP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_vMAP_Vectorised_Object_Mapping_for_Neural_Field_SLAM_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.01838-b31b1b.svg)](http://arxiv.org/abs/2302.01838) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_H_jNnhUAsE) |
| PET-NeuS: Positional Encoding Tri-Planes for Neural Surfaces | [![GitHub](https://img.shields.io/github/stars/yiqun-wang/PET-NeuS?style=flat)](https://github.com/yiqun-wang/PET-NeuS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_PET-NeuS_Positional_Encoding_Tri-Planes_for_Neural_Surfaces_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.05594-b31b1b.svg)](https://arxiv.org/abs/2305.05594) |[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NWxEjw8FzeI) |
| Learnable Skeleton-Aware 3D Point Cloud Sampling | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_Learnable_Skeleton-Aware_3D_Point_Cloud_Sampling_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=blCeuePN58k) |
| ObjectMatch: Robust Registration Using Canonical Object Correspondences | [![GitHub](https://img.shields.io/github/stars/cangumeli/ObjectMatch?style=flat)](https://github.com/cangumeli/ObjectMatch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gumeli_ObjectMatch_Robust_Registration_Using_Canonical_Object_Correspondences_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01985-b31b1b.svg)](https://arxiv.org/abs/2212.01985) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kuXoKVrzURk) |
| DiffRF: Rendering-Guided 3D Radiance Field Diffusion <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sirwyver.github.io/DiffRF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Muller_DiffRF_Rendering-Guided_3D_Radiance_Field_Diffusion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01206-b31b1b.svg)](https://arxiv.org/abs/2212.01206) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=qETBcLu8SUk) |
| Learning a Depth Covariance Function | [![GitHub](https://img.shields.io/github/stars/edexheim/DepthCov?style=flat)](https://github.com/edexheim/DepthCov) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dexheimer_Learning_a_Depth_Covariance_Function_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12157-b31b1b.svg)](http://arxiv.org/abs/2303.12157) | :heavy_minus_sign: |
| Viewpoint Equivariance for Multi-View 3D Object Detection | [![GitHub](https://img.shields.io/github/stars/TRI-ML/VEDet?style=flat)](https://github.com/TRI-ML/VEDet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Viewpoint_Equivariance_for_Multi-View_3D_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14548-b31b1b.svg)](http://arxiv.org/abs/2303.14548) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AKTW7A5w19g) |
| BlendFields: Few-Shot Example-Driven Facial Modeling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://blendfields.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kania_BlendFields_Few-Shot_Example-Driven_Facial_Modeling_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.07514-b31b1b.svg)](http://arxiv.org/abs/2305.07514) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pm0e2lOAQ7U) |
| Implicit Surface Contrastive Clustering for LiDAR Point Clouds | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Implicit_Surface_Contrastive_Clustering_for_LiDAR_Point_Clouds_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pm0e2lOAQ7U) |
| Self-Supervised Super-Plane for Neural 3D Reconstruction| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Self-Supervised_Super-Plane_for_Neural_3D_Reconstruction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oYHy8i6Vr-A) |
| DiffusioNeRF: Regularizing Neural Radiance Fields with Denoising Diffusion Models | [![GitHub](https://img.shields.io/github/stars/nianticlabs/diffusionerf?style=flat)](https://github.com/nianticlabs/diffusionerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wynn_DiffusioNeRF_Regularizing_Neural_Radiance_Fields_With_Denoising_Diffusion_Models_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.12231-b31b1b.svg)](http://arxiv.org/abs/2302.12231) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zyRbeBbM-mw) |
| AligNeRF: High-Fidelity Neural Radiance Fields via Alignment-Aware Training | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yifanjiang19.github.io/alignerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_AligNeRF_High-Fidelity_Neural_Radiance_Fields_via_Alignment-Aware_Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09682-b31b1b.svg)](http://arxiv.org/abs/2211.09682) | :heavy_minus_sign: |
| VisFusion: Visibility-Aware Online 3D Scene Reconstruction from Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://huiyu-gao.github.io/visfusion) <br /> [![GitHub](https://img.shields.io/github/stars/huiyu-gao/VisFusion?style=flat)](https://github.com/huiyu-gao/VisFusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_VisFusion_Visibility-Aware_Online_3D_Scene_Reconstruction_From_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10687-b31b1b.svg)](http://arxiv.org/abs/2304.10687) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WpblFxLq6rE) |
| Fast Monocular Scene Reconstruction with Global-Sparse Local-Dense Grids | [![GitHub](https://img.shields.io/github/stars/theNded/torch-ash?style=flat)](https://github.com/theNded/torch-ash) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_Fast_Monocular_Scene_Reconstruction_With_Global-Sparse_Local-Dense_Grids_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.13220-b31b1b.svg)](http://arxiv.org/abs/2305.13220) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=87guWiDZkSI) |
| Semi-Weakly Supervised Object Kinematic Motion Prediction | [![GitHub](https://img.shields.io/github/stars/GengxinLiu/SWMP?style=flat)](https://github.com/GengxinLiu/SWMP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Semi-Weakly_Supervised_Object_Kinematic_Motion_Prediction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17774-b31b1b.svg)](http://arxiv.org/abs/2303.17774) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QQ1QU1yVQpk) |
| OmniVidar: Omnidirectional Depth Estimation from Multi-Fisheye Images | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_OmniVidar_Omnidirectional_Depth_Estimation_From_Multi-Fisheye_Images_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=d_zsejaxHg0) |
| ContraNeRF: Generalizable Neural Radiance Fields for Synthetic-to-Real Novel View Synthesis via Contrastive Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_ContraNeRF_Generalizable_Neural_Radiance_Fields_for_Synthetic-to-Real_Novel_View_Synthesis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11052-b31b1b.svg)](http://arxiv.org/abs/2303.11052) | :heavy_minus_sign: |
| PointVector: A Vector Representation in Point Cloud Analysis| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_PointVector_A_Vector_Representation_in_Point_Cloud_Analysis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.10528-b31b1b.svg)](http://arxiv.org/abs/2205.10528) | :heavy_minus_sign: |
| Poly-PC: A Polyhedral Network for Multiple Point Cloud Tasks at Once | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Poly-PC_A_Polyhedral_Network_for_Multiple_Point_Cloud_Tasks_at_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=eKrlaIbVt3A) |
| Learning Neural Duplex Radiance Fields for Real-Time View Synthesis | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://raywzy.com/NDRF/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wan_Learning_Neural_Duplex_Radiance_Fields_for_Real-Time_View_Synthesis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10537-b31b1b.svg)](http://arxiv.org/abs/2304.10537) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0xtbTClz7r0) |
| VolRecon: Volume Rendering of Signed Ray Distance Functions for Generalizable Multi-View Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fangjinhuawang.github.io/VolRecon/) <br /> [![GitHub](https://img.shields.io/github/stars/IVRL/VolRecon?style=flat)](https://github.com/IVRL/VolRecon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_VolRecon_Volume_Rendering_of_Signed_Ray_Distance_Functions_for_Generalizable_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.08067-b31b1b.svg)](http://arxiv.org/abs/2212.08067) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mxzeAntXVa8) |
| CompletionFormer: Depth Completion with Convolutions and Vision Transformers | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://youmi-zym.github.io/projects/CompletionFormer/) <br /> [![GitHub](https://img.shields.io/github/stars/youmi-zym/CompletionFormer?style=flat)](https://github.com/youmi-zym/CompletionFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_CompletionFormer_Depth_Completion_With_Convolutions_and_Vision_Transformers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.13030-b31b1b.svg)](http://arxiv.org/abs/2304.13030) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SLKAwrY2qjg) |
| Exact-NeRF: An Exploration of a Precise Volumetric Parameterization for Neural Radiance Fields | [![GitHub](https://img.shields.io/github/stars/KostadinovShalon/exact-nerf?style=flat)](https://github.com/KostadinovShalon/exact-nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Isaac-Medina_Exact-NeRF_An_Exploration_of_a_Precise_Volumetric_Parameterization_for_Neural_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12285-b31b1b.svg)](http://arxiv.org/abs/2211.12285) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1ck25jJdw7A) |
| Collaboration Helps Camera Overtake LiDAR in 3D Detection | [![GitHub](https://img.shields.io/github/stars/MediaBrain-SJTU/CoCa3D?style=flat)](https://github.com/MediaBrain-SJTU/CoCa3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Collaboration_Helps_Camera_Overtake_LiDAR_in_3D_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13560-b31b1b.svg)](http://arxiv.org/abs/2303.13560) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xev7DqT62jQ) |
| SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://spinnerf3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/SamsungLabs/SPIn-NeRF?style=flat)](https://github.com/SamsungLabs/SPIn-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mirzaei_SPIn-NeRF_Multiview_Segmentation_and_Perceptual_Inpainting_With_Neural_Radiance_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12254-b31b1b.svg)](http://arxiv.org/abs/2211.12254) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7TAbfu6qOjY) |
| GeoMVSNet: Learning Multi-View Stereo with Geometry Perception | [![GitHub](https://img.shields.io/github/stars/doubleZ0108/GeoMVSNet?style=flat)](https://github.com/doubleZ0108/GeoMVSNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_GeoMVSNet_Learning_Multi-View_Stereo_With_Geometry_Perception_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XqLDgJAZAKc) |
| 3D Shape Reconstruction of Semi-Transparent Worms | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ilett_3D_Shape_Reconstruction_of_Semi-Transparent_Worms_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14841-b31b1b.svg)](http://arxiv.org/abs/2304.14841) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=k7dqn8kXKNk) |
| Revisiting Rolling Shutter Bundle Adjustment: Toward Accurate and Fast Solution | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://delinqu.github.io/NW-RSBA/) <br /> [![GitHub](https://img.shields.io/github/stars/DelinQu/NW-RSBA?style=flat)](https://github.com/DelinQu/NW-RSBA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liao_Revisiting_Rolling_Shutter_Bundle_Adjustment_Toward_Accurate_and_Fast_Solution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.08503-b31b1b.svg)](http://arxiv.org/abs/2209.08503) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aCo60XUatss) |
| Virtual Occlusions through Implicit Depth | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nianticlabs.github.io/implicit-depth/) <br /> [![GitHub](https://img.shields.io/github/stars/nianticlabs/implicit-depth?style=flat)](https://github.com/nianticlabs/implicit-depth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Watson_Virtual_Occlusions_Through_Implicit_Depth_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.07014-b31b1b.svg)](http://arxiv.org/abs/2305.07014) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-hcvZrXO8wM) |
| Neural Fields meet Explicit Geometric Representations for Inverse Rendering of Urban Scenes | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.nvidia.com/labs/toronto-ai/fegr/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Neural_Fields_Meet_Explicit_Geometric_Representations_for_Inverse_Rendering_of_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03266-b31b1b.svg)](http://arxiv.org/abs/2304.03266) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1KvHY3tlhhY) |
| Building Rearticulable Models for Arbitrary 3D Objects from 4D Point Clouds | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://stevenlsw.github.io/reart/) <br /> [![GitHub](https://img.shields.io/github/stars/stevenlsw/reart?style=flat)](https://github.com/stevenlsw/reart) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Building_Rearticulable_Models_for_Arbitrary_3D_Objects_From_4D_Point_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.00979-b31b1b.svg)](http://arxiv.org/abs/2306.00979) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Bdolp3FTZUc) |
| DynamicStereo: Consistent Dynamic Depth from Stereo Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dynamic-stereo.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/dynamic_stereo?style=flat)](https://github.com/facebookresearch/dynamic_stereo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Karaev_DynamicStereo_Consistent_Dynamic_Depth_From_Stereo_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.02296-b31b1b.svg)](http://arxiv.org/abs/2305.02296) | :heavy_minus_sign: |
| Robust Outlier Rejection for 3D Registration with Variational Bayes | [![GitHub](https://img.shields.io/github/stars/Jiang-HB/VBReg?style=flat)](https://github.com/Jiang-HB/VBReg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Robust_Outlier_Rejection_for_3D_Registration_With_Variational_Bayes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01514-b31b1b.svg)](http://arxiv.org/abs/2304.01514) | :heavy_minus_sign: |
| Meta Architecture for Point Cloud Analysis | [![GitHub](https://img.shields.io/github/stars/linhaojia13/PointMetaBase?style=flat)](https://github.com/linhaojia13/PointMetaBase) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Meta_Architecture_for_Point_Cloud_Analysis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14462-b31b1b.svg)](http://arxiv.org/abs/2211.14462) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=b226ySWoipY) |
| DyLiN: Making Light Field Networks Dynamic | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dylin2023.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Heng14/DyLiN?style=flat)](https://github.com/Heng14/DyLiN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_DyLiN_Making_Light_Field_Networks_Dynamic_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14243-b31b1b.svg)](http://arxiv.org/abs/2303.14243) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8UGWWYJrv3s) |
| Domain Generalized Stereo Matching via Hierarchical Visual Transformation | [![GitHub](https://img.shields.io/github/stars/cty8998/HVT-PSMNet?style=flat)](https://github.com/cty8998/HVT-PSMNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chang_Domain_Generalized_Stereo_Matching_via_Hierarchical_Visual_Transformation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fOWjI67gZz8) |
| Learning Visibility Field for Detailed 3D Human Reconstruction and Relighting | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Learning_Visibility_Field_for_Detailed_3D_Human_Reconstruction_and_Relighting_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11900-b31b1b.svg)](http://arxiv.org/abs/2304.11900) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YeMCgPaz1Ww) |
| LightedDepth: Video Depth Estimation in Light of Limited Inference View Angles | [![GitHub](https://img.shields.io/github/stars/ShngJZ/LightedDepth?style=flat)](https://github.com/ShngJZ/LightedDepth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_LightedDepth_Video_Depth_Estimation_in_Light_of_Limited_Inference_View_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Long-Term Visual Localization with Mobile Sensors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/sensloc/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_Long-Term_Visual_Localization_With_Mobile_Sensors_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.07691-b31b1b.svg)](http://arxiv.org/abs/2304.07691) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zOyaTOiL8vE) |
| Revisiting the P3P Problem | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_Revisiting_the_P3P_Problem_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=X_OeGDfL1vM) |
| I<sup>2</sup>-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jingsenzhu.github.io/i2-sdf/) <br /> [![GitHub](https://img.shields.io/github/stars/jingsenzhu/i2-sdf?style=flat)](https://github.com/jingsenzhu/i2-sdf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_I2-SDF_Intrinsic_Indoor_Scene_Reconstruction_and_Editing_via_Raytracing_in_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07634-b31b1b.svg)](http://arxiv.org/abs/2303.07634) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AJnIPUfUm4I) |
| WildLight: In-the-Wild Inverse Rendering with a Flashlight | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://junxuan-li.github.io/wildlight-website/) <br /> [![GitHub](https://img.shields.io/github/stars/junxuan-li/wildlight-website?style=flat)](https://github.com/junxuan-li/wildlight-website) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cheng_WildLight_In-the-Wild_Inverse_Rendering_With_a_Flashlight_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14190-b31b1b.svg)](http://arxiv.org/abs/2303.14190) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ybzCLnytxA8) |
| SE-ORNet: Self-Ensembling Orientation-Aware Network for Unsupervised Point Cloud Shape Correspondence | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chuxwa.github.io/SE-ORNet/) <br /> [![GitHub](https://img.shields.io/github/stars/OpenSpaceAI/SE-ORNet?style=flat)](https://github.com/OpenSpaceAI/SE-ORNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_SE-ORNet_Self-Ensembling_Orientation-Aware_Network_for_Unsupervised_Point_Cloud_Shape_Correspondence_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05395-b31b1b.svg)](http://arxiv.org/abs/2304.05395) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=P6tZDed1ahg) |
| Teleidoscopic Imaging System for Microscale 3D Shape Reconstruction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kawahara_Teleidoscopic_Imaging_System_for_Microscale_3D_Shape_Reconstruction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xYic6i_XodU) |
| NeuDA: Neural Deformable Anchor for High-Fidelity Implicit Surface Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3d-front-future.github.io/neuda/) <br /> [![GitHub](https://img.shields.io/github/stars/3D-FRONT-FUTURE/NeuDA?style=flat)](https://github.com/3D-FRONT-FUTURE/NeuDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cai_NeuDA_Neural_Deformable_Anchor_for_High-Fidelity_Implicit_Surface_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.02375-b31b1b.svg)](http://arxiv.org/abs/2303.02375) | :heavy_minus_sign: |
| PointClustering: Unsupervised Point Cloud Pre-Training using Transformation Invariance in Clustering | [![GitHub](https://img.shields.io/github/stars/FuchenUSTC/PointClustering?style=flat)](https://github.com/FuchenUSTC/PointClustering) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Long_PointClustering_Unsupervised_Point_Cloud_Pre-Training_Using_Transformation_Invariance_in_Clustering_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LY3pd-AsxHE) |
| PermutoSDF: Fast Multi-View Reconstruction with Implicit Surfaces using Permutohedral Lattices | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://radualexandru.github.io/permuto_sdf/) <br /> [![GitHub](https://img.shields.io/github/stars/RaduAlexandru/permuto_sdf?style=flat)](https://github.com/RaduAlexandru/permuto_sdf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rosu_PermutoSDF_Fast_Multi-View_Reconstruction_With_Implicit_Surfaces_Using_Permutohedral_Lattices_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12562-b31b1b.svg)](http://arxiv.org/abs/2211.12562) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ElpdDxJHLVE) |
| TriVol: Point Cloud Rendering via Triple Volumes | [![GitHub](https://img.shields.io/github/stars/dvlab-research/TriVol?style=flat)](https://github.com/dvlab-research/TriVol) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_TriVol_Point_Cloud_Rendering_via_Triple_Volumes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16485-b31b1b.svg)](http://arxiv.org/abs/2303.16485) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gi-xrif-zX8) |
| Towards Unbiased Volume Rendering of Neural Implicit Surfaces with Geometry Priors | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Towards_Unbiased_Volume_Rendering_of_Neural_Implicit_Surfaces_With_Geometry_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nH4kobACnBw) |
| Semi-Supervised Stereo-based 3D Object Detection via Cross-View Consensus | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Semi-Supervised_Stereo-Based_3D_Object_Detection_via_Cross-View_Consensus_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Self-Supervised Pre-Training with Masked Shape Prediction for 3D Scene Understanding | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Self-Supervised_Pre-Training_With_Masked_Shape_Prediction_for_3D_Scene_Understanding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.05026-b31b1b.svg)](http://arxiv.org/abs/2305.05026) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DLDZpA_LIGU) |
| Octree Guided Unoriented Surface Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chumbyte.github.io/OG-INR-Site/) <br /> [![GitHub](https://img.shields.io/github/stars/Chumbyte/OG-INR?style=flat)](https://github.com/Chumbyte/OG-INR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Koneputugodage_Octree_Guided_Unoriented_Surface_Reconstruction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ys0QWmGdrlY) |
| Towards Domain Generalization for Multi-View 3D Object Detection in Bird-Eye-View | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Towards_Domain_Generalization_for_Multi-View_3D_Object_Detection_in_Bird-Eye-View_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01686-b31b1b.svg)](http://arxiv.org/abs/2303.01686) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cEMvBqETNWY) |
| Learning Neural Volumetric Representations of Dynamic Humans in Minutes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zju3dv.github.io/instant_nvr/) <br /> [![GitHub](https://img.shields.io/github/stars/zju3dv/instant-nvr?style=flat)](https://github.com/zju3dv/instant-nvr) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Geng_Learning_Neural_Volumetric_Representations_of_Dynamic_Humans_in_Minutes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.12237-b31b1b.svg)](http://arxiv.org/abs/2302.12237) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oDgqNi0cdEE) |
| AnchorFormer: Point Cloud Completion from Discriminative Nodes | [![GitHub](https://img.shields.io/github/stars/chenzhik/AnchorFormer?style=flat)](https://github.com/chenzhik/AnchorFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_AnchorFormer_Point_Cloud_Completion_From_Discriminative_Nodes_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9_mdBtWfoq8) |
| Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Transforming_Radiance_Field_With_Lipschitz_Network_for_Photorealistic_3D_Scene_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13232-b31b1b.svg)](http://arxiv.org/abs/2303.13232) | :heavy_minus_sign: |
| GANmouflage: 3D Object Nondetection with Texture Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rrrrrguo.github.io/ganmouflage/) <br /> [![GitHub](https://img.shields.io/github/stars/rrrrrguo/ganmouflage?style=flat)](https://github.com/rrrrrguo/ganmouflage) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_GANmouflage_3D_Object_Nondetection_With_Texture_Fields_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2201.07202-b31b1b.svg)](http://arxiv.org/abs/2201.07202) | :heavy_minus_sign: |
| PEAL: Prior-embedded Explicit Attention Learning for Low-Overlap Point Cloud Registration | [![GitHub](https://img.shields.io/github/stars/Gardlin/PEAL?style=flat)](https://github.com/Gardlin/PEAL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_PEAL_Prior-Embedded_Explicit_Attention_Learning_for_Low-Overlap_Point_Cloud_Registration_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ly-7c_kRMd0) |
| NeRFLight: Fast and Light Neural Radiance Fields using a Shared Feature Grid | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Rivas-Manzaneque_NeRFLight_Fast_and_Light_Neural_Radiance_Fields_Using_a_Shared_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y1b5bxVg3oM) |
| TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jh-choi.github.io/TMO/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_TMO_Textured_Mesh_Acquisition_of_Objects_With_a_Mobile_Device_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15060-b31b1b.svg)](http://arxiv.org/abs/2303.15060) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uyHsYvmVypQ) |
| Generating Part-Aware Editable 3D Shapes without 3D Supervision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ktertikas.github.io/part_nerf) <br /> [![GitHub](https://img.shields.io/github/stars/ktertikas/part_nerf?style=flat)](https://github.com/ktertikas/part_nerf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tertikas_Generating_Part-Aware_Editable_3D_Shapes_Without_3D_Supervision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09554-b31b1b.svg)](http://arxiv.org/abs/2303.09554) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OKPWKt032d4) |
| ALTO: Alternating Latent Topologies for Implicit 3D Reconstruction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://visual.ee.ucla.edu/alto.htm/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_ALTO_Alternating_Latent_Topologies_for_Implicit_3D_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04096-b31b1b.svg)](http://arxiv.org/abs/2212.04096) | :heavy_minus_sign: |
| ORCa: Glossy Objects as Radiance-Field Cameras | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ktiwary2.github.io/objectsascam/) <br /> [![GitHub](https://img.shields.io/github/stars/ktiwary2/orca?style=flat)](https://github.com/ktiwary2/orca) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tiwary_ORCa_Glossy_Objects_As_Radiance-Field_Cameras_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04531-b31b1b.svg)](http://arxiv.org/abs/2212.04531) | :heavy_minus_sign: |
| NeFII: Inverse Rendering for Reflectance Decomposition with Near-Field Indirect Illumination | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://woolseyyy.github.io/nefii/) <br /> [![GitHub](https://img.shields.io/github/stars/FuxiComputerVision/Nefii?style=flat)](https://github.com/FuxiComputerVision/Nefii) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_NeFII_Inverse_Rendering_for_Reflectance_Decomposition_With_Near-Field_Indirect_Illumination_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16617-b31b1b.svg)](http://arxiv.org/abs/2303.16617) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CHNrEw8FQmo) |
| BEV-guided Multi-Modality Fusion for Driving Perception | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yunzeman.github.io/BEVGuide/) <br /> [![GitHub](https://img.shields.io/github/stars/YunzeMan/BEVGuide?style=flat)](https://github.com/YunzeMan/BEVGuide) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Man_BEV-Guided_Multi-Modality_Fusion_for_Driving_Perception_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16617-b31b1b.svg)](http://arxiv.org/abs/2303.16617) | :heavy_minus_sign: |
| <i>K</i>-Planes: Explicit Radiance Fields in Space, Time, and Appearance | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sarafridov.github.io/K-Planes/) <br /> [![GitHub](https://img.shields.io/github/stars/sarafridov/K-Planes?style=flat)](https://github.com/sarafridov/K-Planes) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fridovich-Keil_K-Planes_Explicit_Radiance_Fields_in_Space_Time_and_Appearance_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.10241-b31b1b.svg)](http://arxiv.org/abs/2301.10241) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pBqaAOTGfjQ) |
| RobustNeRF: Ignoring Distractors with Robust Losses | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://robustnerf.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sabour_RobustNeRF_Ignoring_Distractors_With_Robust_Losses_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.00833-b31b1b.svg)](http://arxiv.org/abs/2302.00833) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1cGMXhhmUTM) |
| Unsupervised Deep Asymmetric Stereo Matching with Spatially-Adaptive Self-Similarity | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Unsupervised_Deep_Asymmetric_Stereo_Matching_With_Spatially-Adaptive_Self-Similarity_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| ProxyFormer: Proxy Alignment Assisted Point Cloud Completion with Missing Part Sensitive Transformer | [![GitHub](https://img.shields.io/github/stars/I2-Multimedia-Lab/ProxyFormer?style=flat)](https://github.com/I2-Multimedia-Lab/ProxyFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_ProxyFormer_Proxy_Alignment_Assisted_Point_Cloud_Completion_With_Missing_Part_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14435-b31b1b.svg)](http://arxiv.org/abs/2302.14435) | :heavy_minus_sign: |
| Diffusion-based Signed Distance Fields for 3D Shape Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kitsunetic.github.io/sdf-diffusion/) <br /> [![GitHub](https://img.shields.io/github/stars/Kitsunetic/SDF-Diffusion?style=flat)](https://github.com/Kitsunetic/SDF-Diffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shim_Diffusion-Based_Signed_Distance_Fields_for_3D_Shape_Generation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=96DqsvY09X4) |
| FeatureBooster: Boosting Feature Descriptors with a Lightweight Neural Network | [![GitHub](https://img.shields.io/github/stars/SJTU-ViSYS/FeatureBooster?style=flat)](https://github.com/SJTU-ViSYS/FeatureBooster) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_FeatureBooster_Boosting_Feature_Descriptors_With_a_Lightweight_Neural_Network_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.15069-b31b1b.svg)](http://arxiv.org/abs/2211.15069) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lUImWOVGyvo) |
| Temporal Interpolation is All You Need for Dynamic Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sungheonpark.github.io/tempinterpnerf/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Temporal_Interpolation_Is_All_You_Need_for_Dynamic_Neural_Radiance_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.09311-b31b1b.svg)](http://arxiv.org/abs/2302.09311) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=23UYlHGv81k) |
| Neural Lens Modeling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://neural-lens.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/wxian3/NeuroLens?style=flat)](https://github.com/wxian3/NeuroLens) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xian_Neural_Lens_Modeling_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=brfnulYXGn0) |
| Multi-View Reconstruction using Signed Ray Distance Functions (SRDF) | | | |
| Masked Wavelet Representation for Compact Neural Radiance Fields | | | |
| A Rotation-Translation-Decoupled Solution for Robust and Efficient Visual-Inertial Initialization | | | |
| MACARONS: Mapping and Coverage Anticipation with RGB Online Self-Supervision | | | |
| DualRefine: Self-Supervised Depth and Pose Estimation through Iterative Epipolar Sampling and Refinement Toward Equilibrium | | | |
| CLIP<sup>2</sup>: Contrastive Language-Image-Point Pretraining from Real-World Point Cloud Data | | | |
| Semidefinite Relaxations for Robust Multiview Triangulation | | | |
| High-Frequency Stereo Matching Network | | | |
| CAP: Robust Point Cloud Classification via Semantic and Structural Modeling | | | |
| Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM | | | |
| Temporally Consistent Online Depth Estimation using Point-based Fusion | | | |
| Learning Neural Parametric Head Models | | | |
| PointConvFormer: Revenge of the Point-based Convolution | | | |
| Four-View Geometry with Unknown Radial Distortion | | | |
| Seeing through the Glass: Neural 3D Reconstruction of Object Inside a Transparent Container | | | |
