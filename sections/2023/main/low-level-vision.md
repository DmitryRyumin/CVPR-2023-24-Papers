# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/2023/main/vision-language-and-reasoning.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/2023/main/segmentation-grouping-and-shape-analysis.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
  </a>
</div>

## Low-Level Vision

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Activating More Pixels in Image Super-Resolution Transformer | [![GitHub](https://img.shields.io/github/stars/XPixelGroup/HAT?style=flat)](https://github.com/XPixelGroup/HAT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.04437-b31b1b.svg)](http://arxiv.org/abs/2205.04437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MhuO1FWsOEQ) |
| MetaFusion: Infrared and Visible Image Fusion via Meta-Feature Embedding From Object Detection | [![GitHub](https://img.shields.io/github/stars/wdzhao123/MetaFusion?style=flat)](https://github.com/wdzhao123/MetaFusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_MetaFusion_Infrared_and_Visible_Image_Fusion_via_Meta-Feature_Embedding_From_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=dkaUCO4sPeE) |
| Omni Aggregation Networks for Lightweight Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/Francis0625/Omni-SR?style=flat)](https://github.com/Francis0625/Omni-SR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Omni_Aggregation_Networks_for_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10244-b31b1b.svg)](http://arxiv.org/abs/2304.10244) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G4sOo51WKfE) |
| Blur Interpolation Transformer for Real-World Motion From Blur | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zzh-tech.github.io/BiT/) <br /> [![GitHub](https://img.shields.io/github/stars/zzh-tech/BiT?style=flat)](https://github.com/zzh-tech/BiT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhong_Blur_Interpolation_Transformer_for_Real-World_Motion_From_Blur_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11423-b31b1b.svg)](http://arxiv.org/abs/2211.11423) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O6cMCEQcUsY) |
| Equivalent Transformation and Dual Stream Network Construction for Mobile Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/ECNUSR/ETDS?style=flat)](https://github.com/ECNUSR/ETDS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chao_Equivalent_Transformation_and_Dual_Stream_Network_Construction_for_Mobile_Image_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=puSmTGum6pg) |
| Masked Image Training for Generalizable Deep Image Denoising | [![GitHub](https://img.shields.io/github/stars/haoyuc/MaskedDenoising?style=flat)](https://github.com/haoyuc/MaskedDenoising) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Masked_Image_Training_for_Generalizable_Deep_Image_Denoising_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13132-b31b1b.svg)](http://arxiv.org/abs/2303.13132) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8DZ2HkmO4gg) |
| CutMIB: Boosting Light Field Super-Resolution via Multi-View Image Blending | [![GitHub](https://img.shields.io/github/stars/zeyuxiao1997/CutMIB?style=flat)](https://github.com/zeyuxiao1997/CutMIB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_CutMIB_Boosting_Light_Field_Super-Resolution_via_Multi-View_Image_Blending_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Learning Semantic-Aware Knowledge Guidance for Low-Light Image Enhancement | [![GitHub](https://img.shields.io/github/stars/langmanbusi/Semantic-Aware-Low-Light-Image-Enhancement?style=flat)](https://github.com/langmanbusi/Semantic-Aware-Low-Light-Image-Enhancement) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Learning_Semantic-Aware_Knowledge_Guidance_for_Low-Light_Image_Enhancement_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.07039-b31b1b.svg)](http://arxiv.org/abs/2304.07039) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uJLlMehSpjY) |
| Learning a Sparse Transformer Network for Effective Image Deraining <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/cschenxiang/DRSformer?style=flat)](https://github.com/cschenxiang/DRSformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Learning_a_Sparse_Transformer_Network_for_Effective_Image_Deraining_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11950-b31b1b.svg)](http://arxiv.org/abs/2303.11950)| :heavy_minus_sign: |
| Deep Discriminative Spatial and Temporal Network for Efficient Video Deblurring | [![GitHub](https://img.shields.io/github/stars/xuboming8/DSTNet?style=flat)](https://github.com/xuboming8/DSTNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Deep_Discriminative_Spatial_and_Temporal_Network_for_Efficient_Video_Deblurring_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Learning Weather-General and Weather-Specific Features for Image Restoration Under Multiple Adverse Weather Conditions | [![GitHub](https://img.shields.io/github/stars/zhuyr97/WGWS-Net?style=flat)](https://github.com/zhuyr97/WGWS-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Learning_Weather-General_and_Weather-Specific_Features_for_Image_Restoration_Under_Multiple_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5DR6hnNFzz0) |
| AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation | [![GitHub](https://img.shields.io/github/stars/MCG-NKU/AMT?style=flat)](https://github.com/MCG-NKU/AMT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_AMT_All-Pairs_Multi-Field_Transforms_for_Efficient_Frame_Interpolation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.09790-b31b1b.svg)](http://arxiv.org/abs/2304.09790) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=D6Q5oLGet24) |
| Self-Supervised Non-Uniform Kernel Estimation With Flow-Based Motion Prior for Blind Image Deblurring | [![GitHub](https://img.shields.io/github/stars/Fangzhenxuan/UFPDeblur?style=flat)](https://github.com/Fangzhenxuan/UFPDeblur) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_Self-Supervised_Non-Uniform_Kernel_Estimation_With_Flow-Based_Motion_Prior_for_Blind_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MRR4SwX1ElA) |
| OSRT: Omnidirectional Image Super-Resolution With Distortion-Aware Transformer | [![GitHub](https://img.shields.io/github/stars/Fanghua-Yu/OSRT?style=flat)](https://github.com/Fanghua-Yu/OSRT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_OSRT_Omnidirectional_Image_Super-Resolution_With_Distortion-Aware_Transformer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.03453-b31b1b.svg)](http://arxiv.org/abs/2302.03453) | :heavy_minus_sign: |
| Toward Accurate Post-Training Quantization for Image Super Resolution | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://gitee.com/mindspore/models/tree/master/research/cv/PTQ4SR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tu_Toward_Accurate_Post-Training_Quantization_for_Image_Super_Resolution_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Learning a Simple Low-Light Image Enhancer From Paired Low-Light Instances | [![GitHub](https://img.shields.io/github/stars/zhenqifu/PairLIE?style=flat)](https://github.com/zhenqifu/PairLIE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_Learning_a_Simple_Low-Light_Image_Enhancer_From_Paired_Low-Light_Instances_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Joint Appearance and Motion Learning for Efficient Rolling Shutter Correction | [![GitHub](https://img.shields.io/github/stars/GitCVfb/JAMNet?style=flat)](https://github.com/GitCVfb/JAMNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_Joint_Appearance_and_Motion_Learning_for_Efficient_Rolling_Shutter_Correction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oAozS6qEDjE) |
| Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution | [![GitHub](https://img.shields.io/github/stars/jaroslaw1007/CLIT?style=flat)](https://github.com/jaroslaw1007/CLIT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Cascaded_Local_Implicit_Transformer_for_Arbitrary-Scale_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16513-b31b1b.svg)](http://arxiv.org/abs/2303.16513) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kB2sm_k8P6I) |
| Unsupervised Cumulative Domain Adaptation for Foggy Scene Optical Flow | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Unsupervised_Cumulative_Domain_Adaptation_for_Foggy_Scene_Optical_Flow_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07564-b31b1b.svg)](http://arxiv.org/abs/2303.07564) |:heavy_minus_sign: |
| PyramidFlow: High-Resolution Defect Contrastive Localization Using Pyramid Normalizing Flow | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lei_PyramidFlow_High-Resolution_Defect_Contrastive_Localization_Using_Pyramid_Normalizing_Flow_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.02595-b31b1b.svg)](http://arxiv.org/abs/2303.02595) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XdyWp23_bU0) |
| DR2: Diffusion-Based Robust Degradation Remover for Blind Face Restoration | [![GitHub](https://img.shields.io/github/stars/Kaldwin0106/DR2_Drgradation_Remover?style=flat)](https://github.com/Kaldwin0106/DR2_Drgradation_Remover) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_DR2_Diffusion-Based_Robust_Degradation_Remover_for_Blind_Face_Restoration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06885-b31b1b.svg)](http://arxiv.org/abs/2303.06885) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cxPp1bo9flw) |
| DNF: Decouple and Feedback Network for Seeing in the Dark <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/Srameo/DNF?style=flat)](https://github.com/Srameo/DNF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_DNF_Decouple_and_Feedback_Network_for_Seeing_in_the_Dark_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DZ7y-cLVXhs) |
| Optimization-Inspired Cross-Attention Transformer for Compressive Sensing | [![GitHub](https://img.shields.io/github/stars/songjiechong/OCTUF?style=flat)](https://github.com/songjiechong/OCTUF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Optimization-Inspired_Cross-Attention_Transformer_for_Compressive_Sensing_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.13986-b31b1b.svg)](http://arxiv.org/abs/2304.13986) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-WKuwpS0D9w) |
| Local Implicit Normalizing Flow for Arbitrary-Scale Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/JNNNNYao/LINF?style=flat)](https://github.com/JNNNNYao/LINF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Local_Implicit_Normalizing_Flow_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05156-b31b1b.svg)](http://arxiv.org/abs/2303.05156) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kB2sm_k8P6I) |
| Event-Based Frame Interpolation With Ad-Hoc Deblurring | [![GitHub](https://img.shields.io/github/stars/AHupuJR/REFID?style=flat)](https://github.com/AHupuJR/REFID) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Event-Based_Frame_Interpolation_With_Ad-Hoc_Deblurring_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.05191-b31b1b.svg)](http://arxiv.org/abs/2301.05191) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pInRJ_O2kas) |
| Better ``CMOS`` Produces Clearer Images: Learning Space-Variant Blur Estimation for Blind Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/ByChelsea/CMOS?style=flat)](https://github.com/ByChelsea/CMOS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_Better_CMOS_Produces_Clearer_Images_Learning_Space-Variant_Blur_Estimation_for_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03542-b31b1b.svg)](http://arxiv.org/abs/2304.03542) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y12hM-lm3Ow) |
| SMAE: Few-Shot Learning for HDR Deghosting With Saturation-Aware Masked Autoencoders| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Yan_SMAE_Few-Shot_Learning_for_HDR_Deghosting_With_Saturation-Aware_Masked_Autoencoders_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06914-b31b1b.svg)](http://arxiv.org/abs/2304.06914) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iNBGNf8e3FE) |
| A Unified HDR Imaging Method With Pixel and Patch Level | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Yan_A_Unified_HDR_Imaging_Method_With_Pixel_and_Patch_Level_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06943-b31b1b.svg)](http://arxiv.org/abs/2304.06943) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f932i4j7ABI) |
| DegAE: A New Pretraining Paradigm for Low-Level Vision <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]()  | [![GitHub](https://img.shields.io/github/stars/lyh-18/DegAE_DegradationAutoencoder?style=flat)](https://github.com/lyh-18/DegAE_DegradationAutoencoder) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liu_DegAE_A_New_Pretraining_Paradigm_for_Low-Level_Vision_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_u5oUOrSohY) |
| CABM: Content-Aware Bit Mapping for Single Image Super-Resolution Network With Large Input | [![GitHub](https://img.shields.io/github/stars/Sheldon04/CABM-pytorch?style=flat)](https://github.com/Sheldon04/CABM-pytorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Tian_CABM_Content-Aware_Bit_Mapping_for_Single_Image_Super-Resolution_Network_With_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06454-b31b1b.svg)](http://arxiv.org/abs/2304.06454) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SsFDQwPzQH0) |
| Blind Video Deflickering by Neural Filtering With a Flawed Atlas | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chenyanglei.github.io/deflicker/) <br /> [![GitHub](https://img.shields.io/github/stars/ChenyangLEI/All-In-One-Deflicker?style=flat)](https://github.com/ChenyangLEI/All-In-One-Deflicker) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lei_Blind_Video_Deflickering_by_Neural_Filtering_With_a_Flawed_Atlas_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08120-b31b1b.svg)](http://arxiv.org/abs/2303.08120) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2TsQncdMHjE) |
| Efficient and Explicit Modelling of Image Hierarchies for Image Restoration | [![GitHub](https://img.shields.io/github/stars/ofsoundof/GRL-Image-Restoration?style=flat)](https://github.com/ofsoundof/GRL-Image-Restoration) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Efficient_and_Explicit_Modelling_of_Image_Hierarchies_for_Image_Restoration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00748-b31b1b.svg)](http://arxiv.org/abs/2303.00748) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VMqq7wIyPN8) |
| Learning Distortion Invariant Representation for Image Restoration From a Causality Perspective | [![GitHub](https://img.shields.io/github/stars/lixinustc/Causal-IR-DIL?style=flat)](https://github.com/lixinustc/Causal-IR-DIL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Learning_Distortion_Invariant_Representation_for_Image_Restoration_From_a_Causality_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06859-b31b1b.svg)](http://arxiv.org/abs/2303.06859) | :heavy_minus_sign: |
| Human Guided Ground-Truth Generation for Realistic Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/ChrisDud0257/HGGT?style=flat)](https://github.com/ChrisDud0257/HGGT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_Human_Guided_Ground-Truth_Generation_for_Realistic_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13069-b31b1b.svg)](http://arxiv.org/abs/2303.13069) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_PgVT152vvs) |
| Raw Image Reconstruction With Learned Compact Metadata | [![GitHub](https://img.shields.io/github/stars/wyf0912/R2LCM?style=flat)](https://github.com/wyf0912/R2LCM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_Raw_Image_Reconstruction_With_Learned_Compact_Metadata_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.12995-b31b1b.svg)](http://arxiv.org/abs/2302.12995) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Pqbd8zVABoc) |
| Curricular Contrastive Regularization for Physics-Aware Single Image Dehazing | [![GitHub](https://img.shields.io/github/stars/YuZheng9/C2PNet?style=flat)](https://github.com/YuZheng9/C2PNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zheng_Curricular_Contrastive_Regularization_for_Physics-Aware_Single_Image_Dehazing_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14218-b31b1b.svg)](http://arxiv.org/abs/2303.14218) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s1BOROKKYxM) |
| ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow Removal | [![GitHub](https://img.shields.io/github/stars/GuoLanqing/ShadowDiffusion?style=flat)](https://github.com/GuoLanqing/ShadowDiffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Guo_ShadowDiffusion_When_Degradation_Prior_Meets_Diffusion_Model_for_Shadow_Removal_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04711-b31b1b.svg)](http://arxiv.org/abs/2212.04711) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mnxb6wjQci4) |
| N-Gram in Swin Transformers for Efficient Lightweight Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/rami0205/NGramSwin?style=flat)](https://github.com/rami0205/NGramSwin) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Choi_N-Gram_in_Swin_Transformers_for_Efficient_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11436-b31b1b.svg)](https://arxiv.org/abs/2211.11436) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nUC9hO473Bw) |
| Real-Time 6K Image Rescaling With Rate-Distortion Optimization | [![GitHub](https://img.shields.io/github/stars/AbnerVictor/HyperThumbnail?style=flat)](https://github.com/AbnerVictor/HyperThumbnail) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Qi_Real-Time_6K_Image_Rescaling_With_Rate-Distortion_Optimization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01064-b31b1b.svg)](http://arxiv.org/abs/2304.01064) | :heavy_minus_sign: |
| GamutMLP: A Lightweight MLP for Color Loss Recovery | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gamut-mlp.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/hminle/gamut-mlp?style=flat)](https://github.com/hminle/gamut-mlp) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Le_GamutMLP_A_Lightweight_MLP_for_Color_Loss_Recovery_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11743-b31b1b.svg)](http://arxiv.org/abs/2304.11743) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=w7tjhSRK3rA) |
| CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion |  |  |  |
| Quality-Aware Pre-trained Models for Blind Image Quality Assessment |  |  |  |
| Recurrent Homography Estimation using Homography-guided Image Warping and Focus Transformer |  |  |  |
| Learning Spatial-Temporal Implicit Neural Representations for Event-guided Video Super-Resolution |  |  |  |
| RIDCP: Revitalizing Real Image Dehazing via High-Quality Codebook Priors |  |  |  |
| Generating Aligned Pseudo-Supervision from Non-Aligned Data for Image Restoration in Under-Display Camera |  |  |  |
| Structure Aggregation for Cross-Spectral Stereo Image Guided Denoising |  |  |  |
| Rethinking Optical Flow from Geometric Matching Consistent Perspective |  |  |  |
| Video Dehazing via a Multi-Range Temporal Alignment Network with Physical Prior |  |  |  |
| Perception-Oriented Single Image Super-Resolution using Optimal Objective Estimation |  |  |  |
| Zero-Shot Dual-Lens Super-Resolution |  |  |  |
| Efficient Frequency Domain-based Transformers for High-Quality Image Deblurring |  |  |  |
| A Simple Baseline for Video Restoration with Grouped Spatial-Temporal Shift |  |  |  |
| Learning Generative Structure Prior for Blind Text Image Super-Resolution |  |  |  |
| Motion Information Propagation for Neural Video Compression |  |  |  |
| Joint Video Multi-Frame Interpolation and Deblurring under Unknown Exposure Time |  |  |  |
| Event-based Video Frame Interpolation with Cross-Modal Asymmetric Bidirectional Motion Fields |  |  |  |
| Learning Sample Relationship for Exposure Correction |  |  |  |
| Spatially Adaptive Self-Supervised Learning for Real-World Image Denoising |  |  |  |
| Context-Aware Pretraining for Efficient Blind Image Decomposition |  |  |  |
| Physics-guided ISO-Dependent Sensor Noise Modeling for Extreme Low-Light Photography |  |  |  |
| AnyFlow: Arbitrary Scale Optical Flow with Implicit Neural Representation |  |  |  |
| Complexity-guided Slimmable Decoder for Efficient Deep Video Compression |  |  |  |
| Bitstream-Corrupted JPEG Images are Restorable: Two-Stage Compensation and Alignment Framework for Image Restoration |  |  |  |
| Spectral Enhanced Rectangle Transformer for Hyperspectral Image Denoising |  |  |  |
| Learning from Unique Perspectives: User-Aware Saliency Modeling |  |  |  |
| DINN360: Deformable Invertible Neural Network for Latitude-Aware 360&deg; Image Rescaling |  |  |  |
| ABCD: Arbitrary Bitwise Coefficient for De-Quantization |  |  |  |
| Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning |  |  |  |
| Learning Steerable Function for Efficient Image Resampling |  |  |  |
| Revisiting the Stack-based Inverse Tone Mapping |  |  |  |
| Generative Diffusion Prior for Unified Image Restoration and Enhancement |  |  |  |
| LG-BPN: Local and Global Blind-Patch Network for Self-Supervised Real-World Denoising |  |  |  |
| Adaptive Spot-guided Transformer for Consistent Local Feature Matching |  |  |  |
| SFD2: Semantic-guided Feature Detection and Description |  |  |  |
| Burstormer: Burst Image Restoration and Enhancement Transformer |  |  |  |
| DeepLSD: Line Segment Detection and Refinement with Deep Image Gradients |  |  |  |
| Gated Multi-Resolution Transfer Network for Burst Restoration and Enhancement |  |  |  |
| Structured Sparsity Learning for Efficient Video Super-Resolution |  |  |  |
| DNeRV: Modeling Inherent Dynamics via Difference Neural Representation for Videos |  |  |  |
| Exploring Discontinuity for Video Frame Interpolation |  |  |  |
| Neural Video Compression with Diverse Contexts |  |  |  |
| FlowFormer++: Masked Cost Volume Autoencoding for Pretraining Optical Flow Estimation |  |  |  |
| OPE-SR: Orthogonal Position Encoding for Designing a Parameter-Free Upsampling Module in Arbitrary-Scale Image Super-Resolution |  |  |  |
| Context-based Trit-Plane Coding for Progressive Image Compression |  |  |  |
| All-in-One Image Restoration for Unknown Degradations using Adaptive Discriminative Filters for Specific Degradations |  |  |  |
| Learning to Exploit the Sequence-Specific Prior Knowledge for Image Processing Pipelines Optimization |  |  |  |
| Nighttime Smartphone Reflective Flare Removal using Optical Center Symmetry Prior |  |  |  |
| Enhancing Deformable Local Features by Jointly Learning to Detect and Describe Keypoints |  |  |  |
| Real-Time Controllable Denoising for Image and Video |  |  |  |
| Compression-Aware Video Super-Resolution |  |  |  |
| Spatial-Frequency Mutual Learning for Face Super-Resolution |  |  |  |
| The Treasure Beneath Multiple Annotations: An Uncertainty-Aware Edge Detector |  |  |  |
| Toward Stable, Interpretable, and Lightweight Hyperspectral Super-Resolution |  |  |  |
| Modernizing Old Photos Using Multiple References via Photorealistic Style Transfer |  |  |  |
| Data-Driven Feature Tracking for Event Cameras |  |  |  |
| LVQAC: Lattice Vector Quantization Coupled with Spatially Adaptive Companding for Efficient Learned Image Compression |  |  |  |
| Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger |  |  |  |
| Learning to Detect Mirrors from Videos via Dual Correspondences |  |  |  |
| Robust Unsupervised StyleGAN Image Restoration |  |  |  |
| Ingredient-oriented Multi-Degradation Learning for Image Restoration |  |  |  |
| CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution |  |  |  |
| Semi-Supervised Parametric Real-World Image Harmonization |  |  |  |
| SmartAssign: Learning a Smart Knowledge Assignment Strategy for Deraining and Desnowing |  |  |  |
| Robust Single Image Reflection Removal Against Adversarial Attacks |  |  |  |
| PMatch: Paired Masked Image Modeling for Dense Geometric Matching |  |  |  |
| Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation |  |  |  |
| Residual Degradation Learning Unfolding Framework with Mixing Priors Across Spectral and Spatial for Compressive Spectral Imaging |  |  |  |
| Visual Recognition-Driven Image Restoration for Multiple Degradation with Intrinsic Semantics Recovery |  |  |  |
| sRGB Real Noise Synthesizing with Neighboring Correlation-Aware Noise Model |  |  |  |
| Rethinking Image Super Resolution from Long-Tailed Distribution Learning Perspective |  |  |  |
| Comprehensive and Delicate: An Efficient Transformer for Image Restoration |  |  |  |
| Super-Resolution Neural Operator |  |  |  |
| Neumann Network with Recursive Kernels for Single Image Defocus Deblurring |  |  |  |
| Discriminative Co-Saliency and Background Mining Transformer for Co-Salient Object Detection |  |  |  |
| Learning Rotation-Equivariant Features for Visual Correspondence |  |  |  |
| Patch-Craft Self-Supervised Training for Correlated Image Denoising |  |  |  |
| Metadata-based RAW Reconstruction via Implicit Neural Functions |  |  |  |
| Contrastive Semi-Supervised Learning for Underwater Image Restoration via Reliable Bank |  |  |  |
| Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning |  |  |  |
| Spectral Bayesian Uncertainty for Image Super-Resolution |  |  |  |
| DINER: Disorder-Invariant Implicit Neural Representation |  |  |  |
| NVTC: Nonlinear Vector Transform Coding |  |  |  |
| HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering |  |  |  |
| You Do Not Need Additional Priors or Regularizers in Retinex-based Low-light Image Enhancement |  |  |  |
| Learning a Practical SDR-to-HDRTV Up-Conversion using New Dataset and Degradation Models |  |  |  |
