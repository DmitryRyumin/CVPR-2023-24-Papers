# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/2023/main/vision-language-and-reasoning.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/2023/main/segmentation-grouping-and-shape-analysis.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
  </a>
</div>

## Low-Level Vision

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Activating More Pixels in Image Super-Resolution Transformer | [![GitHub](https://img.shields.io/github/stars/XPixelGroup/HAT?style=flat)](https://github.com/XPixelGroup/HAT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.04437-b31b1b.svg)](http://arxiv.org/abs/2205.04437) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MhuO1FWsOEQ) |
| MetaFusion: Infrared and Visible Image Fusion via Meta-Feature Embedding From Object Detection | [![GitHub](https://img.shields.io/github/stars/wdzhao123/MetaFusion?style=flat)](https://github.com/wdzhao123/MetaFusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_MetaFusion_Infrared_and_Visible_Image_Fusion_via_Meta-Feature_Embedding_From_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=dkaUCO4sPeE) |
| Omni Aggregation Networks for Lightweight Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/Francis0625/Omni-SR?style=flat)](https://github.com/Francis0625/Omni-SR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Omni_Aggregation_Networks_for_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10244-b31b1b.svg)](http://arxiv.org/abs/2304.10244) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G4sOo51WKfE) |
| Blur Interpolation Transformer for Real-World Motion From Blur | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zzh-tech.github.io/BiT/) <br /> [![GitHub](https://img.shields.io/github/stars/zzh-tech/BiT?style=flat)](https://github.com/zzh-tech/BiT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhong_Blur_Interpolation_Transformer_for_Real-World_Motion_From_Blur_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11423-b31b1b.svg)](http://arxiv.org/abs/2211.11423) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O6cMCEQcUsY) |
| Equivalent Transformation and Dual Stream Network Construction for Mobile Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/ECNUSR/ETDS?style=flat)](https://github.com/ECNUSR/ETDS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chao_Equivalent_Transformation_and_Dual_Stream_Network_Construction_for_Mobile_Image_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=puSmTGum6pg) |
| Masked Image Training for Generalizable Deep Image Denoising | [![GitHub](https://img.shields.io/github/stars/haoyuc/MaskedDenoising?style=flat)](https://github.com/haoyuc/MaskedDenoising) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Masked_Image_Training_for_Generalizable_Deep_Image_Denoising_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13132-b31b1b.svg)](http://arxiv.org/abs/2303.13132) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8DZ2HkmO4gg) |
| CutMIB: Boosting Light Field Super-Resolution via Multi-View Image Blending | [![GitHub](https://img.shields.io/github/stars/zeyuxiao1997/CutMIB?style=flat)](https://github.com/zeyuxiao1997/CutMIB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_CutMIB_Boosting_Light_Field_Super-Resolution_via_Multi-View_Image_Blending_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Learning Semantic-Aware Knowledge Guidance for Low-Light Image Enhancement | [![GitHub](https://img.shields.io/github/stars/langmanbusi/Semantic-Aware-Low-Light-Image-Enhancement?style=flat)](https://github.com/langmanbusi/Semantic-Aware-Low-Light-Image-Enhancement) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Learning_Semantic-Aware_Knowledge_Guidance_for_Low-Light_Image_Enhancement_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.07039-b31b1b.svg)](http://arxiv.org/abs/2304.07039) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uJLlMehSpjY) |
| Learning a Sparse Transformer Network for Effective Image Deraining <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/cschenxiang/DRSformer?style=flat)](https://github.com/cschenxiang/DRSformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Learning_a_Sparse_Transformer_Network_for_Effective_Image_Deraining_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11950-b31b1b.svg)](http://arxiv.org/abs/2303.11950)| :heavy_minus_sign: |
| Deep Discriminative Spatial and Temporal Network for Efficient Video Deblurring | [![GitHub](https://img.shields.io/github/stars/xuboming8/DSTNet?style=flat)](https://github.com/xuboming8/DSTNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Deep_Discriminative_Spatial_and_Temporal_Network_for_Efficient_Video_Deblurring_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Learning Weather-General and Weather-Specific Features for Image Restoration Under Multiple Adverse Weather Conditions | [![GitHub](https://img.shields.io/github/stars/zhuyr97/WGWS-Net?style=flat)](https://github.com/zhuyr97/WGWS-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Learning_Weather-General_and_Weather-Specific_Features_for_Image_Restoration_Under_Multiple_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5DR6hnNFzz0) |
| AMT: All-Pairs Multi-Field Transforms for Efficient Frame Interpolation | [![GitHub](https://img.shields.io/github/stars/MCG-NKU/AMT?style=flat)](https://github.com/MCG-NKU/AMT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_AMT_All-Pairs_Multi-Field_Transforms_for_Efficient_Frame_Interpolation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.09790-b31b1b.svg)](http://arxiv.org/abs/2304.09790) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=D6Q5oLGet24) |
| Self-Supervised Non-Uniform Kernel Estimation With Flow-Based Motion Prior for Blind Image Deblurring | [![GitHub](https://img.shields.io/github/stars/Fangzhenxuan/UFPDeblur?style=flat)](https://github.com/Fangzhenxuan/UFPDeblur) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_Self-Supervised_Non-Uniform_Kernel_Estimation_With_Flow-Based_Motion_Prior_for_Blind_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MRR4SwX1ElA) |
| OSRT: Omnidirectional Image Super-Resolution With Distortion-Aware Transformer | [![GitHub](https://img.shields.io/github/stars/Fanghua-Yu/OSRT?style=flat)](https://github.com/Fanghua-Yu/OSRT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_OSRT_Omnidirectional_Image_Super-Resolution_With_Distortion-Aware_Transformer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.03453-b31b1b.svg)](http://arxiv.org/abs/2302.03453) | :heavy_minus_sign: |
| Toward Accurate Post-Training Quantization for Image Super Resolution | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://gitee.com/mindspore/models/tree/master/research/cv/PTQ4SR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tu_Toward_Accurate_Post-Training_Quantization_for_Image_Super_Resolution_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Learning a Simple Low-Light Image Enhancer From Paired Low-Light Instances | [![GitHub](https://img.shields.io/github/stars/zhenqifu/PairLIE?style=flat)](https://github.com/zhenqifu/PairLIE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_Learning_a_Simple_Low-Light_Image_Enhancer_From_Paired_Low-Light_Instances_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Joint Appearance and Motion Learning for Efficient Rolling Shutter Correction | [![GitHub](https://img.shields.io/github/stars/GitCVfb/JAMNet?style=flat)](https://github.com/GitCVfb/JAMNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_Joint_Appearance_and_Motion_Learning_for_Efficient_Rolling_Shutter_Correction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oAozS6qEDjE) |
| Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution | [![GitHub](https://img.shields.io/github/stars/jaroslaw1007/CLIT?style=flat)](https://github.com/jaroslaw1007/CLIT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Cascaded_Local_Implicit_Transformer_for_Arbitrary-Scale_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16513-b31b1b.svg)](http://arxiv.org/abs/2303.16513) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kB2sm_k8P6I) |
| Unsupervised Cumulative Domain Adaptation for Foggy Scene Optical Flow | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Unsupervised_Cumulative_Domain_Adaptation_for_Foggy_Scene_Optical_Flow_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07564-b31b1b.svg)](http://arxiv.org/abs/2303.07564) |:heavy_minus_sign: |
| PyramidFlow: High-Resolution Defect Contrastive Localization Using Pyramid Normalizing Flow | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lei_PyramidFlow_High-Resolution_Defect_Contrastive_Localization_Using_Pyramid_Normalizing_Flow_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.02595-b31b1b.svg)](http://arxiv.org/abs/2303.02595) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XdyWp23_bU0) |
| DR2: Diffusion-Based Robust Degradation Remover for Blind Face Restoration | [![GitHub](https://img.shields.io/github/stars/Kaldwin0106/DR2_Drgradation_Remover?style=flat)](https://github.com/Kaldwin0106/DR2_Drgradation_Remover) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_DR2_Diffusion-Based_Robust_Degradation_Remover_for_Blind_Face_Restoration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06885-b31b1b.svg)](http://arxiv.org/abs/2303.06885) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cxPp1bo9flw) |
| DNF: Decouple and Feedback Network for Seeing in the Dark <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/Srameo/DNF?style=flat)](https://github.com/Srameo/DNF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_DNF_Decouple_and_Feedback_Network_for_Seeing_in_the_Dark_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DZ7y-cLVXhs) |
| Optimization-Inspired Cross-Attention Transformer for Compressive Sensing | [![GitHub](https://img.shields.io/github/stars/songjiechong/OCTUF?style=flat)](https://github.com/songjiechong/OCTUF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Optimization-Inspired_Cross-Attention_Transformer_for_Compressive_Sensing_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.13986-b31b1b.svg)](http://arxiv.org/abs/2304.13986) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-WKuwpS0D9w) |
| Local Implicit Normalizing Flow for Arbitrary-Scale Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/JNNNNYao/LINF?style=flat)](https://github.com/JNNNNYao/LINF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Local_Implicit_Normalizing_Flow_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05156-b31b1b.svg)](http://arxiv.org/abs/2303.05156) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kB2sm_k8P6I) |
| Event-Based Frame Interpolation With Ad-Hoc Deblurring | [![GitHub](https://img.shields.io/github/stars/AHupuJR/REFID?style=flat)](https://github.com/AHupuJR/REFID) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Event-Based_Frame_Interpolation_With_Ad-Hoc_Deblurring_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.05191-b31b1b.svg)](http://arxiv.org/abs/2301.05191) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pInRJ_O2kas) |
| Better ``CMOS`` Produces Clearer Images: Learning Space-Variant Blur Estimation for Blind Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/ByChelsea/CMOS?style=flat)](https://github.com/ByChelsea/CMOS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Better_CMOS_Produces_Clearer_Images_Learning_Space-Variant_Blur_Estimation_for_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03542-b31b1b.svg)](http://arxiv.org/abs/2304.03542) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y12hM-lm3Ow) |
| SMAE: Few-Shot Learning for HDR Deghosting With Saturation-Aware Masked Autoencoders| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_SMAE_Few-Shot_Learning_for_HDR_Deghosting_With_Saturation-Aware_Masked_Autoencoders_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06914-b31b1b.svg)](http://arxiv.org/abs/2304.06914) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iNBGNf8e3FE) |
| A Unified HDR Imaging Method With Pixel and Patch Level | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yan_A_Unified_HDR_Imaging_Method_With_Pixel_and_Patch_Level_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06943-b31b1b.svg)](http://arxiv.org/abs/2304.06943) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f932i4j7ABI) |
| DegAE: A New Pretraining Paradigm for Low-Level Vision <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/lyh-18/DegAE_DegradationAutoencoder?style=flat)](https://github.com/lyh-18/DegAE_DegradationAutoencoder) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_DegAE_A_New_Pretraining_Paradigm_for_Low-Level_Vision_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_u5oUOrSohY) |
| CABM: Content-Aware Bit Mapping for Single Image Super-Resolution Network With Large Input | [![GitHub](https://img.shields.io/github/stars/Sheldon04/CABM-pytorch?style=flat)](https://github.com/Sheldon04/CABM-pytorch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_CABM_Content-Aware_Bit_Mapping_for_Single_Image_Super-Resolution_Network_With_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06454-b31b1b.svg)](http://arxiv.org/abs/2304.06454) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SsFDQwPzQH0) |
| Blind Video Deflickering by Neural Filtering With a Flawed Atlas | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chenyanglei.github.io/deflicker/) <br /> [![GitHub](https://img.shields.io/github/stars/ChenyangLEI/All-In-One-Deflicker?style=flat)](https://github.com/ChenyangLEI/All-In-One-Deflicker) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lei_Blind_Video_Deflickering_by_Neural_Filtering_With_a_Flawed_Atlas_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08120-b31b1b.svg)](http://arxiv.org/abs/2303.08120) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2TsQncdMHjE) |
| Efficient and Explicit Modelling of Image Hierarchies for Image Restoration | [![GitHub](https://img.shields.io/github/stars/ofsoundof/GRL-Image-Restoration?style=flat)](https://github.com/ofsoundof/GRL-Image-Restoration) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Efficient_and_Explicit_Modelling_of_Image_Hierarchies_for_Image_Restoration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00748-b31b1b.svg)](http://arxiv.org/abs/2303.00748) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VMqq7wIyPN8) |
| Learning Distortion Invariant Representation for Image Restoration From a Causality Perspective | [![GitHub](https://img.shields.io/github/stars/lixinustc/Causal-IR-DIL?style=flat)](https://github.com/lixinustc/Causal-IR-DIL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Distortion_Invariant_Representation_for_Image_Restoration_From_a_Causality_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06859-b31b1b.svg)](http://arxiv.org/abs/2303.06859) | :heavy_minus_sign: |
| Human Guided Ground-Truth Generation for Realistic Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/ChrisDud0257/HGGT?style=flat)](https://github.com/ChrisDud0257/HGGT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Human_Guided_Ground-Truth_Generation_for_Realistic_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13069-b31b1b.svg)](http://arxiv.org/abs/2303.13069) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_PgVT152vvs) |
| Raw Image Reconstruction With Learned Compact Metadata | [![GitHub](https://img.shields.io/github/stars/wyf0912/R2LCM?style=flat)](https://github.com/wyf0912/R2LCM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Raw_Image_Reconstruction_With_Learned_Compact_Metadata_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.12995-b31b1b.svg)](http://arxiv.org/abs/2302.12995) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Pqbd8zVABoc) |
| Curricular Contrastive Regularization for Physics-Aware Single Image Dehazing | [![GitHub](https://img.shields.io/github/stars/YuZheng9/C2PNet?style=flat)](https://github.com/YuZheng9/C2PNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Curricular_Contrastive_Regularization_for_Physics-Aware_Single_Image_Dehazing_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14218-b31b1b.svg)](http://arxiv.org/abs/2303.14218) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s1BOROKKYxM) |
| ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow Removal | [![GitHub](https://img.shields.io/github/stars/GuoLanqing/ShadowDiffusion?style=flat)](https://github.com/GuoLanqing/ShadowDiffusion) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_ShadowDiffusion_When_Degradation_Prior_Meets_Diffusion_Model_for_Shadow_Removal_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04711-b31b1b.svg)](http://arxiv.org/abs/2212.04711) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mnxb6wjQci4) |
| N-Gram in Swin Transformers for Efficient Lightweight Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/rami0205/NGramSwin?style=flat)](https://github.com/rami0205/NGramSwin) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_N-Gram_in_Swin_Transformers_for_Efficient_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.11436-b31b1b.svg)](https://arxiv.org/abs/2211.11436) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nUC9hO473Bw) |
| Real-Time 6K Image Rescaling With Rate-Distortion Optimization | [![GitHub](https://img.shields.io/github/stars/AbnerVictor/HyperThumbnail?style=flat)](https://github.com/AbnerVictor/HyperThumbnail) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qi_Real-Time_6K_Image_Rescaling_With_Rate-Distortion_Optimization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01064-b31b1b.svg)](http://arxiv.org/abs/2304.01064) | :heavy_minus_sign: |
| GamutMLP: A Lightweight MLP for Color Loss Recovery | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gamut-mlp.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/hminle/gamut-mlp?style=flat)](https://github.com/hminle/gamut-mlp) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Le_GamutMLP_A_Lightweight_MLP_for_Color_Loss_Recovery_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.11743-b31b1b.svg)](http://arxiv.org/abs/2304.11743) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=w7tjhSRK3rA) |
| CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion | [![GitHub](https://img.shields.io/github/stars/Zhaozixiang1228/MMIF-CDDFuse?style=flat)](https://github.com/Zhaozixiang1228/MMIF-CDDFuse) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_CDDFuse_Correlation-Driven_Dual-Branch_Feature_Decomposition_for_Multi-Modality_Image_Fusion_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14461-b31b1b.svg)](http://arxiv.org/abs/2211.14461) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gDpyRKKDWsY) |
| Quality-Aware Pre-Trained Models for Blind Image Quality Assessment | [![GitHub](https://img.shields.io/github/stars/zwx8981/UNIQUE?style=flat)](https://github.com/zwx8981/UNIQUE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Quality-Aware_Pre-Trained_Models_for_Blind_Image_Quality_Assessment_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.00521-b31b1b.svg)](http://arxiv.org/abs/2303.00521) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zZlTy015M2g) |
| Recurrent Homography Estimation Using Homography-Guided Image Warping and Focus Transformer | [![GitHub](https://img.shields.io/github/stars/imdumpl78/rhwf?style=flat)](https://github.com/imdumpl78/rhwf) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Recurrent_Homography_Estimation_Using_Homography-Guided_Image_Warping_and_Focus_Transformer_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zH_H2MjG8v4) |
| Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution |  [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gamut-mlp.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Learning_Spatial-Temporal_Implicit_Neural_Representations_for_Event-Guided_Video_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13767-b31b1b.svg)](http://arxiv.org/abs/2303.13767) | :heavy_minus_sign: |
| RIDCP: Revitalizing Real Image Dehazing via High-Quality Codebook Priors | [![GitHub](https://img.shields.io/github/stars/RQ-Wu/RIDCP_dehazing?style=flat)](https://github.com/RQ-Wu/RIDCP_dehazing) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_RIDCP_Revitalizing_Real_Image_Dehazing_via_High-Quality_Codebook_Priors_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.03994-b31b1b.svg)](http://arxiv.org/abs/2304.03994) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PqmmpInqaHM) |
| Generating Aligned Pseudo-Supervision From Non-Aligned Data for Image Restoration in Under-Display Camera | [![GitHub](https://img.shields.io/github/stars/jnjaby/AlignFormer?style=flat)](https://github.com/jnjaby/AlignFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Generating_Aligned_Pseudo-Supervision_From_Non-Aligned_Data_for_Image_Restoration_in_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06019-b31b1b.svg)](http://arxiv.org/abs/2304.06019) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=98WNitG9IQo) |
| Structure Aggregation for Cross-Spectral Stereo Image Guided Denoising | [![GitHub](https://img.shields.io/github/stars/lustrouselixir/SANet?style=flat)](https://github.com/lustrouselixir/SANet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sheng_Structure_Aggregation_for_Cross-Spectral_Stereo_Image_Guided_Denoising_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://m.youtube.com/watch?v=dv8m87i31vM) |
| Rethinking Optical Flow From Geometric Matching Consistent Perspective | [![GitHub](https://img.shields.io/github/stars/DQiaole/MatchFlow?style=flat)](https://github.com/DQiaole/MatchFlow) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_Rethinking_Optical_Flow_From_Geometric_Matching_Consistent_Perspective_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08384-b31b1b.svg)](http://arxiv.org/abs/2303.08384) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=T5WID5SuAVQ) |
| Video Dehazing via a Multi-Range Temporal Alignment Network With Physical Prior | [![GitHub](https://img.shields.io/github/stars/jiaqixuac/MAP-Net?style=flat)](https://github.com/jiaqixuac/MAP-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Video_Dehazing_via_a_Multi-Range_Temporal_Alignment_Network_With_Physical_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09757-b31b1b.svg)](http://arxiv.org/abs/2303.09757) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lvzE58jxbdg) |
| Perception-Oriented Single Image Super-Resolution Using Optimal Objective Estimation | [![GitHub](https://img.shields.io/github/stars/seungho-snu/SROOE?style=flat)](https://github.com/seungho-snu/SROOE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Perception-Oriented_Single_Image_Super-Resolution_Using_Optimal_Objective_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13676-b31b1b.svg)](http://arxiv.org/abs/2211.13676) | :heavy_minus_sign: |
| Zero-Shot Dual-Lens Super-Resolution | [![GitHub](https://img.shields.io/github/stars/memad73/DualSR?style=flat)](https://github.com/memad73/DualSR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Zero-Shot_Dual-Lens_Super-Resolution_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ChHAIGyDFAI) |
| Efficient Frequency Domain-Based Transformers for High-Quality Image Deblurring <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/kkkls/FFTformer?style=flat)](https://github.com/kkkls/FFTformer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Efficient_Frequency_Domain-Based_Transformers_for_High-Quality_Image_Deblurring_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12250-b31b1b.svg)](http://arxiv.org/abs/2211.12250) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YDk6mjXsvX0) |
| A Simple Baseline for Video Restoration With Grouped Spatial-Temporal Shift | [![GitHub](https://img.shields.io/github/stars/dasongli1/Shift-Net?style=flat)](https://github.com/dasongli1/Shift-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_A_Simple_Baseline_for_Video_Restoration_With_Grouped_Spatial-Temporal_Shift_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.10810-b31b1b.svg)](http://arxiv.org/abs/2206.10810) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0Q5b8_eT9ko) |
| Learning Generative Structure Prior for Blind Text Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/csxmli2016/MARCONet?style=flat)](https://github.com/csxmli2016/MARCONet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Generative_Structure_Prior_for_Blind_Text_Image_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14726-b31b1b.svg)](http://arxiv.org/abs/2303.14726) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7SjH94vqFkA) |
| Motion Information Propagation for Neural Video Compression | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Qi_Motion_Information_Propagation_for_Neural_Video_Compression_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](hhttps://m.youtube.com/watch?v=uxVl9hGti14) |
| Joint Video Multi-Frame Interpolation and Deblurring Under Unknown Exposure Time | [![GitHub](https://img.shields.io/github/stars/shangwei5/VIDUE?style=flat)](https://github.com/shangwei5/VIDUE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shang_Joint_Video_Multi-Frame_Interpolation_and_Deblurring_Under_Unknown_Exposure_Time_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15043-b31b1b.svg)](http://arxiv.org/abs/2303.15043) | :heavy_minus_sign: |
| Event-Based Video Frame Interpolation With Cross-Modal Asymmetric Bidirectional Motion Fields <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/intelpro/CBMNet?style=flat)](https://github.com/intelpro/CBMNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Event-Based_Video_Frame_Interpolation_With_Cross-Modal_Asymmetric_Bidirectional_Motion_Fields_CVPR_2023_paper.pdf)  | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xw4pQjzoGVg) |
| Learning Sample Relationship for Exposure Correction | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Learning_Sample_Relationship_for_Exposure_Correction_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mWkCEwfI5t4) |
| Spatially Adaptive Self-Supervised Learning for Real-World Image Denoising | [![GitHub](https://img.shields.io/github/stars/nagejacob/SpatiallyAdaptiveSSID?style=flat)](https://github.com/nagejacob/SpatiallyAdaptiveSSID) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Spatially_Adaptive_Self-Supervised_Learning_for_Real-World_Image_Denoising_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14934-b31b1b.svg)](http://arxiv.org/abs/2303.14934) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0f4GbEFwB78) |
| Context-Aware Pretraining for Efficient Blind Image Decomposition | [![GitHub](https://img.shields.io/github/stars/Oliiveralien/CPNet?style=flat)](https://github.com/Oliiveralien/CPNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Context-Aware_Pretraining_for_Efficient_Blind_Image_Decomposition_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Physics-Guided ISO-Dependent Sensor Noise Modeling for Extreme Low-Light Photography | [![GitHub](https://img.shields.io/github/stars/happycaoyue/LLD?style=flat)](https://github.com/happycaoyue/LLD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Physics-Guided_ISO-Dependent_Sensor_Noise_Modeling_for_Extreme_Low-Light_Photography_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G8rD1pCI6P8) |
| AnyFlow: Arbitrary Scale Optical Flow With Implicit Neural Representation <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jung_AnyFlow_Arbitrary_Scale_Optical_Flow_With_Implicit_Neural_Representation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16493-b31b1b.svg)](http://arxiv.org/abs/2303.16493) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wykpSvssilA) |
| Complexity-Guided Slimmable Decoder for Efficient Deep Video Compression | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Complexity-Guided_Slimmable_Decoder_for_Efficient_Deep_Video_Compression_CVPR_2023_paper.pdf) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JPoIab7OZSc) |
| Bitstream-Corrupted JPEG Images Are Restorable: Two-Stage Compensation and Alignment Framework for Image Restoration | [![GitHub](https://img.shields.io/github/stars/wenyang001/Two-ACIR?style=flat)](https://github.com/wenyang001/Two-ACIR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Bitstream-Corrupted_JPEG_Images_Are_Restorable_Two-Stage_Compensation_and_Alignment_Framework_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06976-b31b1b.svg)](http://arxiv.org/abs/2304.06976) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9DlKlXln8I4) |
| Spectral Enhanced Rectangle Transformer for Hyperspectral Image Denoising | [![GitHub](https://img.shields.io/github/stars/MyuLi/SERT?style=flat)](https://github.com/MyuLi/SERT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Spectral_Enhanced_Rectangle_Transformer_for_Hyperspectral_Image_Denoising_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00844-b31b1b.svg)](http://arxiv.org/abs/2304.00844) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KPJjD2Dsi0A) |
| Learning From Unique Perspectives: User-Aware Saliency Modeling | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Learning_From_Unique_Perspectives_User-Aware_Saliency_Modeling_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hyYXmCN3IYc) |
| DINN360: Deformable Invertible Neural Network for Latitude-Aware 360&deg; Image Rescaling| [![GitHub](https://img.shields.io/github/stars/gyc9709/DINN360?style=flat)](https://github.com/gyc9709/DINN360) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_DINN360_Deformable_Invertible_Neural_Network_for_Latitude-Aware_360deg_Image_Rescaling_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1E1Vr2jq8JI) |
| ABCD: Arbitrary Bitwise Coefficient for De-Quantization | [![GitHub](https://img.shields.io/github/stars/WooKyoungHan/ABCD?style=flat)](https://github.com/WooKyoungHan/ABCD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Han_ABCD_Arbitrary_Bitwise_Coefficient_for_De-Quantization_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UJrraJzDZ9U) |
| Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning | [![GitHub](https://img.shields.io/github/stars/chengtan9907/OpenSTL?style=flat)](https://github.com/chengtan9907/OpenSTL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_Temporal_Attention_Unit_Towards_Efficient_Spatiotemporal_Predictive_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.12126-b31b1b.svg)](http://arxiv.org/abs/2206.12126) | :heavy_minus_sign: |
| Learning Steerable Function for Efficient Image Resampling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lerf.pages.dev/) <br /> [![GitHub](https://img.shields.io/github/stars/ddlee-cn/LeRF-MindSpore?style=flat)](https://github.com/ddlee-cn/LeRF-MindSpore) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Steerable_Function_for_Efficient_Image_Resampling_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=6Sgnq2AD5yw) |
| Revisiting the Stack-Based Inverse Tone Mapping| [![GitHub](https://img.shields.io/github/stars/zhangn77/Revisiting-the-Stack-Based-Inverse-Tone-Mapping?style=flat)](https://github.com/zhangn77/Revisiting-the-Stack-Based-Inverse-Tone-Mapping) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Revisiting_the_Stack-Based_Inverse_Tone_Mapping_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rk4CsDMjFPg) |
| Generative Diffusion Prior for Unified Image Restoration and Enhancement | [![GitHub](https://img.shields.io/github/stars/Fayeben/GenerativeDiffusionPrior?style=flat)](https://github.com/Fayeben/GenerativeDiffusionPrior) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fei_Generative_Diffusion_Prior_for_Unified_Image_Restoration_and_Enhancement_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01247-b31b1b.svg)](http://arxiv.org/abs/2304.01247) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://m.youtube.com/watch?v=uxX6L2syn5Y) |
| LG-BPN: Local and Global Blind-Patch Network for Self-Supervised Real-World Denoising | [![GitHub](https://img.shields.io/github/stars/Wang-XIaoDingdd/LGBPN?style=flat)](https://github.com/Wang-XIaoDingdd/LGBPN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_LG-BPN_Local_and_Global_Blind-Patch_Network_for_Self-Supervised_Real-World_Denoising_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00534-b31b1b.svg)](https://arxiv.org/abs/2304.00534) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OlNepkCZ_G4) |
| Adaptive Spot-Guided Transformer for Consistent Local Feature Matching | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://astr2023.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/ASTR2023/ASTR?style=flat)](https://github.com/ASTR2023/ASTR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Adaptive_Spot-Guided_Transformer_for_Consistent_Local_Feature_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16624-b31b1b.svg)](http://arxiv.org/abs/2303.16624) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=q10xY8AOVho) |
| SFD2: Semantic-Guided Feature Detection and Description | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://feixue94.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/feixue94/sfd2?style=flat)](https://github.com/feixue94/sfd2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_SFD2_Semantic-Guided_Feature_Detection_and_Description_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14845-b31b1b.svg)](http://arxiv.org/abs/2304.14845) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WzVXG5pyrgo) |
| Burstormer: Burst Image Restoration and Enhancement Transformer | [![GitHub](https://img.shields.io/github/stars/akshaydudhane16/Burstormer?style=flat)](https://github.com/akshaydudhane16/Burstormer)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Dudhane_Burstormer_Burst_Image_Restoration_and_Enhancement_Transformer_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01194-b31b1b.svg)](http://arxiv.org/abs/2304.01194) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3goqbKsqfcw) |
| DeepLSD: Line Segment Detection and Refinement With Deep Image Gradients | [![GitHub](https://img.shields.io/github/stars/cvg/DeepLSD?style=flat)](https://github.com/cvg/DeepLSD)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Pautrat_DeepLSD_Line_Segment_Detection_and_Refinement_With_Deep_Image_Gradients_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07766-b31b1b.svg)](http://arxiv.org/abs/2212.07766)  | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jHcfCzuoqp8) |
| Gated Multi-Resolution Transfer Network for Burst Restoration and Enhancement | [![GitHub](https://img.shields.io/github/stars/nanmehta/GMTNet?style=flat)](https://github.com/nanmehta/GMTNet)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Mehta_Gated_Multi-Resolution_Transfer_Network_for_Burst_Restoration_and_Enhancement_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06703-b31b1b.svg)](http://arxiv.org/abs/2304.06703) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Xe2HeGGYrc4) |
| Structured Sparsity Learning for Efficient Video Super-Resolution | [![GitHub](https://img.shields.io/github/stars/Zj-BinXia/SSL?style=flat)](https://github.com/Zj-BinXia/SSL)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Xia_Structured_Sparsity_Learning_for_Efficient_Video_Super-Resolution_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.07687-b31b1b.svg)](http://arxiv.org/abs/2206.07687) | :heavy_minus_sign: |
| DNeRV: Modeling Inherent Dynamics via Difference Neural Representation for Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://haochen-rye.github.io/HNeRV/) <br /> [![GitHub](https://img.shields.io/github/stars/haochen-rye/HNeRV?style=flat)](https://github.com/haochen-rye/HNeRV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhao_DNeRV_Modeling_Inherent_Dynamics_via_Difference_Neural_Representation_for_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06544-b31b1b.svg)](http://arxiv.org/abs/2304.06544) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=v7_fqRxiKEI) |
| Exploring Discontinuity for Video Frame Interpolation <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]() | [![GitHub](https://img.shields.io/github/stars/pandatimo/Exploring-Discontinuity-for-VFI?style=flat)](https://github.com/pandatimo/Exploring-Discontinuity-for-VFI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lee_Exploring_Discontinuity_for_Video_Frame_Interpolation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2202.07291-b31b1b.svg)](http://arxiv.org/abs/2202.07291) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uaKJtD-2KZc) |
| Neural Video Compression With Diverse Contexts | [![GitHub](https://img.shields.io/github/stars/microsoft/DCVC?style=flat)](https://github.com/microsoft/DCVC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14402-b31b1b.svg)](http://arxiv.org/abs/2302.14402) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s8PSvl5FbWQ) |
| FlowFormer++: Masked Cost Volume Autoencoding for Pretraining Optical Flow Estimation | [![GitHub](https://img.shields.io/github/stars/XiaoyuShi97/FlowFormerPlusPlus?style=flat)](https://github.com/XiaoyuShi97/FlowFormerPlusPlus) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Shi_FlowFormer_Masked_Cost_Volume_Autoencoding_for_Pretraining_Optical_Flow_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01237-b31b1b.svg)](https://arxiv.org/abs/2303.01237) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-XZi1HT0Y7o) |
| OPE-SR: Orthogonal Position Encoding for Designing a Parameter-Free Upsampling Module in Arbitrary-Scale Image Super-Resolution| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Song_OPE-SR_Orthogonal_Position_Encoding_for_Designing_a_Parameter-Free_Upsampling_Module_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01091-b31b1b.svg)](https://arxiv.org/abs/2303.01091) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OqoiHUdZ3O0) |
| Context-Based Trit-Plane Coding for Progressive Image Compression | [![GitHub](https://img.shields.io/github/stars/seungminjeon-github/CTC?style=flat)](https://github.com/seungminjeon-github/CTC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Jeon_Context-Based_Trit-Plane_Coding_for_Progressive_Image_Compression_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05715-b31b1b.svg)](http://arxiv.org/abs/2303.05715) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=p1_UW8cge7g) |
| All-in-One Image Restoration for Unknown Degradations Using Adaptive Discriminative Filters for Specific Degradations| :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Park_All-in-One_Image_Restoration_for_Unknown_Degradations_Using_Adaptive_Discriminative_Filters_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xn3EpFsZ_hQ) |
| Learning To Exploit the Sequence-Specific Prior Knowledge for Image Processing Pipelines Optimization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Qin_Learning_To_Exploit_the_Sequence-Specific_Prior_Knowledge_for_Image_Processing_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Oh-kgpe-S_Y) |
| Nighttime Smartphone Reflective Flare Removal using Optical Center Symmetry Prior |  |  |  |
| Enhancing Deformable Local Features by Jointly Learning to Detect and Describe Keypoints |  |  |  |
| Real-Time Controllable Denoising for Image and Video |  |  |  |
| Compression-Aware Video Super-Resolution |  |  |  |
| Spatial-Frequency Mutual Learning for Face Super-Resolution |  |  |  |
| The Treasure Beneath Multiple Annotations: An Uncertainty-Aware Edge Detector |  |  |  |
| Toward Stable, Interpretable, and Lightweight Hyperspectral Super-Resolution |  |  |  |
| Modernizing Old Photos Using Multiple References via Photorealistic Style Transfer |  |  |  |
| Data-Driven Feature Tracking for Event Cameras |  |  |  |
| LVQAC: Lattice Vector Quantization Coupled with Spatially Adaptive Companding for Efficient Learned Image Compression |  |  |  |
| Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger |  |  |  |
| Learning to Detect Mirrors from Videos via Dual Correspondences |  |  |  |
| Robust Unsupervised StyleGAN Image Restoration |  |  |  |
| Ingredient-oriented Multi-Degradation Learning for Image Restoration |  |  |  |
| CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution |  |  |  |
| Semi-Supervised Parametric Real-World Image Harmonization |  |  |  |
| SmartAssign: Learning a Smart Knowledge Assignment Strategy for Deraining and Desnowing |  |  |  |
| Robust Single Image Reflection Removal Against Adversarial Attacks |  |  |  |
| PMatch: Paired Masked Image Modeling for Dense Geometric Matching |  |  |  |
| Extracting Motion and Appearance via Inter-Frame Attention for Efficient Video Frame Interpolation |  |  |  |
| Residual Degradation Learning Unfolding Framework with Mixing Priors Across Spectral and Spatial for Compressive Spectral Imaging |  |  |  |
| Visual Recognition-Driven Image Restoration for Multiple Degradation with Intrinsic Semantics Recovery |  |  |  |
| sRGB Real Noise Synthesizing with Neighboring Correlation-Aware Noise Model |  |  |  |
| Rethinking Image Super Resolution from Long-Tailed Distribution Learning Perspective |  |  |  |
| Comprehensive and Delicate: An Efficient Transformer for Image Restoration |  |  |  |
| Super-Resolution Neural Operator |  |  |  |
| Neumann Network with Recursive Kernels for Single Image Defocus Deblurring |  |  |  |
| Discriminative Co-Saliency and Background Mining Transformer for Co-Salient Object Detection |  |  |  |
| Learning Rotation-Equivariant Features for Visual Correspondence |  |  |  |
| Patch-Craft Self-Supervised Training for Correlated Image Denoising |  |  |  |
| Metadata-based RAW Reconstruction via Implicit Neural Functions |  |  |  |
| Contrastive Semi-Supervised Learning for Underwater Image Restoration via Reliable Bank |  |  |  |
| Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning |  |  |  |
| Spectral Bayesian Uncertainty for Image Super-Resolution |  |  |  |
| DINER: Disorder-Invariant Implicit Neural Representation |  |  |  |
| NVTC: Nonlinear Vector Transform Coding |  |  |  |
| HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering |  |  |  |
| You Do Not Need Additional Priors or Regularizers in Retinex-based Low-light Image Enhancement |  |  |  |
| Learning a Practical SDR-to-HDRTV Up-Conversion using New Dataset and Degradation Models |  |  |  |
