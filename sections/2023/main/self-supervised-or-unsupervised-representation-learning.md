# CVPR-2023-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>New collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
                <img src="http://img.shields.io/badge/CVPR-2024-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/navigation-and-autonomous-driving.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2023/main/datasets-and-evaluation.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
  </a>
</div>

## Self-Supervised or Unsupervised Representation Learning

![Section Papers](https://img.shields.io/badge/Section%20Papers-71-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-58-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-57-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-48-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| SimpleNet: A Simple Network for Image Anomaly Detection and Localization | [![GitHub](https://img.shields.io/github/stars/DonaldRR/SimpleNet?style=flat)](https://github.com/DonaldRR/SimpleNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_SimpleNet_A_Simple_Network_for_Image_Anomaly_Detection_and_Localization_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15140-b31b1b.svg)](http://arxiv.org/abs/2303.15140) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=R9P4ULNBvSk) |
| Masked Image Modeling with Local Multi-Scale Reconstruction <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/Haoqing-Wang/LocalMIM?style=flat)](https://github.com/Haoqing-Wang/LocalMIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Masked_Image_Modeling_With_Local_Multi-Scale_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05251-b31b1b.svg)](http://arxiv.org/abs/2303.05251) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_QmCpjHMcMI) |
| <i>Ada</i>MAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.wgcban.com/research/adamae) <br /> [![GitHub](https://img.shields.io/github/stars/wgcban/adamae?style=flat)](https://github.com/wgcban/adamae) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Bandara_AdaMAE_Adaptive_Masking_for_Efficient_Spatiotemporal_Learning_With_Masked_Autoencoders_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09120-b31b1b.svg)](http://arxiv.org/abs/2211.09120) | :heavy_minus_sign: |
| ActMAD: Activation Matching to Align Distributions for Test-Time-Training | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jmiemirza.github.io/ActMAD) <br /> [![GitHub](https://img.shields.io/github/stars/jmiemirza/ActMAD?style=flat)](https://github.com/jmiemirza/ActMAD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mirza_ActMAD_Activation_Matching_To_Align_Distributions_for_Test-Time-Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12870-b31b1b.svg)](http://arxiv.org/abs/2211.12870) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GI5auU8TpG4) |
| Rethinking Out-of-Distribution (OOD) Detection: Masked Image Modeling is All You Need | [![GitHub](https://img.shields.io/github/stars/JulietLJY/MOOD?style=flat)](https://github.com/JulietLJY/MOOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Rethinking_Out-of-Distribution_OOD_Detection_Masked_Image_Modeling_Is_All_You_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.02615-b31b1b.svg)](http://arxiv.org/abs/2302.02615) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JtBZ6lO67F4) |
| DLBD: A Self-Supervised Direct-Learned Binary Descriptor | [![GitHub](https://img.shields.io/github/stars/CQUPT-CV/DLBD?style=flat)](https://github.com/CQUPT-CV/DLBD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_DLBD_A_Self-Supervised_Direct-Learned_Binary_Descriptor_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=emMctSoP6Cs) |
| Cut and Learn for Unsupervised Object Detection and Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/facebookresearch/CutLER?style=flat)](https://github.com/facebookresearch/CutLER) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Cut_and_Learn_for_Unsupervised_Object_Detection_and_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.11320-b31b1b.svg)](http://arxiv.org/abs/2301.11320) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=y4b5wkf9vp0) |
| Unsupervised Deep Probabilistic Approach for Partial Point Cloud Registration | [![GitHub](https://img.shields.io/github/stars/gfmei/UDPReg?style=flat)](https://github.com/gfmei/UDPReg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mei_Unsupervised_Deep_Probabilistic_Approach_for_Partial_Point_Cloud_Registration_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13290-b31b1b.svg)](http://arxiv.org/abs/2303.13290) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YH9rI-kot0g) |
| Masked Motion Encoding for Self-Supervised Video Representation Learning | [![GitHub](https://img.shields.io/github/stars/XinyuSun/MME?style=flat)](https://github.com/XinyuSun/MME) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Masked_Motion_Encoding_for_Self-Supervised_Video_Representation_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.06096-b31b1b.svg)](http://arxiv.org/abs/2210.06096) | :heavy_minus_sign: |
| Stare at what You See: Masked Image Modeling without Reconstruction | [![GitHub](https://img.shields.io/github/stars/OpenDriveLab/maskalign?style=flat)](https://github.com/OpenDriveLab/maskalign) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_Stare_at_What_You_See_Masked_Image_Modeling_Without_Reconstruction_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.08887-b31b1b.svg)](http://arxiv.org/abs/2211.08887) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iBVc1Vvhx84) |
| Hard Patches Mining for Masked Image Modeling | [![GitHub](https://img.shields.io/github/stars/Haochen-Wang409/HPM?style=flat)](https://github.com/Haochen-Wang409/HPM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Hard_Patches_Mining_for_Masked_Image_Modeling_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05919-b31b1b.svg)](http://arxiv.org/abs/2304.05919) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ns6A-kJXPzo) |
| Multi-Mode Online Knowledge Distillation for Self-Supervised Visual Representation Learning | [![GitHub](https://img.shields.io/github/stars/skyoux/mokd?style=flat)](https://github.com/skyoux/mokd) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Multi-Mode_Online_Knowledge_Distillation_for_Self-Supervised_Visual_Representation_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.06461-b31b1b.svg)](http://arxiv.org/abs/2304.06461) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=g3WmZt0OSKs) |
| EVA: Exploring the Limits of Masked Visual Representation Learning at Scale <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/baaivision/EVA/tree/master/EVA-01) <br /> [![GitHub](https://img.shields.io/github/stars/baaivision/EVA?style=flat)](https://github.com/baaivision/EVA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_EVA_Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.07636-b31b1b.svg)](http://arxiv.org/abs/2211.07636) | :heavy_minus_sign: |
| MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis | [![GitHub](https://img.shields.io/github/stars/LTH14/mage?style=flat)](https://github.com/LTH14/mage) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MAGE_MAsked_Generative_Encoder_To_Unify_Representation_Learning_and_Image_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09117-b31b1b.svg)](http://arxiv.org/abs/2211.09117) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YeroKjJq9nk) |
| Token Boosting for Robust Self-Supervised Visual Transformer Pre-Training | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Token_Boosting_for_Robust_Self-Supervised_Visual_Transformer_Pre-Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04175-b31b1b.svg)](http://arxiv.org/abs/2304.04175) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kefATZoHqNI) |
| Unsupervised 3D Point Cloud Representation Learning by Triangle Constrained Contrast for Autonomous Driving | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Pang_Unsupervised_3D_Point_Cloud_Representation_Learning_by_Triangle_Constrained_Contrast_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TWEH5LdCGTo) |
| Masked Auto-Encoders Meet Generative Adversarial Networks and Beyond | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Fei_Masked_Auto-Encoders_Meet_Generative_Adversarial_Networks_and_Beyond_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Integrally Pre-Trained Transformer Pyramid Networks | [![GitHub](https://img.shields.io/github/stars/sunsmarterjie/iTPN?style=flat)](https://github.com/sunsmarterjie/iTPN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Integrally_Pre-Trained_Transformer_Pyramid_Networks_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12735-b31b1b.svg)](http://arxiv.org/abs/2211.12735) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=k7oX2m0T7OU) |
| Mixed Autoencoder for Self-Supervised Visual Representation Learning | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Mixed_Autoencoder_for_Self-Supervised_Visual_Representation_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17152-b31b1b.svg)](http://arxiv.org/abs/2303.17152) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ic8GYtwjSuw) |
| Correlational Image Modeling for Self-Supervised Visual Pre-Training | [![GitHub](https://img.shields.io/github/stars/weivision/Correlational-Image-Modeling?style=flat)](https://github.com/weivision/Correlational-Image-Modeling) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Correlational_Image_Modeling_for_Self-Supervised_Visual_Pre-Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12670-b31b1b.svg)](http://arxiv.org/abs/2303.12670) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ud0uKNNQ5t4) |
| Shepherding Slots to Objects: Towards Stable and Robust Object-Centric Learning | [![GitHub](https://img.shields.io/github/stars/object-understanding/SLASH?style=flat)](https://github.com/object-understanding/SLASH) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Shepherding_Slots_to_Objects_Towards_Stable_and_Robust_Object-Centric_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17842-b31b1b.svg)](http://arxiv.org/abs/2303.17842) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rrxjDndltlA) |
| Deep Fair Clustering via Maximizing and Minimizing Mutual Information: Theory, Algorithm and Metric | [![GitHub](https://img.shields.io/github/stars/XLearning-SCU/2023-CVPR-FCMI?style=flat)](https://github.com/XLearning-SCU/2023-CVPR-FCMI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_Deep_Fair_Clustering_via_Maximizing_and_Minimizing_Mutual_Information_Theory_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2209.12396-b31b1b.svg)](http://arxiv.org/abs/2209.12396) | :heavy_minus_sign: |
| Evolved Part Masking for Self-Supervised Learning | [![GitHub](https://img.shields.io/github/stars/ZhanzhouFeng/Evolved-Part-Masking?style=flat)](https://github.com/ZhanzhouFeng/Evolved-Part-Masking) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Evolved_Part_Masking_for_Self-Supervised_Learning_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Change-Aware Sampling and Contrastive Learning for Satellite Images | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://research.cs.cornell.edu/caco/) <br /> [![GitHub](https://img.shields.io/github/stars/utkarshmall13/caco?style=flat)](https://github.com/utkarshmall13/caco) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Mall_Change-Aware_Sampling_and_Contrastive_Learning_for_Satellite_Images_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZwwGP8XD7Io) |
| Learning Common Rationale to Improve Self-Supervised Representation for Fine-Grained Visual Recognition Problems | [![GitHub](https://img.shields.io/github/stars/GANPerf/LCR?style=flat)](https://github.com/GANPerf/LCR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shu_Learning_Common_Rationale_To_Improve_Self-Supervised_Representation_for_Fine-Grained_Visual_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.01669-b31b1b.svg)](http://arxiv.org/abs/2303.01669) | :heavy_minus_sign: |
| DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks | [![GitHub](https://img.shields.io/github/stars/jimmy-dq/DropMAE?style=flat)](https://github.com/jimmy-dq/DropMAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_DropMAE_Masked_Autoencoders_With_Spatial-Attention_Dropout_for_Tracking_Tasks_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.00571-b31b1b.svg)](http://arxiv.org/abs/2304.00571) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QIfY5RFJTJU) |
| RILS: Masked Visual Reconstruction in Language Semantic Space | [![GitHub](https://img.shields.io/github/stars/hustvl/RILS?style=flat)](https://github.com/hustvl/RILS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_RILS_Masked_Visual_Reconstruction_in_Language_Semantic_Space_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.06958-b31b1b.svg)](http://arxiv.org/abs/2301.06958) | :heavy_minus_sign: |
| Three Guidelines You Should know for Universally Slimmable Self-Supervised Learning | [![GitHub](https://img.shields.io/github/stars/megvii-research/US3L-CVPR2023?style=flat)](https://github.com/megvii-research/US3L-CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Three_Guidelines_You_Should_Know_for_Universally_Slimmable_Self-Supervised_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06870-b31b1b.svg)](http://arxiv.org/abs/2303.06870) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EbMfGAzm5T4) |
| BASiS: Batch Aligned Spectral Embedding Space | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Streicher_BASiS_Batch_Aligned_Spectral_Embedding_Space_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.16960-b31b1b.svg)](http://arxiv.org/abs/2211.16960) | :heavy_minus_sign: |
| Co-Salient Object Detection with Uncertainty-Aware Group Exchange-Masking | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Co-Salient_Object_Detection_With_Uncertainty-Aware_Group_Exchange-Masking_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YqDkInedx34) |
| Hyperbolic Contrastive Learning for Visual Representations beyond Objects | [![GitHub](https://img.shields.io/github/stars/shlokk/HCL?style=flat)](https://github.com/shlokk/HCL/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ge_Hyperbolic_Contrastive_Learning_for_Visual_Representations_Beyond_Objects_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.00653-b31b1b.svg)](http://arxiv.org/abs/2212.00653) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=voDgTcd8qQk) |
| Active Finetuning: Exploiting Annotation Budget in the Pretraining-Finetuning Paradigm | [![GitHub](https://img.shields.io/github/stars/yichen928/ActiveFT?style=flat)](https://github.com/yichen928/ActiveFT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Active_Finetuning_Exploiting_Annotation_Budget_in_the_Pretraining-Finetuning_Paradigm_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14382-b31b1b.svg)](http://arxiv.org/abs/2303.14382) | :heavy_minus_sign: |
| MV-JAR: Masked Voxel Jigsaw and Reconstruction for LiDAR-based Self-Supervised Pre-Training | [![GitHub](https://img.shields.io/github/stars/OpenRobotLab/MV-JAR?style=flat)](https://github.com/OpenRobotLab/MV-JAR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_MV-JAR_Masked_Voxel_Jigsaw_and_Reconstruction_for_LiDAR-Based_Self-Supervised_Pre-Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13510-b31b1b.svg)](http://arxiv.org/abs/2303.13510) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nlZd-twMOaE) |
| OmniAL: A Unified CNN Framework for Unsupervised Anomaly Localization | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_OmniAL_A_Unified_CNN_Framework_for_Unsupervised_Anomaly_Localization_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| TinyMIM: An Empirical Study of Distilling MIM Pre-Trained Models | [![GitHub](https://img.shields.io/github/stars/OliverRensu/TinyMIM?style=flat)](https://github.com/OliverRensu/TinyMIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_TinyMIM_An_Empirical_Study_of_Distilling_MIM_Pre-Trained_Models_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01296-b31b1b.svg)](http://arxiv.org/abs/2301.01296) | :heavy_minus_sign: |
| ALSO: Automotive Lidar Self-Supervision by Occupancy Estimation | [![GitHub](https://img.shields.io/github/stars/valeoai/ALSO?style=flat)](https://github.com/valeoai/ALSO) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Boulch_ALSO_Automotive_Lidar_Self-Supervision_by_Occupancy_Estimation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05867-b31b1b.svg)](http://arxiv.org/abs/2212.05867) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GGIBKlMvphw) |
| Non-Contrastive Unsupervised Learning of Physiological Signals from Video <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/CVRL/SiNC-rPPG?style=flat)](https://github.com/CVRL/SiNC-rPPG) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Speth_Non-Contrastive_Unsupervised_Learning_of_Physiological_Signals_From_Video_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07944-b31b1b.svg)](http://arxiv.org/abs/2303.07944) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Bg7VkxWcOhQ) |
| CrOC: Cross-View Online Clustering for Dense Visual Representation Learning | [![GitHub](https://img.shields.io/github/stars/stegmuel/CrOC?style=flat)](https://github.com/stegmuel/CrOC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Stegmuller_CrOC_Cross-View_Online_Clustering_for_Dense_Visual_Representation_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13245-b31b1b.svg)](https://arxiv.org/abs/2303.13245)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=al067JbNNzw) |
| MOVES: Manipulated Objects in Video Enable Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://relh.github.io/moves/) <br /> [![GitHub](https://img.shields.io/github/stars/relh/moves?style=flat)](https://github.com/relh/moves) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Higgins_MOVES_Manipulated_Objects_in_Video_Enable_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JBz4zzQdoso) |
| Self-Supervised Representation Learning for CAD | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Jones_Self-Supervised_Representation_Learning_for_CAD_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.10807-b31b1b.svg)](https://arxiv.org/abs/2210.10807) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ICWOmook9w8) |
| Movies2Scenes: using Movie Metadata to Learn Scene Representation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Movies2Scenes_Using_Movie_Metadata_To_Learn_Scene_Representation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2202.10650-b31b1b.svg)](http://arxiv.org/abs/2202.10650) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NrXEIoocKFg) |
| PointCMP: Contrastive Mask Prediction for Self-Supervised Learning on Point Cloud Videos | [![GitHub](https://img.shields.io/github/stars/JohnsonSign/PointCMP?style=flat)](https://github.com/JohnsonSign/PointCMP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shen_PointCMP_Contrastive_Mask_Prediction_for_Self-Supervised_Learning_on_Point_Cloud_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.04075-b31b1b.svg)](http://arxiv.org/abs/2305.04075) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EzI9Vn9HPNY) |
| Texture-guided Saliency Distilling for Unsupervised Salient Object Detection | [![GitHub](https://img.shields.io/github/stars/moothes/A2S-v2?style=flat)](https://github.com/moothes/A2S-v2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Texture-Guided_Saliency_Distilling_for_Unsupervised_Salient_Object_Detection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.05921-b31b1b.svg)](http://arxiv.org/abs/2207.05921) | :heavy_minus_sign: |
| Multi-Realism Image Compression with a Conditional Generator | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Agustsson_Multi-Realism_Image_Compression_With_a_Conditional_Generator_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.13824-b31b1b.svg)](http://arxiv.org/abs/2212.13824) | :heavy_minus_sign: |
| Understanding Masked Autoencoders via Hierarchical Latent Variable Models <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/martinmamql/mae_understand?style=flat)](https://github.com/martinmamql/mae_understand) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Understanding_Masked_Autoencoders_via_Hierarchical_Latent_Variable_Models_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.04898-b31b1b.svg)](https://arxiv.org/abs/2306.04898) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=004ojgVKYtA) |
| GeoMAE: Masked Geometric Target Prediction for Self-Supervised Point Cloud Pre-Training | [![GitHub](https://img.shields.io/github/stars/Tsinghua-MARS-Lab/GeoMAE?style=flat)](https://github.com/Tsinghua-MARS-Lab/GeoMAE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_GeoMAE_Masked_Geometric_Target_Prediction_for_Self-Supervised_Point_Cloud_Pre-Training_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.08808-b31b1b.svg)](http://arxiv.org/abs/2305.08808) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZJ7ukv1-WEk) |
| Siamese DETR | [![GitHub](https://img.shields.io/github/stars/Zx55/SiameseDETR?style=flat)](https://github.com/Zx55/SiameseDETR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Siamese_DETR_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.18144-b31b1b.svg)](http://arxiv.org/abs/2303.18144) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kPV-RZwgp7A) |
| Generalizable Implicit Neural Representations via Instance Pattern Composers <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/kakaobrain/ginr-ipc?style=flat)](https://github.com/kakaobrain/ginr-ipc) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Generalizable_Implicit_Neural_Representations_via_Instance_Pattern_Composers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13223-b31b1b.svg)](http://arxiv.org/abs/2211.13223) | :heavy_minus_sign: |
| Pose-Disentangled Contrastive Learning for Self-Supervised Facial Representation | [![GitHub](https://img.shields.io/github/stars/DreamMr/PCL?style=flat)](https://github.com/DreamMr/PCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Pose-Disentangled_Contrastive_Learning_for_Self-Supervised_Facial_Representation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13490-b31b1b.svg)](http://arxiv.org/abs/2211.13490) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rayPoX6I5Bc) |
| OT-Filter: An Optimal Transport Filter for Learning with Noisy Labels | [![GitHub](https://img.shields.io/github/stars/ryl0427/Code-for-OT-Filter?style=flat)](https://github.com/ryl0427/Code-for-OT-Filter) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_OT-Filter_An_Optimal_Transport_Filter_for_Learning_With_Noisy_Labels_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Teacher-Generated Spatial-Attention Labels Boost Robustness and Accuracy of Contrastive Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg?style=flat)](https://github.com/google-research/google-research/tree/master/human_attention/saliency_model_from_scratch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Teacher-Generated_Spatial-Attention_Labels_Boost_Robustness_and_Accuracy_of_Contrastive_Models_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WyC1zfqbrgU) |
| Spatio-Temporal Self-Supervised Learning for Point Clouds in the Wild | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yanhaowu.github.io/STSSL/) <br /> [![GitHub](https://img.shields.io/github/stars/YanhaoWu/STSSL?style=flat)](https://github.com/YanhaoWu/STSSL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Spatiotemporal_Self-Supervised_Learning_for_Point_Clouds_in_the_Wild_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16235-b31b1b.svg)](http://arxiv.org/abs/2303.16235) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ck5bShcRFwk) |
| BKinD-3D: Self-Supervised 3D Keypoint Discovery from Multi-View Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/b-kind/3d) <br /> [![GitHub](https://img.shields.io/github/stars/neuroethology/BKinD-3D?style=flat)](https://github.com/neuroethology/BKinD-3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_BKinD-3D_Self-Supervised_3D_Keypoint_Discovery_From_Multi-View_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07401-b31b1b.svg)](https://arxiv.org/abs/2212.07401) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CqYw1DicsTg) |
| Learning Decorrelated Representations Efficiently using Fast Fourier Transform | [![GitHub](https://img.shields.io/github/stars/yutaro-s/scalable-decorrelation-ssl?style=flat)](https://github.com/yutaro-s/scalable-decorrelation-ssl) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Shigeto_Learning_Decorrelated_Representations_Efficiently_Using_Fast_Fourier_Transform_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01569-b31b1b.svg)](http://arxiv.org/abs/2301.01569) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ngPiU13Fg0M) |
| Beyond Appearance: A Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks | [![GitHub](https://img.shields.io/github/stars/tinyvision/SOLIDER?style=flat)](https://github.com/tinyvision/SOLIDER) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Beyond_Appearance_A_Semantic_Controllable_Self-Supervised_Learning_Framework_for_Human-Centric_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17602-b31b1b.svg)](http://arxiv.org/abs/2303.17602) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jOCLYkEV2d0) |
| Learning Geometry-Aware Representations by Sketching | [![GitHub](https://img.shields.io/github/stars/illhyhl1111/LearningBySketching?style=flat)](https://github.com/illhyhl1111/LearningBySketching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Learning_Geometry-Aware_Representations_by_Sketching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.08204-b31b1b.svg)](http://arxiv.org/abs/2304.08204) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=26hCySC0354) |
| Improving Visual Representation Learning through Perceptual Understanding | [![GitHub](https://img.shields.io/github/stars/tractableai/perceptual-mae?style=flat)](https://github.com/tractableai/perceptual-mae) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Tukra_Improving_Visual_Representation_Learning_Through_Perceptual_Understanding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.14504-b31b1b.svg)](http://arxiv.org/abs/2212.14504) | :heavy_minus_sign: |
| MixMAE: Mixed and Masked Autoencoder for Efficient Pretraining of Hierarchical Vision Transformers | [![GitHub](https://img.shields.io/github/stars/Sense-X/MixMIM?style=flat)](https://github.com/Sense-X/MixMIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_MixMAE_Mixed_and_Masked_Autoencoder_for_Efficient_Pretraining_of_Hierarchical_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.13137-b31b1b.svg)](http://arxiv.org/abs/2205.13137) | :heavy_minus_sign: |
| Unsupervised Object Localization: Observing the Background to Discover Objects | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://valeoai.github.io/blog/publications/found/) <br /> [![GitHub](https://img.shields.io/github/stars/valeoai/FOUND?style=flat)](https://github.com/valeoai/FOUND) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Simeoni_Unsupervised_Object_Localization_Observing_the_Background_To_Discover_Objects_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07834-b31b1b.svg)](https://arxiv.org/abs/2212.07834) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jfYQfFcrJBE) |
| MCF: Mutual Correction Framework for Semi-Supervised Medical Image Segmentation | [![GitHub](https://img.shields.io/github/stars/WYC-321/MCF?style=flat)](https://github.com/WYC-321/MCF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_MCF_Mutual_Correction_Framework_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ViF28ArbhFY) |
| DivClust: Controlling Diversity in Deep Clustering | [![GitHub](https://img.shields.io/github/stars/ManiadisG/DivClust?style=flat)](https://github.com/ManiadisG/DivClust) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Metaxas_DivClust_Controlling_Diversity_in_Deep_Clustering_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01042-b31b1b.svg)](http://arxiv.org/abs/2304.01042) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UHruFy7X4RU) |
| On Data Scaling in Masked Image Modeling | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_On_Data_Scaling_in_Masked_Image_Modeling_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.04664-b31b1b.svg)](http://arxiv.org/abs/2206.04664) | :heavy_minus_sign: |
| Revealing the Dark Secrets of Masked Image Modeling | [![GitHub](https://img.shields.io/github/stars/SwinTransformer/MIM-Depth-Estimation?style=flat)](https://github.com/SwinTransformer/MIM-Depth-Estimation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Revealing_the_Dark_Secrets_of_Masked_Image_Modeling_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2205.13543-b31b1b.svg)](http://arxiv.org/abs/2205.13543) | :heavy_minus_sign: |
| Open-Set Representation Learning through Combinatorial Embedding | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Open-Set_Representation_Learning_Through_Combinatorial_Embedding_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2106.15278-b31b1b.svg)](http://arxiv.org/abs/2106.15278) | :heavy_minus_sign: |
| Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning | [![GitHub](https://img.shields.io/github/stars/sungnyun/openssl-simcore?style=flat)](https://github.com/sungnyun/openssl-simcore) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Coreset_Sampling_From_Open-Set_for_Fine-Grained_Self-Supervised_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11101-b31b1b.svg)](http://arxiv.org/abs/2303.11101) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f_-dIVRo8Q8) |
| ToThePoint: Efficient Contrastive Learning of 3D Point Clouds via Recycling | [![GitHub](https://img.shields.io/github/stars/Lyccl/Tothepoint?style=flat)](https://github.com/Lyccl/Tothepoint) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_ToThePoint_Efficient_Contrastive_Learning_of_3D_Point_Clouds_via_Recycling_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| MetaViewer: Towards a Unified Multi-View Representation | [![GitHub](https://img.shields.io/github/stars/xxLifeLover/MetaViewer?style=flat)](https://github.com/xxLifeLover/MetaViewer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_MetaViewer_Towards_a_Unified_Multi-View_Representation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06329-b31b1b.svg)](http://arxiv.org/abs/2303.06329) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RbFTH8G-w1U) |
| Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture | [![GitHub](https://img.shields.io/github/stars/facebookresearch/ijepa?style=flat)](https://github.com/facebookresearch/ijepa) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.08243-b31b1b.svg)](http://arxiv.org/abs/2301.08243) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gPlXDlFn0U4) |
| Understanding Masked Image Modeling via Learning Occlusion Invariant Feature <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Understanding_Masked_Image_Modeling_via_Learning_Occlusion_Invariant_Feature_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.04164-b31b1b.svg)](http://arxiv.org/abs/2208.04164) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rqyhxBz_xYg) |
| CHMATCH: Contrastive Hierarchical Matching and Robust Adaptive Threshold Boosted Semi-Supervised Learning | [![GitHub](https://img.shields.io/github/stars/sailist/CHMatch?style=flat)](https://github.com/sailist/CHMatch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_CHMATCH_Contrastive_Hierarchical_Matching_and_Robust_Adaptive_Threshold_Boosted_Semi-Supervised_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AMyJCI0PIdo) |
| Regularize Implicit Neural Representation by Itself <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | [![GitHub](https://img.shields.io/github/stars/YannickStruempler/inr_based_compression?style=flat)](https://github.com/YannickStruempler/inr_based_compression) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Regularize_Implicit_Neural_Representation_by_Itself_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15484-b31b1b.svg)](http://arxiv.org/abs/2303.15484) | :heavy_minus_sign: |
