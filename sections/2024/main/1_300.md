# CVPR-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/CVPR-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/README.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers/blob/main/sections/2024/main/301_600.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 1-300 papers

![Section Papers](https://img.shields.io/badge/Section%20Papers-250-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-204-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-165-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-83-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Open-Vocabulary Video Anomaly Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2311.07042-b31b1b.svg)](http://arxiv.org/abs/2311.07042) | :heavy_minus_sign: |
| Any-Shift Prompting for Generalization over Distributions | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.10099-b31b1b.svg)](http://arxiv.org/abs/2402.10099) | :heavy_minus_sign: |
| BlockGCN: Redefine Topology Awareness for Skeleton-based Action Recognition | [![GitHub](https://img.shields.io/github/stars/ZhouYuxuanYX/BlockGCN?style=flat)](https://github.com/ZhouYuxuanYX/BlockGCN) | :heavy_minus_sign: | :heavy_minus_sign: |
| Fine-grained Prototypical Voting with Heterogeneous Mixup for Semi-Supervised 2D-3D Cross-Modal Retrieval | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| OneLLM: One Framework to Align All Modalities with Language | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://onellm.csuhan.com/) <br /> [![GitHub](https://img.shields.io/github/stars/csuhan/OneLLM?style=flat)](https://github.com/csuhan/OneLLM) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-model-FFD21F.svg)](https://huggingface.co/csuhan/OneLLM-7B) | [![arXiv](https://img.shields.io/badge/arXiv-2312.03700-b31b1b.svg)](http://arxiv.org/abs/2312.03700) | :heavy_minus_sign: |
| SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yihua7.github.io/SC-GS-web/) <br /> [![GitHub](https://img.shields.io/github/stars/yihua7/SC-GS?style=flat)](https://github.com/yihua7/SC-GS) | [![arXiv](https://img.shields.io/badge/arXiv-2312.14937-b31b1b.svg)](http://arxiv.org/abs/2312.14937) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CYQYX_0xi5E) |
| Attentive Illumination Decomposition Model for Multi-Illuminant White Balancing | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.dykim.me/projects/aid) | [![arXiv](https://img.shields.io/badge/arXiv-2402.18277-b31b1b.svg)](http://arxiv.org/abs/2402.18277) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f2yNsVVS2h0) |
| Not All Prompts are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transfomers | [![GitHub](https://img.shields.io/github/stars/20000yshust/SWARM?style=flat)](https://github.com/20000yshust/SWARM) | :heavy_minus_sign: | :heavy_minus_sign: |
| Weakly Supervised Monocular 3D Detection with a Single-View Image | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.19144-b31b1b.svg)](http://arxiv.org/abs/2402.19144) | :heavy_minus_sign: |
| Coherent Temporal Synthesis for Incremental Action Segmentation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://guodongding.cn/projects/itas/itas.html) | [![arXiv](https://img.shields.io/badge/arXiv-2403.06102-b31b1b.svg)](http://arxiv.org/abs/2403.06102) | :heavy_minus_sign: |
| Autoregressive Queries for Adaptive Tracking with Spatio-Temporal Transformers | [![GitHub](https://img.shields.io/github/stars/GXNU-ZhongLab/AQATrack?style=flat)](https://github.com/GXNU-ZhongLab/AQATrack) | [![arXiv](https://img.shields.io/badge/arXiv-2403.10574-b31b1b.svg)](http://arxiv.org/abs/2403.10574) | :heavy_minus_sign: |
| Language Models as Black-Box Optimizers for Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://llm-can-optimize-vlm.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/shihongl1998/LLM-as-a-blackbox-optimizer?style=flat)](https://github.com/shihongl1998/LLM-as-a-blackbox-optimizer) | [![arXiv](https://img.shields.io/badge/arXiv-2309.05950-b31b1b.svg)](http://arxiv.org/abs/2309.05950) | :heavy_minus_sign: |
| Domain Prompt Learning with Quaternion Networks | [![GitHub](https://img.shields.io/github/stars/caoql98/DPLQ?style=flat)](https://github.com/caoql98/DPLQ) | [![arXiv](https://img.shields.io/badge/arXiv-2312.08878-b31b1b.svg)](http://arxiv.org/abs/2312.08878) | :heavy_minus_sign: |
| ZePT: Zero-Shot Pan-Tumor Segmentation via Query-Disentangling and Self-Prompting | [![GitHub](https://img.shields.io/github/stars/Yankai96/ZePT?style=flat)](https://github.com/Yankai96/ZePT) | [![arXiv](https://img.shields.io/badge/arXiv-2312.04964-b31b1b.svg)](http://arxiv.org/abs/2312.04964) | :heavy_minus_sign: |
| ODCR: Orthogonal Decoupling Contrastive Regularization for Unpaired Image Dehazing | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.17825-b31b1b.svg)](http://arxiv.org/abs/2404.17825) | :heavy_minus_sign: |
| Learning CNN on ViT: A Hybrid Model to Explicitly Class-Specific Boundaries for Domain Adaptation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dotrannhattuong.github.io/ECB/website/) <br /> [![GitHub](https://img.shields.io/github/stars/dotrannhattuong/ECB?style=flat)](https://github.com/dotrannhattuong/ECB) | [![arXiv](https://img.shields.io/badge/arXiv-2403.18360-b31b1b.svg)](http://arxiv.org/abs/2403.18360) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZYAhJLIkR_4) |
| MemoNav: Working Memory Model for Visual Navigation | [![GitHub](https://img.shields.io/github/stars/ZJULiHongxin/MemoNav?style=flat)](https://github.com/ZJULiHongxin/MemoNav) | [![arXiv](https://img.shields.io/badge/arXiv-2402.19161-b31b1b.svg)](http://arxiv.org/abs/2402.19161) | :heavy_minus_sign: |
| Inversion-Free Image Editing with Language-Guided Diffusion Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| RoHM: Robust Human Motion Reconstruction via Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sanweiliti.github.io/ROHM/ROHM.html) <br /> [![GitHub](https://img.shields.io/github/stars/sanweiliti/RoHM?style=flat)](https://github.com/sanweiliti/RoHM) | [![arXiv](https://img.shields.io/badge/arXiv-2401.08570-b31b1b.svg)](http://arxiv.org/abs/2401.08570) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hX7yO2c1hEE) |
| SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://daveredrum.github.io/SceneTex/) <br /> [![GitHub](https://img.shields.io/github/stars/daveredrum/SceneTex?style=flat)](https://github.com/daveredrum/SceneTex) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17261-b31b1b.svg)](http://arxiv.org/abs/2311.17261) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-x8oMeLovDU) |
| MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs | [![GitHub](https://img.shields.io/github/stars/PurdueDigitalTwin/LaMPilot?style=flat)](https://github.com/PurdueDigitalTwin/LaMPilot) | [![arXiv](https://img.shields.io/badge/arXiv-2312.04372-b31b1b.svg)](http://arxiv.org/abs/2312.04372) | :heavy_minus_sign: |
| SuperPrimitive: Scene Reconstruction at a Primitive Level | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://makezur.github.io/SuperPrimitive/) <br /> [![GitHub](https://img.shields.io/github/stars/makezur/super_primitive?style=flat)](https://github.com/makezur/super_primitive) | [![arXiv](https://img.shields.io/badge/arXiv-2312.05889-b31b1b.svg)](http://arxiv.org/abs/2312.05889) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=hKYgAf6MoB8) |
| HOLD: Category-Agnostic 3D Reconstruction of Interacting Hands and Objects from Video | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zc-alexfan.github.io/hold) <br /> [![GitHub](https://img.shields.io/github/stars/zc-alexfan/hold?style=flat)](https://github.com/zc-alexfan/hold) | [![arXiv](https://img.shields.io/badge/arXiv-2311.18448-b31b1b.svg)](http://arxiv.org/abs/2311.18448) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xm6WSkr2sIs) |
| Robust Depth Enhancement via Polarization Prompt Fusion Tuning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lastbasket.github.io/PPFT/) <br /> [![GitHub](https://img.shields.io/github/stars/lastbasket/Polarization-Prompt-Fusion-Tuning?style=flat)](https://github.com/lastbasket/Polarization-Prompt-Fusion-Tuning) | [![arXiv](https://img.shields.io/badge/arXiv-2404.04318-b31b1b.svg)](http://arxiv.org/abs/2404.04318) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KlnD0C-VeKw) |
| MAP: MAsk-Pruning for Source-Free Model Intellectual Property Protection | [![GitHub](https://img.shields.io/github/stars/ispc-lab/MAP?style=flat)](https://github.com/ispc-lab/MAP) | [![arXiv](https://img.shields.io/badge/arXiv-2403.04149-b31b1b.svg)](http://arxiv.org/abs/2403.04149) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tBEms735eY8) |
| Entity-NeRF: Detecting and Removing Moving Entities in Urban Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://otonari726.github.io/entitynerf/) | [![arXiv](https://img.shields.io/badge/arXiv-2403.16141-b31b1b.svg)](http://arxiv.org/abs/2403.16141) | :heavy_minus_sign: |
| LeftRefill: Filling Right Canvas based on Left Reference through Generalized Text-to-Image Diffusion Model | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ewrfcas.github.io/LeftRefill/) <br /> [![GitHub](https://img.shields.io/github/stars/ewrfcas/LeftRefill?style=flat)](https://github.com/ewrfcas/LeftRefill) | [![arXiv](https://img.shields.io/badge/arXiv-2305.11577-b31b1b.svg)](http://arxiv.org/abs/2305.11577) | :heavy_minus_sign: |
| MVBench: A Comprehensive Multi-Modal Video Understanding Benchmark | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/OpenGVLab/Ask-Anything/tree/main/video_chat2) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17005-b31b1b.svg)](http://arxiv.org/abs/2311.17005) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OMXlbt7A2OU) |
| EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-Centric View of Procedural Activities in Real World | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://egoexolearn.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/OpenGVLab/EgoExoLearn?style=flat)](https://github.com/OpenGVLab/EgoExoLearn) | [![arXiv](https://img.shields.io/badge/arXiv-2403.16182-b31b1b.svg)](http://arxiv.org/abs/2403.16182) | :heavy_minus_sign: |
| Puff-Net: Efficient Style Transfer with Pure Content and Style Feature Fusion Network | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Object Recognition as Next Token Prediction | [![GitHub](https://img.shields.io/github/stars/kaiyuyue/nxtp?style=flat)](https://github.com/kaiyuyue/nxtp) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-model-FFD21F.svg)](https://huggingface.co/kaiyuyue/nxtp) | [![arXiv](https://img.shields.io/badge/arXiv-2312.02142-b31b1b.svg)](http://arxiv.org/abs/2312.02142) | :heavy_minus_sign: |
| Garment Recovery with Shape and Deformation Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://liren2515.github.io/page/prior/prior.html) <br /> [![GitHub](https://img.shields.io/github/stars/liren2515/GarmentRecovery?style=flat)](https://github.com/liren2515/GarmentRecovery) | [![arXiv](https://img.shields.io/badge/arXiv-2311.10356-b31b1b.svg)](http://arxiv.org/abs/2311.10356) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xoO029AyC7U) |
| OmniVid: A Generative Framework for Universal Video Understanding | [![GitHub](https://img.shields.io/github/stars/wangjk666/OmniVid?style=flat)](https://github.com/wangjk666/OmniVid) | [![arXiv](https://img.shields.io/badge/arXiv-2403.17935-b31b1b.svg)](http://arxiv.org/abs/2403.17935) | :heavy_minus_sign: |
| MotionEditor: Editing Video Motion via Content-Aware Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://francis-rings.github.io/MotionEditor/) <br /> [![GitHub](https://img.shields.io/github/stars/Francis-Rings/MotionEditor?style=flat)](https://github.com/Francis-Rings/MotionEditor) | [![arXiv](https://img.shields.io/badge/arXiv-2311.18830-b31b1b.svg)](http://arxiv.org/abs/2311.18830) | :heavy_minus_sign: |
| Doubly Abductive Counterfactual Inference for Text-based Image Editing | [![GitHub](https://img.shields.io/github/stars/xuesong39/DAC?style=flat)](https://github.com/xuesong39/DAC) | [![arXiv](https://img.shields.io/badge/arXiv-2403.02981-b31b1b.svg)](http://arxiv.org/abs/2403.02981) | :heavy_minus_sign: |
| Learning to Rank Patches for Unbiased Image Redundancy Reduction | [![GitHub](https://img.shields.io/github/stars/irsLu/ltrp?style=flat)](https://github.com/irsLu/ltrp) | [![arXiv](https://img.shields.io/badge/arXiv-2404.00680-b31b1b.svg)](http://arxiv.org/abs/2404.00680) | :heavy_minus_sign: |
| SimDA: Simple Diffusion Adapter for Efficient Video Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chenhsing.github.io/SimDA/) <br /> [![GitHub](https://img.shields.io/github/stars/ChenHsing/SimDA?style=flat)](https://github.com/ChenHsing/SimDA) | [![arXiv](https://img.shields.io/badge/arXiv-2308.09710-b31b1b.svg)](http://arxiv.org/abs/2308.09710) | :heavy_minus_sign: |
| Misalignment-Robust Frequency Distribution Loss for Image Transformation | [![GitHub](https://img.shields.io/github/stars/eezkni/FDL?style=flat)](https://github.com/eezkni/FDL) | [![arXiv](https://img.shields.io/badge/arXiv-2402.18192-b31b1b.svg)](http://arxiv.org/abs/2402.18192) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=x31JcP0UoMI) |
| InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jiuntian.github.io/interactdiffusion/) <br /> [![GitHub](https://img.shields.io/github/stars/jiuntian/interactdiffusion?style=flat)](https://github.com/jiuntian/interactdiffusion) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-demo-FFD21F.svg)](https://huggingface.co/interactdiffusion/interactdiffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2312.05849-b31b1b.svg)](http://arxiv.org/abs/2312.05849) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Uunzufq8m6Y) |
| Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yusufma03.github.io/projects/hdp/) <br /> [![GitHub](https://img.shields.io/github/stars/dyson-ai/hdp?style=flat)](https://github.com/dyson-ai/hdp) | [![arXiv](https://img.shields.io/badge/arXiv-2403.03890-b31b1b.svg)](http://arxiv.org/abs/2403.03890) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f6vmzd3AKwY) |
| Multi-Scale Video Anomaly Detection by Multi-Grained Spatio-Temporal Representation Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Consistent Prompting for Rehearsal-Free Continual Learning | [![GitHub](https://img.shields.io/github/stars/Zhanxin-Gao/CPrompt?style=flat)](https://github.com/Zhanxin-Gao/CPrompt) | [![arXiv](https://img.shields.io/badge/arXiv-2403.08568-b31b1b.svg)](http://arxiv.org/abs/2403.08568) | :heavy_minus_sign: |
| TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models | [![GitHub](https://img.shields.io/github/stars/ModelTC/TFMQ-DM?style=flat)](https://github.com/ModelTC/TFMQ-DM) | [![arXiv](https://img.shields.io/badge/arXiv-2311.16503-b31b1b.svg)](http://arxiv.org/abs/2311.16503) | :heavy_minus_sign: |
| PeLK: Parameter-efficient Large Kernel ConvNets with Peripheral Convolution | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.07589-b31b1b.svg)](http://arxiv.org/abs/2403.07589) | :heavy_minus_sign: |
| Towards Better Vision-Inspired Vision-Language Models | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=d91e0EwAIZc) |
| An Upload-Efficient Scheme for Transferring Knowledge from a Server-Side Pre-trained Generator to Clients in Heterogeneous Federated Learning | [![GitHub](https://img.shields.io/github/stars/TsingZ0/FedKTL?style=flat)](https://github.com/TsingZ0/FedKTL) | [![arXiv](https://img.shields.io/badge/arXiv-2403.15760-b31b1b.svg)](http://arxiv.org/abs/2403.15760) | :heavy_minus_sign: |
| Bidirectional Autoregessive Diffusion Model for Dance Generation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SEAS: ShapE-Aligned Supervision for Person Re-Identification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| XScale-NVS: Cross-Scale Novel View Synthesis with Hash Featurized Manifold | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xscalenvs.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/THU-luvision/XScale-NVS?style=flat)](https://github.com/THU-luvision/XScale-NVS) | [![arXiv](https://img.shields.io/badge/arXiv-2403.19517-b31b1b.svg)](http://arxiv.org/abs/2403.19517) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=x06QnYyIiGQ) |
| Objects as Volumes: A Stochastic Geometry View of Opaque Solids | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://imaging.cs.cmu.edu/volumetric_opaque_solids/) <br /> [![GitHub](https://img.shields.io/github/stars/cmu-ci-lab/volumetric_opaque_solids?style=flat)](https://github.com/cmu-ci-lab/volumetric_opaque_solids) | [![arXiv](https://img.shields.io/badge/arXiv-2312.15406-b31b1b.svg)](http://arxiv.org/abs/2312.15406) | :heavy_minus_sign: |
| Neural Refinement for Absolute Pose Regression with Feature Synthesis | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://nefes.active.vision/) <br /> [![GitHub](https://img.shields.io/github/stars/ActiveVisionLab/NeFeS?style=flat)](https://github.com/ActiveVisionLab/NeFeS) | [![arXiv](https://img.shields.io/badge/arXiv-2303.10087-b31b1b.svg)](http://arxiv.org/abs/2303.10087) | :heavy_minus_sign: |
| TextNeRF: A Novel Scene-Text Image Synthesis Method based on Neural Radiance Fields | [![GitHub](https://img.shields.io/github/stars/cuijl-ai/TextNeRF?style=flat)](https://github.com/cuijl-ai/TextNeRF) | :heavy_minus_sign: | :heavy_minus_sign: |
| EpiDiff: Enhancing Multi-View Synthesis via Localized Epipolar-Constrained Diffusion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://huanngzh.github.io/EpiDiff/) <br /> [![GitHub](https://img.shields.io/github/stars/huanngzh/EpiDiff?style=flat)](https://github.com/huanngzh/EpiDiff) | [![arXiv](https://img.shields.io/badge/arXiv-2312.06725-b31b1b.svg)](http://arxiv.org/abs/2312.06725) | :heavy_minus_sign: |
| No more Ambiguity in 360Â° Room Layout via Bi-Layout Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://liagm.github.io/Bi_Layout/) | [![arXiv](https://img.shields.io/badge/arXiv-2404.09993-b31b1b.svg)](http://arxiv.org/abs/2404.09993) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pgR-IgOcNgg) |
| A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization Inversion for Zero-Shot Video Editing | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://stem-inv.github.io/page/) <br /> [![GitHub](https://img.shields.io/github/stars/STEM-Inv/stem-inv?style=flat)](https://github.com/STEM-Inv/stem-inv) | [![arXiv](https://img.shields.io/badge/arXiv-2312.05856-b31b1b.svg)](http://arxiv.org/abs/2312.05856) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FZnDn4wBPqY) |
| Pixel-Level Semantic Correspondence through Layout-Aware Representation Learning and Multi-Scale Matching Integration | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://freedomgu.github.io/DiffPortrait3D/) <br /> [![GitHub](https://img.shields.io/github/stars/FreedomGu/DiffPortrait3D?style=flat)](https://github.com/FreedomGu/DiffPortrait3D) | [![arXiv](https://img.shields.io/badge/arXiv-2312.13016-b31b1b.svg)](http://arxiv.org/abs/2312.13016) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mI8RJ_f3Csw) |
| Learning Group Activity Features through Person Attribute Prediction | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.toyota-ti.ac.jp/Lab/Denshi/iim/ukita/selection/CVPR2024-GAFL.html) <br /> [![GitHub](https://img.shields.io/github/stars/chihina/GAFL-CVPR2024?style=flat)](https://github.com/chihina/GAFL-CVPR2024) | [![arXiv](https://img.shields.io/badge/arXiv-2403.02753-b31b1b.svg)](http://arxiv.org/abs/2403.02753) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Jnnhvsrij74) |
| Real-World Efficient Blind Motion Deblurring via Blur Pixel Discretization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.12168-b31b1b.svg)](http://arxiv.org/abs/2404.12168) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GB-88qsaYtg) |
| Egocentric Full Body Motion Capture with FisheyeViT and Diffusion-based Motion Refinement | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Revamping Federated Learning Security from a Defender's Perspective: A Unified Defense with Homomorphic Encrypted Data Space | [![GitHub](https://img.shields.io/github/stars/NaveenKumar-1311/FCD?style=flat)](https://github.com/NaveenKumar-1311/FCD) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Nh2Dx6npc-s) |
| Learning Transferable Negative Prompts for Out-of-Distribution Detection | [![GitHub](https://img.shields.io/github/stars/mala-lab/negprompt?style=flat)](https://github.com/mala-lab/negprompt) | [![arXiv](https://img.shields.io/badge/arXiv-2404.03248-b31b1b.svg)](http://arxiv.org/abs/2404.03248) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KlFPgxtYieA) |
| Training-Free Pretrained Model Merging | [![GitHub](https://img.shields.io/github/stars/zju-vipa/training_free_model_merging?style=flat)](https://github.com/zju-vipa/training_free_model_merging) | [![arXiv](https://img.shields.io/badge/arXiv-2403.01753-b31b1b.svg)](http://arxiv.org/abs/2403.01753) | :heavy_minus_sign: |
| How Far Can We Compress Instant NGP-based NeRF? | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://customnerf.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/hrz2000/CustomNeRF?style=flat)](https://github.com/hrz2000/CustomNeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2312.01663-b31b1b.svg)](http://arxiv.org/abs/2312.01663) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=B8dW4Jpwerg) |
| Class Incremental Learning with Multi-Teacher Distillation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unsupervised Semantic Segmentation through Depth-Guided Feature Correlation and Sampling | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.12378-b31b1b.svg)](http://arxiv.org/abs/2309.12378) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-MlyVq8t51M) |
| CLIP-Driven Open-Vocabulary 3D Scene Graph Generation via Cross-Modality Contrastive Learning | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=BsCxM0-lB3A) |
| Self-Distilled Masked Auto-Encoders are Efficient Video Anomaly Detectors | [![GitHub](https://img.shields.io/github/stars/ristea/aed-mae?style=flat)](https://github.com/ristea/aed-mae) | [![arXiv](https://img.shields.io/badge/arXiv-2306.12041-b31b1b.svg)](http://arxiv.org/abs/2306.12041) | :heavy_minus_sign: |
| Animatable Gaussians: Learning Pose-Dependent Gaussian Maps for High-Fidelity Human Avatar Modeling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://animatable-gaussians.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/lizhe00/AnimatableGaussians?style=flat)](https://github.com/lizhe00/AnimatableGaussians) | [![arXiv](https://img.shields.io/badge/arXiv-2311.16096-b31b1b.svg)](http://arxiv.org/abs/2311.16096) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kOmZxD0HxZI) |
| Gaussian Head Avatar: Ultra High-Fidelity Head Avatar via Dynamic Gaussians | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yuelangx.github.io/gaussianheadavatar/) <br /> [![GitHub](https://img.shields.io/github/stars/YuelangX/Gaussian-Head-Avatar?style=flat)](https://github.com/YuelangX/Gaussian-Head-Avatar) | [![arXiv](https://img.shields.io/badge/arXiv-2312.03029-b31b1b.svg)](http://arxiv.org/abs/2312.03029) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kvrrI3EoM5g) |
| LORS: Low-Rank Residual Structure for Parameter-Efficient Network Stacking | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.04303-b31b1b.svg)](http://arxiv.org/abs/2403.04303) | :heavy_minus_sign: |
| A Closer Look at the Few-Shot Adaptation of Large Vision-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jusiro.github.io/projects/clap) <br /> [![GitHub](https://img.shields.io/github/stars/jusiro/CLAP?style=flat)](https://github.com/jusiro/CLAP) | [![arXiv](https://img.shields.io/badge/arXiv-2312.12730-b31b1b.svg)](http://arxiv.org/abs/2312.12730) | :heavy_minus_sign: |
| FedMef: Towards Memory-Efficient Federated Dynamic Pruning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.14737-b31b1b.svg)](http://arxiv.org/abs/2403.14737) | :heavy_minus_sign: |
| 3D Human Pose Perception from Egocentric Stereo Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://4dqv.mpi-inf.mpg.de/UnrealEgo2/) <br /> [![GitHub](https://img.shields.io/github/stars/hiroyasuakada/3D-Human-Pose-Perception-from-Egocentric-Stereo-Videos?style=flat)](https://github.com/hiroyasuakada/3D-Human-Pose-Perception-from-Egocentric-Stereo-Videos) | [![arXiv](https://img.shields.io/badge/arXiv-2401.00889-b31b1b.svg)](http://arxiv.org/abs/2401.00889) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iU6bjFoyfRY) |
| EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://4dqv.mpi-inf.mpg.de/EventEgo3D/) <br /> [![GitHub](https://img.shields.io/github/stars/Chris10M/EventEgo3D?style=flat)](https://github.com/Chris10M/EventEgo3D) | [![arXiv](https://img.shields.io/badge/arXiv-2404.08640-b31b1b.svg)](http://arxiv.org/abs/2404.08640) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V9bmGXz6OfI) |
| Federated Online Adaptation for Deep Stereo | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fedstereo.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/mattpoggi/fedstereo?style=flat)](https://github.com/mattpoggi/fedstereo) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gVpWsjrUTJc) |
| Super-Resolution Reconstruction from Bayer-Pattern Spike Streams | [![GitHub](https://img.shields.io/github/stars/csycdong/CSCSR?style=flat)](https://github.com/csycdong/CSCSR) | :heavy_minus_sign: | :heavy_minus_sign: |
| A Vision Check-Up for Language Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://vision-checkup.csail.mit.edu/) | [![arXiv](https://img.shields.io/badge/arXiv-2401.01862-b31b1b.svg)](http://arxiv.org/abs/2401.01862) | :heavy_minus_sign: |
| SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder for Self-Supervised Landmark Estimation | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fd6Z4mRNJS4) |
| RealNet: A Feature Selection Network with Realistic Synthetic Anomaly for Anomaly Detection | [![GitHub](https://img.shields.io/github/stars/cnulab/RealNet?style=flat)](https://github.com/cnulab/RealNet) | [![arXiv](https://img.shields.io/badge/arXiv-2403.05897-b31b1b.svg)](http://arxiv.org/abs/2403.05897) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FClO0GsqKxY) |
| Using Human Feedback to Fine-Tune Diffusion Models without any Reward Model | [![GitHub](https://img.shields.io/github/stars/yk7333/d3po?style=flat)](https://github.com/yk7333/d3po) | [![arXiv](https://img.shields.io/badge/arXiv-2311.13231-b31b1b.svg)](http://arxiv.org/abs/2311.13231) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Lprx2wKgiQ0) |
| OA-CNNs: Omni-Adaptive Sparse CNNs for 3D Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/Pointcept/Pointcept?style=flat)](https://github.com/Pointcept/Pointcept) | [![arXiv](https://img.shields.io/badge/arXiv-2403.14418-b31b1b.svg)](http://arxiv.org/abs/2403.14418) | :heavy_minus_sign: |
| Lookahead Exploration with Neural Radiance Representation for Continuous Vision-Language Navigation | [![GitHub](https://img.shields.io/github/stars/MrZihan/HNR-VLN?style=flat)](https://github.com/MrZihan/HNR-VLN) | [![arXiv](https://img.shields.io/badge/arXiv-2404.01943-b31b1b.svg)](http://arxiv.org/abs/2404.01943) | :heavy_minus_sign: |
| Robust Synthetic-to-Real Transfer for Stereo Matching | [![GitHub](https://img.shields.io/github/stars/jiaw-z/DKT-Stereo?style=flat)](https://github.com/jiaw-z/DKT-Stereo) | [![arXiv](https://img.shields.io/badge/arXiv-2403.07705-b31b1b.svg)](http://arxiv.org/abs/2403.07705) | :heavy_minus_sign: |
| UniMODE: Unified Monocular 3D Object Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.18573-b31b1b.svg)](http://arxiv.org/abs/2402.18573) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=q85uiEDj5gE) |
| A Dynamic Kernel Prior Model for Unsupervised Blind Image Super-Resolution | [![GitHub](https://img.shields.io/github/stars/XYLGroup/DKP?style=flat)](https://github.com/XYLGroup/DKP) | [![arXiv](https://img.shields.io/badge/arXiv-2404.15620-b31b1b.svg)](http://arxiv.org/abs/2404.15620) | :heavy_minus_sign: |
| Audio-Visual Segmentation via Unlabeled Frame Exploitation | [![GitHub](https://img.shields.io/github/stars/jinxiang-liu/UFE-AVS?style=flat)](https://github.com/jinxiang-liu/UFE-AVS) | [![arXiv](https://img.shields.io/badge/arXiv-2403.11074-b31b1b.svg)](http://arxiv.org/abs/2403.11074) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=j28vpsKaUuY) |
| EFHQ: Multi-Purpose ExtremePose-Face-HQ Dataset | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://bomcon123456.github.io/efhq/) | [![arXiv](https://img.shields.io/badge/arXiv-2312.17205-b31b1b.svg)](http://arxiv.org/abs/2312.17205) | :heavy_minus_sign: |
| Editable Scene Simulation for Autonomous Driving via LLM-Agent Collaboration | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yifanlu0227.github.io/ChatSim/) <br /> [![GitHub](https://img.shields.io/github/stars/yifanlu0227/ChatSim?style=flat)](https://github.com/yifanlu0227/ChatSim) | [![arXiv](https://img.shields.io/badge/arXiv-2402.05746-b31b1b.svg)](http://arxiv.org/abs/2402.05746) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5xWz5YBsE5M) |
| Learning to Localize Objects Improves Spatial Reasoning in Visual-LLMs | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.07449-b31b1b.svg)](http://arxiv.org/abs/2404.07449) | :heavy_minus_sign: |
| Enhancing Quality of Compressed Images by Mitigating Enhancement Bias Towards Compression Domain | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.17200-b31b1b.svg)](http://arxiv.org/abs/2402.17200) | :heavy_minus_sign: |
| Precise Image Editing via Recognition and Generation Tasks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2311.10089-b31b1b.svg)](http://arxiv.org/abs/2311.10089) | :heavy_minus_sign: |
| Spin-UP: Spin Light for Natural Light Uncalibrated Photometric Stereo | [![GitHub](https://img.shields.io/github/stars/LMozart/CVPR2024-SpinUP?style=flat)](https://github.com/LMozart/CVPR2024-SpinUP) | [![arXiv](https://img.shields.io/badge/arXiv-2404.01612-b31b1b.svg)](http://arxiv.org/abs/2404.01612) | :heavy_minus_sign: |
| Leak and Learn: An Attacker's Cookbook to Train using Leaked Data from Federated Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.18144-b31b1b.svg)](http://arxiv.org/abs/2403.18144) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ovmSnjSOcks) |
| EAGLE: Eigen Aggregation Learning for Object-Centric Unsupervised Semantic Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://micv-yonsei.github.io/eagle2024/) <br /> [![GitHub](https://img.shields.io/github/stars/MICV-yonsei/EAGLE?style=flat)](https://github.com/MICV-yonsei/EAGLE) | [![arXiv](https://img.shields.io/badge/arXiv-2403.01482-b31b1b.svg)](http://arxiv.org/abs/2403.01482) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0a799IDW4e0) |
| A Physics-Informed Low-Rank Deep Neural Network for Blind and Universal Lens Aberration Correction | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nDVteyCT2Yw) |
| The Devil is in the Fine-Grained Details: Evaluating Open-Vocabulary Object Detectors for Fine-Grained Understanding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lorebianchi98.github.io/FG-OVD/) <br /> [![GitHub](https://img.shields.io/github/stars/lorebianchi98/FG-OVD?style=flat)](https://github.com/lorebianchi98/FG-OVD) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17518-b31b1b.svg)](http://arxiv.org/abs/2311.17518) | :heavy_minus_sign: |
| VRP-SAM: SAM with Visual Reference Prompt | [![GitHub](https://img.shields.io/github/stars/syp2ysy/VRP-SAM?style=flat)](https://github.com/syp2ysy/VRP-SAM) | [![arXiv](https://img.shields.io/badge/arXiv-2402.17726-b31b1b.svg)](http://arxiv.org/abs/2402.17726) | :heavy_minus_sign: |
| Vanishing-Point-Guided Video Semantic Segmentation of Driving Scenes | [![GitHub](https://img.shields.io/github/stars/RascalGdd/VPSeg?style=flat)](https://github.com/RascalGdd/VPSeg) | [![arXiv](https://img.shields.io/badge/arXiv-2401.15261-b31b1b.svg)](http://arxiv.org/abs/2401.15261) | :heavy_minus_sign: |
| Data Poisoning based Backdoor Attacks to Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/jzhang538/CorruptEncoder?style=flat)](https://github.com/jzhang538/CorruptEncoder) | [![arXiv](https://img.shields.io/badge/arXiv-2211.08229-b31b1b.svg)](http://arxiv.org/abs/2211.08229) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zr-F3LYq9b8) |
| A2XP: Towards Private Domain Generalization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://airlabkhu.github.io/A2XP/) <br /> [![GitHub](https://img.shields.io/github/stars/AIRLABkhu/A2XP?style=flat)](https://github.com/AIRLABkhu/A2XP) | [![arXiv](https://img.shields.io/badge/arXiv-2311.10339-b31b1b.svg)](http://arxiv.org/abs/2311.10339) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RLb8EdYWaDk) |
| ParameterNet: Parameters are All You Need for Large-Scale Visual Pretraining of Mobile Networks | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://parameternet.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/huawei-noah/Efficient-AI-Backbones?style=flat)](https://github.com/huawei-noah/Efficient-AI-Backbones) | [![arXiv](https://img.shields.io/badge/arXiv-2306.14525-b31b1b.svg)](http://arxiv.org/abs/2306.14525) | :heavy_minus_sign: |
| An Empirical Study of Scaling Law for Scene Text Recognition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://large-ocr-model.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/large-ocr-model/large-ocr-model.github.io?style=flat)](https://github.com/large-ocr-model/large-ocr-model.github.io) | [![arXiv](https://img.shields.io/badge/arXiv-2401.00028-b31b1b.svg)](http://arxiv.org/abs/2401.00028) | :heavy_minus_sign: |
| FMA-Net: Flow Guided Dynamic Filtering and Iterative Feature Refinement with Multi-Attention for Joint Video Super-Resolution and Deblurring | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kaist-viclab.github.io/fmanet-site/) <br /> [![GitHub](https://img.shields.io/github/stars/KAIST-VICLab/FMA-Net?style=flat)](https://github.com/KAIST-VICLab/FMA-Net) | [![arXiv](https://img.shields.io/badge/arXiv-2401.03707-b31b1b.svg)](http://arxiv.org/abs/2401.03707) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G6qqJXztJDM) |
| Deep Imbalanced Regression via Hierarchical Classification Adjustment | [![GitHub](https://img.shields.io/github/stars/xhp-hust-2018-2011/HCA?style=flat)](https://github.com/xhp-hust-2018-2011/HCA) | [![arXiv](https://img.shields.io/badge/arXiv-2310.17154-b31b1b.svg)](http://arxiv.org/abs/2310.17154) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oOs9RGdEA1g) |
| Don't Look into the Dark: Latent Codes for Pluralistic Image Inpainting | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.18186-b31b1b.svg)](http://arxiv.org/abs/2403.18186) | :heavy_minus_sign: |
| FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ericslyman.com/fairdedup/) | [![arXiv](https://img.shields.io/badge/arXiv-2404.16123-b31b1b.svg)](http://arxiv.org/abs/2404.16123) | :heavy_minus_sign: |
| Modular Blind Video Quality Assessment | [![GitHub](https://img.shields.io/github/stars/winwinwenwen77/ModularBVQA?style=flat)](https://github.com/winwinwenwen77/ModularBVQA) | [![arXiv](https://img.shields.io/badge/arXiv-2402.19276-b31b1b.svg)](http://arxiv.org/abs/2402.19276) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MaMn24Do62I) |
| GlitchBench: Can Large Multimodal Models Detect Video Game Glitches? | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| LAA-Net: Localized Artifact Attention Network for Quality-Agnostic and Generalizable Deepfake Detection | [![GitHub](https://img.shields.io/github/stars/10Ring/LAA-Net?style=flat)](https://github.com/10Ring/LAA-Net) | [![arXiv](https://img.shields.io/badge/arXiv-2401.13856-b31b1b.svg)](http://arxiv.org/abs/2401.13856) | :heavy_minus_sign: |
| DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ivl.cs.brown.edu/research/diva) <br /> [![GitHub](https://img.shields.io/github/stars/brown-ivl/DiVa360?style=flat)](https://github.com/brown-ivl/DiVa360) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16897-b31b1b.svg)](http://arxiv.org/abs/2307.16897) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=eWDvmBQP7Uk) |
| DreamControl: Control-based Text-to-3D Generation with 3D Self-Prior | [![GitHub](https://img.shields.io/github/stars/tyhuang0428/DreamControl?style=flat)](https://github.com/tyhuang0428/DreamControl) | [![arXiv](https://img.shields.io/badge/arXiv-2312.06439-b31b1b.svg)](http://arxiv.org/abs/2312.06439) | :heavy_minus_sign: |
| Open-Vocabulary Object 6D Pose Estimation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://jcorsetti.github.io/oryon/) <br /> [![GitHub](https://img.shields.io/github/stars/jcorsetti/oryon?style=flat)](https://github.com/jcorsetti/oryon) | [![arXiv](https://img.shields.io/badge/arXiv-2312.00690-b31b1b.svg)](http://arxiv.org/abs/2312.00690) | :heavy_minus_sign: |
| GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://buaacyw.github.io/gaussian-editor/) <br /> [![GitHub](https://img.shields.io/github/stars/buaacyw/GaussianEditor?style=flat)](https://github.com/buaacyw/GaussianEditor) | [![arXiv](https://img.shields.io/badge/arXiv-2311.14521-b31b1b.svg)](http://arxiv.org/abs/2311.14521) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TdZIICSFqsU) |
| Motion2VecSets: 4D Latent Vector Set Diffusion for Non-Rigid Shape Reconstruction and Tracking | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vveicao.github.io/projects/Motion2VecSets/) <br /> [![GitHub](https://img.shields.io/github/stars/VVeiCao/Motion2VecSets?style=flat)](https://github.com/VVeiCao/Motion2VecSets) | [![arXiv](https://img.shields.io/badge/arXiv-2401.06614-b31b1b.svg)](http://arxiv.org/abs/2401.06614) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VXI3y2o0SqY) |
| From Activation to Initialization: Scaling Insights for Optimizing Neural Fields | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.19205-b31b1b.svg)](http://arxiv.org/abs/2403.19205) | :heavy_minus_sign: |
| MoST: Multi-Modality Scene Tokenization for Motion Prediction | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.19531-b31b1b.svg)](http://arxiv.org/abs/2404.19531) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Z-aiXiJvzhE) |
| RankED: Addressing Imbalance and Uncertainty in Edge Detection using Ranking-based Losses | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ranked-cvpr24.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Bedrettin-Cetinkaya/RankED?style=flat)](https://github.com/Bedrettin-Cetinkaya/RankED) | [![arXiv](https://img.shields.io/badge/arXiv-2403.01795-b31b1b.svg)](http://arxiv.org/abs/2403.01795) | :heavy_minus_sign: |
| Efficient Model Stealing Defense with Noise Transition Matrix | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=M7jjktRk8Go) |
| Streaming Dense Video Captioning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/google-research/scenic/tree/main/scenic/projects/streaming_dvc) <br /> [![GitHub](https://img.shields.io/github/stars/google-research/scenic?style=flat)](https://github.com/google-research/scenic) | [![arXiv](https://img.shields.io/badge/arXiv-2404.01297-b31b1b.svg)](http://arxiv.org/abs/2404.01297) | :heavy_minus_sign: |
| End-to-End Spatio-Temporal Action Localisation with Video Transformers | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.12160-b31b1b.svg)](http://arxiv.org/abs/2304.12160) | :heavy_minus_sign: |
| Modeling Dense Multimodal Interactions between Biological Pathways and Histology for Survival Prediction | [![GitHub](https://img.shields.io/github/stars/mahmoodlab/SurvPath?style=flat)](https://github.com/mahmoodlab/SurvPath) | [![arXiv](https://img.shields.io/badge/arXiv-2304.06819-b31b1b.svg)](http://arxiv.org/abs/2304.06819) | :heavy_minus_sign: |
| Morphological Prototyping for Unsupervised Slide Representation Learning in Computational Pathology | [![GitHub](https://img.shields.io/github/stars/mahmoodlab/PANTHER?style=flat)](https://github.com/mahmoodlab/PANTHER) | [![arXiv](https://img.shields.io/badge/arXiv-2405.11643-b31b1b.svg)](http://arxiv.org/abs/2405.11643) | :heavy_minus_sign: |
| DL3DV-10K: A Large-Scale Scene Dataset for Deep Learning-based 3D Vision | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dl3dv-10k.github.io/DL3DV-10K/) | [![arXiv](https://img.shields.io/badge/arXiv-2312.16256-b31b1b.svg)](http://arxiv.org/abs/2312.16256) | :heavy_minus_sign: |
| ZONE: Zero-Shot Instruction-Guided Local Editing | [![GitHub](https://img.shields.io/github/stars/lsl001006/ZONE?style=flat)](https://github.com/lsl001006/ZONE) | [![arXiv](https://img.shields.io/badge/arXiv-2312.16794-b31b1b.svg)](http://arxiv.org/abs/2312.16794) | :heavy_minus_sign: |
| DriveWorld: 4D Pre-trained Scene Understanding via World Models for Autonomous Driving | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2405.04390-b31b1b.svg)](http://arxiv.org/abs/2405.04390) | :heavy_minus_sign: |
| Describing Differences in Image Sets with Natural Language | [![GitHub](https://img.shields.io/github/stars/Understanding-Visual-Datasets/VisDiff?style=flat)](https://github.com/Understanding-Visual-Datasets/VisDiff) | [![arXiv](https://img.shields.io/badge/arXiv-2312.02974-b31b1b.svg)](http://arxiv.org/abs/2312.02974) | :heavy_minus_sign: |
| Shadows Don't Lie and Lines Can't Bend! Generative Models don't know Projective Geometry ... for now | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://projective-geometry.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/hanlinm2/projective-geometry?style=flat)](https://github.com/hanlinm2/projective-geometry) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17138-b31b1b.svg)](http://arxiv.org/abs/2311.17138) | :heavy_minus_sign: |
| Perturbing Attention Gives You more Bang for the Buck: Subtle Imaging Perturbations that Efficiently Fool Customized Diffusion Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.15081-b31b1b.svg)](http://arxiv.org/abs/2404.15081) | :heavy_minus_sign: |
| BioCLIP: A Vision Foundation Model for the Tree of Life | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://imageomics.github.io/bioclip/) <br /> [![GitHub](https://img.shields.io/github/stars/Imageomics/BioCLIP?style=flat)](https://github.com/Imageomics/BioCLIP) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-model-FFD21F.svg)](https://huggingface.co/imageomics/bioclip) | [![arXiv](https://img.shields.io/badge/arXiv-2311.18803-b31b1b.svg)](http://arxiv.org/abs/2311.18803) | :heavy_minus_sign: |
| Dual-View Visual Contextualization for Web Navigation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.04476-b31b1b.svg)](http://arxiv.org/abs/2402.04476) | :heavy_minus_sign: |
| Learned Representation-guided Diffusion Models for Large-Image Generation | [![GitHub](https://img.shields.io/github/stars/cvlab-stonybrook/Large-Image-Diffusion?style=flat)](https://github.com/cvlab-stonybrook/Large-Image-Diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2312.07330-b31b1b.svg)](http://arxiv.org/abs/2312.07330) | :heavy_minus_sign: |
| Desigen: A Pipeline for Controllable Design Template Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://whaohan.github.io/desigen/) <br /> [![GitHub](https://img.shields.io/github/stars/whaohan/desigen?style=flat)](https://github.com/whaohan/desigen) | [![arXiv](https://img.shields.io/badge/arXiv-2403.09093-b31b1b.svg)](http://arxiv.org/abs/2403.09093) | :heavy_minus_sign: |
| From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/audio2photoreal?style=flat)](https://github.com/facebookresearch/audio2photoreal) | [![arXiv](https://img.shields.io/badge/arXiv-2401.01885-b31b1b.svg)](http://arxiv.org/abs/2401.01885) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y0GMaMtUynQ) |
| Multiview Aerial Visual RECognition (MAVREC) Dataset: Can Multi-view Improve Aerial Visual Perception? | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A Picture is Worth more than 77 Text Tokens: Evaluating CLIP-Style Models on Dense Captions | [![GitHub](https://img.shields.io/github/stars/facebookresearch/DCI?style=flat)](https://github.com/facebookresearch/DCI) | [![arXiv](https://img.shields.io/badge/arXiv-2312.08578-b31b1b.svg)](http://arxiv.org/abs/2312.08578) | :heavy_minus_sign: |
| Ego-Exo4D: Understanding Skilled Human Activity from First- and Third-Person Perspectives | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ego-exo4d-data.org/) | [![arXiv](https://img.shields.io/badge/arXiv-2311.18259-b31b1b.svg)](http://arxiv.org/abs/2311.18259) | :heavy_minus_sign: |
| Gaussian Shell Maps for Efficient 3D Human Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rameenabdal.github.io/GaussianShellMaps/) <br /> [![GitHub](https://img.shields.io/github/stars/computational-imaging/GSM?style=flat)](https://github.com/computational-imaging/GSM) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17857-b31b1b.svg)](http://arxiv.org/abs/2311.17857) | :heavy_minus_sign: |
| 4D-fy: Text-to-4D Generation using Hybrid Score Distillation Sampling | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sherwinbahmani.github.io/4dfy/) <br /> [![GitHub](https://img.shields.io/github/stars/sherwinbahmani/4dfy?style=flat)](https://github.com/sherwinbahmani/4dfy) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17984-b31b1b.svg)](http://arxiv.org/abs/2311.17984) | :heavy_minus_sign: |
| Improving Single Domain-Generalized Object Detection: A Focus on Diversification and Alignment | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2405.14497-b31b1b.svg)](http://arxiv.org/abs/2405.14497) | :heavy_minus_sign: |
| Looking Similar, Sounding Different: Leveraging Counterfactual Cross-Modal Pairs for Audiovisual Representation Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2304.05600-b31b1b.svg)](http://arxiv.org/abs/2304.05600) | :heavy_minus_sign: |
| MeshPose: Unifying DensePose and 3D Body Mesh Reconstruction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MULAN: A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mulan-dataset.github.io/) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-dataset-FFD21F.svg)](https://huggingface.co/datasets/mulan-dataset/v1.0) | [![arXiv](https://img.shields.io/badge/arXiv-2404.02790-b31b1b.svg)](http://arxiv.org/abs/2404.02790) | :heavy_minus_sign: |
| Taming Self-Training for Open-Vocabulary Object Detection | [![GitHub](https://img.shields.io/github/stars/xiaofeng94/SAS-Det?style=flat)](https://github.com/xiaofeng94/SAS-Det) | [![arXiv](https://img.shields.io/badge/arXiv-2308.06412-b31b1b.svg)](http://arxiv.org/abs/2308.06412) | :heavy_minus_sign: |
| Generating Enhanced Negatives for Training Language-based Object Detectors | [![GitHub](https://img.shields.io/github/stars/xiaofeng94/Gen-Enhanced-Negs?style=flat)](https://github.com/xiaofeng94/Gen-Enhanced-Negs) | [![arXiv](https://img.shields.io/badge/arXiv-2401.00094-b31b1b.svg)](http://arxiv.org/abs/2401.00094) | :heavy_minus_sign: |
| Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://facebookresearch.github.io/real-acoustic-fields/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/real-acoustic-fields?style=flat)](https://github.com/facebookresearch/real-acoustic-fields) | [![arXiv](https://img.shields.io/badge/arXiv-2403.18821-b31b1b.svg)](http://arxiv.org/abs/2403.18821) | :heavy_minus_sign: |
| Practical Measurements of Translucent Materials with Inter-Pixel Translucency Prior | [![GitHub](https://img.shields.io/github/stars/ZhenyuChen1999/IPTNet?style=flat)](https://github.com/ZhenyuChen1999/IPTNet) | :heavy_minus_sign: | :heavy_minus_sign: |
| Unsupervised Universal Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://u2seg.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/u2seg/U2Seg?style=flat)](https://github.com/u2seg/U2Seg) | [![arXiv](https://img.shields.io/badge/arXiv-2312.17243-b31b1b.svg)](http://arxiv.org/abs/2312.17243) | :heavy_minus_sign: |
| Gated Fields: Learning Scene Reconstruction from Gated Videos | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://light.princeton.edu/publication/gatedfields/) | [![arXiv](https://img.shields.io/badge/arXiv-2405.19819-b31b1b.svg)](http://arxiv.org/abs/2405.19819) | :heavy_minus_sign: |
| FADES: Fair Disentanglement with Sensitive Relevance | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MonoNPHM: Dynamic Head Reconstruction from Monocular Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://simongiebenhain.github.io/MonoNPHM/) <br /> [![GitHub](https://img.shields.io/github/stars/facebookresearch/real-acoustic-fields?style=flat)](https://github.com/facebookresearch/real-acoustic-fields) | [![arXiv](https://img.shields.io/badge/arXiv-2312.06740-b31b1b.svg)](http://arxiv.org/abs/2312.06740) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=n-wjaC3UIeE) |
| Codebook Transfer with Part-of-Speech for Vector-Quantized Image Modeling | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.10071-b31b1b.svg)](http://arxiv.org/abs/2403.10071) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=N6M0jcMP9lo) |
| TACO: Benchmarking Generalizable Bimanual Tool-ACtion-Object Understanding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://taco2024.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/leolyliu/TACO-Instructions?style=flat)](https://github.com/leolyliu/TACO-Instructions) | [![arXiv](https://img.shields.io/badge/arXiv-2401.08399-b31b1b.svg)](http://arxiv.org/abs/2401.08399) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bIgHylU1oZo) |
| Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation guided by the Characteristic Dance Primitives | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://li-ronghui.github.io/lodge) <br /> [![GitHub](https://img.shields.io/github/stars/li-ronghui/LODGE?style=flat)](https://github.com/li-ronghui/LODGE) | [![arXiv](https://img.shields.io/badge/arXiv-2403.10518-b31b1b.svg)](http://arxiv.org/abs/2403.10518) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2Sp7OrNrCiU) |
| ProxyCap: Real-Time Monocular Full-Body Capture in World Space via Human-Centric Proxy-to-Motion Learning | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zhangyux15.github.io/ProxyCapV2/) | [![arXiv](https://img.shields.io/badge/arXiv-2307.01200-b31b1b.svg)](http://arxiv.org/abs/2307.01200) | :heavy_minus_sign: |
| HumanNorm: Learning Normal Diffusion Model for High-Quality and Realistic 3D Human Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://humannorm.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/xhuangcv/humannorm?style=flat)](https://github.com/xhuangcv/humannorm) | [![arXiv](https://img.shields.io/badge/arXiv-2310.01406-b31b1b.svg)](http://arxiv.org/abs/2310.01406) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2y-0Kfj5-FI) |
| DeiT-LT: Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rangwani-harsh.github.io/DeiT-LT/) <br /> [![GitHub](https://img.shields.io/github/stars/val-iisc/DeiT-LT?style=flat)](https://github.com/val-iisc/DeiT-LT) | [![arXiv](https://img.shields.io/badge/arXiv-2404.02900-b31b1b.svg)](http://arxiv.org/abs/2404.02900) | :heavy_minus_sign: |
| Validating Privacy-Preserving Face Recognition under a Minimum Assumption | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Low-Power, Continuous Remote Behavioral Localization with Event Cameras | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://tub-rip.github.io/eventpenguins/) <br /> [![GitHub](https://img.shields.io/github/stars/tub-rip/event_penguins?style=flat)](https://github.com/tub-rip/event_penguins) | [![arXiv](https://img.shields.io/badge/arXiv-2312.03799-b31b1b.svg)](http://arxiv.org/abs/2312.03799) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=o79wbZh0gU4) |
| Multimodal Sense-Informed Prediction of 3D Human Motions | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sites.google.com/view/cvpr2024sif3d) <br /> [![GitHub](https://img.shields.io/github/stars/kjle6/SIF3D-master?style=flat)](https://github.com/kjle6/SIF3D-master) | [![arXiv](https://img.shields.io/badge/arXiv-2405.02911-b31b1b.svg)](http://arxiv.org/abs/2405.02911) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UkB0BhJcmLA) |
| MiKASA: Multi-Key-Anchor Scene-Aware Transformer for 3D Visual Grounding | [![GitHub](https://img.shields.io/github/stars/dfki-av/MiKASA-3DVG?style=flat)](https://github.com/dfki-av/MiKASA-3DVG) | [![arXiv](https://img.shields.io/badge/arXiv-2403.03077-b31b1b.svg)](http://arxiv.org/abs/2403.03077) | :heavy_minus_sign: |
| LIVE: Online Large Video-Language Model for Streaming Video | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MP5: A Multi-Modal Open-ended Embodied System in Minecraft via Active Perception | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://iranqin.github.io/MP5.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/IranQin/MP5?style=flat)](https://github.com/IranQin/MP5) | [![arXiv](https://img.shields.io/badge/arXiv-2312.07472-b31b1b.svg)](http://arxiv.org/abs/2312.07472) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AZeS3C_S_3M) |
| SportsSloMo: A New Benchmark and Baselines for Human-Centric Video Frame Interpolation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://neu-vi.github.io/SportsSlomo/) <br /> [![GitHub](https://img.shields.io/github/stars/neu-vi/SportsSloMo?style=flat)](https://github.com/neu-vi/SportsSloMo) | [![arXiv](https://img.shields.io/badge/arXiv-2308.16876-b31b1b.svg)](http://arxiv.org/abs/2308.16876) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SkL-LOKksgk) |
| CLIP-KD: An Empirical Study of CLIP Model Distillation | [![GitHub](https://img.shields.io/github/stars/winycg/CLIP-KD?style=flat)](https://github.com/winycg/CLIP-KD) | [![arXiv](https://img.shields.io/badge/arXiv-2307.12732-b31b1b.svg)](http://arxiv.org/abs/2307.12732) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zub8fktlJ1M) |
| InNeRF360: Text-Guided 3D-Consistent Object Inpainting on 360-Degree Neural Radiance Fields | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ivrl.github.io/InNeRF360/) | [![arXiv](https://img.shields.io/badge/arXiv-2305.15094-b31b1b.svg)](http://arxiv.org/abs/2305.15094) | :heavy_minus_sign: |
| Total-Decom: Decomposed 3D Scene Reconstruction with Minimal Interaction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cvmi-lab.github.io/Total-Decom/) <br /> [![GitHub](https://img.shields.io/github/stars/CVMI-Lab/Total-Decom?style=flat)](https://github.com/CVMI-Lab/Total-Decom) | [![arXiv](https://img.shields.io/badge/arXiv-2403.19314-b31b1b.svg)](http://arxiv.org/abs/2403.19314) | :heavy_minus_sign: |
| CAPE: CAM as a Probabilistic Ensemble for Enhanced DNN Interpretation | [![GitHub](https://img.shields.io/github/stars/AIML-MED/CAPE?style=flat)](https://github.com/AIML-MED/CAPE) | [![arXiv](https://img.shields.io/badge/arXiv-2404.02388-b31b1b.svg)](http://arxiv.org/abs/2404.02388) | :heavy_minus_sign: |
| GenHowTo: Learning to Generate Actions and State Transformations from Instructional Videos | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://soczech.github.io/genhowto/) <br /> [![GitHub](https://img.shields.io/github/stars/soCzech/genhowto?style=flat)](https://github.com/soCzech/genhowto) | [![arXiv](https://img.shields.io/badge/arXiv-2312.07322-b31b1b.svg)](http://arxiv.org/abs/2312.07322) | :heavy_minus_sign: |
| CN-RMA: Combined Network with Ray Marching Aggregation for 3D Indoor Object Detection from Multi-View Images | [![GitHub](https://img.shields.io/github/stars/SerCharles/CN-RMA?style=flat)](https://github.com/SerCharles/CN-RMA) | [![arXiv](https://img.shields.io/badge/arXiv-2403.04198-b31b1b.svg)](http://arxiv.org/abs/2403.04198) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mmdjD2aZjTc) |
| Generative 3D Part Assembly via Part-whole-Hierarchy Message Passing | [![GitHub](https://img.shields.io/github/stars/pkudba/3DHPA?style=flat)](https://github.com/pkudba/3DHPA) | [![arXiv](https://img.shields.io/badge/arXiv-2402.17464-b31b1b.svg)](http://arxiv.org/abs/2402.17464) | :heavy_minus_sign: |
| LightIt: Illumination Modeling and Control for Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://peter-kocsis.github.io/LightIt/) | [![arXiv](https://img.shields.io/badge/arXiv-2403.10615-b31b1b.svg)](http://arxiv.org/abs/2403.10615) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cCfSBD5aPLI) |
| Test-Time Zero-Shot Temporal Action Localization | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://benedettaliberatori.github.io/T3AL/) <br /> [![GitHub](https://img.shields.io/github/stars/benedettaliberatori/T3AL?style=flat)](https://github.com/benedettaliberatori/T3AL) | [![arXiv](https://img.shields.io/badge/arXiv-2404.05426-b31b1b.svg)](http://arxiv.org/abs/2404.05426) | :heavy_minus_sign: |
| HIVE: Harnessing Human Feedback for Instructional Visual Editing | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shugerdou.github.io/hive/) <br /> [![GitHub](https://img.shields.io/github/stars/salesforce/HIVE?style=flat)](https://github.com/salesforce/HIVE) | [![arXiv](https://img.shields.io/badge/arXiv-2303.09618-b31b1b.svg)](http://arxiv.org/abs/2303.09618) | :heavy_minus_sign: |
| NeRF Director: Revisiting View Selection in Neural Volume Rendering | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wenwhx.github.io/nerfdirector/) <br /> [![GitHub](https://img.shields.io/github/stars/wenwhx/nerfdirector?style=flat)](https://github.com/wenwhx/nerfdirector) | :heavy_minus_sign: | :heavy_minus_sign: |
| Unbiased Faster R-CNN for Single-Source Domain Generalized Object Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2405.15225-b31b1b.svg)](http://arxiv.org/abs/2405.15225) | :heavy_minus_sign: |
| Collaborative Semantic Occupancy Prediction with Hybrid Feature Fusion in Connected Automated Vehicles | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rruisong.github.io/publications/CoHFF/) | [![arXiv](https://img.shields.io/badge/arXiv-2402.07635-b31b1b.svg)](http://arxiv.org/abs/2402.07635) | :heavy_minus_sign: |
| GAFusion: Adaptive Fusing LiDAR and Camera with Multiple Guidance for 3D Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Cy3oVumuprc) |
| NIFTY: Neural Object Interaction Fields for Guided Human Motion Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nileshkulkarni.github.io/nifty/) <br /> [![GitHub](https://img.shields.io/github/stars/nileshkulkarni/nifty?style=flat)](https://github.com/nileshkulkarni/nifty) | [![arXiv](https://img.shields.io/badge/arXiv-2307.07511-b31b1b.svg)](http://arxiv.org/abs/2307.07511) | :heavy_minus_sign: |
| Prompting Vision Foundation Models for Pathology Image Analysis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| XFibrosis: Explicit Vessel-Fiber Modeling for Fibrosis Staging from Liver Pathology Images | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_Yiu5g71ZHo) |
| The more You See in 2D, the more You Perceive in 3D | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sap3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/sap3d/Sap3D?style=flat)](https://github.com/sap3d/Sap3D) | [![arXiv](https://img.shields.io/badge/arXiv-2404.03652-b31b1b.svg)](http://arxiv.org/abs/2404.03652) | :heavy_minus_sign: |
| LLM4SGG: Large Language Models for Weakly Supervised Scene Graph Generation | [![GitHub](https://img.shields.io/github/stars/rlqja1107/torch-LLM4SGG?style=flat)](https://github.com/rlqja1107/torch-LLM4SGG) | [![arXiv](https://img.shields.io/badge/arXiv-2310.10404-b31b1b.svg)](http://arxiv.org/abs/2310.10404) | :heavy_minus_sign: |
| Modeling Collaborator: Enabling Subjective Vision Classification with Minimal Human Effort via LLM Tool-use | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.02626-b31b1b.svg)](http://arxiv.org/abs/2403.02626) | :heavy_minus_sign: |
| LEOD: Label-Efficient Object Detection for Event Cameras | [![GitHub](https://img.shields.io/github/stars/Wuziyi616/LEOD?style=flat)](https://github.com/Wuziyi616/LEOD) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17286-b31b1b.svg)](http://arxiv.org/abs/2311.17286) | :heavy_minus_sign: |
| Producing and Leveraging Online Map Uncertainty in Trajectory Prediction | [![GitHub](https://img.shields.io/github/stars/alfredgu001324/MapUncertaintyPrediction?style=flat)](https://github.com/alfredgu001324/MapUncertaintyPrediction) | [![arXiv](https://img.shields.io/badge/arXiv-2403.16439-b31b1b.svg)](http://arxiv.org/abs/2403.16439) | :heavy_minus_sign: |
| SPAD: Spatially Aware Multiview Diffusers | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://yashkant.github.io/spad/) <br /> [![GitHub](https://img.shields.io/github/stars/yashkant/spad?style=flat)](https://github.com/yashkant/spad) | [![arXiv](https://img.shields.io/badge/arXiv-2402.05235-b31b1b.svg)](http://arxiv.org/abs/2402.05235) | :heavy_minus_sign: |
| CDMAD: Class-Distribution-Mismatch-Aware Debiasing for Class-Imbalanced Semi-Supervised Learning | [![GitHub](https://img.shields.io/github/stars/LeeHyuck/CDMAD?style=flat)](https://github.com/LeeHyuck/CDMAD) | [![arXiv](https://img.shields.io/badge/arXiv-2403.10391-b31b1b.svg)](http://arxiv.org/abs/2403.10391) | :heavy_minus_sign: |
| MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://boheumd.github.io/MA-LMM/) <br /> [![GitHub](https://img.shields.io/github/stars/boheumd/MA-LMM?style=flat)](https://github.com/boheumd/MA-LMM) | [![arXiv](https://img.shields.io/badge/arXiv-2404.05726-b31b1b.svg)](http://arxiv.org/abs/2404.05726) | :heavy_minus_sign: |
| Towards more Unified In-Context Visual Understanding | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2312.02520-b31b1b.svg)](http://arxiv.org/abs/2312.02520) | :heavy_minus_sign: |
| PIE-NeRF: Physics-based Interactive Elastodynamics with NeRF | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://fytalon.github.io/pienerf/) <br /> [![GitHub](https://img.shields.io/github/stars/FYTalon/pienerf?style=flat)](https://github.com/FYTalon/pienerf) | [![arXiv](https://img.shields.io/badge/arXiv-2311.13099-b31b1b.svg)](http://arxiv.org/abs/2311.13099) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GhCch50GqRY) |
| MuseChat: A Conversational Music Recommendation System for Videos | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2310.06282-b31b1b.svg)](http://arxiv.org/abs/2310.06282) | :heavy_minus_sign: |
| Rotation-Agnostic Image Representation Learning for Digital Pathology | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kimialabmayo.github.io/PathDino-Page/) <br /> [![GitHub](https://img.shields.io/github/stars/KimiaLabMayo/PathDino?style=flat)](https://github.com/KimiaLabMayo/PathDino) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-demo-FFD21F.svg)](https://huggingface.co/spaces/Saghir/PathDino) | [![arXiv](https://img.shields.io/badge/arXiv-2311.08359-b31b1b.svg)](http://arxiv.org/abs/2311.08359) | :heavy_minus_sign: |
| CodedEvents: Optimal Point-Spread-Function Engineering for 3D-Tracking with Event Cameras | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| The Audio-Visual Conversational Graph: From an Egocentric-Exocentric Perspective | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vjwq.github.io/AV-CONV/) <br /> [![GitHub](https://img.shields.io/github/stars/VJWQ/AV-CONV?style=flat)](https://github.com/VJWQ/AV-CONV) | [![arXiv](https://img.shields.io/badge/arXiv-2312.12870-b31b1b.svg)](http://arxiv.org/abs/2312.12870) | :heavy_minus_sign: |
| LEDITS++: Limitless Image Editing using Text-to-Image Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://leditsplusplus-project.static.hf.space/index.html) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-demo-FFD21F.svg)](https://huggingface.co/spaces/editing-images/leditsplusplus) | [![arXiv](https://img.shields.io/badge/arXiv-2311.16711-b31b1b.svg)](http://arxiv.org/abs/2311.16711) | :heavy_minus_sign: |
| MemFlow: Optical Flow Estimation and Prediction with Memory | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dqiaole.github.io/MemFlow/) <br /> [![GitHub](https://img.shields.io/github/stars/DQiaole/MemFlow?style=flat)](https://github.com/DQiaole/MemFlow) | [![arXiv](https://img.shields.io/badge/arXiv-2404.04808-b31b1b.svg)](http://arxiv.org/abs/2404.04808) | :heavy_minus_sign: |
| SemCity: Semantic Scene Generation with Triplane Diffusion | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://sglab.kaist.ac.kr/SemCity/) <br /> [![GitHub](https://img.shields.io/github/stars/zoomin-lee/SemCity?style=flat)](https://github.com/zoomin-lee/SemCity) | [![arXiv](https://img.shields.io/badge/arXiv-2403.07773-b31b1b.svg)](http://arxiv.org/abs/2403.07773) | :heavy_minus_sign: |
| UnScene3D: Unsupervised 3D Instance Segmentation for Indoor Scenes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rozdavid.github.io/unscene3d) <br /> [![GitHub](https://img.shields.io/github/stars/RozDavid/UnScene3D?style=flat)](https://github.com/RozDavid/UnScene3D) | [![arXiv](https://img.shields.io/badge/arXiv-2303.14541-b31b1b.svg)](http://arxiv.org/abs/2303.14541) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ukovRRni79c) |
| TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vp3d-cvpr24.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2403.17005-b31b1b.svg)](http://arxiv.org/abs/2403.17005) | :heavy_minus_sign: |
| Boosting Diffusion Models with Moving Average Sampling in Frequency Domain | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.17870-b31b1b.svg)](http://arxiv.org/abs/2403.17870) | :heavy_minus_sign: |
| Learning Spatial Adaptation and Temporal Coherence in Diffusion Models for Video Super-Resolution | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.17000-b31b1b.svg)](http://arxiv.org/abs/2403.17000) | :heavy_minus_sign: |
| SD-DiT: Unleashing the Power of Self-supervised Discrimination in Diffusion Transformer | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.17004-b31b1b.svg)](http://arxiv.org/abs/2403.17004) | :heavy_minus_sign: |
| VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://vp3d-cvpr24.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2403.17001-b31b1b.svg)](http://arxiv.org/abs/2403.17001) | :heavy_minus_sign: |
| Riemannian Multinomial Logistics Regression for SPD Neural Networks | [![GitHub](https://img.shields.io/github/stars/GitZH-Chen/SPDMLR?style=flat)](https://github.com/GitZH-Chen/SPDMLR) | [![arXiv](https://img.shields.io/badge/arXiv-2305.11288-b31b1b.svg)](http://arxiv.org/abs/2305.11288) | :heavy_minus_sign: |
| VideoMAC: Video Masked Autoencoders Meet ConvNets | [![GitHub](https://img.shields.io/github/stars/Video-MAC/VideoMAC?style=flat)](https://github.com/Video-MAC/VideoMAC) | [![arXiv](https://img.shields.io/badge/arXiv-2402.19082-b31b1b.svg)](http://arxiv.org/abs/2402.19082) | :heavy_minus_sign: |
| Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching | [![GitHub](https://img.shields.io/github/stars/shaoshitong/G_VBSM_Dataset_Condensation?style=flat)](https://github.com/shaoshitong/G_VBSM_Dataset_Condensation) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17950-b31b1b.svg)](http://arxiv.org/abs/2311.17950) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O2E2soSDv3c) |
| ICP-Flow: LiDAR Scene Flow Estimation with ICP | [![GitHub](https://img.shields.io/github/stars/yanconglin/ICP-Flow?style=flat)](https://github.com/yanconglin/ICP-Flow) | [![arXiv](https://img.shields.io/badge/arXiv-2402.17351-b31b1b.svg)](http://arxiv.org/abs/2402.17351) | :heavy_minus_sign: |
| GP-NeRF: Generalized Perception NeRF for Context-Aware 3D Scene Understanding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lifuguan.github.io/gpnerf-pages/) <br /> [![GitHub](https://img.shields.io/github/stars/lifuguan/GP-NeRF?style=flat)](https://github.com/lifuguan/GP-NeRF) | [![arXiv](https://img.shields.io/badge/arXiv-2311.11863-b31b1b.svg)](http://arxiv.org/abs/2311.11863) | :heavy_minus_sign: |
| JRDB-Social: A Multifaceted Robotic Dataset for Understanding of Context and Dynamics of Human Interactions within Social Groups | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://jrdb.erc.monash.edu/dataset/social) <br /> [![GitHub](https://img.shields.io/github/stars/sjahangard/JRDB-Social?style=flat)](https://github.com/sjahangard/JRDB-Social) | [![arXiv](https://img.shields.io/badge/arXiv-2404.04458-b31b1b.svg)](http://arxiv.org/abs/2404.04458) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LvstLIoKK4c) |
| MOHO: Learning Single-View Hand-Held Object Reconstruction with Multi-View Occlusion-Aware Supervision | [![GitHub](https://img.shields.io/github/stars/ZhangCYG/MOHO?style=flat)](https://github.com/ZhangCYG/MOHO) | [![arXiv](https://img.shields.io/badge/arXiv-2310.11696-b31b1b.svg)](http://arxiv.org/abs/2310.11696) | :heavy_minus_sign: |
| Exploring Region-Word Alignment in Built-in Detector for Open-Vocabulary Object Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers | [![GitHub](https://img.shields.io/github/stars/shahaf-arica/cuvler?style=flat)](https://github.com/shahaf-arica/cuvler) | [![arXiv](https://img.shields.io/badge/arXiv-2403.07700-b31b1b.svg)](http://arxiv.org/abs/2403.07700) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tymfia30jhI) |
| MoST: Motion Style Transformer between Diverse Action Contents | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://boeun-kim.github.io/page-MoST/) <br /> [![GitHub](https://img.shields.io/github/stars/Boeun-Kim/MoST?style=flat)](https://github.com/Boeun-Kim/MoST) | [![arXiv](https://img.shields.io/badge/arXiv-2403.06225-b31b1b.svg)](http://arxiv.org/abs/2403.06225) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cLWswPCF-8I) |
| Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in Autonomous Driving Applications | [![GitHub](https://img.shields.io/github/stars/haomo-ai/Cam4DOcc?style=flat)](https://github.com/haomo-ai/Cam4DOcc) | [![arXiv](https://img.shields.io/badge/arXiv-2311.17663-b31b1b.svg)](http://arxiv.org/abs/2311.17663) | :heavy_minus_sign: |
| Low-Resource Vision Challenges for Foundation Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xiaobai1217.github.io/Low-Resource-Vision/) <br /> [![GitHub](https://img.shields.io/github/stars/xiaobai1217/Low-Resource-Vision?style=flat)](https://github.com/xiaobai1217/Low-Resource-Vision) | [![arXiv](https://img.shields.io/badge/arXiv-2401.04716-b31b1b.svg)](http://arxiv.org/abs/2401.04716) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4dHpJown1eU) |
| AdaRevD: Adaptive Patch Exiting Reversible Decoder Pushes the Limit of Image Deblurring | [![GitHub](https://img.shields.io/github/stars/DeepMed-Lab-ECNU/Single-Image-Deblur?style=flat)](https://github.com/DeepMed-Lab-ECNU/Single-Image-Deblur) | :heavy_minus_sign: | :heavy_minus_sign: |
| KP-RED: Exploiting Semantic Keypoints for Joint 3D Shape Retrieval and Deformation | [![GitHub](https://img.shields.io/github/stars/lolrudy/KP-RED?style=flat)](https://github.com/lolrudy/KP-RED) | [![arXiv](https://img.shields.io/badge/arXiv-2403.10099-b31b1b.svg)](http://arxiv.org/abs/2403.10099) | :heavy_minus_sign: |
| MVHumanNet: A Large-Scale Dataset of Multi-View Daily Dressing Human Captures | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://x-zhangyang.github.io/MVHumanNet/) <br /> [![GitHub](https://img.shields.io/github/stars/GAP-LAB-CUHK-SZ/MVHumanNet?style=flat)](https://github.com/GAP-LAB-CUHK-SZ/MVHumanNet) | [![arXiv](https://img.shields.io/badge/arXiv-2312.02963-b31b1b.svg)](http://arxiv.org/abs/2312.02963) | :heavy_minus_sign: |
| DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.08506-b31b1b.svg)](http://arxiv.org/abs/2403.08506) | :heavy_minus_sign: |
| SSR-Encoder: Encoding Selective Subject Representation for Subject-Driven Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ssr-encoder.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/Xiaojiu-z/SSR_Encoder?style=flat)](https://github.com/Xiaojiu-z/SSR_Encoder) | [![arXiv](https://img.shields.io/badge/arXiv-2312.16272-b31b1b.svg)](http://arxiv.org/abs/2312.16272) | :heavy_minus_sign: |
| Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld | [![GitHub](https://img.shields.io/github/stars/stevenyangyj/Emma-Alfworld?style=flat)](https://github.com/stevenyangyj/Emma-Alfworld) | [![arXiv](https://img.shields.io/badge/arXiv-2311.16714-b31b1b.svg)](http://arxiv.org/abs/2311.16714) | :heavy_minus_sign: |
| POCE: Primal Policy Optimization with Conservative Estimation for Multi-Constraint Offline Reinforcement Learning | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Bayesian Differentiable Physics for Cloth Digitalization | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://drhewang.com/pages/BDP.html) <br /> [![GitHub](https://img.shields.io/github/stars/realcrane/Bayesian-Differentiable-Physics-for-Cloth-Digitalization?style=flat)](https://github.com/realcrane/Bayesian-Differentiable-Physics-for-Cloth-Digitalization) | [![arXiv](https://img.shields.io/badge/arXiv-2402.17664-b31b1b.svg)](http://arxiv.org/abs/2402.17664) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ProN0y1bURY) |
| Monocular Identity-Conditioned Facial Reflectance Reconstruction | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://xingyuren.github.io/id2reflectance/) | [![arXiv](https://img.shields.io/badge/arXiv-2404.00301-b31b1b.svg)](http://arxiv.org/abs/2404.00301) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LUpP089LO8E) |
| Ensemble Diversity Facilitates Adversarial Transferability | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| From a Bird's Eye View to See: Joint Camera and Subject Registration without the Camera Calibration | [![GitHub](https://img.shields.io/github/stars/zekunqian/bevsee?style=flat)](https://github.com/zekunqian/bevsee) | [![arXiv](https://img.shields.io/badge/arXiv-2212.09298-b31b1b.svg)](http://arxiv.org/abs/2212.09298) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AQivxJiuwKc) |
| Accept the Modality Gap: An Exploration in the Hyperbolic Space | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0yue5VXR_rA) |
| Move as You Say, Interact as You Can: Language-guided Human Motion Generation with Scene Affordance | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://afford-motion.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/afford-motion/afford-motion?style=flat)](https://github.com/afford-motion/afford-motion) | [![arXiv](https://img.shields.io/badge/arXiv-2403.18036-b31b1b.svg)](http://arxiv.org/abs/2403.18036) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=emT0FHDYY1U) |
| PHYSCENE: Physically Interactable 3D Scene Synthesis for Embodied AI | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://physcene.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/PhyScene/PhyScene?style=flat)](https://github.com/PhyScene/PhyScene) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=C9sEwcqrTww) |
| 6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-Criteria Token Fusion with One-Step-ahead Attention for Efficient Vision Transformers | [![GitHub](https://img.shields.io/github/stars/mlvlab/MCTF?style=flat)](https://github.com/mlvlab/MCTF) | [![arXiv](https://img.shields.io/badge/arXiv-2403.10030-b31b1b.svg)](http://arxiv.org/abs/2403.10030) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=DQVoe4VHYZg) |
| DIMAT: Decentralized Iterative Merging-and-Training for Deep Learning Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A Semi-Supervised Nighttime Dehazing Baseline with Spatial-Frequency aware and Realistic Brightness Constraint | [![GitHub](https://img.shields.io/github/stars/Xiaofeng-life/SFSNiD?style=flat)](https://github.com/Xiaofeng-life/SFSNiD) | :heavy_minus_sign: | :heavy_minus_sign: |
| A Dual-Augmentor Framework for Domain Generalization in 3D Human Pose Estimation | [![GitHub](https://img.shields.io/github/stars/davidpengucf/DAF-DG?style=flat)](https://github.com/davidpengucf/DAF-DG) | [![arXiv](https://img.shields.io/badge/arXiv-2403.11310-b31b1b.svg)](http://arxiv.org/abs/2403.11310) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rmUM7N91vNA) |
| OpticalDR: A Deep Optical Imaging Model for Privacy-Protective Depression Recognition | [![GitHub](https://img.shields.io/github/stars/divertingPan/OpticalDR?style=flat)](https://github.com/divertingPan/OpticalDR) | [![arXiv](https://img.shields.io/badge/arXiv-2402.18786-b31b1b.svg)](http://arxiv.org/abs/2402.18786) | :heavy_minus_sign: |
| Enhancing the Power of OOD Detection via Sample-Aware Model Selection | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XNso9qsWxHo) |
| SPU-PMD: Self-Supervised Point Cloud Upsampling via Progressive Mesh Deformation | [![GitHub](https://img.shields.io/github/stars/lyz21/SPU-PMD?style=flat)](https://github.com/lyz21/SPU-PMD) | :heavy_minus_sign: | :heavy_minus_sign: |
| Hearing Anything Anywhere | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://masonlwang.com/hearinganythinganywhere/) <br /> [![GitHub](https://img.shields.io/github/stars/maswang32/hearinganythinganywhere?style=flat)](https://github.com/maswang32/hearinganythinganywhere) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=q8wKHaex3BA) |
| MICap: A Unified Model for Identity-Aware Movie Descriptions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://katha-ai.github.io/projects/micap/) <br /> [![GitHub](https://img.shields.io/github/stars/katha-ai/MovieIdentityCaptioner-CVPR2024?style=flat)](https://github.com/katha-ai/MovieIdentityCaptioner-CVPR2024) <br /> [![Hugging Face](https://img.shields.io/badge/ðŸ¤—-demo-FFD21F.svg)](https://huggingface.co/spaces/dnaveenr/iSPICE-Metric) | [![arXiv](https://img.shields.io/badge/arXiv-2405.11483-b31b1b.svg)](http://arxiv.org/abs/2405.11483) | :heavy_minus_sign: |
| SD2Event: Self-Supervised Learning of Dynamic Detectors and Contextual Descriptors for Event Cameras | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models | [![GitHub](https://img.shields.io/github/stars/SHI-Labs/Prompt-Free-Diffusion?style=flat)](https://github.com/SHI-Labs/Prompt-Free-Diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2305.16223-b31b1b.svg)](http://arxiv.org/abs/2305.16223) | :heavy_minus_sign: |
| MeaCap: Memory-Augmented Zero-Shot Image Captioning | [![GitHub](https://img.shields.io/github/stars/joeyz0z/MeaCap?style=flat)](https://github.com/joeyz0z/MeaCap) | [![arXiv](https://img.shields.io/badge/arXiv-2403.03715-b31b1b.svg)](http://arxiv.org/abs/2403.03715) | :heavy_minus_sign: |
| Re-thinking Data Availability Attacks Against Deep Neural Networks | [![GitHub](https://img.shields.io/github/stars/EuterpeK/Rethinking-Data-Availability-Attacks?style=flat)](https://github.com/EuterpeK/Rethinking-Data-Availability-Attacks) | [![arXiv](https://img.shields.io/badge/arXiv-2305.10691-b31b1b.svg)](http://arxiv.org/abs/2305.10691) | :heavy_minus_sign: |
| Self-Supervised Facial Representation Learning with Facial Region Awareness | [![GitHub](https://img.shields.io/github/stars/zaczgao/Facial_Region_Awareness?style=flat)](https://github.com/zaczgao/Facial_Region_Awareness) | [![arXiv](https://img.shields.io/badge/arXiv-2403.02138-b31b1b.svg)](http://arxiv.org/abs/2403.02138) | :heavy_minus_sign: |
| Breathing Life Into Sketches using Text-to-Video Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://livesketch.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/yael-vinker/live_sketch?style=flat)](https://github.com/yael-vinker/live_sketch) | [![arXiv](https://img.shields.io/badge/arXiv-2311.13608-b31b1b.svg)](http://arxiv.org/abs/2311.13608) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QwRilmoU-tY) |
| Abductive Ego-View Accident Video Understanding for Safe Driving Perception | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://www.lotvsmmau.net/) <br /> [![GitHub](https://img.shields.io/github/stars/jeffreychou777/LOTVS-MM-AU?style=flat)](https://github.com/jeffreychou777/LOTVS-MM-AU) | [![arXiv](https://img.shields.io/badge/arXiv-2403.00436-b31b1b.svg)](http://arxiv.org/abs/2403.00436) | :heavy_minus_sign: |
| FedHCA<sup>2</sup>: Towards Hetero-Client Federated Multi-Task Learning | [![GitHub](https://img.shields.io/github/stars/innovator-zero/FedHCA2?style=flat)](https://github.com/innovator-zero/FedHCA2) | [![arXiv](https://img.shields.io/badge/arXiv-2311.13250-b31b1b.svg)](http://arxiv.org/abs/2311.13250) | :heavy_minus_sign: |
| Hybrid Functional Maps for Crease-Aware Non-Isometric Shape Matching | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hybridfmaps.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/xieyizheng/hybridfmaps?style=flat)](https://github.com/xieyizheng/hybridfmaps) | [![arXiv](https://img.shields.io/badge/arXiv-2312.03678-b31b1b.svg)](http://arxiv.org/abs/2312.03678) | :heavy_minus_sign: |
| vid-TLDR: Training Free Token Merging for Light-Weight Video Transformer | [![GitHub](https://img.shields.io/github/stars/mlvlab/vid-TLDR?style=flat)](https://github.com/mlvlab/vid-TLDR) | [![arXiv](https://img.shields.io/badge/arXiv-2403.13347-b31b1b.svg)](http://arxiv.org/abs/2403.13347) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gM7vBdDjWpA) |
| MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://eddie221.github.io/MCPNet/) | [![arXiv](https://img.shields.io/badge/arXiv-2404.08968-b31b1b.svg)](http://arxiv.org/abs/2404.08968) | :heavy_minus_sign: |
| 3D Feature Tracking via Event Camera | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=X8rr9x3B1ns) |
| Seeing Unseen: Discover Novel Biomedical Concepts via Geometry-Constrained Probabilistic Modeling | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.01053-b31b1b.svg)](http://arxiv.org/abs/2403.01053) | :heavy_minus_sign: |
| Segment any Event Streams via Weighted Adaptation of Pivotal Tokens | [![GitHub](https://img.shields.io/github/stars/zhiwen-xdu/EventSAM?style=flat)](https://github.com/zhiwen-xdu/EventSAM) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LCLp12PlnyY) |
| DETRs Beat YOLOs on Real-Time Object Detection | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zhao-yian.github.io/RTDETR/) <br /> [![GitHub](https://img.shields.io/github/stars/lyuwenyu/RT-DETR?style=flat)](https://github.com/lyuwenyu/RT-DETR) | [![arXiv](https://img.shields.io/badge/arXiv-2304.08069-b31b1b.svg)](http://arxiv.org/abs/2304.08069) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UOc0qMSX4Ac) |
| Neural Clustering based Visual Representation Learning | [![GitHub](https://img.shields.io/github/stars/guikunchen/FEC?style=flat)](https://github.com/guikunchen/FEC) | [![arXiv](https://img.shields.io/badge/arXiv-2403.17409-b31b1b.svg)](http://arxiv.org/abs/2403.17409) | :heavy_minus_sign: |
| I'M HOI: Inertia-Aware Monocular Capture of 3D Human-Object Interactions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://afterjourney00.github.io/IM-HOI.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/AfterJourney00/IMHD-Dataset?style=flat)](https://github.com/AfterJourney00/IMHD-Dataset) | [![arXiv](https://img.shields.io/badge/arXiv-2312.08869-b31b1b.svg)](http://arxiv.org/abs/2312.08869) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MdG00uakBa8) |
| AvatarGPT: All-in-One Framework for Motion Understanding, Planning, Generation and Beyond | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zixiangzhou916.github.io/AvatarGPT/) <br /> [![GitHub](https://img.shields.io/github/stars/zixiangzhou916/AvatarGPT?style=flat)](https://github.com/zixiangzhou916/AvatarGPT) | [![arXiv](https://img.shields.io/badge/arXiv-2311.16468-b31b1b.svg)](http://arxiv.org/abs/2311.16468) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JYoUmuypM4I) |
| De-confounded Data-Free Knowledge Distillation for Handling Distribution Shifts | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.19539-b31b1b.svg)](http://arxiv.org/abs/2403.19539) | :heavy_minus_sign: |
| HOIDiffusion: Generating Realistic 3D Hand-Object Interaction Data | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://mq-zhang1.github.io/HOIDiffusion/) <br /> [![GitHub](https://img.shields.io/github/stars/Mq-Zhang1/HOIDiffusion?style=flat)](https://github.com/Mq-Zhang1/HOIDiffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2403.12011-b31b1b.svg)](http://arxiv.org/abs/2403.12011) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YD_buFwMX44) |
| Think Twice Before Selection: Federated Evidential Active Learning for Medical Image Analysis with Domain Shifts | [![GitHub](https://img.shields.io/github/stars/JiayiChen815/FEAL?style=flat)](https://github.com/JiayiChen815/FEAL) | [![arXiv](https://img.shields.io/badge/arXiv-2312.02567-b31b1b.svg)](http://arxiv.org/abs/2312.02567) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=koDt8nN0gxg) |
| OHTA: One-Shot Hand Avatar via Data-Driven Implicit Priors | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zxz267.github.io/OHTA/) <br /> [![GitHub](https://img.shields.io/github/stars/zxz267/OHTA?style=flat)](https://github.com/zxz267/OHTA) | [![arXiv](https://img.shields.io/badge/arXiv-2402.18969-b31b1b.svg)](http://arxiv.org/abs/2402.18969) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VPjjHNgtzJI) |
| Split to Merge: Unifying Separated Modalities for Unsupervised Domain Adaptation | [![GitHub](https://img.shields.io/github/stars/TL-UESTC/UniMoS?style=flat)](https://github.com/TL-UESTC/UniMoS) | [![arXiv](https://img.shields.io/badge/arXiv-2403.06946-b31b1b.svg)](http://arxiv.org/abs/2403.06946) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ijuakdf1X10) |
| Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://yu1ut.com/MotionPatches-HP/) | [![arXiv](https://img.shields.io/badge/arXiv-2405.04771-b31b1b.svg)](http://arxiv.org/abs/2405.04771) | :heavy_minus_sign: |
| Structure-Guided Adversarial Training of Diffusion Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.17563-b31b1b.svg)](http://arxiv.org/abs/2402.17563) | :heavy_minus_sign: |
| MonoHair: High-Fidelity Hair Modeling from a Monocular Video | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://keyuwu-cs.github.io/MonoHair/) <br /> [![GitHub](https://img.shields.io/github/stars/KeyuWu-CS/MonoHair?style=flat)](https://github.com/KeyuWu-CS/MonoHair) | [![arXiv](https://img.shields.io/badge/arXiv-2403.18356-b31b1b.svg)](http://arxiv.org/abs/2403.18356) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xHfkuAYmcAA) |
| CMA: A Chromaticity Map Adapter for Robust Detection of Screen-Recapture Document Images | [![GitHub](https://img.shields.io/github/stars/chenlewis/Chromaticity-Map-Adapter-for-DPAD?style=flat)](https://github.com/chenlewis/Chromaticity-Map-Adapter-for-DPAD) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QCac4b8PogU) |
| MovieChat: From Dense Token to Sparse Memory for Long Video Understanding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rese1f.github.io/MovieChat/) <br /> [![GitHub](https://img.shields.io/github/stars/rese1f/MovieChat?style=flat)](https://github.com/rese1f/MovieChat) | [![arXiv](https://img.shields.io/badge/arXiv-2307.16449-b31b1b.svg)](http://arxiv.org/abs/2307.16449) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=g985zv12lyg) |
| Expandable Subspace Ensemble for Pre-Trained Model-based Class-Incremental Learning | [![GitHub](https://img.shields.io/github/stars/sun-hailong/CVPR24-Ease?style=flat)](https://github.com/sun-hailong/CVPR24-Ease) | [![arXiv](https://img.shields.io/badge/arXiv-2403.12030-b31b1b.svg)](http://arxiv.org/abs/2403.12030) | :heavy_minus_sign: |
| Habitat Synthetic Scenes Dataset (HSSD-200): An Analysis of 3D Scene Scale and Realism Tradeoffs for ObjectGoal Navigation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://3dlg-hcvc.github.io/hssd/) <br /> [![GitHub](https://img.shields.io/github/stars/3dlg-hcvc/hssd?style=flat)](https://github.com/3dlg-hcvc/hssd) | [![arXiv](https://img.shields.io/badge/arXiv-2306.11290-b31b1b.svg)](http://arxiv.org/abs/2306.11290) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tU0MwbuqKpg) |
| No Time to Train: Empowering Non-Parametric Networks for Few-Shot 3D Scene Segmentation | [![GitHub](https://img.shields.io/github/stars/yangyangyang127/Seg-NN?style=flat)](https://github.com/yangyangyang127/Seg-NN) | [![arXiv](https://img.shields.io/badge/arXiv-2404.04050-b31b1b.svg)](http://arxiv.org/abs/2404.04050) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4piBUB9vkbo) |
| Brain Decodes Deep Nets | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://huzeyann.github.io/brain-decodes-deep-nets) <br /> [![GitHub](https://img.shields.io/github/stars/huzeyann/BrainDecodesDeepNets?style=flat)](https://github.com/huzeyann/BrainDecodesDeepNets) | [![arXiv](https://img.shields.io/badge/arXiv-2312.01280-b31b1b.svg)](http://arxiv.org/abs/2312.01280) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Qh49zQQCW1g) |
| Dual Memory Networks: A Versatile Adaptation Approach for Vision-Language Models | [![GitHub](https://img.shields.io/github/stars/YBZh/DMN?style=flat)](https://github.com/YBZh/DMN) | [![arXiv](https://img.shields.io/badge/arXiv-2403.17589-b31b1b.svg)](http://arxiv.org/abs/2403.17589) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VPKCpAwB0vU) |
| EvalCrafter: Benchmarking and Evaluating Large Video Generation Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://evalcrafter.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/EvalCrafter/EvalCrafter?style=flat)](https://github.com/EvalCrafter/EvalCrafter) | [![arXiv](https://img.shields.io/badge/arXiv-2310.11440-b31b1b.svg)](http://arxiv.org/abs/2310.11440) | :heavy_minus_sign: |
| MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://wangyanhui666.github.io/MicroCinema.github.io/) | [![arXiv](https://img.shields.io/badge/arXiv-2311.18829-b31b1b.svg)](http://arxiv.org/abs/2311.18829) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=H7O-Ku_lqPA) |
| PH-Net: Semi-Supervised Breast Lesion Segmentation via Patch-Wise Hardness | :heavy_minus_sign: | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=l7xcZGof75Y) |
| Towards Text-guided 3D Scene Composition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://zqh0253.github.io/SceneWiz3D/) <br /> [![GitHub](https://img.shields.io/github/stars/zqh0253/SceneWiz3D?style=flat)](https://github.com/zqh0253/SceneWiz3D) | [![arXiv](https://img.shields.io/badge/arXiv-2312.08885-b31b1b.svg)](http://arxiv.org/abs/2312.08885) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QBQC9wbew7g) |
| MemSAM: Taming Segment Anything Model for Echocardiography Video Segmentation | [![GitHub](https://img.shields.io/github/stars/dengxl0520/MemSAM?style=flat)](https://github.com/dengxl0520/MemSAM) | :heavy_minus_sign: | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=N2usOkkNHQs) |
| Structure Matters: Tackling the Semantic Discrepancy in Diffusion Models for Image Inpainting | [![GitHub](https://img.shields.io/github/stars/htyjers/StrDiffusion?style=flat)](https://github.com/htyjers/StrDiffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2403.19898-b31b1b.svg)](http://arxiv.org/abs/2403.19898) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AjbKLsBVaCc) |
| SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM |  |  |  |
| Density-Guided Semi-Supervised 3D Semantic Segmentation with Dual-Space Hardness Sampling |  |  |  |
| From Correspondences to Pose: Non-minimal Certifiably Optimal Relative Pose without Disambiguation |  |  |  |
| Visual Anagrams: Synthesizing Multi-View Optical Illusions with Diffusion Models |  |  |  |
| SI-MIL: Taming Deep MIL for Self-Interpretability in Gigapixel Histopathology |  |  |  |
| Low-Latency Neural Stereo Streaming |  |  |  |
| mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration |  |  |  |
| Forgery-aware Adaptive Transformer for Generalizable Synthetic Image Detection |  |  |  |
| OmniParser: A Unified Framework for Text Spotting, Key Information Extraction and Table Recognition |  |  |  |
| Transferable and Principled Efficiency for Open-Vocabulary Segmentation |  |  |  |
| LowRankOcc: Tensor Decomposition and Low-Rank Recovery for Vision-based 3D Semantic Occupancy Prediction |  |  |  |
| SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities |  |  |  |
| Taming Mode Collapse in Score Distillation for Text-to-3D Generation |  |  |  |
| HAVE-FUN: Human Avatar Reconstruction from Few-Shot Unconstrained Images |  |  |  |
| Sequential Modeling Enables Scalable Learning for Large Vision Models |  |  |  |
| Distraction is All You Need: Memory-Efficient Image Immunization against Diffusion-Based Image Editing |  |  |  |
| OmniMedVQA: A New Large-Scale Comprehensive  Evaluation Benchmark for Medical LVLM |  |  |  |
| UniPAD: A Universal Pre-training Paradigm for Autonomous Driving |  |  |  |
| Semantics, Distortion, and Style Matter: Towards Source-free UDA for Panoramic Segmentation |  |  |  |
