# CVPR-2023-Papers

<div align="center">
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/computer-vision-for-social-good.md">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" />
  </a>
  <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
    <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" />
  </a>
</div>

## Others

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

[![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.pdf)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| A Bag-of-Prototypes Representation for Dataset-Level Applications | [![GitHub](https://img.shields.io/github/stars/Klaus-Tu/Bag-of-Prototypes)](https://github.com/Klaus-Tu/Bag-of-Prototypes) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Tu_A_Bag-of-Prototypes_Representation_for_Dataset-Level_Applications_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13251-b31b1b.svg)](http://arxiv.org/abs/2303.13251) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kSB0GO9pEYE) |
| Learning To Retain While Acquiring: Combating Distribution-Shift in Adversarial Data-Free Knowledge Distillation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Patel_Learning_To_Retain_While_Acquiring_Combating_Distribution-Shift_in_Adversarial_Data-Free_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14290-b31b1b.svg)](http://arxiv.org/abs/2302.14290) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VwEKrqMym4k) |
| Label Information Bottleneck for Label Enhancement | [![GitHub](https://img.shields.io/github/stars/qinghai-zheng/LIBLE)](https://github.com/qinghai-zheng/LIBLE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Tang_Label_Information_Bottleneck_for_Label_Enhancement_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06836-b31b1b.svg)](http://arxiv.org/abs/2303.06836) | :heavy_minus_sign: |
| DISC: Learning from Noisy Labels via Dynamic Instance-Specific Selection and Correction | [![GitHub](https://img.shields.io/github/stars/JackYFL/DISC)](https://github.com/JackYFL/DISC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_DISC_Learning_From_Noisy_Labels_via_Dynamic_Instance-Specific_Selection_and_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YGWGU3m4whc) |
| Restoration of Hand-Drawn Architectural Drawings using Latent Space Mapping with Degradation Generator | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Choi_Restoration_of_Hand-Drawn_Architectural_Drawings_Using_Latent_Space_Mapping_With_CVPR_2023_paper.pdf)  | :heavy_minus_sign: |
| DaFKD: Domain-Aware Federated Knowledge Distillation | [![GitHub](https://img.shields.io/github/stars/haozhaowang/DaFKD2023)](https://github.com/haozhaowang/DaFKD2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_DaFKD_Domain-Aware_Federated_Knowledge_Distillation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NxmLN6uWUBA) |
| Enhanced Stable View Synthesis | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Jain_Enhanced_Stable_View_Synthesis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17094-b31b1b.svg)](http://arxiv.org/abs/2303.17094) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CZW6HLDQRD4) |
| ScaleFL: Resource-Adaptive Federated Learning with Heterogeneous Clients | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ilhan_ScaleFL_Resource-Adaptive_Federated_Learning_With_Heterogeneous_Clients_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| GradMA: A Gradient-Memory-based Accelerated Federated Learning with Alleviated Catastrophic Forgetting <br /> ![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Luo_GradMA_A_Gradient-Memory-Based_Accelerated_Federated_Learning_With_Alleviated_Catastrophic_Forgetting_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14307-b31b1b.svg)](http://arxiv.org/abs/2302.14307) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kzZH_5eSsZ4) |
| High-Resolution Image Reconstruction with Latent Diffusion Models from Human Brain Activity | [![GitHub](https://img.shields.io/github/stars/yu-takagi/StableDiffusionReconstruction)](https://github.com/yu-takagi/StableDiffusionReconstruction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Takagi_High-Resolution_Image_Reconstruction_With_Latent_Diffusion_Models_From_Human_Brain_CVPR_2023_paper.pdf) <br /> [![DOI:10.1101/2022.11.18.517004v3](http://img.shields.io/badge/DOI-10.1101/2022.11.18.517004v3-B31B1B.svg)](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v3) | :heavy_minus_sign: |
| A Unified Knowledge Distillation Framework for Deep Directed Graphical Models | [![GitHub](https://img.shields.io/github/stars/YizhuoChen99/KD4DGM-CVPR)](https://github.com/YizhuoChen99/KD4DGM-CVPR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_A_Unified_Knowledge_Distillation_Framework_for_Deep_Directed_Graphical_Models_CVPR_2023_paper.pdf)  | :heavy_minus_sign: |
| How to Prevent the Poor Performance Clients for Personalized Federated Learning? | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Qu_How_To_Prevent_the_Poor_Performance_Clients_for_Personalized_Federated_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
