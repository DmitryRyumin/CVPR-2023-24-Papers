# CVPR-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/low-level-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/deep-learning-architectures-and-techniques.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Segmentation, Grouping and Shape Analysis

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Efficient Semantic Segmentation by Altering Resolutions for Compressed Videos | [![GitHub](https://img.shields.io/github/stars/THU-LYJ-Lab/AR-Seg?style=flat)](https://github.com/THU-LYJ-Lab/AR-Seg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Hu_Efficient_Semantic_Segmentation_by_Altering_Resolutions_for_Compressed_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07224-b31b1b.svg)](http://arxiv.org/abs/2303.07224) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WN9ok0xd0po) |
| Vision Transformers Are Good Mask Auto-Labelers | [![GitHub](https://img.shields.io/github/stars/NVlabs/mask-auto-labeler?style=flat)](https://github.com/NVlabs/mask-auto-labeler) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lan_Vision_Transformers_Are_Good_Mask_Auto-Labelers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.03992-b31b1b.svg)](http://arxiv.org/abs/2301.03992) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=n9cmRYzKNVc) |
| Visual Recognition by Request | [![GitHub](https://img.shields.io/github/stars/chufengt/Visual-Recognition-by-Request?style=flat)](https://github.com/chufengt/Visual-Recognition-by-Request) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Tang_Visual_Recognition_by_Request_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.14227-b31b1b.svg)](http://arxiv.org/abs/2207.14227) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0wuVwYPcSQg) |
| Ultra-High Resolution Segmentation With Ultra-Rich Context: A Novel Benchmark | [![GitHub](https://img.shields.io/github/stars/jankyee/URUR?style=flat)](https://github.com/jankyee/URUR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ji_Ultra-High_Resolution_Segmentation_With_Ultra-Rich_Context_A_Novel_Benchmark_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10899-b31b1b.svg)](http://arxiv.org/abs/2305.10899) | :heavy_minus_sign: |
| AttentionShift: Iteratively Estimated Part-Based Attention Map for Pointly Supervised Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/MingXiangL/AttentionShift?style=flat)](https://github.com/MingXiangL/AttentionShift) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liao_AttentionShift_Iteratively_Estimated_Part-Based_Attention_Map_for_Pointly_Supervised_Instance_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| MDQE: Mining Discriminative Query Embeddings To Segment Occluded Instances on Challenging Videos | [![GitHub](https://img.shields.io/github/stars/MinghanLi/MDQE_CVPR2023?style=flat)](https://github.com/MinghanLi/MDQE_CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_MDQE_Mining_Discriminative_Query_Embeddings_To_Segment_Occluded_Instances_on_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14395-b31b1b.svg)](http://arxiv.org/abs/2303.14395) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cK1SvHJgYYc) | 
| Look Before You Match: Instance Understanding Matters in Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/suhwan-cho/awesome-video-object-segmentation?style=flat)](https://github.com/suhwan-cho/awesome-video-object-segmentation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_Look_Before_You_Match_Instance_Understanding_Matters_in_Video_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06826-b31b1b.svg)](http://arxiv.org/abs/2212.06826) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Sd7iS5Icf30) |
| SIM: Semantic-Aware Instance Mask Generation for Box-Supervised Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/lslrh/SIM?style=flat)](https://github.com/lslrh/SIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_SIM_Semantic-Aware_Instance_Mask_Generation_for_Box-Supervised_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08578-b31b1b.svg)](http://arxiv.org/abs/2303.08578) | :heavy_minus_sign: |
| EFEM: Equivariant Neural Field Expectation Maximization for 3D Object Segmentation Without Scene Supervision | [![GitHub](https://img.shields.io/github/stars/JiahuiLei/EFEM?style=flat)](https://github.com/JiahuiLei/EFEM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lei_EFEM_Equivariant_Neural_Field_Expectation_Maximization_for_3D_Object_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15440-b31b1b.svg)](http://arxiv.org/abs/2303.15440) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=chPX8_iUxEw) |
| Camouflaged Object Detection With Feature Decomposition and Edge Reconstruction | [![GitHub](https://img.shields.io/github/stars/ChunmingHe/FEDER?style=flat)](https://github.com/ChunmingHe/FEDER) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/He_Camouflaged_Object_Detection_With_Feature_Decomposition_and_Edge_Reconstruction_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| LOCATE: Localize and Transfer Object Parts for Weakly Supervised Affordance Grounding | [![GitHub](https://img.shields.io/github/stars/Reagan1311/LOCATE?style=flat)](https://github.com/Reagan1311/LOCATE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_LOCATE_Localize_and_Transfer_Object_Parts_for_Weakly_Supervised_Affordance_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09665-b31b1b.svg)](http://arxiv.org/abs/2303.09665) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RLHansdFxII) |
| OneFormer: One Transformer To Rule Universal Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://praeclarumjj3.github.io/oneformer/) <br /> [![GitHub](https://img.shields.io/github/stars/SHI-Labs/OneFormer?style=flat)](https://github.com/SHI-Labs/OneFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Jain_OneFormer_One_Transformer_To_Rule_Universal_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06220-b31b1b.svg)](http://arxiv.org/abs/2211.06220) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CIU3udcaoW4) |
| Mask-Free Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/SysCV/MaskFreeVIS?style=flat)](https://github.com/SysCV/MaskFreeVIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ke_Mask-Free_Video_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15904-b31b1b.svg)](http://arxiv.org/abs/2303.15904) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7P7PX3gd14I) |
| Less Is More: Reducing Task and Model Complexity for 3D Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/l1997i/lim3d?style=flat)](https://github.com/l1997i/lim3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Less_Is_More_Reducing_Task_and_Model_Complexity_for_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11203-b31b1b.svg)](http://arxiv.org/abs/2303.11203) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5f-waFfjsOY) |
| InstMove: Instance Motion for Object-Centric Video Segmentation | [![GitHub](https://img.shields.io/github/stars/wjf5203/VNext?style=flat)](https://github.com/wjf5203/VNext) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liu_InstMove_Instance_Motion_for_Object-Centric_Video_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08132-b31b1b.svg)](http://arxiv.org/abs/2303.08132) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GzH8hLteEIY) |
| The Devil Is in the Points: Weakly Semi-Supervised Instance Segmentation via Point-Guided Mask Representation | [![GitHub](https://img.shields.io/github/stars/clovaai/PointWSSIS?style=flat)](https://github.com/clovaai/PointWSSIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Kim_The_Devil_Is_in_the_Points_Weakly_Semi-Supervised_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15062-b31b1b.svg)](http://arxiv.org/abs/2303.15062) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iGlDjXFO6TY) |
| Edge-Aware Regional Message Passing Controller for Image Forgery Localization | [![GitHub](https://img.shields.io/github/stars/greatzh/Papers?style=flat)](https://github.com/greatzh/Papers) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Edge-Aware_Regional_Message_Passing_Controller_for_Image_Forgery_Localization_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2pDR-hOFcQw) |
| Interactive Segmentation As Gaussion Process Classification <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]()  | [![GitHub](https://img.shields.io/github/stars/zmhhmz/GPCIS_CVPR2023?style=flat)](https://github.com/zmhhmz/GPCIS_CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhou_Interactive_Segmentation_As_Gaussion_Process_Classification_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14578-b31b1b.svg)](https://arxiv.org/abs/2302.14578) |[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mapyH-WujhY) |
| Semantic-Promoted Debiasing and Background Disambiguation for Zero-Shot Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/heshuting555/D2Zero?style=flat)](https://github.com/heshuting555/D2Zero) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/He_Semantic-Promoted_Debiasing_and_Background_Disambiguation_for_Zero-Shot_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.13173-b31b1b.svg)](https://arxiv.org/abs/2305.13173) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-Wci6cJAyRE) |
| Adversarially Masking Synthetic To Mimic Real: Adaptive Noise Injection for Point Cloud Segmentation Adaptation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.guangrui.li/projects/ASM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Adversarially_Masking_Synthetic_To_Mimic_Real_Adaptive_Noise_Injection_for_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L0z2SOw2Yvg) |
| Generative Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/fudan-zvg/GSS?style=flat)](https://github.com/fudan-zvg/GSS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_Generative_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11316-b31b1b.svg)](http://arxiv.org/abs/2303.11316) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bw5z5RU91ps) |
| Modeling the Distributional Uncertainty for Salient Object Detection Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://npucvr.github.io/Distributional_uncer/) <br /> [![GitHub](https://img.shields.io/github/stars/txynwpu/Distributional_uncertainty_SOD?style=flat)](https://github.com/txynwpu/Distributional_uncertainty_SOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Tian_Modeling_the_Distributional_Uncertainty_for_Salient_Object_Detection_Models_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4S5tWc2uMKo) |
| Simultaneously Short- and Long-Term Temporal Modeling for Semi-Supervised Video Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lao_Simultaneously_Short-_and_Long-Term_Temporal_Modeling_for_Semi-Supervised_Video_Semantic_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OqkRQJoh4d0) |
| Out-of-Candidate Rectification for Weakly Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/sennnnn/Out-of-Candidate-Rectification?style=flat)](https://github.com/sennnnn/Out-of-Candidate-Rectification) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Cheng_Out-of-Candidate_Rectification_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12268-b31b1b.svg)](http://arxiv.org/abs/2211.12268) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JQajrSReXkU) |
| DynaMask: Dynamic Mask Selection for Instance Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_DynaMask_Dynamic_Mask_Selection_for_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07868-b31b1b.svg)](http://arxiv.org/abs/2303.07868) | :heavy_minus_sign: |
| MSeg3D: Multi-Modal 3D Semantic Segmentation for Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/jialeli1/lidarseg3d?style=flat)](https://github.com/jialeli1/lidarseg3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_MSeg3D_Multi-Modal_3D_Semantic_Segmentation_for_Autonomous_Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08600-b31b1b.svg)](http://arxiv.org/abs/2303.08600) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lRLxOfHrfmI) |
| Generalizable Local Feature Pre-Training for Deformable Shape Analysis <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]()  | [![GitHub](https://img.shields.io/github/stars/pvnieo/vader?style=flat)](https://github.com/pvnieo/vader) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Attaiki_Generalizable_Local_Feature_Pre-Training_for_Deformable_Shape_Analysis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15104-b31b1b.svg)](http://arxiv.org/abs/2303.15104) | :heavy_minus_sign: |
| Understanding and Improving Features Learned in Deep Functional Maps <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]()  | [![GitHub](https://img.shields.io/github/stars/pvnieo/clover?style=flat)](https://github.com/pvnieo/clover) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Attaiki_Understanding_and_Improving_Features_Learned_in_Deep_Functional_Maps_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16527-b31b1b.svg)](http://arxiv.org/abs/2303.16527) | :heavy_minus_sign: |
| G-MSM: Unsupervised Multi-Shape Matching With Graph-Based Affinity Priors | [![GitHub](https://img.shields.io/github/stars/marvin-eisenberger/gmsm-matching?style=flat)](https://github.com/marvin-eisenberger/gmsm-matching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Eisenberger_G-MSM_Unsupervised_Multi-Shape_Matching_With_Graph-Based_Affinity_Priors_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02910-b31b1b.svg)](https://arxiv.org/abs/2212.02910) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vEE9gQ6RFoU) |
| Continual Semantic Segmentation With Automatic Memory Sample Selection |  :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhu_Continual_Semantic_Segmentation_With_Automatic_Memory_Sample_Selection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05015-b31b1b.svg)](http://arxiv.org/abs/2304.05015) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Bcrh9_76PTY) |
| FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation | [![GitHub](https://img.shields.io/github/stars/bytedance/FreeSeg?style=flat)](https://github.com/bytedance/FreeSeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Qin_FreeSeg_Unified_Universal_and_Open-Vocabulary_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17225-b31b1b.svg)](http://arxiv.org/abs/2303.17225) | :heavy_minus_sign: |
| Object Discovery From Motion-Guided Tokens | [![GitHub](https://img.shields.io/github/stars/zpbao/MoTok?style=flat)](https://github.com/zpbao/MoTok/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Bao_Object_Discovery_From_Motion-Guided_Tokens_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15555-b31b1b.svg)](http://arxiv.org/abs/2303.15555) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VgTrLMQIdgg) |
| Efficient Mask Correction for Click-Based Interactive Image Segmentation | [![GitHub](https://img.shields.io/github/stars/feiaxyt/EMC-Click?style=flat)](https://github.com/feiaxyt/EMC-Click) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Du_Efficient_Mask_Correction_for_Click-Based_Interactive_Image_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Balancing Logit Variation for Long-Tailed Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/grantword8/BLV?style=flat)](https://github.com/grantword8/BLV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_Balancing_Logit_Variation_for_Long-Tailed_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.02061-b31b1b.svg)](https://arxiv.org/abs/2306.02061) | :heavy_minus_sign: |
| Fuzzy Positive Learning for Semi-Supervised Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Qiao_Fuzzy_Positive_Learning_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.08519-b31b1b.svg)](http://arxiv.org/abs/2210.08519) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PVZRs1E2pWI) |
| Learning Open-Vocabulary Semantic Segmentation Models From Natural Language Supervision |  |  |  |
| Improving Graph Representation for Point Cloud Segmentation via Attentive Filtering |  |  |  |
| BUOL: A Bottom-Up Framework with Occupancy-Aware Lifting for Panoptic 3D Scene Reconstruction from a Single Image |  |  |  |
| ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation |  |  |  |
| CCuantuMM: Cycle-Consistent Quantum-Hybrid Matching of Multiple Shapes |  |  |  |
| Hierarchical Dense Correlation Distillation for Few-Shot Segmentation |  |  |  |
| UniDAformer: Unified Domain Adaptive Panoptic Segmentation Transformer via Hierarchical Mask Calibration |  |  |  |
| FedSeg: Class-Heterogeneous Federated Learning for Semantic Segmentation |  |  |  |
| Understanding Imbalanced Semantic Segmentation through Neural Collapse |  |  |  |
| Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic Segmentation |  |  |  |
| PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models |  |  |  |
| PartDistillation: Learning Parts from Instance Segmentation |  |  |  |
| Sketch2Saliency: Learning to Detect Salient Objects from Human Drawings |  |  |  |
| FastInst: A Simple Query-based Model for Real-Time Instance Segmentation |  |  |  |
| SemiCVT: Semi-Supervised Convolutional Vision Transformer for Semantic Segmentation |  |  |  |
| Semantic Human Parsing via Scalable Semantic Transfer over Multiple Label Domains |  |  |  |
| Open-Set Semantic Segmentation for Point Clouds via Adversarial Prototype Framework |  |  |  |
| Hunting Sparsity: Density-guided Contrastive Learning for Semi-Supervised Semantic Segmentation |  |  |  |
| A Generalized Framework for Video Instance Segmentation |  |  |  |
| SimpSON: Simplifying Photo Cleanup with Single-Click Distracting Object Segmentation Network |  |  |  |
| Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud Sequence Representation Learning |  |  |  |
| Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching |  |  |  |
| Ultrahigh Resolution Image/Video Matting with Spatio-Temporal Sparsity |  |  |  |
| Style Projected Clustering for Domain Generalized Semantic Segmentation |  |  |  |
| MarS3D: A Plug-and-Play Motion-Aware Model for Semantic Segmentation on Multi-Scan 3D Point Clouds |  |  |  |
| Compositor: Bottom-Up Clustering and Compositing for Robust Part and Object Segmentation |  |  |  |
| Dynamic Focus-Aware Positional Queries for Semantic Segmentation |  |  |  |
| HGFormer: Hierarchical Grouping Transformer for Domain Generalized Semantic Segmentation |  |  |  |
| Marching-Primitives: Shape Abstraction from Signed Distance Function |  |  |  |
| Multimodal Industrial Anomaly Detection via Hybrid Fusion |  |  |  |
| CLIP is also an Efficient Segmenter: A Text-Driven Approach for Weakly Supervised Semantic Segmentation |  |  |  |
| Weakly Supervised Semantic Segmentation via Adversarial Learning of Classifier and Reconstructor |  |  |  |
| Conjugate Product Graphs for Globally Optimal 2D-3D Shape Matching |  |  |  |
| Interactive Segmentation of Radiance Fields |  |  |  |
| Boundary-enhanced Co-Training for Weakly Supervised Semantic Segmentation |  |  |  |
| Learning Multi-Modal Class-Specific Tokens for Weakly Supervised Dense Object Localization |  |  |  |
| Quantum Multi-Model Fitting |  |  |  |
| Two-Shot Video Object Segmentation |  |  |  |
| End-to-End Video Matting with Trimap Propagation |  |  |  |
| ISBNet: A 3D Point Cloud Instance Segmentation Network with Instance-Aware Sampling and Box-Aware Dynamic Convolution |  |  |  |
| On Calibrating Semantic Segmentation Models: Analyses and an Algorithm |  |  |  |
| Explicit Visual Prompting for Low-Level Structure Segmentations |  |  |  |
| Neural Intrinsic Embedding for Non-rigid Point Cloud Matching |  |  |  |
| Incrementer: Transformer for Class-Incremental Semantic Segmentation with Knowledge Distillation Focusing on Old Class |  |  |  |
| Camouflaged Instance Segmentation via Explicit De-Camouflaging |  |  |  |
| Leveraging Hidden Positives for Unsupervised Semantic Segmentation |  |  |  |
| Rethinking the Correlation in Few-Shot Segmentation: A Buoys View |  |  |  |
| Sparsely Annotated Semantic Segmentation with Adaptive Gaussian Mixtures |  |  |  |
| Mask-guided Matting in the Wild |  |  |  |
| Visual Dependency Transformers: Dependency Tree Emerges from Reversed Attention |  |  |  |
| Conflict-based Cross-View Consistency for Semi-Supervised Semantic Segmentation |  |  |  |
| Augmentation Matters: A Simple-yet-Effective Approach to Semi-Supervised Semantic Segmentation |  |  |  |
| Attention-based Point Cloud Edge Sampling |  |  |  |
| DA Wand: Distortion-Aware Selection using Neural Mesh Parameterization |  |  |  |
| Extracting Class Activation Maps from Non-Discriminative Features as well |  |  |  |
| Focused and Collaborative Feedback Integration for Interactive Image Segmentation |  |  |  |
| Boosting Low-Data Instance Segmentation by Unsupervised Pre-Training with Saliency Prompt |  |  |  |
| Unsupervised 3D Shape Reconstruction by Part Retrieval and Assembly |  |  |  |
| MobileVOS: Real-Time Video Object Segmentation Contrastive Learning meets Knowledge Distillation |  |  |  |
| Transformer Scale Gate for Semantic Segmentation |  |  |  |
| PIDNet: A Real-Time Semantic Segmentation Network Inspired by PID Controllers |  |  |  |
| Side Adapter Network for Open-Vocabulary Semantic Segmentation |  |  |  |
| Test Time Adaptation with Regularized Loss for Weakly Supervised Salient Object Detection |  |  |  |
| Feature Shrinkage Pyramid for Camouflaged Object Detection with Transformers |  |  |  |
| Reliability in Semantic Segmentation: Are We on the Right Track? |  |  |  |
| Beyond mAP: Towards Better Evaluation of Instance Segmentation |  |  |  |
| Heat Diffusion based Multi-Scale and Geometric Structure-Aware Transformer for Mesh Segmentation |  |  |  |
| Tree Instance Segmentation with Temporal Contour Graph |  |  |  |
| Exemplar-FreeSOLO: Enhancing Unsupervised Instance Segmentation with Exemplars |  |  |  |
| Omnimatte3D: Associating Objects and their Effects in Unconstrained Monocular Video |  |  |  |
| Learning Orthogonal Prototypes for Generalized Few-Shot Semantic Segmentation |  |  |  |
| Instance-Specific and Model-Adaptive Supervision for Semi-Supervised Semantic Segmentation |  |  |  |
| Improving Robustness of Semantic Segmentation to Motion-Blur using Class-Centric Augmentation |  |  |  |
| IFSeg: Image-Free Semantic Segmentation via Vision-Language Model |  |  |  |
| CLIP-S<sup>4</sup>: Language-guided Self-Supervised Semantic Segmentation |  |  |  |
| Pruning Parameterization with Bi-Level Optimization for Efficient Semantic Segmentation on the Edge |  |  |  |
