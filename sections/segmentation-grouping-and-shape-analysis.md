# CVPR-2023-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/low-level-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/CVPR-2023-Papers/blob/main/sections/deep-learning-architectures-and-techniques.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Segmentation, Grouping and Shape Analysis

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Efficient Semantic Segmentation by Altering Resolutions for Compressed Videos | [![GitHub](https://img.shields.io/github/stars/THU-LYJ-Lab/AR-Seg?style=flat)](https://github.com/THU-LYJ-Lab/AR-Seg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Hu_Efficient_Semantic_Segmentation_by_Altering_Resolutions_for_Compressed_Videos_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07224-b31b1b.svg)](http://arxiv.org/abs/2303.07224) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WN9ok0xd0po) |
| Vision Transformers Are Good Mask Auto-Labelers | [![GitHub](https://img.shields.io/github/stars/NVlabs/mask-auto-labeler?style=flat)](https://github.com/NVlabs/mask-auto-labeler) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lan_Vision_Transformers_Are_Good_Mask_Auto-Labelers_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.03992-b31b1b.svg)](http://arxiv.org/abs/2301.03992) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=n9cmRYzKNVc) |
| Visual Recognition by Request | [![GitHub](https://img.shields.io/github/stars/chufengt/Visual-Recognition-by-Request?style=flat)](https://github.com/chufengt/Visual-Recognition-by-Request) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Tang_Visual_Recognition_by_Request_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2207.14227-b31b1b.svg)](http://arxiv.org/abs/2207.14227) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0wuVwYPcSQg) |
| Ultra-High Resolution Segmentation With Ultra-Rich Context: A Novel Benchmark | [![GitHub](https://img.shields.io/github/stars/jankyee/URUR?style=flat)](https://github.com/jankyee/URUR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ji_Ultra-High_Resolution_Segmentation_With_Ultra-Rich_Context_A_Novel_Benchmark_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10899-b31b1b.svg)](http://arxiv.org/abs/2305.10899) | :heavy_minus_sign: |
| AttentionShift: Iteratively Estimated Part-Based Attention Map for Pointly Supervised Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/MingXiangL/AttentionShift?style=flat)](https://github.com/MingXiangL/AttentionShift) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liao_AttentionShift_Iteratively_Estimated_Part-Based_Attention_Map_for_Pointly_Supervised_Instance_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| MDQE: Mining Discriminative Query Embeddings To Segment Occluded Instances on Challenging Videos | [![GitHub](https://img.shields.io/github/stars/MinghanLi/MDQE_CVPR2023?style=flat)](https://github.com/MinghanLi/MDQE_CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_MDQE_Mining_Discriminative_Query_Embeddings_To_Segment_Occluded_Instances_on_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14395-b31b1b.svg)](http://arxiv.org/abs/2303.14395) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cK1SvHJgYYc) | 
| Look Before You Match: Instance Understanding Matters in Video Object Segmentation | [![GitHub](https://img.shields.io/github/stars/suhwan-cho/awesome-video-object-segmentation?style=flat)](https://github.com/suhwan-cho/awesome-video-object-segmentation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_Look_Before_You_Match_Instance_Understanding_Matters_in_Video_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06826-b31b1b.svg)](http://arxiv.org/abs/2212.06826) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Sd7iS5Icf30) |
| SIM: Semantic-Aware Instance Mask Generation for Box-Supervised Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/lslrh/SIM?style=flat)](https://github.com/lslrh/SIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_SIM_Semantic-Aware_Instance_Mask_Generation_for_Box-Supervised_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08578-b31b1b.svg)](http://arxiv.org/abs/2303.08578) | :heavy_minus_sign: |
| EFEM: Equivariant Neural Field Expectation Maximization for 3D Object Segmentation Without Scene Supervision | [![GitHub](https://img.shields.io/github/stars/JiahuiLei/EFEM?style=flat)](https://github.com/JiahuiLei/EFEM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lei_EFEM_Equivariant_Neural_Field_Expectation_Maximization_for_3D_Object_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15440-b31b1b.svg)](http://arxiv.org/abs/2303.15440) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=chPX8_iUxEw) |
| Camouflaged Object Detection With Feature Decomposition and Edge Reconstruction | [![GitHub](https://img.shields.io/github/stars/ChunmingHe/FEDER?style=flat)](https://github.com/ChunmingHe/FEDER) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/He_Camouflaged_Object_Detection_With_Feature_Decomposition_and_Edge_Reconstruction_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| LOCATE: Localize and Transfer Object Parts for Weakly Supervised Affordance Grounding | [![GitHub](https://img.shields.io/github/stars/Reagan1311/LOCATE?style=flat)](https://github.com/Reagan1311/LOCATE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_LOCATE_Localize_and_Transfer_Object_Parts_for_Weakly_Supervised_Affordance_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09665-b31b1b.svg)](http://arxiv.org/abs/2303.09665) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RLHansdFxII) |
| OneFormer: One Transformer To Rule Universal Image Segmentation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://praeclarumjj3.github.io/oneformer/) <br /> [![GitHub](https://img.shields.io/github/stars/SHI-Labs/OneFormer?style=flat)](https://github.com/SHI-Labs/OneFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Jain_OneFormer_One_Transformer_To_Rule_Universal_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06220-b31b1b.svg)](http://arxiv.org/abs/2211.06220) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CIU3udcaoW4) |
| Mask-Free Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/SysCV/MaskFreeVIS?style=flat)](https://github.com/SysCV/MaskFreeVIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ke_Mask-Free_Video_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15904-b31b1b.svg)](http://arxiv.org/abs/2303.15904) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=7P7PX3gd14I) |
| Less Is More: Reducing Task and Model Complexity for 3D Point Cloud Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/l1997i/lim3d?style=flat)](https://github.com/l1997i/lim3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Less_Is_More_Reducing_Task_and_Model_Complexity_for_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11203-b31b1b.svg)](http://arxiv.org/abs/2303.11203) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5f-waFfjsOY) |
| InstMove: Instance Motion for Object-Centric Video Segmentation | [![GitHub](https://img.shields.io/github/stars/wjf5203/VNext?style=flat)](https://github.com/wjf5203/VNext) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liu_InstMove_Instance_Motion_for_Object-Centric_Video_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08132-b31b1b.svg)](http://arxiv.org/abs/2303.08132) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GzH8hLteEIY) |
| The Devil Is in the Points: Weakly Semi-Supervised Instance Segmentation via Point-Guided Mask Representation | [![GitHub](https://img.shields.io/github/stars/clovaai/PointWSSIS?style=flat)](https://github.com/clovaai/PointWSSIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Kim_The_Devil_Is_in_the_Points_Weakly_Semi-Supervised_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15062-b31b1b.svg)](http://arxiv.org/abs/2303.15062) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iGlDjXFO6TY) |
| Edge-Aware Regional Message Passing Controller for Image Forgery Localization | [![GitHub](https://img.shields.io/github/stars/greatzh/Papers?style=flat)](https://github.com/greatzh/Papers) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Edge-Aware_Regional_Message_Passing_Controller_for_Image_Forgery_Localization_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2pDR-hOFcQw) |
| Interactive Segmentation As Gaussion Process Classification <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]()  | [![GitHub](https://img.shields.io/github/stars/zmhhmz/GPCIS_CVPR2023?style=flat)](https://github.com/zmhhmz/GPCIS_CVPR2023) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhou_Interactive_Segmentation_As_Gaussion_Process_Classification_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.14578-b31b1b.svg)](https://arxiv.org/abs/2302.14578) |[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mapyH-WujhY) |
| Semantic-Promoted Debiasing and Background Disambiguation for Zero-Shot Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/heshuting555/D2Zero?style=flat)](https://github.com/heshuting555/D2Zero) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/He_Semantic-Promoted_Debiasing_and_Background_Disambiguation_for_Zero-Shot_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.13173-b31b1b.svg)](https://arxiv.org/abs/2305.13173) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-Wci6cJAyRE) |
| Adversarially Masking Synthetic To Mimic Real: Adaptive Noise Injection for Point Cloud Segmentation Adaptation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.guangrui.li/projects/ASM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Adversarially_Masking_Synthetic_To_Mimic_Real_Adaptive_Noise_Injection_for_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L0z2SOw2Yvg) |
| Generative Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/fudan-zvg/GSS?style=flat)](https://github.com/fudan-zvg/GSS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_Generative_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11316-b31b1b.svg)](http://arxiv.org/abs/2303.11316) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bw5z5RU91ps) |
| Modeling the Distributional Uncertainty for Salient Object Detection Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://npucvr.github.io/Distributional_uncer/) <br /> [![GitHub](https://img.shields.io/github/stars/txynwpu/Distributional_uncertainty_SOD?style=flat)](https://github.com/txynwpu/Distributional_uncertainty_SOD) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Tian_Modeling_the_Distributional_Uncertainty_for_Salient_Object_Detection_Models_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4S5tWc2uMKo) |
| Simultaneously Short- and Long-Term Temporal Modeling for Semi-Supervised Video Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Lao_Simultaneously_Short-_and_Long-Term_Temporal_Modeling_for_Semi-Supervised_Video_Semantic_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OqkRQJoh4d0) |
| Out-of-Candidate Rectification for Weakly Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/sennnnn/Out-of-Candidate-Rectification?style=flat)](https://github.com/sennnnn/Out-of-Candidate-Rectification) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Cheng_Out-of-Candidate_Rectification_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.12268-b31b1b.svg)](http://arxiv.org/abs/2211.12268) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JQajrSReXkU) |
| DynaMask: Dynamic Mask Selection for Instance Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_DynaMask_Dynamic_Mask_Selection_for_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.07868-b31b1b.svg)](http://arxiv.org/abs/2303.07868) | :heavy_minus_sign: |
| MSeg3D: Multi-Modal 3D Semantic Segmentation for Autonomous Driving | [![GitHub](https://img.shields.io/github/stars/jialeli1/lidarseg3d?style=flat)](https://github.com/jialeli1/lidarseg3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_MSeg3D_Multi-Modal_3D_Semantic_Segmentation_for_Autonomous_Driving_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08600-b31b1b.svg)](http://arxiv.org/abs/2303.08600) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lRLxOfHrfmI) |
| Generalizable Local Feature Pre-Training for Deformable Shape Analysis <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]()  | [![GitHub](https://img.shields.io/github/stars/pvnieo/vader?style=flat)](https://github.com/pvnieo/vader) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Attaiki_Generalizable_Local_Feature_Pre-Training_for_Deformable_Shape_Analysis_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15104-b31b1b.svg)](http://arxiv.org/abs/2303.15104) | :heavy_minus_sign: |
| Understanding and Improving Features Learned in Deep Functional Maps <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]()  | [![GitHub](https://img.shields.io/github/stars/pvnieo/clover?style=flat)](https://github.com/pvnieo/clover) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Attaiki_Understanding_and_Improving_Features_Learned_in_Deep_Functional_Maps_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16527-b31b1b.svg)](http://arxiv.org/abs/2303.16527) | :heavy_minus_sign: |
| G-MSM: Unsupervised Multi-Shape Matching With Graph-Based Affinity Priors | [![GitHub](https://img.shields.io/github/stars/marvin-eisenberger/gmsm-matching?style=flat)](https://github.com/marvin-eisenberger/gmsm-matching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Eisenberger_G-MSM_Unsupervised_Multi-Shape_Matching_With_Graph-Based_Affinity_Priors_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02910-b31b1b.svg)](https://arxiv.org/abs/2212.02910) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vEE9gQ6RFoU) |
| Continual Semantic Segmentation With Automatic Memory Sample Selection |  :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhu_Continual_Semantic_Segmentation_With_Automatic_Memory_Sample_Selection_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.05015-b31b1b.svg)](http://arxiv.org/abs/2304.05015) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Bcrh9_76PTY) |
| FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation | [![GitHub](https://img.shields.io/github/stars/bytedance/FreeSeg?style=flat)](https://github.com/bytedance/FreeSeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Qin_FreeSeg_Unified_Universal_and_Open-Vocabulary_Image_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17225-b31b1b.svg)](http://arxiv.org/abs/2303.17225) | :heavy_minus_sign: |
| Object Discovery From Motion-Guided Tokens | [![GitHub](https://img.shields.io/github/stars/zpbao/MoTok?style=flat)](https://github.com/zpbao/MoTok/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Bao_Object_Discovery_From_Motion-Guided_Tokens_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.15555-b31b1b.svg)](http://arxiv.org/abs/2303.15555) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VgTrLMQIdgg) |
| Efficient Mask Correction for Click-Based Interactive Image Segmentation | [![GitHub](https://img.shields.io/github/stars/feiaxyt/EMC-Click?style=flat)](https://github.com/feiaxyt/EMC-Click) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Du_Efficient_Mask_Correction_for_Click-Based_Interactive_Image_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Balancing Logit Variation for Long-Tailed Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/grantword8/BLV?style=flat)](https://github.com/grantword8/BLV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_Balancing_Logit_Variation_for_Long-Tailed_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.02061-b31b1b.svg)](https://arxiv.org/abs/2306.02061) | :heavy_minus_sign: |
| Fuzzy Positive Learning for Semi-Supervised Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Qiao_Fuzzy_Positive_Learning_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.08519-b31b1b.svg)](http://arxiv.org/abs/2210.08519) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PVZRs1E2pWI) |
| Learning Open-Vocabulary Semantic Segmentation Models From Natural Language Supervision | [![GitHub](https://img.shields.io/github/stars/Jazzcharles/OVSegmentor?style=flat)](https://github.com/Jazzcharles/OVSegmentor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Xu_Learning_Open-Vocabulary_Semantic_Segmentation_Models_From_Natural_Language_Supervision_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.09121-b31b1b.svg)](http://arxiv.org/abs/2301.09121)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=j4FSgpEP4XM) |
| Improving Graph Representation for Point Cloud Segmentation via Attentive Filtering | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhang_Improving_Graph_Representation_for_Point_Cloud_Segmentation_via_Attentive_Filtering_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| BUOL: A Bottom-Up Framework With Occupancy-Aware Lifting for Panoptic 3D Scene Reconstruction From a Single Image | [![GitHub](https://img.shields.io/github/stars/chtsy/buol?style=flat)](https://github.com/chtsy/buol) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Chu_BUOL_A_Bottom-Up_Framework_With_Occupancy-Aware_Lifting_for_Panoptic_3D_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.00965-b31b1b.svg)](http://arxiv.org/abs/2306.00965)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pOZq5YbtBww) |
| ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]() | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://lkhl.github.io/ACSeg/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_ACSeg_Adaptive_Conceptualization_for_Unsupervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.05944-b31b1b.svg)](http://arxiv.org/abs/2210.05944)|:heavy_minus_sign: |
| CCuantuMM: Cycle-Consistent Quantum-Hybrid Matching of Multiple Shapes| [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://4dqv.mpi-inf.mpg.de/CCuantuMM/) <br /> [![GitHub](https://img.shields.io/github/stars/HarshilBhatia/CCuantuMM?style=flat)](https://github.com/HarshilBhatia/CCuantuMM/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Bhatia_CCuantuMM_Cycle-Consistent_Quantum-Hybrid_Matching_of_Multiple_Shapes_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.16202-b31b1b.svg)](https://arxiv.org/abs/2303.16202) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gwBhXkJ5W3k) |
| Hierarchical Dense Correlation Distillation for Few-Shot Segmentation <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]() | [![GitHub](https://img.shields.io/github/stars/Pbihao/HDMNet?style=flat)](https://github.com/Pbihao/HDMNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Peng_Hierarchical_Dense_Correlation_Distillation_for_Few-Shot_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14652-b31b1b.svg)](http://arxiv.org/abs/2303.14652)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nFYTxfngUY0) |
| UniDAformer: Unified Domain Adaptive Panoptic Segmentation Transformer via Hierarchical Mask Calibration | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhang_UniDAformer_Unified_Domain_Adaptive_Panoptic_Segmentation_Transformer_via_Hierarchical_Mask_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.15083-b31b1b.svg)](http://arxiv.org/abs/2206.15083)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1k3bSwyaPEw) |
| FedSeg: Class-Heterogeneous Federated Learning for Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Miao_FedSeg_Class-Heterogeneous_Federated_Learning_for_Semantic_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=v834xUST26c) |
| Understanding Imbalanced Semantic Segmentation Through Neural Collapse | [![GitHub](https://img.shields.io/github/stars/NeuralCollapseApplications/Semantic-Segmentation?style=flat)](https://github.com/NeuralCollapseApplications/Semantic-Segmentation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhong_Understanding_Imbalanced_Semantic_Segmentation_Through_Neural_Collapse_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.01100-b31b1b.svg)](http://arxiv.org/abs/2301.01100) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0ZMfyRY5zjE) |
| Revisiting Weak-to-Strong Consistency in Semi-Supervised Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/LiheYoung/UniMatch?style=flat)](https://github.com/LiheYoung/UniMatch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Yang_Revisiting_Weak-to-Strong_Consistency_in_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2208.09910-b31b1b.svg)](http://arxiv.org/abs/2208.09910) | :heavy_minus_sign: |
| PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://colin97.github.io/PartSLIP_page/) <br /> [![Google Drive](https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white)](https://drive.google.com/drive/u/3/folders/19j6PZfW8TDQ1ifHZwHIhn6X4BHjYRFCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liu_PartSLIP_Low-Shot_Part_Segmentation_for_3D_Point_Clouds_via_Pretrained_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.01558-b31b1b.svg)](http://arxiv.org/abs/2212.01558)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VGORtR2mJog) |
| PartDistillation: Learning Parts From Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/facebookresearch/PartDistillation?style=flat)](https://github.com/facebookresearch/PartDistillation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Cho_PartDistillation_Learning_Parts_From_Instance_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5T5Z0F1J8oY) |
| Sketch2Saliency: Learning To Detect Salient Objects From Human Drawings | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ayankumarbhunia.github.io/Sketch2Saliency/) <br /> [![GitHub](https://img.shields.io/github/stars/AyanKumarBhunia/Sketch2Saliency?style=flat)](https://github.com/AyanKumarBhunia/Sketch2Saliency) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Bhunia_Sketch2Saliency_Learning_To_Detect_Salient_Objects_From_Human_Drawings_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11502-b31b1b.svg)](http://arxiv.org/abs/2303.11502)| [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IsbE365ByYI) |
| FastInst: A Simple Query-Based Model for Real-Time Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/junjiehe96/FastInst?style=flat)](https://github.com/junjiehe96/FastInst) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/He_FastInst_A_Simple_Query-Based_Model_for_Real-Time_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.08594-b31b1b.svg)](http://arxiv.org/abs/2303.08594) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JxHuMMu6N50) |
| SemiCVT: Semi-Supervised Convolutional Vision Transformer for Semantic Segmentation | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Huang_SemiCVT_Semi-Supervised_Convolutional_Vision_Transformer_for_Semantic_Segmentation_CVPR_2023_paper.pdf) |:heavy_minus_sign: |
| Semantic Human Parsing via Scalable Semantic Transfer Over Multiple Label Domains | [![GitHub](https://img.shields.io/github/stars/yangjie-cv/SST?style=flat)](https://github.com/yangjie-cv/SST) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Semantic_Human_Parsing_via_Scalable_Semantic_Transfer_Over_Multiple_Label_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.04140-b31b1b.svg)](http://arxiv.org/abs/2304.04140) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PHRVCSAYEHU) |
| Open-Set Semantic Segmentation for Point Clouds via Adversarial Prototype Framework | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Li_Open-Set_Semantic_Segmentation_for_Point_Clouds_via_Adversarial_Prototype_Framework_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_wV90rUkfhU) |
| Hunting Sparsity: Density-Guided Contrastive Learning for Semi-Supervised Semantic Segmentation| [![GitHub](https://img.shields.io/github/stars/Gavinwxy/DGCL?style=flat)](https://github.com/Gavinwxy/DGCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Wang_Hunting_Sparsity_Density-Guided_Contrastive_Learning_for_Semi-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| A Generalized Framework for Video Instance Segmentation | [![GitHub](https://img.shields.io/github/stars/miranheo/GenVIS?style=flat)](https://github.com/miranheo/GenVIS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Heo_A_Generalized_Framework_for_Video_Instance_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.08834-b31b1b.svg)](http://arxiv.org/abs/2211.08834)|:heavy_minus_sign: |
| SimpSON: Simplifying Photo Cleanup With Single-Click Distracting Object Segmentation Network | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://simpson-cvpr23.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/hmchuong/SimpSON?style=flat)](https://github.com/hmchuong/SimpSON) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Huynh_SimpSON_Simplifying_Photo_Cleanup_With_Single-Click_Distracting_Object_Segmentation_Network_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.17624-b31b1b.svg)](https://arxiv.org/abs/2305.17624) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m4eIkwJUDfo) |
| Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud Sequence Representation Learning | [![GitHub](https://img.shields.io/github/stars/dongyh20/C2P?style=flat)](https://github.com/dongyh20/C2P) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Zhang_Complete-to-Partial_4D_Distillation_for_Self-Supervised_Point_Cloud_Sequence_Representation_Learning_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.05330-b31b1b.svg)](http://arxiv.org/abs/2212.05330) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_4C7vmLN0nM) |
| Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching <br/> [![CVPR - Highlight](https://img.shields.io/badge/CVPR-Highlight-FFFF00)]() | [![GitHub](https://img.shields.io/github/stars/dongliangcao/Self-Supervised-Multimodal-Shape-Matching?style=flat)](https://github.com/dongliangcao/Self-Supervised-Multimodal-Shape-Matching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Cao_Self-Supervised_Learning_for_Multimodal_Non-Rigid_3D_Shape_Matching_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10971-b31b1b.svg)](http://arxiv.org/abs/2303.10971) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cQX1OOne0bk) |
| Ultrahigh Resolution Image/Video Matting With Spatio-Temporal Sparsity | [![GitHub](https://img.shields.io/github/stars/nowsyn/sparsemat?style=flat)](https://github.com/nowsyn/sparsemat) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Sun_Ultrahigh_Resolution_ImageVideo_Matting_With_Spatio-Temporal_Sparsity_CVPR_2023_paper.pdf) | :heavy_minus_sign: |
| Style Projected Clustering for Domain Generalized Semantic Segmentation| [![Gitee](https://gitee.com/mindspore/models/badge/star.svg?theme=dark)](https://gitee.com/mindspore/models/tree/master/research/cv/SPC-Net) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Huang_Style_Projected_Clustering_for_Domain_Generalized_Semantic_Segmentation_CVPR_2023_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FVFvc8TH5eI) |
| MarS3D: A Plug-and-Play Motion-Aware Model for Semantic Segmentation on Multi-Scan 3D Point Clouds| [![GitHub](https://img.shields.io/github/stars/CVMI-Lab/MarS3D?style=flat)](https://github.com/CVMI-Lab/MarS3D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Liu_MarS3D_A_Plug-and-Play_Motion-Aware_Model_for_Semantic_Segmentation_on_Multi-Scan_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.09316-b31b1b.svg)](https://arxiv.org/abs/2307.09316) |  [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PPPyZkwvsvs) | 
| Compositor: Bottom-Up Clustering and Compositing for Robust Part and Object Segmentation | [![GitHub](https://img.shields.io/github/stars/TACJu/Compositor?style=flat)](https://github.com/TACJu/Compositor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/He_Compositor_Bottom-Up_Clustering_and_Compositing_for_Robust_Part_and_Object_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07404-b31b1b.svg)](https://arxiv.org/abs/2306.07404) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SQlrky70y9A) |
| Dynamic Focus-Aware Positional Queries for Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/ziplab/FASeg?style=flat)](https://github.com/ziplab/FASeg) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/He_Dynamic_Focus-Aware_Positional_Queries_for_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.01244-b31b1b.svg)](http://arxiv.org/abs/2204.01244) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LAut7f4mxsA) |
| HGFormer: Hierarchical Grouping Transformer for Domain Generalized Semantic Segmentation | [![GitHub](https://img.shields.io/github/stars/dingjiansw101/HGFormer?style=flat)](https://github.com/dingjiansw101/HGFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com//content/CVPR2023/papers/Ding_HGFormer_Hierarchical_Grouping_Transformer_for_Domain_Generalized_Semantic_Segmentation_CVPR_2023_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.13031-b31b1b.svg)](http://arxiv.org/abs/2305.13031) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tKMTUZAH0q0) |
| Marching-Primitives: Shape Abstraction from Signed Distance Function |  |  |  |
| Multimodal Industrial Anomaly Detection via Hybrid Fusion |  |  |  |
| CLIP is also an Efficient Segmenter: A Text-Driven Approach for Weakly Supervised Semantic Segmentation |  |  |  |
| Weakly Supervised Semantic Segmentation via Adversarial Learning of Classifier and Reconstructor |  |  |  |
| Conjugate Product Graphs for Globally Optimal 2D-3D Shape Matching |  |  |  |
| Interactive Segmentation of Radiance Fields |  |  |  |
| Boundary-enhanced Co-Training for Weakly Supervised Semantic Segmentation |  |  |  |
| Learning Multi-Modal Class-Specific Tokens for Weakly Supervised Dense Object Localization |  |  |  |
| Quantum Multi-Model Fitting |  |  |  |
| Two-Shot Video Object Segmentation |  |  |  |
| End-to-End Video Matting with Trimap Propagation |  |  |  |
| ISBNet: A 3D Point Cloud Instance Segmentation Network with Instance-Aware Sampling and Box-Aware Dynamic Convolution |  |  |  |
| On Calibrating Semantic Segmentation Models: Analyses and an Algorithm |  |  |  |
| Explicit Visual Prompting for Low-Level Structure Segmentations |  |  |  |
| Neural Intrinsic Embedding for Non-rigid Point Cloud Matching |  |  |  |
| Incrementer: Transformer for Class-Incremental Semantic Segmentation with Knowledge Distillation Focusing on Old Class |  |  |  |
| Camouflaged Instance Segmentation via Explicit De-Camouflaging |  |  |  |
| Leveraging Hidden Positives for Unsupervised Semantic Segmentation |  |  |  |
| Rethinking the Correlation in Few-Shot Segmentation: A Buoys View |  |  |  |
| Sparsely Annotated Semantic Segmentation with Adaptive Gaussian Mixtures |  |  |  |
| Mask-guided Matting in the Wild |  |  |  |
| Visual Dependency Transformers: Dependency Tree Emerges from Reversed Attention |  |  |  |
| Conflict-based Cross-View Consistency for Semi-Supervised Semantic Segmentation |  |  |  |
| Augmentation Matters: A Simple-yet-Effective Approach to Semi-Supervised Semantic Segmentation |  |  |  |
| Attention-based Point Cloud Edge Sampling |  |  |  |
| DA Wand: Distortion-Aware Selection using Neural Mesh Parameterization |  |  |  |
| Extracting Class Activation Maps from Non-Discriminative Features as well |  |  |  |
| Focused and Collaborative Feedback Integration for Interactive Image Segmentation |  |  |  |
| Boosting Low-Data Instance Segmentation by Unsupervised Pre-Training with Saliency Prompt |  |  |  |
| Unsupervised 3D Shape Reconstruction by Part Retrieval and Assembly |  |  |  |
| MobileVOS: Real-Time Video Object Segmentation Contrastive Learning meets Knowledge Distillation |  |  |  |
| Transformer Scale Gate for Semantic Segmentation |  |  |  |
| PIDNet: A Real-Time Semantic Segmentation Network Inspired by PID Controllers |  |  |  |
| Side Adapter Network for Open-Vocabulary Semantic Segmentation |  |  |  |
| Test Time Adaptation with Regularized Loss for Weakly Supervised Salient Object Detection |  |  |  |
| Feature Shrinkage Pyramid for Camouflaged Object Detection with Transformers |  |  |  |
| Reliability in Semantic Segmentation: Are We on the Right Track? |  |  |  |
| Beyond mAP: Towards Better Evaluation of Instance Segmentation |  |  |  |
| Heat Diffusion based Multi-Scale and Geometric Structure-Aware Transformer for Mesh Segmentation |  |  |  |
| Tree Instance Segmentation with Temporal Contour Graph |  |  |  |
| Exemplar-FreeSOLO: Enhancing Unsupervised Instance Segmentation with Exemplars |  |  |  |
| Omnimatte3D: Associating Objects and their Effects in Unconstrained Monocular Video |  |  |  |
| Learning Orthogonal Prototypes for Generalized Few-Shot Semantic Segmentation |  |  |  |
| Instance-Specific and Model-Adaptive Supervision for Semi-Supervised Semantic Segmentation |  |  |  |
| Improving Robustness of Semantic Segmentation to Motion-Blur using Class-Centric Augmentation |  |  |  |
| IFSeg: Image-Free Semantic Segmentation via Vision-Language Model |  |  |  |
| CLIP-S<sup>4</sup>: Language-guided Self-Supervised Semantic Segmentation |  |  |  |
| Pruning Parameterization with Bi-Level Optimization for Efficient Semantic Segmentation on the Edge |  |  |  |
